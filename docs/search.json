[
  {
    "objectID": "primero/recursos/02-lectura.html",
    "href": "primero/recursos/02-lectura.html",
    "title": "Lectura de un archivo de datos de texto plano",
    "section": "",
    "text": "Anteriormente dijimos que para leer o importar datos de un archivo de datos con texto plano separado por comas vamos a utilizar alguna de las funciones del paquete readr del tidyverse.\nPero para saber cual es la función adecuada y para adaptar sus argumentos correctamente vamos a necesitar conocer la configuración del archivo de datos.\nEn este paso a paso, mostraremos las etapas a ejecutar ante una situación de lectura.\nEn primer lugar, es deseable que conozcamos previamente los archivos con los cuales trabajamos, o bien si son archivos de datos que se reciben de alguna fuente externa vengan acompañados de un diccionario de datos con especificaciones técnicas del propio archivo como de sus variables.\nUn ejemplo de esto es el detalle técnico de la tabla de datos que figura en el documento usuario de la Encuesta Nacional de Factores de Riesgo que vemos debajo:\n\n\n\n\n\n\n\n\n\nEsta información nos dice que el archivo es de texto plano, utiliza como delimitador de columna a la barra vertical, que la primera línea lleva los nombres de las variables y que la codificación (encoding) de los caracteres tiene el estándar UTF-8.\nEn función de estos datos podríamos componer nuestra lectura de la siguiente forma:\n\nenfr &lt;- read_delim(file = \"ENFR2013_base_usuario.txt\", \n                   delim = \"|\", \n                   locale = locale(encoding = \"UTF-8\"))\n\nAunque es el estándar predeterminado, completamos el argumento del encoding a propósito para mostrar como se vincula cada parte de la función con la información del archivo de datos.\nSi no llegasemos a disponer de esta información es muy posible que debamos investigar el archivo que deseamos importar para saber sus características.\nEn este documento utilizaremos el archivo def2022.csv con las defunciones del año 2022 producido por la DEIS."
  },
  {
    "objectID": "primero/recursos/02-lectura.html#introducción",
    "href": "primero/recursos/02-lectura.html#introducción",
    "title": "Lectura de un archivo de datos de texto plano",
    "section": "",
    "text": "Anteriormente dijimos que para leer o importar datos de un archivo de datos con texto plano separado por comas vamos a utilizar alguna de las funciones del paquete readr del tidyverse.\nPero para saber cual es la función adecuada y para adaptar sus argumentos correctamente vamos a necesitar conocer la configuración del archivo de datos.\nEn este paso a paso, mostraremos las etapas a ejecutar ante una situación de lectura.\nEn primer lugar, es deseable que conozcamos previamente los archivos con los cuales trabajamos, o bien si son archivos de datos que se reciben de alguna fuente externa vengan acompañados de un diccionario de datos con especificaciones técnicas del propio archivo como de sus variables.\nUn ejemplo de esto es el detalle técnico de la tabla de datos que figura en el documento usuario de la Encuesta Nacional de Factores de Riesgo que vemos debajo:\n\n\n\n\n\n\n\n\n\nEsta información nos dice que el archivo es de texto plano, utiliza como delimitador de columna a la barra vertical, que la primera línea lleva los nombres de las variables y que la codificación (encoding) de los caracteres tiene el estándar UTF-8.\nEn función de estos datos podríamos componer nuestra lectura de la siguiente forma:\n\nenfr &lt;- read_delim(file = \"ENFR2013_base_usuario.txt\", \n                   delim = \"|\", \n                   locale = locale(encoding = \"UTF-8\"))\n\nAunque es el estándar predeterminado, completamos el argumento del encoding a propósito para mostrar como se vincula cada parte de la función con la información del archivo de datos.\nSi no llegasemos a disponer de esta información es muy posible que debamos investigar el archivo que deseamos importar para saber sus características.\nEn este documento utilizaremos el archivo def2022.csv con las defunciones del año 2022 producido por la DEIS."
  },
  {
    "objectID": "primero/recursos/02-lectura.html#separador-o-delimitador-de-columnas",
    "href": "primero/recursos/02-lectura.html#separador-o-delimitador-de-columnas",
    "title": "Lectura de un archivo de datos de texto plano",
    "section": "Separador o delimitador de columnas",
    "text": "Separador o delimitador de columnas\nLa primera cosa que podemos hacer con un archivo de texto plano es abrirlo con un software tipo block de notas o con el mismo RStudio para saber cual es el caracter que utiliza como separador de columnas.\nCuando el archivo tiene extensión csv generalmente el separador puede ser coma o punto y coma. Pero recién vimos que la extensión puede ser txt y el separador, alguno de los caracteres habituales (espacio, tabulación, etc).\nDesde RStudio, cuando se pulsa el botón izquierdo del mouse sobre el archivo de datos que aparece en el panel Files, se abre una ventana emergente que nos ofrece la posibilidad de visualizarlo en el editor (“View File”). Si el archivo es muy pesado (mayor a 5 Mb) RStudio nos avisará que no lo puede hacer porque excede su capacidad, entonces deberemos hacerlo desde un programa similar al Block de Notas de Windows que trabaja con texto plano.\nVeríamos algo así:\n\n\n\n\n\n\n\n\n\nPodemos identificar claramente que el caracter que se repite como delimitador es la coma (,). Si hubiese datos numéricos con decimales, también es importante identificar cual es el separador de decimales (en los casos de delimitadores de columna con coma se utiliza el punto para los decimales).\nTambién se puede advertir que la primera línea corresponde a los nombres de las columnas (variables) de nuestra tabla de datos.\nCon esta información seleccionaremos como función de lectura a read_csv() que tiene estos valores de separadores como predeterminados."
  },
  {
    "objectID": "primero/recursos/02-lectura.html#encoding",
    "href": "primero/recursos/02-lectura.html#encoding",
    "title": "Lectura de un archivo de datos de texto plano",
    "section": "Encoding",
    "text": "Encoding\nPara conocer cual es la codificación del archivo podemos usar una función del paquete readr, llamada guess_encoding().\n\nlibrary(tidyverse)\n\nguess_encoding(\"datos/def2022.csv\")\n\n# A tibble: 1 × 2\n  encoding   confidence\n  &lt;chr&gt;           &lt;dbl&gt;\n1 ISO-8859-1       0.52\n\n\nEl resultado nos informa del estándar ISO-8859-1 con una confianza del 52 %. Existen muchos estandares como posibilidad en el mundo informático, aunque el predeterminado de RStudio es el UTF-8.\nA partir de tener esta información podemos configurar el argumento necesario para hacer una lectura correcta de los caracteres especiales que puede tener el archivo.\n\ndef2022 &lt;- read_csv(\"datos/def2022.csv\", \n                 locale = locale(encoding = \"ISO-8859-1\"))\n\nRows: 397115 Columns: 28\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): JURI, MEDSUS, CODMUER, FECDEF, FECNAC, DEPOC, PROVOC, DEPRES, PROV...\ndbl  (8): ANO, ATENMED, EDAD, UNIEDAD, SEXO, OCLOC, PAISRES, ASOCIAD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLa ejecución de la función nos confirma que se realizó usando:\n\nla coma como delimitador.\nque se importaron 397115 filas y 28 columnas.\ndetectó 20 variables de tipo character y 8 numéricas (double)\n\nVeamos 10 observaciones para verificar la lectura:\n\n\n# A tibble: 10 × 28\n   JURI    ANO ATENMED MEDSUS CODMUER FECDEF    FECNAC  EDAD UNIEDAD  SEXO OCLOC\n   &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 02     2022       1 1      J189    04/01/20… 03/05…    83       1     2     1\n 2 02     2022       1 1      I509    01/11/20… 02/05…    68       1     1     1\n 3 02     2022       1 1      G409    12/06/20… 22/09…     1       1     2     2\n 4 02     2022       1 2      J129    22/12/20… 31/10…    90       1     2     2\n 5 02     2022       1 1      K746    28/09/20… 26/02…    65       1     1     2\n 6 02     2022       1 1      C700    12/06/20… 25/02…    48       1     2     2\n 7 02     2022       1 2      I470    27/03/20… 09/09…    89       1     1     2\n 8 02     2022       1 2      F03X    05/02/20… 14/09…    97       1     2     2\n 9 02     2022       1 2      I470    30/01/20… 08/07…    71       1     2     1\n10 02     2022       1 1      J189    28/09/20… 21/09…    91       1     1     2\n# ℹ 17 more variables: DEPOC &lt;chr&gt;, PROVOC &lt;chr&gt;, DEPRES &lt;chr&gt;, PROVRES &lt;chr&gt;,\n#   PAISRES &lt;dbl&gt;, ASOCIAD &lt;dbl&gt;, FINSTRUC &lt;chr&gt;, FSITLABOR &lt;chr&gt;,\n#   MINSTRUC &lt;chr&gt;, MEDAD &lt;chr&gt;, MSITCONY &lt;chr&gt;, PINSTRUC &lt;chr&gt;,\n#   SITLABOR &lt;chr&gt;, PESONAC &lt;chr&gt;, PESOMOR &lt;chr&gt;, TIEMGEST &lt;chr&gt;,\n#   GRUPEDAD &lt;chr&gt;\n\n\nHacer coincidir el encoding del archivo con el definido en la lectura hace que los caracteres se importen adecuadamente y no tengamos inconvenientes con caracteres especiales como vocales acentuadas, eñes u otras situaciones."
  },
  {
    "objectID": "primero/clases/04-tipos.html#exploración-de-datos",
    "href": "primero/clases/04-tipos.html#exploración-de-datos",
    "title": "Gestión de tipos de datos",
    "section": "Exploración de datos",
    "text": "Exploración de datos\nEl primer paso en la exploración de un conjunto de datos es conocer su estructura y tamaño.\nEl tamaño está definido por la cantidad de observaciones (filas) y la cantidad de variables (columnas).\nLlamamos estructura a la forma en se organizan sus variables, sus tipos de datos y sus categorías/valores.\nVamos a utilizar un dataframe de ejemplo con variedad en sus tipos de datos. Para ver su estructura en R base tenemos la función str()\n\nstr(datos)\n\n'data.frame':   74 obs. of  7 variables:\n $ id     : int  1 2 3 4 5 6 7 8 9 10 ...\n $ sexo   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ edad   : num  76 68 50 49 51 68 70 64 60 57 ...\n $ peso   : num  71 71 79 71 87 75 80 83 69 73 ...\n $ talla  : num  167 164 164 164 168 ...\n $ trabaja: logi  FALSE FALSE FALSE TRUE TRUE FALSE ...\n $ fecha  : Date, format: \"2020-10-20\" \"2020-10-20\" ...\n\n\nNos informa que la tabla tiene 74 observaciones y 7 variables con su tipo de dato al lado.\nEn R base los tipos de datos son:\n\nint (integer): números enteros\nnum (numeric): números reales\nchr (character): caracteres (texto)\nlogi (logical): valores lógicos\nDate: fechas\nfct (factor): factores\n\nEn tidyverse, la función que reemplaza a str() es glimpse():\n\nglimpse(datos)\n\nRows: 74\nColumns: 7\n$ id      &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…\n$ sexo    &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", NA, \"F\", \"F\", \"M\", \"F\"…\n$ edad    &lt;dbl&gt; 76, 68, 50, 49, 51, 68, 70, 64, 60, 57, 83, 76, 27, 34, 17, 45…\n$ peso    &lt;dbl&gt; 71.0, 71.0, 79.0, 71.0, 87.0, 75.0, 80.0, 83.0, 69.0, 73.0, 60…\n$ talla   &lt;dbl&gt; 167.0, 164.0, 164.0, 164.0, 167.5, 170.0, 166.0, 160.0, 160.0,…\n$ trabaja &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, NA, TRUE, TRUE, TRUE, …\n$ fecha   &lt;date&gt; 2020-10-20, 2020-10-20, 2020-10-20, 2020-11-05, 2020-11-05, 2…\n\n\nParece idéntica pero tiene una ventaja cuando la tabla de datos tiene muchas variables. La lista de respuesta de str() se trunca y no nos deja visualizar la totalidad de columnas, cosa que si hace glimpse().\nPor otra parte vamos a encontrar distintas definiciones para los tipos de datos, del modo tidyverse:\n\nnum para a ser dbl (double): números reales\nlogi para a ser lgl (logical): valores lógicos\n\nY se incluyen un tipo nuevo:\n\ndttm (date-time): fechas y horas\n\nEsta exploración inicial de la estructura generalmente viene acompañada por el “diccionario de datos” (codebook) asociado a la tabla de datos, ya sea que esta tabla provenga de un proyecto de investigación propio (fuente primaria), producto de una fuente secundaria o de un sistema de vigilancia epidemiológica."
  },
  {
    "objectID": "primero/clases/04-tipos.html#comprobación-y-coerción-de-tipos-de-datos",
    "href": "primero/clases/04-tipos.html#comprobación-y-coerción-de-tipos-de-datos",
    "title": "Gestión de tipos de datos",
    "section": "Comprobación y coerción de tipos de datos",
    "text": "Comprobación y coerción de tipos de datos\nLa mayoría de las funciones producen un error cuando el tipo de datos que esperan no coincide con los que pasamos como argumentos. En esta situación seguiremos el siguiente camino:\n\nComprobar el tipo de datos utilizando las funciones is.*(), que nos responden con un valor lógico (TRUE si el tipo de dato coincide y FALSE si no lo hace). Si el tipo de dato coincide con el formato esperado por el argumento de la función, entonces podemos aplicarla, de lo contrario necesitaremos continuar:\nForzar el tipo de datos deseado coercionando con funciones de la familia as.*(), que fuerzan el tipo de datos, siempre y cuando esto devuelva valores correctos. Por ejemplo, no podremos obtener valores correctos si intento coercionar caracteres a tipos numéricos.\n\n\n# Ejmeplo coercionando la variable sexo de caracter a factor\n\nas.factor(datos$sexo) # llamamos a la variable con el formato &lt;dataframe&gt;$&lt;variable&gt;\n\n [1] M    M    M    M    M    M    M    M    &lt;NA&gt; F    F    M    F    F    F   \n[16] F    F    M    M    M    M    M    M    F    M    F    &lt;NA&gt; M    F    M   \n[31] F    F    M    F    F    F    M    M    M    M    M    F    M    F    M   \n[46] M    F    M    F    &lt;NA&gt; M    M    M    F    M    M    M    M    M    F   \n[61] F    M    F    F    M    M    F    F    F    M    M    M    M    M   \nLevels: F M\n\n# detecta que hay dos niveles o categorías posibles (F y M) \n\nis.factor(as.factor(datos$sexo))\n\n[1] TRUE\n\n# nos confirma que los datos se coercionaron a factor\n\n\nTransformar el tipo de dato a partir de aplicar funciones específicas incluidas en paquetes que gestionan datos especiales, como por ejemplo las fechas (el paquete lubridate del tidyverse, que conoceremos más adelante, se ocupa de esto)\n\nA continuación se muestra una lista con los tipos más importantes que se pueden comprobar o forzar a partir de funciones de R base:\n\n\n\nTipo\nComprobación\nCoerción\n\n\n\n\ncharacter\nis.character()\nas.character()\n\n\nnumeric\nis.numeric()\nas.numeric()\n\n\ninteger\nis.integer()\nas.integer()\n\n\ndouble\nis.double()\nas.double()\n\n\nfactor\nis.factor()\nas.factor()\n\n\nlogical\nis.logical()\nas.logical()\n\n\nNA\nis.na()\nas.na()"
  },
  {
    "objectID": "primero/clases/04-tipos.html#variables-de-tiempo",
    "href": "primero/clases/04-tipos.html#variables-de-tiempo",
    "title": "Gestión de tipos de datos",
    "section": "Variables de tiempo",
    "text": "Variables de tiempo\n\n\n\n\nArtwork por @allison_horst\n\n\n\nLos eventos epidemiológicos se presentan en algun momento del tiempo, por lo que las variables de tiempo son habituales componentes de las bases de datos con las que trabaja un epidemiólogo. Estas variables pueden presentarse en distintas unidades de medida, tales como horas, días, años, decadas, etc.\nA veces trabajar con datos tipo fecha y hora puede ser frustrante.Las fechas vienen en muchos formatos diferentes, que hace que reconocerlos y analizarlos sea un desafío.\nPrimero necesitamos que los datos sean reconocidos como formato fecha (Date) y luego debemos lidiar con operaciones específicas como extraer componentes de los horarios, como años, meses o segundos, o cambiar zonas horarias o hacer cálculos entres fechas.\nPara simplificar esta tarea tidyverse trae el paquete lubridate que proporciona herramientas para manipular variables fecha-hora.\nEspecíficamente, lubridate ayuda a los usuarios a:\n\nIdentificar y analizar los datos de fecha y hora.\nExtrer y modificar componentes de una fecha y hora, como años, meses, días, horas, minutos y segundos.\nRealizar cálculos precisos con fecha y hora.\nManejar zonas horarias y horario de verano.\n\nlubridate se instala y activa con tidyverse:\n\nLectura de fechas\nPodemos leer fechas en R usando la serie de funciones ymd() proporcionada por este paquete. Estas funciones analizan el contenido de cadenas de caracteres y las transforman a fechas.\nLas letras y, m y d corresponden al año, mes y día de una fecha. Para leer una fecha, seleccionamos el nombre de la función que coincide con el orden de los elementos contenidos en el objeto original. Por ejemplo, en la siguiente fecha el elemento mes viene primero, seguido por el día y luego el año, al estilo estadounidense. Entonces usaríamos la función mdy():\n\nmdy(\"01-24-2024\")\n\n[1] \"2024-01-24\"\n\n\nEl formato de salida siempre año-mes-día, es decir se organiza del elemento más grande que anida a los otros.\nSi en cambio tuviese la forma en que usamos las fechas nosotros, usaríamos dmy().\n\ndmy(\"24-01-2024\")\n\n[1] \"2024-01-24\"\n\n\nComo se observa el formato de los caracteres de entrada pueden utilizar distintos separadores, como guión medio (-), punto (.), barra inclinada (/), guión bajo (_) o incluso espacios.\nLa clase de los objetos convertidos es Date.\n\nx &lt;- dmy(\"24/01/2024\")\n\nclass(x)\n\n[1] \"Date\"\n\n\n\n\n\nOrden de los elementos\nFunción\n\n\n\n\naño, mes y día\nymd()\n\n\naño, día y mes\nydm()\n\n\nmes, día y año\nmdy()\n\n\ndía, mes y año\ndmy()\n\n\nhora y minuto\nhm()\n\n\nhora, minuto y segundo\nhms()\n\n\naño, mes, día, hora, minuto y segundo\nymd_hms()\n\n\n\nLas funciones que tienen componente de hora crean objetos POSIXct.\nCuando una función dmy() se aplica a un vector de fechas, lubridate supone que todas las fechas tienen el mismo orden y los mismos separadores.\n\n\nManipulando fechas\nCada estructura fecha-hora es una combinación de diferentes elementos, cada uno con su propio valor. Por ejemplo, la mayoría de las fechas incluyen un valor de año, un valor de mes, un valor de día, etc. Juntos estos elementos especifican el momento exacto al que se refiere la fecha y la hora.\nPodemos extraer fácilmente cada elemento de una fecha-hora con la función de acceso que tiene su nombre, como se muestra en la siguiente tabla.\n\n\n\nComponente de fecha\nFunción\n\n\n\n\nAño\nyear()\n\n\nMes\nmonth()\n\n\nSemana\nweek()\n\n\nDía del año\nyday()\n\n\nDía del mes\nmday()\n\n\nDía de la semana\nwday()\n\n\nHora\nhour()\n\n\nMinuto\nminute()\n\n\nSegundo\nsecond()\n\n\nZona horaria (huso horario)\ntz()\n\n\n\nPor ejemplo, si almacenamos la fecha y hora actual del sistema en un objeto:\n\nfecha &lt;- now()\n\nfecha\n\n[1] \"2024-09-13 13:32:13 -03\"\n\n\npodemos extraer cada uno de sus elementos.\nTengamos en cuenta que la función now(), perteneciente al mismo paquete lubridate, devolverá una fecha diferente cada vez que se ejecute.\n\nyear(fecha)\n\n[1] 2024\n\n\n\nmday(fecha)\n\n[1] 13\n\n\n\nhour(fecha)\n\n[1] 13\n\nminute(fecha)\n\n[1] 32\n\n\nPara los elementos de mes y día de la semana (wday), también podemos especificar si queremos extraer el valor numérico del elemento, una abreviatura del nombre del mes o día de la semana, o el nombre completo.\nPor ejemplo:\n\nmonth(fecha)\n\n[1] 9\n\n\n\nmonth(fecha, label = TRUE)\n\n[1] sep\n12 Levels: ene &lt; feb &lt; mar &lt; abr &lt; may &lt; jun &lt; jul &lt; ago &lt; sep &lt; ... &lt; dic\n\n\n\nmonth(fecha, label = TRUE, abbr = FALSE)\n\n[1] septiembre\n12 Levels: enero &lt; febrero &lt; marzo &lt; abril &lt; mayo &lt; junio &lt; ... &lt; diciembre\n\n\n\nwday(fecha, label = TRUE, abbr = FALSE)\n\n[1] viernes\n7 Levels: domingo &lt; lunes &lt; martes &lt; miércoles &lt; jueves &lt; ... &lt; sábado\n\n\nOtra buena noticia es que el paquete se adapta al formato regional del sistema operativo donde se encuentra funcionando, por lo que los nombres de los meses o los días de la semana, en este caso, figuran en español (si nuestro sistema operativo está instalado bajo ese idioma).\nPor otra parte, también podemos usar cualquiera de las funciones de acceso para establecer el valor de un elemento. Por ejemplo,\n\nfecha\n\n[1] \"2024-09-13 13:32:13 -03\"\n\nday(fecha) &lt;- 5\n\nfecha\n\n[1] \"2024-09-05 13:32:13 -03\"\n\n\ncambia nuestra fecha al quinto día del mes. También podemos configurar los elementos para más valores complicados, por ejemplo:\n\nfechas &lt;- ymd_hms(\"2017-01-01 01:00:00\", \"2017-01-01 01:30:00\")\n\nminute(fechas) &lt;- mean(minute(fechas))\n\nfechas # promedió los minutos en los dos casos\n\n[1] \"2017-01-01 01:15:00 UTC\" \"2017-01-01 01:15:00 UTC\"\n\n\nSi asignamos a un elemento un valor mayor de lo admitido, la diferencia se extenderá en el siguiente elemento superior (respetando la cantidad de días del mes de mayo adecuadamente en este caso.)\n\nfecha\n\n[1] \"2024-09-05 13:32:13 -03\"\n\nday(fecha) &lt;- 35 \n\nfecha\n\n[1] \"2024-10-05 13:32:13 -03\"\n\n\nFinalmente, también podemos cambiar las fechas agregando o restando unidades de tiempo.\n\nfecha\n\n[1] \"2024-10-05 13:32:13 -03\"\n\nfecha &lt;- fecha + hours(3)\n\nfecha\n\n[1] \"2024-10-05 16:32:13 -03\"\n\n\nObservemos que hours() (plural) no es la misma función que hour() (singular).\nPor último, algo muy útil para nuestro trabajo es poder extraer la semana epidemiologica, con la función epiweek(), en la que cae una fecha en particular o un conjunto de ellas dentro de una variable.\n\nepiweek(fecha)\n\n[1] 40\n\n\nJunto con la semana epidemiológica se puede obtener el año epidemiológico con la función epiyear()\nPor ejemplo, la fecha 01/01/2022 es el primer día de enero de 2022 pero pertenece a la semana epidemiológica 52 de año 2021. Veamos:\n\nfecha &lt;- dmy(\"01-01-2022\")\n\nfecha\n\n[1] \"2022-01-01\"\n\nepiweek(fecha)\n\n[1] 52\n\n\nSi uno obtiene el año al que pertenece, nos dice que 2022 pero si lo queremos asociar con su semana epidemiológica, nos quedaría que estamos en la semana 52 del año 2022, cosa que no es cierta.\n\nyear(fecha)\n\n[1] 2022\n\n\nEn estas situaciones que no coinciden el año de la fecha con el año epidemiológico de la semana es que se aplica epiyear().\n\nepiyear(fecha)\n\n[1] 2021\n\n\n\n\nCálculos con fecha-horas\nLos cálculos con fechas y horas son más complicados que la aritmética con números, pero puede hacerse con precisión y facilidad mediante este paquete.\n¿Qué es lo que complica a la aritmética con datos de tiempo (fechas u horas)?\nEl tiempo que medimos en el reloj se calibra periódicamente para ajustar las condiciones astronómicas, por caso los años bisiestos o los horarios de verano que se utilizan en muchos países.\nEn diferentes momentos, la duración de meses, semanas, días, horas e incluso minutos puede variar. Por lo tanto, podemos considerar que son unidades relativas de tiempo; su longitud es relativa a cuando ocurren; por el contrario, los segundos siempre tienen una longitud constante (son unidades de tiempo exactas)\nlubridate permite cálculos con unidades relativas y exactas introduciendo cuatro nuevos elementos relacionados: instantes, intervalos, duraciones y períodos. Estos conceptos son tomados del proyecto Joda Time (Colebourne y O’Neill 2010). Conceptos similares para instantes, períodos y duraciones también aparecen en la biblioteca C++ Boost - Date Time (Garland 2011).\nlubridate proporciona funciones auxiliares, clases de objetos y métodos para usar los cuatro conceptos en el lenguaje R.\n\nInstantes\nUn instante es un momento específico en el tiempo, como el 1 de enero de 2024. Creamos un instante cada vez que convertimos una fecha a formato Date de R.\n\nstart_2024 &lt;- ymd_hms(\"2024-01-01 12:00:00\")\n\nlubridate no crea una nueva clase de objetos instantes. En cambio, reconoce cualquier objeto de fecha y hora como un instante. Podemos probar si un objeto es un instante usando el identificador is.instant(). Por ejemplo:\n\nis.instant(start_2024)\n\n[1] TRUE\n\n\n\n\nIntervalos\nLos intervalos, duraciones y períodos son todas formas de registrar tiempos. De estos, los intervalos son los más simples. Un intervalo es un lapso de tiempo que ocurre entre dos instantes específicos.\nPodemos crear objetos de intervalo restando dos instantes, mediante %–% o usando la función new_interval().\n\nstart_2023 &lt;- ymd_hms(\"2023-01-01 12:00:00\")\nstart_2024 &lt;- ymd_hms(\"2024-01-01 12:00:00\")\nintervalo &lt;- start_2023 %--% start_2024\nintervalo\n\n[1] 2023-01-01 12:00:00 UTC--2024-01-01 12:00:00 UTC\n\n\nPodemos acceder a las fechas de inicio y finalización de un objeto de intervalo con int_start() e int_end().\nLos intervalos siempre comienzan en la fecha y hora que ocurre primero y finaliza en la fecha y hora que ocurre último. Por lo tanto, los intervalos siempre tienen una longitud positiva.\n\nint_start(intervalo)\n\n[1] \"2023-01-01 12:00:00 UTC\"\n\n\n\nint_end(intervalo)\n\n[1] \"2024-01-01 12:00:00 UTC\"\n\n\nDesafortunadamente, dado que los intervalos están anclados a sus fechas de inicio y finalización, no son muy útiles para cálculos de fecha y hora.\n\n\nDuraciones\nSi eliminamos las fechas de inicio y finalización de un intervalo, tendremos un intervalo de tiempo genérico que podemos agregar a cualquier fecha. Pero, en que unidad es conveniente medir este período de tiempo? Como vimos anteriormente, si lo almacenamos en segundos, tendrá una longitud exacta ya que los segundos siempre tienen la misma longitud.\nLlamamos duraciones de estos lapsos de tiempo. Alternativamente, podemos registrar el lapso de tiempo en unidades más grandes, como minutos o años.\nDado que la longitud de estas unidades varía con el tiempo, la longitud exacta de el lapso de tiempo dependerá de cuándo comience. Estos períodos de tiempo no exactos se llaman períodos y será discutido en la siguiente sección.\nLa duración de una duración es invariable para saltar años, segundos intercalares y horario de verano porque las duraciones se miden en segundos.\nPor lo tanto, las duraciones tienen longitudes consistentes y se puede comparar fácilmente con otras duraciones. Las duraciones son el objeto apropiado para usar cuando se comparan atributos basados en tiempo, como velocidades, tasas y tiempos de vida.\nEl paquete base de R tiene definido a objetos de tipo duración en la clase difftime.\nlubridate incorpora un segundo tipo: objetos clase duration\nEstos objetos se pueden usar con otros objetos de fecha y hora sin preocuparse sobre en qué unidades se muestran. Se puede crear un objeto de duración con la función duration():\n\nduration(60)\n\n[1] \"60s (~1 minutes)\"\n\n\nPara duraciones grandes, resulta inconveniente describir la longitud en segundos. Por ejemplo, no muchas personas reconocerían que 31557600 segundos es la duración de un año estándar. Por esta razón, los objetos de gran duración son seguidos entre paréntesis por una longitud estimada. Un minuto son 60 segundos, una hora 3600 segundos, un día 86400, una semana 604800 y un año 31557600 (365.25 días).\nLos objetos de clase duration se pueden crear fácilmente con las funciones auxiliares dyears(), dweeks(), ddays(), dhours(), dminutes() y dseconds(). La d en el nombre representa duración.\nCada objeto se crea tomando como unidad los segundos usando las relaciones estimadas descriptas arriba. El argumento de cada función es el número de unidades estimadas que deseamos incluir en la duración.\n\ndminutes(1)\n\n[1] \"60s (~1 minutes)\"\n\n\n\ndseconds(60)\n\n[1] \"60s (~1 minutes)\"\n\n\n\ndminutes(2)\n\n[1] \"120s (~2 minutes)\"\n\n\n\n1:3 * dhours(1)\n\n[1] \"3600s (~1 hours)\"  \"7200s (~2 hours)\"  \"10800s (~3 hours)\"\n\n\nLas duraciones se pueden agregar o restar a cualquier objeto instante.\n\nstart_2024\n\n[1] \"2024-01-01 12:00:00 UTC\"\n\nstart_2024 + ddays(10)\n\n[1] \"2024-01-11 12:00:00 UTC\"\n\n\nLas duraciones también se pueden agregar o restar de intervalos y otras duraciones. Por ejemplo:\n\ndweeks(1) + ddays(6) + dhours(2) + dminutes(1.5) + dseconds(3)\n\n[1] \"1130493s (~1.87 weeks)\"\n\n\nTambién podemos crear duraciones a partir de objetos intervalo y períodos usando as.duration().\n\nas.duration(intervalo)\n\n[1] \"31536000s (~52.14 weeks)\"\n\n\n\n\nPeríodos\nLos períodos registran un intervalo de tiempo en unidades mayores que segundos, como años, meses, semanas, días, horas y minutos. Para mayor comodidad, también podemos crear un período que solo use segundos, pero dicho período tendría las mismas propiedades que una duración. lubridate introduce la clase period para modelar períodos. Construimos objetos de período con las funciones auxiliares years(), months(), weeks(), days(), hours(), minutes() y seconds().\n\nmonths(3)\n\n[1] \"3m 0d 0H 0M 0S\"\n\n\n\nmonths(3) + days(2)\n\n[1] \"3m 2d 0H 0M 0S\"\n\n\nEstas funciones no contienen una d en su nombre, porque no crean duraciones; ya no tienen longitudes consistentes (medidas en segundos). Por ejemplo, meses (2) siempre tiene una duración de dos meses, aunque la duración de dos meses cambiará según cuando comienza el período (podrán ser meses de 30, 31 0 28 días).\nPor esta razón, no podemos calcular exactamente cuánto tiempo será un período en segundos hasta que sepamos cuándo ocurre. Sin embargo, aún podemos realizar cálculos de fecha y hora con períodos. Cuando agregamos o restamos un período a un instante, el período queda asociado al instante. El instante nos dice cuándo ocurre el período, lo que nos permite calcular su longitud exacta en segundos.\nPor ejemplo para un año bisiesto, primero sumamos un año con years():\n\nstart_2024 + years(1)\n\n[1] \"2025-01-01 12:00:00 UTC\"\n\n\nvs. sumar un año como duración con dyears()\n\nstart_2024 + dyears(1)\n\n[1] \"2024-12-31 18:00:00 UTC\"\n\n\nTambién podemos convertir otros objetos intervalo en períodos con la función as.period().\n\nas.period(intervalo)\n\n[1] \"1y 0m 0d 0H 0M 0S\"\n\n\nLos períodos se pueden agregar a instantes, intervalos y otros períodos, pero no a duraciones.\n\n\n\nDivisión con intervalos de tiempo\nA veces necesitamos responder preguntas que implican dividir un intervalo de tiempo por otro. Por ejemplo, ¿Cuántos años tiene una persona nacida el 26 de junio de 1976?\nObjetos de clase interval, duration y period pueden dividirse por otros objetos de las mismas clases. Los resultados de estas divisiones varían dependiendo de la naturaleza de los intervalos de tiempo involucrados. La división modular (%/%) también funciona con estas clases.\nPara ilustrar esto, hacemos un intervalo entre la fecha de nacimiento y la fecha actual.\n\nnacimiento &lt;- ymd(\"1976-06-26\")\n\nhoy &lt;- now()\n\nintervalo &lt;- interval(nacimiento, hoy)\n\nintervalo\n\n[1] 1976-06-26 UTC--2024-09-13 16:32:14 UTC\n\n\nComo las duraciones son una medida exacta de un intervalo de tiempo, podemos dividir este intervalo por una duración para obtener una respuesta exacta.\n\nintervalo / dyears(1)\n\n[1] 48.21818\n\n\nPodríamos utilizar un período en lugar de duración\n\nintervalo / years()\n\n[1] 48.21833\n\n\nPero lo más útil es la división modular para redondear y quedarnos solo con los años:\n\nintervalo %/% dyears()\n\n[1] 48\n\n\nEn resumen, la aritmética con tipos fecha-hora puede involucrar cuatro tipos de objetos: instantes, intervalos, duraciones y períodos.\nlubridate crea nuevas clases de objetos: interval, duration y period. Reconoce que las clases de fecha y hora más comunes, como POSIXt y Date, se refieren a instantes. La siguiente tabla describe qué objetos se pueden combinar con otro y qué tipo de objeto resultará.\n\n\n\n\ninstante\ninterval\nduration\nperiod\n\n\n\n\ninstante\nNA\ninstante\ninstante\ninstante\n\n\ninterval\ninstante\ninterval*\ninterval\ninterval\n\n\nduration\ninstante\ninterval\nduration\nperiod\n\n\nperiod\ninstante\ninterval\nperiod\nperiod\n\n\n\n*= clase duration si los intervalos no se alinean.\n\n\nRedondeando fechas\nAl igual que los números, las fechas se ordenan en forma creciente. Esto permite redondear los tipos de datos fecha-hora.\nlubridate proporciona tres métodos que ayudan a realizar este redondeo: round_date(), floor_date(), y ceiling_date().\nEl primer argumento de cada función es la fecha-hora a ser redondeada. El segundo argumento es la unidad tomada para redondear.\nPor ejemplo, podríamos redondear la siguiente fecha-hora a la unidad día:\n\nnov23 &lt;- ymd_hms(\"2023-11-23 09:38:29\")\n\nnov23\n\n[1] \"2023-11-23 09:38:29 UTC\"\n\nround_date(nov23, \"day\")\n\n[1] \"2023-11-23 UTC\"\n\n\nPero también podríamos desear redondear al comienzo de mes más próximo, asi:\n\nround_date(nov23, \"month\")\n\n[1] \"2023-12-01 UTC\"\n\n\nTenga en cuenta que al redondear un dato fecha-hora a una unidad determinada, se establece la fecha al inicio de esa unidad (al definir día, por ejemplo se establece la información de horas, minutos y segundos en 00).\nLas otras dos funciones de redondeo lo hacen al comienzo del mes menor (floor) o mayor (ceiling).\nPor ejemplo, con ceiling_date(), podemos hallar el último día de cada mes, sin importar la fecha que tengamos almacenada. Luego de ubicar el inicio del próximo mes, restamos un día.\n\nceiling_date(nov23, \"month\") - days(1)\n\n[1] \"2023-11-30 UTC\"\n\n\n\noct02 &lt;- ymd_hms(\"2023-10-02 00:00:00\")\n\nceiling_date(oct02, \"month\") - days(1)\n\n[1] \"2023-10-31 UTC\"\n\n\n\n\nZonas horarias\nLas zonas horarias complejizan a los datos fecha-hora, pero algunas veces nos encontramos con bases de datos o situaciones en que debemos lidiar con ellas. Cuando creamos instantes en R, la zona horaria estándar es la universal (UTC).\nlubridate ofrece dos formas de trabajar con zonas horarias.\nPodemos cambiar la zona horaria en la que se muestra un instante utilizando la función with_tz(). Esto cambia la forma en que se muestra el instante, pero continúa siendo el mismo. Por ejemplo, el objeto fecha tiene cargada una fecha-hora creada a partir de la función now() y al ejecutarse en un equipo con configuración regional de Argentina toma el uso horario de Buenos Aires (aparece -03 al final del día y horario)\n\nfecha\n\n[1] \"2022-01-01\"\n\n\nAl llevarlo a la zona horaria universal, le agrega 3 horas más, aunque sigue siendo el mismo instante.\n\nwith_tz(fecha, \"UTC\")\n\n[1] \"2022-01-01 UTC\"\n\n\nforce_tz() hace lo contrario de with_tz(): cambia el instante real de tiempo guardado en el objeto. Por ejemplo, el siguiente código nos mueve a un nuevo instante que ocurre 3 horas más temprano.\n\nforce_tz(fecha, \"UTC\")\n\n[1] \"2022-01-01 UTC\"\n\n\nEn este caso, un instante horario 11:32:01 UTC correponde al instante 08:32:01 -3\nwith_tz() y force_tz() solo funcionan con zonas horarias reconocidas por el sistema operativo de la computadora que aloja R. Esta lista de zonas horarias variará de una computadora a otra. Para más información ver la página de ayuda de R para Sys.timezone().\nEl código de nuestra zona horaria (es conocida como UTC-03:00 - Ciudad de Buenos Aires) para incorporar al argumento es America/Buenos_Aires"
  },
  {
    "objectID": "primero/clases/04-tipos.html#cadena-de-caracteres",
    "href": "primero/clases/04-tipos.html#cadena-de-caracteres",
    "title": "Gestión de tipos de datos",
    "section": "Cadena de caracteres",
    "text": "Cadena de caracteres\n\n\n\n\nArtwork por @allison_horst\n\n\n\nEl paquete encargado de trabajar con cadenas de caracteres dentro de tidyverse es stringr.\nTodas las funciones del paquete comienzan con str_ y trabajan sobre un vector de caracteres como primer argumento.\nHay tres grandes familias útiles de funciones en string:\nFunciones de manipulación de caracteres: estas funciones permiten manipular caracteres dentro de cadenas\nHerramientas para tratamiento de espacios en blanco: para agregar, eliminar y manipular espacios en blanco.\nFunciones de coincidencia de patrones: trabaja con motores de descripción de patrones, para funciones de busqueda, extracción, reemplazo, etc. Trabajan con expresiones regulares.\nstringr también se instala y activa junto a tidyverse.\n\nManipulación de caracteres\nPodemos obtener la longitud de la cadena con str_lenght()\n\nstr_length(\"abc\")\n\n[1] 3\n\n\nEsta función es equivalente a la función de R base nchar().\nPara acceder a un carácter individual se utiliza sub_str().\nSe necesitan tres argumentos: un vector de caracteres, una posición inicial y una posición final. Cualquiera de las posiciones puede ser un entero positivo, que cuenta a partir de la longitud, o un entero negativo que cuenta desde la derecha. Las posiciones son inclusivas, y si es más larga que la cadena, se truncarán silenciosamente.\n\nx &lt;- c(\"abcdef\", \"ghifjk\")\n\nla tercer letra de cada cadena\n\nstr_sub(x, 3, 3)\n\n[1] \"c\" \"i\"\n\n\ndesde la segunda letra hasta la anteúltima\n\nstr_sub(x, 2, -2)\n\n[1] \"bcde\" \"hifj\"\n\n\nTambién puede utilizar str_sub() para modificar cadenas de caracteres\n\nstr_sub(x, 3, 3) &lt;- \"X\"\n\nx\n\n[1] \"abXdef\" \"ghXfjk\"\n\n\nEl paquete stringr trae incorporado algunas funciones para manipulación de mayúsculas y minúsculas, similares a tolower() y toupper()\n\nx &lt;- \"Curso de lenguaje R\"\n\nconvierte a mayúsculas\n\nstr_to_upper(x)\n\n[1] \"CURSO DE LENGUAJE R\"\n\n\nconvierte a minúsculas\n\nstr_to_lower(x)\n\n[1] \"curso de lenguaje r\"\n\n\nconvierte a tipo título (la primer letra de cada palabra en mayúsculas)\n\nstr_to_title(x)\n\n[1] \"Curso De Lenguaje R\"\n\n\nTambién existen funciones para ordenar secuencias de caracteres\n\nx &lt;- c(\"y\", \"i\", \"k\")\n\nstr_order(x)\n\n[1] 2 3 1\n\n\ndevuelve el orden alfabético del índice de los elementos\n\nstr_sort(x)\n\n[1] \"i\" \"k\" \"y\"\n\n\ndevuelve los caracteres en orden alfabético\n\nstr_sort(x, decreasing = T)\n\n[1] \"y\" \"k\" \"i\"\n\n\nigual al anterior pero en orden decreciente\n\n\nEspacios en blanco\nHay tres funciones que añaden, eliminan o modifican espacios en blanco\nstr_pad() agrega espacio en blanco extra a una cadena a una longitud fija puede ser a izquierda, derecha o ambos lados.\n\nx &lt;- c (\"abc\", \"defghi\")\n\n\nstr_pad(x, 10)\n\n[1] \"       abc\" \"    defghi\"\n\n\nrellena con espacios en blanco hasta alcanzar la cantidad de 10 caracteres por cadena sin definir el argumento side= lo hace a la izquierda\n\nstr_pad(x, 10, side = \"both\")\n\n[1] \"   abc    \" \"  defghi  \"\n\n\naquí lo hacemos rellenando los espacios en blanco a ambos lados\nLo opuesto a rellenar de espacios en blanco es eliminarlos y esta tarea la realiza la función str_trim()\n\nx &lt;- c(\"  a   \", \"b   \",  \"   c\")\n\nstr_trim(x)\n\n[1] \"a\" \"b\" \"c\"\n\n\nelimina todos los espacios en blanco a ambos lados de la cadena\n\nstr_trim(x, side=\"left\")\n\n[1] \"a   \" \"b   \" \"c\"   \n\n\ncon el argumento side= le podemos indicar de que lado queremos eliminarlos\n\n\nPatrones\n\n\n\n\nArtwork por @allison_horst\n\n\n\nLa mayoría de las funciones de stringr para trabajo con patrones de caracteres funcionan con expresiones regulares (un lenguaje conciso para describir patrones de texto).\nBásicamente una expresión regular es una cadena de texto especial para describir un patrón de búsqueda que se puede utilizar para:\n\nlocalizar cadenas de caracteres (ubicar - filtrar)\nextraer una porción de los datos (extraer)\nmodificar los datos localizados (reemplazar)\n\nHabitualmente se construyen concatenando la especificación de caracteres secuenciados junto a otros metacaracteres.\nSon muy útiles cuando tenemos variables de alfanuméricas regulares, es decir con una estructura que se repite. Por ejemplo, los códigos internacionales de enfermedad, conocidos como CIE (actualmente en la versión CIE10/CIE11)\nAlgunos de los metacaracteres para construir expresiones regulares son:\n\n\n\n\n\n\n\nSímbolos y metacaracteres\nDescripción\n\n\n\n\n^\nInicio de la cadena\n\n\n$\nFinal de la cadena\n\n\n[ ]\nCualquier carácter del conjunto entre paréntesis\n\n\n[^]\nCualquier carácter no incluido en el conjunto\n\n\n?\nCero o una ocurrencia de lo que precede al símbolo\n\n\n+\nEl caracter que le precede debe aparecer al menos una vez\n\n\n*\nEl caracter que le precede debe aparecer cero, una o más veces\n\n\n{x}\nx ocurrencias del caracter que lo precede\n\n\n{x,z}\nEntre x y z ocurrencias del caracter que lo precede\n\n\n{x,}\nx o más ocurrencias de lo que lo precede\n\n\n\n\n\n\n\n\n\n\nSímbolos y metacaracteres\nDescripción\n\n\n\n\n|\nUne subexpresiones\n\n\n.\nConcuerda con cualquier carácter individual\n\n\n( )\nAgrupa subexpresiones\n\n\n0-9 a-z A-Z\nRangos de números, letras…\n\n\n\\\nMarca el carácter siguiente como un carácter especial\n\n\n.\nRepresenta un punto dentro del patrón\n\n\ns\nRepresenta un espacio en blanco dentro del patrón\n\n\nn\nRepresenta un salto de línea dentro del patrón\n\n\nd\nRepresenta un dígito numérico dentro del patrón\n\n\nw\nRepresenta un carácter alfanumérico dentro del patrón\n\n\n\n\nVeamos un ejemplo con un grupo de códigos CIE10 relacionados a la hepatitis B.\nTenemos una pequeña tabla de datos con 10 códigos en la variable hepb\n\ncodigos\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nSupongamos que se encuentran insertos en una tabla de datos con otros códigos y necesitamos detectarlos para extraerlos o contarlos.\nSi las expresiones regulares no existiesen deberíamos hacer algo así:\n\ncodigos %&gt;% \n  filter(hepb ==\"B16\" | hepb &gt;= \"B160\" & hepb &lt;= \"B162\" | hepb == \"B169\" | \n         hepb == \"B170\" | hepb ==\"B178\" | hepb ==\"B180\" | hepb ==\"B181\" | \n         hepb == \"B189\")\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nEs decir, concatenar una serie de operadores y conectores lógicos OR dentro de un filtro por ejemplo para lograr su extracción.\nCon las expresiones regulares tenemos una alternativa de hacer esta tarea dividiendo el trabajo en partes y aplicar la función str_detect() de stringr.\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B16[0-2|9]?$\"))  #  selecciona el grupo B16x\n\n  hepb\n1  B16\n2 B160\n3 B161\n4 B162\n5 B169\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B17[08]$\")) # selecciona el grupo B17x\n\n  hepb\n1 B170\n2 B178\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B18[019]$\")) # selecciona el grupo B18x\n\n  hepb\n1 B180\n2 B181\n3 B189\n\n\nY finalmente unirlo con conectores OR:\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B16[0-2|9]?$|^B17[08]$|^B18[019]$\"))\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nO mejor construir una expresión regular más sintética aprovechando los metadatos adecuados.\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B1[6-9][0-9]?$\"))\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nAdemás de la función de detección str_detect() el paquete aporta str_extract() para extraer y str_replace() para reemplazar directamente"
  },
  {
    "objectID": "primero/clases/04-tipos.html#factores",
    "href": "primero/clases/04-tipos.html#factores",
    "title": "Gestión de tipos de datos",
    "section": "Factores",
    "text": "Factores\n\n\n\n\nArtwork por @allison_horst\n\n\n\nLos factores son simplemente el formato de datos que R reserva para las variables categóricas y estan compuesto por valores numéricos internos asociados a etiquetas que definen cada una de los niveles (categorías o niveles definidos).\nEl paquete forcats es parte del ecosistema tidyverse pensado para trabajar con este tipo de dato.\nEn función de que las herramientas del paquete son de aplicación práctica vamos a trabajar con un conjunto de datos ficticios creados con la finalidad de mostrar la potencialidad de forcats.\n\nglimpse(datos)\n\nRows: 19\nColumns: 6\n$ Enfermedad     &lt;chr&gt; \"Si\", \"Si\", \"No\", \"Si\", \"No\", \"No\", \"No\", \"Si\", \"Si\", \"…\n$ Sexo           &lt;chr&gt; \"Varon\", \"Mujer\", \"Mujer\", \"Mujer\", \"Masculino\", \"Varon…\n$ Civil          &lt;chr&gt; \"Soltero\", \"Viudo\", \"Casado\", \"Soltero\", \"Soltero\", \"Vi…\n$ Esalud         &lt;chr&gt; \"Mala\", \"Muy mala\", \"Buena\", \"Mala\", \"Buena\", \"Buena\", …\n$ Ciudad         &lt;chr&gt; \"Mar del Plata\", \"Mar del Plata\", \"Mar del Plata\", \"Mar…\n$ Comorbilidades &lt;chr&gt; \"EPOC\", \"Gastritis\", \"aterosclerosis\", \"TBC\", \"Neumonia…\n\n\nObservamos que el objeto llamado datos tiene 6 variables de tipo caracter y 19 observaciones.\nEstas variables de caracter tienen como característica representar variables cualitativas nominales y ordinales que para su mejor tratamiento dentro del R deberían ser convertidas a factores.\nComenzamos con la primer variable (Enfermedad). La función simple y de R base que conocemos para convertirla en factor es factor().\n\ndatos &lt;- datos |&gt; \n  mutate(Enfermedad = factor(Enfermedad))\n\nlevels(datos$Enfermedad)\n\n[1] \"No\" \"Si\"\n\n\nLa función del paquete forcats para realizar la misma tarea se llama as_factor(). No agrega ningun funcionalidad extra por lo que es indistinto utilizar una forma u otra.\nAquí la utilizamos para convertir la variable Sexo\n\ndatos &lt;- datos |&gt; \n  mutate(Sexo = as_factor(Sexo))\n\nSi queremos visualizar los niveles del factor podemos usar levels() (función de R base):\n\nlevels(datos$Sexo)\n\n[1] \"Varon\"     \"Mujer\"     \"Masculino\" \"Femenino\" \n\n\nEncontramos uno de los problemas habituales cuando trabajamos con datos reales cargados por diferentes usuarios o cuando unimos bases de diverso origen. Las categorías se encuentran etiquetadas de manera diferente aunque conceptualmente se refieran a lo mismo (ejemplo: “Femenino” - “Mujer”)\nDebemos corregir este inconveniente y para esta tarea el paquete ofrece una función que recodifica los niveles. Se llama fct_recode() y la aplicamos así:\n\ndatos &lt;- datos |&gt; \n  mutate(Sexo = fct_recode(Sexo, \n                           Varon = \"Masculino\", \n                           Mujer = \"Femenino\"))\n\nlevels(datos$Sexo)\n\n[1] \"Varon\" \"Mujer\"\n\ndatos |&gt; \n  reframe(fct_count(Sexo))\n\n# A tibble: 2 × 2\n  f         n\n  &lt;fct&gt; &lt;int&gt;\n1 Varon    10\n2 Mujer     9\n\n\nVemos en los argumentos que le indicamos que “Masculino” es igual a Varon y “Femenino” igual a Mujer. Esto provoca que en todos los casos donde aparezca “Masculino” sea reemplazado por Varon y cuando aparezcan “Femenino” se cambie por Mujer.\nFinalmente verificamos que los niveles sean los dos que necesitamos y además podemos producir un listado de frecuencias de los niveles del factor con fct_count() dentro de un reframe() que es la opción correcta al summarise() cuando el resultado es mayor a una fila a partir de la versión 1.1.0 de dplyr.\nHasta aquí tenemos las dos primeras variables convertidas y podrían ser utilizadas en un análisis posterior para construir una tabla de contingencia de Sexo vs Enfermedad.\n\nlibrary(janitor)\n\ndatos |&gt; \n  tabyl(Sexo, Enfermedad)\n\n  Sexo No Si\n Varon  5  5\n Mujer  3  6\n\n\nObservemos que en esta tabla el orden de los niveles de Enfermedad quizás no sea el más conveniente para tablas 2x2 y sus cálculos asociados (razones o diferencias de razones), donde se necesita que la tabla tenga una forma y orden específico para que los valores e las ecuaciones sean los correctos.\nEsta situación causa que muchas veces tengamos que reordenar las categorías de las variables cualitativas y los niveles de los factores son ideales para esto. La función encargada de esta tarea en forcats es fct_relevel() que no es muy diferente al relevel() del R base.\n\ndatos &lt;- datos |&gt; \n  mutate(Enfermedad = fct_relevel(Enfermedad, \"Si\"))\n\ndatos |&gt; \n  tabyl(Sexo, Enfermedad)\n\n  Sexo Si No\n Varon  5  5\n Mujer  6  3\n\n\nAplicado sobre Enfermedad observamos, luego en la tabla 2x2, que la categoría Si aparece primera como necesitamos.\nLo mismo podríamos hacer con la variable Sexo si quisieramos que el nivel de referencia fuese Mujer en lugar de Varon.\n\ndatos &lt;- datos |&gt; \n  mutate(Sexo = fct_relevel(Sexo, \"Mujer\"))\n\ndatos |&gt; \n  tabyl(Sexo, Enfermedad)\n\n  Sexo Si No\n Mujer  6  3\n Varon  5  5\n\n\nContinuamos con la siguiente variable y luego de transformarla pedimos sus niveles.\n\ndatos &lt;- datos |&gt; \n  mutate(Civil = factor(Civil))\n\nlevels(datos$Civil)\n\n[1] \"Casado\"     \"Divorciado\" \"Soltero\"    \"Viudo\"     \n\n\nAparecen 4 niveles para la variable. Para ver la frecuencia de aparición hacemos:\n\ndatos |&gt; \n  reframe(fct_count(Civil))\n\n# A tibble: 5 × 2\n  f              n\n  &lt;fct&gt;      &lt;int&gt;\n1 Casado         5\n2 Divorciado     3\n3 Soltero        7\n4 Viudo          3\n5 &lt;NA&gt;           1\n\n\nEn la frecuencia aparecen los 4 niveles más un valor faltante (NA). Estos valores habitualmente se omiten en muchas de las operaciones que realiza el lenguaje.\nPero supongamos que deseamos mostrar dentro de una tabla de frecuencia la cantidad de valores perdidos o desconocidos que tenemos de la variable Estado Civil. Deberíamos etiquetar ese NA para poder visualizarlo.\nLa función del paquete encargada de la tarea es fct_na_value_to_level()\n\ndatos &lt;- datos |&gt; \n  mutate(Civil = fct_na_value_to_level(Civil, \n                                       level = \"Desconocido\"))\n\ndatos |&gt; \n  reframe(fct_count(Civil))\n\n# A tibble: 5 × 2\n  f               n\n  &lt;fct&gt;       &lt;int&gt;\n1 Casado          5\n2 Divorciado      3\n3 Soltero         7\n4 Viudo           3\n5 Desconocido     1\n\nlevels(datos$Civil)\n\n[1] \"Casado\"      \"Divorciado\"  \"Soltero\"     \"Viudo\"       \"Desconocido\"\n\n\nPensando en poder graficar esta variable construimos un gráfico de barras sencillo.\n\ndatos |&gt; \n  ggplot(aes(x = Civil, fill = Civil)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nUna mejor presentación sería si las barras se encuentran ordenadas (de mayor a menor) por la frecuencia de cada categoría.\nPodríamos ordenar mediante arrange() (del paquete dplyr de tidyverse) pero este ordenamiento sirve solo como prosentación, es decir el nuevo orden no se guarda dentro de los niveles del factor.\nPara poder hacer usamos fct_infreq():\n\ndatos &lt;- datos |&gt; \n  mutate(Civil = fct_infreq(Civil))\n\nlevels(datos$Civil)\n\n[1] \"Soltero\"     \"Casado\"      \"Divorciado\"  \"Viudo\"       \"Desconocido\"\n\n\nAhora el gráfico nos saldría como queremos:\n\ndatos |&gt; \n  ggplot(aes(x = Civil, fill = Civil)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nSigamos con otra de las variables. En este caso Esalud que tiene el estado de salud autoreportado por las personas. Como representa una variable categórica ordinal tenemos que estar atentos al orden de las categorías que R siempre forzará a que cumpla con el alfabético.\nPodemos usar directamente fct_relevel() con los niveles completos en el orden correcto.\n\nclass(datos$Esalud)\n\n[1] \"character\"\n\ndatos &lt;- datos |&gt; \n  mutate(Esalud = fct_relevel(Esalud,\n                              \"Muy buena\",\n                              \"Buena\",\n                              \"Regular\",\n                              \"Mala\",\n                              \"Muy mala\"))\n         \nlevels(datos$Esalud)\n\n[1] \"Muy buena\" \"Buena\"     \"Regular\"   \"Mala\"      \"Muy mala\" \n\n\nObservemos que no hizo falta primero convertir en factor y luego aplicar la función de forcats. Todas las funciones comenzadas con fct_ aplicadas a un tipo caracter convertiran a factor previamente a la operación que realicen.\nEn este caso además los niveles tienen un orden lógico que comienza en “Muy buena” salud y termina en “Muy mala”. Quizás el orden necesario sea inverso y fct_rev() hace la tarea.\n\ndatos &lt;- datos |&gt; \n  mutate(Esalud = fct_rev(Esalud))\n\nlevels(datos$Esalud)\n\n[1] \"Muy mala\"  \"Mala\"      \"Regular\"   \"Buena\"     \"Muy buena\"\n\n\nFinalmente conseguimos que el factor sea ordenado y que los niveles sigan el esquema de aumentar hacia la derecha.\nLa siguiente variable es Ciudad. Veamos su contenido:\n\ndatos |&gt; \n  count(Ciudad)\n\n# A tibble: 4 × 2\n  Ciudad            n\n  &lt;chr&gt;         &lt;int&gt;\n1 Batan             1\n2 Mar del Plata    16\n3 Miramar           1\n4 Santa Clara       1\n\n\nPosee 4 etiquetas con nombres de ciudades. Su frecuencia es:\nVemos que mayoritariamente las observaciones pertenecen a Mar del Plata. Muchas veces cuando estamos frente a situaciones como esta, donde hay varias categorías con poca frecuencia, es mejor agruparlas en un “Otras/os”. Eso mismo vamos a realizar con la función fct_other().\n\ndatos &lt;- datos |&gt; \n  mutate(Ciudad = fct_other(Ciudad, \n                            keep = \"Mar del Plata\", \n                            other_level = \"Otras\"))\n\nlevels(datos$Ciudad)\n\n[1] \"Mar del Plata\" \"Otras\"        \n\ndatos |&gt; \n  count(Ciudad)\n\n# A tibble: 2 × 2\n  Ciudad            n\n  &lt;fct&gt;         &lt;int&gt;\n1 Mar del Plata    16\n2 Otras             3\n\n\nLa última de las variables de la tabla de datos es Comorbilidades.\n\ndatos |&gt; \n  count(Comorbilidades)\n\n# A tibble: 7 × 2\n  Comorbilidades     n\n  &lt;chr&gt;          &lt;int&gt;\n1 EPOC               4\n2 Gastritis          2\n3 Hepatitis          2\n4 Hipertensión       2\n5 Neumonia           3\n6 TBC                4\n7 aterosclerosis     2\n\n\nSus etiquetas son 7 y se trata de enfermedades que podemos vincular a distintos grupos, es decir, que nos va a servir de excusa para probar otra función de forcats.\nLa función es fct_collapse() y permite agrupar niveles a grupos que serían las nuevas etiquetas de nivel.\nLo vamos a hacer asignando a una nueva variable (Comor_agrupadas) y generando los niveles Respiratoria, Digestiva y Circulatorio, para enfermedades respiratorias, enfermedades del aparato digestivo y enfermedades del aparato circulatorio.\n\ndatos &lt;- datos |&gt; \n  mutate(Comor_agrupadas = fct_collapse(Comorbilidades,\n                                      Respiratoria = c(\"EPOC\",\n                                                       \"TBC\", \n                                                       \"Neumonia\"),\n                                      Digestiva = c(\"Hepatitis\",\n                                                    \"Gastritis\"),\n                                      Circulatorio  = c(\"aterosclerosis\",\n                                                        \"Hipertensión\")))\n\nlevels(datos$Comor_agrupadas)\n\n[1] \"Circulatorio\" \"Respiratoria\" \"Digestiva\"   \n\ndatos |&gt; \n  count(Comor_agrupadas)\n\n# A tibble: 3 × 2\n  Comor_agrupadas     n\n  &lt;fct&gt;           &lt;int&gt;\n1 Circulatorio        4\n2 Respiratoria       11\n3 Digestiva           4\n\n\nNos quedan para ver tres funciones más del paquete presentado.\nLa primera es fct_drop() que elimina los niveles que no se utilizan. Veamosla en acción.\nTomamos el caso de una selección de la tabla original datos filtrado por las observaciones que pertenecen a Mar del Plata, guardado en otro dataframe al que llamaremos datos_MdP\n\ndatos_MdP &lt;- datos  |&gt;  \n  filter(Ciudad == \"Mar del Plata\")\n\nSi vemos sus niveles confirmaremos que heredó los que tenía la variable en el tibble original. Pero una tabla nos mostraría que no hay datos para el nivel “Otras”.\n\nlevels(datos_MdP$Ciudad)\n\n[1] \"Mar del Plata\" \"Otras\"        \n\ndatos_MdP |&gt; \n  tabyl(Ciudad)\n\n        Ciudad  n percent\n Mar del Plata 16       1\n         Otras  0       0\n\n\nAquí entra en juego la función fct_drop() que aplicada a la variable Ciudad de datos_MdP produce:\n\ndatos_MdP &lt;- datos_MdP |&gt; \n  mutate(Ciudad = fct_drop(Ciudad))\n\nlevels(datos_MdP$Ciudad)\n\n[1] \"Mar del Plata\"\n\ndatos_MdP |&gt; \n  tabyl(Ciudad)\n\n        Ciudad  n percent\n Mar del Plata 16       1\n\n\nA la inversa, la función fct_expand() incorpora niveles a la lista de niveles de un factor.\nVolvemos a trabajar con el dataframe datos y vamos a asignar nuevos niveles al factor de la variable Ciudad.\n\ndatos &lt;- datos |&gt; \n  mutate(Ciudad = fct_expand(Ciudad, \"La Plata\", \n                             \"Tandil\", \n                             \"CABA\"))\n\nlevels(datos$Ciudad)\n\n[1] \"Mar del Plata\" \"Otras\"         \"La Plata\"      \"Tandil\"       \n[5] \"CABA\"         \n\n\nEsto significa que tenemos tres categorías posibles más en el factor que están disponibles para nuevas observaciones, aunque en el conjunto de datos no esten siendo utilizadas por ahora.\nPor último, la función fct_c() concatena factores combinandos niveles. Para ejemplificar su uso vamos a construir dos factores tipo vector que finalmente uniremos.\nImaginemos que tenemos que unir dos variables pertenecientes a conjuntos de datos que queremos unificar. En la variable1 hay definidos dos niveles “Corrientes” y “Posadas” y en la variable2 tres niveles “Corrientes”, “Resistencia” y “Goya”.\n\nvar1 &lt;- factor(c(\"Corrientes\",\"Corrientes\",\"Posadas\",\"Corrientes\",\n                 \"Posadas\"))\n\nvar2 &lt;- factor(c(\"Resistencia\",\"Goya\",\"Goya\",\"Resistencia\",\"Resistencia\",\n                 \"Corrientes\",\"Goya\"))\n\nvar1\n\n[1] Corrientes Corrientes Posadas    Corrientes Posadas   \nLevels: Corrientes Posadas\n\nvar2\n\n[1] Resistencia Goya        Goya        Resistencia Resistencia Corrientes \n[7] Goya       \nLevels: Corrientes Goya Resistencia\n\n\nA continuación concatenamos aplicando fct_c():\n\nvar3 &lt;- fct_c(var1, var2)\n\nvar3\n\n [1] Corrientes  Corrientes  Posadas     Corrientes  Posadas     Resistencia\n [7] Goya        Goya        Resistencia Resistencia Corrientes  Goya       \nLevels: Corrientes Posadas Goya Resistencia\n\n\nObservamos que no solo une los datos de las variables sino que respeta los niveles definidos de cada uno fusionando las categorías."
  },
  {
    "objectID": "primero/clases/02-introRStudio.html",
    "href": "primero/clases/02-introRStudio.html",
    "title": "Introducción a RStudio",
    "section": "",
    "text": "Una vez instalado el software (R + RStudio + Rtools) tenemos todo lo necesario para comenzar a trabajar con el lenguaje R.\nEn este documento vamos a explicar algunos procedimientos que vamos a llevar a cabo muchas veces en las practicas a lo largo del curso.\nEn principio, aunque instalamos tres programas, el único que debemos ejecutar para ponernos a trabajar es RStudio. Éste se encarga de utilizar a R como motor/interprete y a Rtools si llegamos a necesitar instalar algún paquete desarrollado en C/C++ o Fortran. (proceso desantendido al que no deberemos prestar atención)"
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#proyectos-de-rstudio",
    "href": "primero/clases/02-introRStudio.html#proyectos-de-rstudio",
    "title": "Introducción a RStudio",
    "section": "Proyectos de RStudio",
    "text": "Proyectos de RStudio\nLos proyectos de RStudio se utilizan para organizar todo el código, los resultados y salidas, las fuentes de datos y cualquier otro archivo utilizado en un análisis.\nLa organización del trabajo en proyectos es muy útil para asegurarnos que cada vez que necesitemos importar datos, RStudio los buscará dentro de la carpeta asociada al proyecto.\n\nCrear un nuevo proyecto de RStudio\nCreamos un nuevo proyecto de RStudio seleccionando la opción File y luego New Project … de la barra de menú en la parte superior de la pantalla de RStudio como se muestra en la siguiente figura.\n\n\n\n\n\n\n\n\n\nTambién accedemos a generar un proyecto nuevo a partir de pulsar sobre New Project… del menú desplegado en el extremo derecho superior de la interface de RStudio.\n\n\n\n\n\n\n\n\n\nEn cualquiera de los dos casos aparecerá un cuadro de diálogo que presenta algunas opciones para crear el nuevo proyecto de RStudio.\n\n\n\n\n\n\n\n\n\nPor lo general, seleccionaremos la primera opción, New Directory, que crea una nueva carpeta a la que deberemos colocarle un nombre. Esta es la forma de crear un nuevo proyecto cuando aún no tenemos archivos dentro de alguna carpeta con los que deseemos trabajar.\nEn el caso que tengamos algunos archivos de código o archivos de datos con los que necesitemos trabajar, podemos elegir la segunda opción, Existing Directory. El proyecto tomará el nombre de la carpeta que seleccionemos en forma predeterminada.\n\n\nTipos de proyectos\nExisten varios tipos de proyectos pero nosotros en este curso utilizaremos solo la primera opción, que nos abre la siguiente ventana.\n\n\n\n\n\n\n\n\n\nDebemos completar los dos campos.\nEn Directory name hay que escribir el nombre de la nueva carpeta que también será el nombre de nuestro proyecto.\nEn Create Project as subdirectory of: podemos pulsar sobre el botón Browse… y navegar por nuestro Explorador de Archivos hasta ubicar la carpeta donde queremos que se ubique el nuevo proyecto con su nueva carpeta asociada.\nFinalmente hacemos click en el botón Create Project.\nSupongamos que nombremos a nuestro nuevo proyecto como “Practica R” y que lo generamos dentro de la carpeta Mis Documentos.\n\n\n\n\n\n\n\n\n\nEste nuevo proyecto de RStudio se almacenará en la carpeta Practica R que encontraremos en Mis Documentos.\nLos proyectos de RStudio tienen sus propios entornos, por lo que si cerramos o cambiamos de proyecto, nuestra configuración se mantendrá inalterable.\nEsto es cierto para los scripts y cualquier otra cosa que se pueda necesitar para un análisis, mientras esté almacenado dentro de esa carpeta de trabajo.\nEchemos un vistazo a lo que RStudio realizó.\n\n\n\n\n\n\n\n\n\nEn la figura anterior podemos ver dos cambios en la pantalla de inicio.\nEn primer lugar el panel Files (pantalla inferior derecha) apunta a la nueva carpeta Practica R y dentro de ella vemos un nuevo archivo el nombre del proyecto y la extensión Rproj. Este archivo contiene todas las configuraciones del proyecto.\nEl otro cambio se observa en la parte superior derecha, que muestra el nombre del proyecto activo."
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#scripts",
    "href": "primero/clases/02-introRStudio.html#scripts",
    "title": "Introducción a RStudio",
    "section": "Scripts",
    "text": "Scripts\nComo dijimos en Introducción al lenguaje R un script es un archivo de código que contiene un listado secuencial de funciones para ser ejecutadas por el interprete. Estos archivos permiten guardar el código que vamos creando y volver a utilizarlo tantas veces como se quiera, además de poder compartirlo con otras personas.\n\nCómo creamos un script nuevo en RStudio?\nTenemos dos formas de crear un script nuevo. Desde el menú superior pulsando File &gt; New File &gt; R Script (atajo Ctrl+Shift+N) o con el ícono del documento con un símbolo +, como se muestra debajo.\n\n\n\n\n\n\n\n\n\n\n\nCómo editamos un script en RStudio?\nSi queremos comenzar a escribir código o modificar alguna línea ya escrita vamos a utilizar el editor de código.\nEste editor posee algunas herramientas especiales que nos facilitan el trabajo, evitando problemas de sintaxis entre otras ventajas.\nEstas herramientas las vamos a detallar más adelante.\n\n\nCómo ejecutamos un script en RStudio?\nLa forma de ejecutar habitualmente el código escrito, es línea por línea mediante el uso de la combinación de teclas Ctrl+Enter o el botón Run del editor de código de RStudio. Para esto tenemos que tener el cursor activo en la línea que queremos correr (puede ser en cualquier parte de la línea) y luego de ser ejecutada el cursor saltará automáticamente a la siguiente línea que tenga código.\nMientras ejecutamos cada línea debemos ir observando la salida en la consola y también los cambios que se dan en el bloque Environment (Entorno) donde aparecerán los objetos que vayamos creando y modificando.\n\n\nCómo guardamos un script en RStudio?\nCualquier código agregado o modificación que hayamos realizado al script que nos interese mantener nos obligará a guardar el archivo.\nBasta con pulsar sobre el ícono del diskette celeste del editor de código para guardar el script, o bien hacerlo desde el menú principal File &gt; Save o presionando el atajo Ctrl+S.\nSi en cambio quisiera guardarlo como otro archivo para mantener el script original, podemos guardarlo con diferente nombre mediante File &gt; Save As…\n\n\nCómo abrimos un script en RStudio?\nLos scripts que construyamos o bien que nos compartan siempre tendrán extensión .R y generalmente, se encontrarán dentro de algún proyecto.\nPara abrir estos archivos .R podemos pulsar sobre ellos dentro del panel Files (abajo a la derecha) o bien desde el manú con File &gt; Open file… (atajo de teclado Ctrl+O)\nVisualizaremos el script en una nueva pestaña en el editor de código."
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#herramientas-de-rstudio",
    "href": "primero/clases/02-introRStudio.html#herramientas-de-rstudio",
    "title": "Introducción a RStudio",
    "section": "Herramientas de RStudio",
    "text": "Herramientas de RStudio\n\nAsistente de código\nCuando escribimos desde el teclado en el editor de código o en la consola de RStudio, aparece un asistente de forma automática que autocompleta las funciones que vamos tipeando.\nEsta herramienta de autocompletado también se ejecuta pulsando la tecla de tabulación (Tab) y nos muestra las posibilidades de finalizar las palabras que vamos escribiendo junto al esquema de argumentos obligatorios que tiene asociado dicha función. Solo debemos presionar Enter para seleccionar el término correcto.\n\n\n\n\n\n\n\n\n\nAl sistematizar la escritura de código apoyandonos en el uso del autocompletado vamos a reducir la tasa de errores de sintaxis, dado que las funciones, los argumentos y los nombres de las tablas y variables de nuestros datos van a estar correctamente escritos.\n\n\nAyuda en línea\nSi necesitamos acceder a una ayuda adicional en línea bastará que presionemos la tecla F1 con el cursor situado sobre el nombre de la función escrita en el editor de código para que aparezca la información relacionada en el bloque Help de Rstudio (generalmente panel abajo a la derecha).\n\n\n\n\n\n\n\n\n\n\n\nHistorial de funciones\nOtra característica de utilidad dentro de la Consola de RStudio es que si nos situamos en el prompt activo, y pulsamos las teclas flecha hacia arriba o abajo, veremos pasar la lista completa de código ejecutado en la sesion de trabajo.\nEsto nos ayuda a la hora de volver a ejecutar una función o bien cuando debemos hacer alguna corrección de la o las líneas anteriores, puesto que nos ahorra tiempo y trabajo evitando volver a tener que tipear lo que ya escribimos.\nEste historial de funciones también lo encontramos en el bloque superior derecho de RStudio, dentro de la pestaña History.\nHistory almacena todos las funciones ejecutados en consola de forma acumulativa, incluso anidando sesión tras sesión.\nLos comandos que aparecen en ese panel se pueden copiar y pegar en la Consola o, de forma más directa, puedes seleccionar uno de ellos con el mouse, y pulsar en el botón To Console (Enter) para insertarlo en consola o To Source (Shitft+Enter) para insertarlo en el script activo en el que estemos trabajando.\n\n\n\n\n\n\n\n\n\n\n\nAtajos de teclados relevantes (para Windows)\n\n\n\n\n\n\n\nMenú Archivo (File)\n\n\n\n\n\nCtrl+Shift+N\nCrea un nuevo script\n\n\nCtrl+O\nAbre un script guardado\n\n\nCtrl+S\nGuarda el script activo\n\n\nCtrl+W\nCierra el script activo\n\n\nCtrl+Q\nSale del programa RStudio\n\n\nMenú Edición (Edit)\n\n\n\nCtrl+F\nAbre la ventana de búsqueda (para buscar palabras dentro de un script)\n\n\nCtrl+L\nLimpia la consola\n\n\nMenú Código (Code)\n\n\n\nCtrl+Enter\nEjecuta la línea de código donde está situado el cursor\n\n\nCtrl+Alt+R\nEjecuta todo el código del script activo"
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#paquetes-librerías",
    "href": "primero/clases/02-introRStudio.html#paquetes-librerías",
    "title": "Introducción a RStudio",
    "section": "Paquetes (librerías)",
    "text": "Paquetes (librerías)\nR consta de un sistema base y de librerías adicionales, llamados paquetes (packages) que extienden su funcionalidad.\nSiendo open source cualquier persona puede construir paquetes con nuevas funciones, aunque no todos se publican en el repositorio CRAN (Comprehensive R Archive Network).\nUn grupo de paquetes conforman el sistema base que quedan activos cuando instalamos el software R.\nOtros paquetes se encuentran publicados en el repositorio para ser descargados cuando sea necesario. Actualmente existen más de 19000 paquetes para múltiples aplicaciones.\nExisten dos formas de descargar estos paquetes, directamente desde RStudio/R y por medio del sitio web, descargándolos como archivos comprimidos .zip\nSi el equipo se encuentra conectado a Internet es más cómodo realizar las descargas desde RStudio, pero en el caso de no tener acceso permanente a la red, se pueden descargar desde la web en otro equipo y luego guardar en el equipo donde tenemos el programa R.\nEl sitio web para las descargas de los paquetes publicados es https://cran.r-project.org/web/packages/\nAllí se encuentran los enlaces para ver el listado de paquetes ordenados alfabéticamente o por fecha de publicación.\nUna vez que ingresamos al link del paquete que nos interesa veremos en la página algunos datos relacionados como un breve texto de que trata el paquete, el numero de versión, la fecha de publicación, el autor, el archivo de documentación, y por supuesto los archivos a descargar para cada sistema operativo.\nAfortunadamente en la actualidad la mayoría de las computadoras cuentan con acceso a Internet por lo cual explicaremos como se puede descargar, instalar y activar los paquetes desde RStudio.\nRStudio tiene una pestaña específica para gestionar los paquetes ubicada de forma predeterminada en el bloque inferior derecho de la interfaz (Packages)\n\n\n\n\n\n\n\n\n\nPrácticamente todos las acciones que nos facilita la interfaz de RStudio se traduce internamente en ejecuciones de funciones de R que podemos ver en la consola.\nLa secuencia para instalar un paquete que no tengamos previamente instalado inicia a partir de pulsar el botón Install y la ventana emergente que visualizaremos es la siguiente:\n\n\n\n\n\n\n\n\n\n\nDependencias\nLa gran mayoría de las funciones que integran los paquetes que podemos descargar y utilizar están construidas en el mismo lenguaje R y para su elaboración se usan muchas veces funciones pertenecientes a otros paquetes.\nQue pasa cuando queremos ejecutar una función que necesita de otra que no tenemos instalada? Sucede que no es posible ejecutarla dado que no puede encontrar la o las funciones que están siendo llamadas en su propio código y no existen en la actual instalación de R; por lo tanto nos devolverá un mensaje de error alertando por la función desconocida.\nEsta relación de funciones que llaman a otras funciones se denomina dependencia. Es decir, que un paquete puede depender de otro u otros que tienen funciones que son llamadas y por ende, debe asegurarse su previa instalación para evitar el error.\nHay una forma de asegurarnos cuando instalamos un paquete que a su vez se instalen los paquetes del cual depende y es marcando la opción Install dependencies en la ventana anterior (Install Packages)."
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#lectura-de-archivos-de-datos",
    "href": "primero/clases/02-introRStudio.html#lectura-de-archivos-de-datos",
    "title": "Introducción a RStudio",
    "section": "Lectura de archivos de datos",
    "text": "Lectura de archivos de datos\nEl lenguaje nos permite importar variados formatos de tablas de datos utilizando funciones propias de R base como de paquetes que se dedican a esta tarea.\nEl formato nativo de tablas de datos de R es el texto plano (ASCII - Codigo Estadounidense Estandar para el Intercambio de Informacion) con sus columnas separadas por algún caracter. Estos pueden ser caracteres habituales como la coma (,) o el punto y coma (;) que da lugar a la extensión *.csv, o algunos especiales como la barra vertical (|) que suele utilizar el INDEC para sus productos o bien cualquier otro, como espacios o la tabulación.\nOtra característica que tienen estos archivos es que generalmente poseen una cabecera donde se ubican los nombres de cada columna/variable y por supuesto que cada una de ellas debe respetar un mismo tipo de dato para cumplir con la condición que la hace una tabla/base de datos.\nLo más importante para hacer una buena lectura de la tabla de datos con la que deseamos trabajar es conocer previamente el formato que tiene, si tiene cabecera, que caracter usa como separador de columnas, etc. Al ser un texto plano se puede abrir desde un simple Block de Notas de Windows o desde el mismo RStudio para conocer sus particularidades.\nActualmente y dentro del ecosistema con el que vamos a trabajar durante este curso hay un paquete con funciones diseñadas para importar estos tipos de archivos. Se llama readr y su fuerte es detectar el formato que tiene cada columna en el momento de la lectura.\nPosee una familia de funciones analizadoras donde se destacan:\n\nread_csv(): archivos separados por comas (CSV)\nread_delim(): archivos separados con delimitadores generales\nread_tsv(): archivos separados por tabulaciones\nread_fwf(): archivos con columnas de ancho fijo\nread_table(): archivos formato tabla con columnas separadas por espacios\n\nTodas estas funciones tiene argumentos comunes, además de file = donde se declara el nombre del archivo a importar entre comillas. Algunos de estos argumentos importantes son:\ncol_names = con TRUE le indicamos que la primera fila contiene los nombres de las columnas (con FALSE lo negamos)\nskip = salteamos una cantidad determinada de líneas que el archivo puede contener. En el caso que existan textos que no pertenecen al formato de la tabla de datos.\nlocale = es la configuración regional que el arhivo puede tener. Estos incluyen:\n\nLas marcas decimales y de agrupación, utilizadas al leer números.\nLa codificación de caracteres, utilizada al leer cadenas que no son ASCII.\nLos nombres de meses y días, utilizados al analizar fechas.\nLa zona horaria predeterminada, utilizada al analizar fechas y horas.\n\nLa adecuada configuración de este argumento evitará que palabras que tengan acentos o eñes o diferentes formatos de fecha sean bien reconocidos.\nPor lo tanto, nuestra tarea es hacer coincidir el formato de origen del archivo a leer con la función y los argumentos correctos.\nDurante el proceso de importación, decíamos que las funciones analizan columna por columna a que tipo de dato pertenecen. Los posibles tipos de datos son: character, integer, numeric, double, logical y date/time.\nPor ejemplo, si tenemos un archivo con punto y coma de separador, vamos a utilizar read_csv2() y si queremos importar la tabla de datos que ofrece el INDEC para los datos de las Encuestas Nacionales de Factores de Riesgo utilizaremos read_delim() declarando “|” dentro del argumento delim = (única función de la familia que la incorpora)."
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#agunas-buenas-prácticas-de-trabajo",
    "href": "primero/clases/02-introRStudio.html#agunas-buenas-prácticas-de-trabajo",
    "title": "Introducción a RStudio",
    "section": "Agunas buenas prácticas de trabajo",
    "text": "Agunas buenas prácticas de trabajo\n\nAgrupar nuestros datos, scripts y resultados dentro de proyectos de RStudio (Rproj)\nDeclarar en el inicio de los scripts la activación de paquetes necesarios para ejecutar las funciones incluídas en el código. ( función library() )\nDocumentar el código que vayamos creando por medio de comentarios (iniciados con #)\nCumplir con un correcto estilo de codificación (Intentar utilizar espacios e identación adecuada para que el código sea de fácil lectura)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gestión de datos epidemiológicos con R + RStudio",
    "section": "",
    "text": "Fundamentación\nLa vigilancia en salud y la investigación epidemiológica son pilares fundamentales para la salud pública, dado que a través de estas se recopilan, analizan e interpretan datos sobre la salud de las poblaciones, permitiendo identificar problemas de salud, evaluar la efectividad de intervenciones y formular políticas públicas basadas en evidencia.\nEn la actualidad, la generación y acumulación de datos en salud ha crecido exponencialmente, lo que presenta tanto un desafío como una oportunidad. El desafío radica en la capacidad de procesar y analizar grandes volúmenes de datos de manera eficiente y rigurosa, mientras que la oportunidad reside en la posibilidad de extraer información valiosa para mejorar la salud de las poblaciones.\nEn este contexto, el uso de lenguajes informático-estadísticos se ha vuelto indispensable para los profesionales de la salud pública. R es un lenguaje de programación y entorno de software estadístico gratuito y de código abierto, que ofrece una amplia gama de herramientas para el análisis de datos y la creación de visualizaciones. A su vez, RStudio es un entorno de desarrollo integrado (IDE) para R, que facilita la escritura, ejecución y depuración de código, así como la gestión de proyectos, la colaboración entre investigadores y la producción de documentos científicos y tableros dinámicos soportados por Quarto.\n\n\nContribución esperada:\nIncorporar habilidades técnicas vinculadas con el procesamiento de datos, análisis y visualización destinados a la producción de informes técnicos epidemiológicos utilizando un software de código abierto.\nObjetivos:\nSe espera que al finalizar este curso los participantes puedan:\n● Utilizar R + RStudio para procesar y analizar datos epidemiológicos\n● Aplicar en R y con filosofía tidyverse, metodología estadística en el análisis de datos de salud\n● Producir informes técnicos en diferentes formatos mediante Quarto\n\n\nInstructor\n\nChristian Ballejo    \n\n\n\nTemario\n\n\n\n\n\nFecha\n\n\nTema\n\n\nLectura\n\n\nDiapositiva\n\n\nPráctica\n\n\nRecursos\n\n\n\n\n\n\n01/10/2024\n\n\nBienvenida\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n01/10/2024\n\n\nDatos - Parte 1\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n03/10/2024\n\n\nDatos - Parte 2\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n15/10/2024\n\n\nDatos - Parte 3\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n17/10/2024\n\n\nLenguaje R\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n17/10/2024\n\n\nRStudio\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n17/10/2024\n\n\nTidyverse\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n22/10/2024\n\n\nImportación y exportación de archivos\n\n\n\n\n\n\n\n\n \n\n\n\n\n24/10/2024\n\n\nManipulación de datos\n\n\n\n\n\n\n\n\n\n\n\n\n29/10/2024\n\n\nDiagnóstico y depuración de datos\n\n\n \n\n\n\n\n\n\n \n\n\n\n\n31/10/2024\n\n\nDatos ordenados y relacionales\n\n\n\n\n\n\n\n\n \n\n\n\n\n05/11/2024\n\n\nGestión de tipos de datos: caracteres, factores y variables de tiempo\n\n\n \n\n\n\n\n\n\n\n\n\n\n07/11/2024\n\n\nAnálisis Exploratorio de datos - uni y bivariado\n\n\n \n\n\n\n\n\n\n \n\n\n\n\n14/11/2024\n\n\nVisualización de datos\n\n\n \n\n\n\n\n\n\n\n\n\n\n19/11/2024\n\n\nVisualización de datos\n\n\n\n\n\n\n\n\n\n\n\n\n21/11/2024\n\n\nComunicar - Documentos Quarto\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nBibliografía\nR for Data Science (2e)\nEpiRhandbook en español\nData Visualization\nFundamentos de ciencia de datos con R\nGuía de Quarto (en inglés)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "primero/clases/01-introR.html",
    "href": "primero/clases/01-introR.html",
    "title": "Introducción al lenguaje R",
    "section": "",
    "text": "El sitio oficial r-project.org dice que “R es un entorno de software libre para gráficos y computación estadística. Se compila y se ejecuta en una amplia variedad de plataformas UNIX, Windows y MacOS.”.\nProfundizando en su descripción podemos decir, técnicamente, que es un lenguaje de programación interpretado, orientado a objetos, multiplataforma y open source aplicado al manejo de datos estadísticos.\nA continuación detallamos cada parte de la definición:\nR es un lenguaje de programación estadístico\nR es un lenguaje de programación, con sus estructuras y reglas de sintaxis, que posee una gran variedad de funciones desarrolladas con fines estadísticos.\nR es un lenguaje Orientado a Objetos\nImplementa conceptos de la programación orientada a objetos y esto le permite ser simple y flexible en el manejo de datos. En R todo con lo que trabajamos es considerado un “objeto”: las variables, funciones, datos, resultados, etc. que pueden ser modificados por otros objetos.\nR es un lenguaje interpretado\nNo es necesario compilar los scripts de programación para construir ejecutables sino que directamente se ejecutan por medio del intérprete que devuelve resultados de forma inmediata.\nR es multiplataforma (corre en Linux, Windows y Mac)\nFunciona en diferentes sistemas operativos como Linux, Windows y Mac.\nR es Open Source y se distribuye bajo licencia GNU - GPL\nEsto quiere decir que se distribuye gratuitamente bajo licencia GNU (General Public License) – GPL y que los usuarios tienen la libertad de usar, estudiar, compartir (copiar) y modificar el software."
  },
  {
    "objectID": "primero/clases/01-introR.html#qué-es-el-lenguaje-r",
    "href": "primero/clases/01-introR.html#qué-es-el-lenguaje-r",
    "title": "Introducción al lenguaje R",
    "section": "",
    "text": "El sitio oficial r-project.org dice que “R es un entorno de software libre para gráficos y computación estadística. Se compila y se ejecuta en una amplia variedad de plataformas UNIX, Windows y MacOS.”.\nProfundizando en su descripción podemos decir, técnicamente, que es un lenguaje de programación interpretado, orientado a objetos, multiplataforma y open source aplicado al manejo de datos estadísticos.\nA continuación detallamos cada parte de la definición:\nR es un lenguaje de programación estadístico\nR es un lenguaje de programación, con sus estructuras y reglas de sintaxis, que posee una gran variedad de funciones desarrolladas con fines estadísticos.\nR es un lenguaje Orientado a Objetos\nImplementa conceptos de la programación orientada a objetos y esto le permite ser simple y flexible en el manejo de datos. En R todo con lo que trabajamos es considerado un “objeto”: las variables, funciones, datos, resultados, etc. que pueden ser modificados por otros objetos.\nR es un lenguaje interpretado\nNo es necesario compilar los scripts de programación para construir ejecutables sino que directamente se ejecutan por medio del intérprete que devuelve resultados de forma inmediata.\nR es multiplataforma (corre en Linux, Windows y Mac)\nFunciona en diferentes sistemas operativos como Linux, Windows y Mac.\nR es Open Source y se distribuye bajo licencia GNU - GPL\nEsto quiere decir que se distribuye gratuitamente bajo licencia GNU (General Public License) – GPL y que los usuarios tienen la libertad de usar, estudiar, compartir (copiar) y modificar el software."
  },
  {
    "objectID": "primero/clases/01-introR.html#breve-historia",
    "href": "primero/clases/01-introR.html#breve-historia",
    "title": "Introducción al lenguaje R",
    "section": "Breve historia",
    "text": "Breve historia\nR fue desarrollado a partir del lenguaje S que tiene sus orígenes en Bell Labs de la AT&T (actualmente Lucent Technologies) de mediados de la década del ’70. Posteriormente, S fue vendido y dio origen a una versión propietaria denominada S-Plus que es comercializada por Insighful Corporation.\nEn 1995 dos profesores de estadística de la Universidad de Auckland, en Nueva Zelanda Ross Ihaka y Robert Gentleman, iniciaron el “Proyecto R”, con la intención de desarrollar un programa estadístico inspirado en el lenguaje S pero de dominio público.\nAunque se dice que R es un dialecto de S existen diferencias importantes en el diseño de ambos lenguajes.\nEl software está desarrollado en lenguaje C++ con algunas rutinas agregadas en Fortran) y su nombre se debe a la letra con la que inician los nombres de pila de sus autores (Ross y Robert).\nActualmente es mantenido por un grupo internacional de desarrolladores voluntarios denominado Core Development Team."
  },
  {
    "objectID": "primero/clases/01-introR.html#scripts",
    "href": "primero/clases/01-introR.html#scripts",
    "title": "Introducción al lenguaje R",
    "section": "Scripts",
    "text": "Scripts\nUn script es un archivo de texto plano con una lista secuencial de funciones y comandos del lenguaje R para ser ejecutado por el intérprete de R.\nScript se puede traducir como guión, archivo de órdenes, archivo de procesamiento por lotes o archivo de sintaxis.\nGeneralmente se crea en editores especiales y/o en cualquier procesador básico de texto plano. Se almacena en un archivo que puede ser leído, modificado, guardado y se puede ejecutar completo o línea a línea.\nPoseen una cualidad muy provechosa: son re-utilizables, adaptándolos a otras necesidades.\nDocumentación de los scripts de R:\nLa documentación es una tarea de mucha importancia en cualquier lenguaje de programación, ya que nos permite entender que estamos haciendo en el script. Además nos sirve para el futuro mantenimiento o para la reutilización del código elaborado, tanto para otros usuarios como para nosotros mismos.\nLa forma de documentar los scripts de código en R es utilizando comentarios. Toda línea que comienza con el símbolo # es entendido por el interprete como un comentario y los caracteres que sigan a ese símbolo no seran tenidos en cuenta cuando se ejecute ese código.\n\n# esto es una línea de comentario y no es tenida en cuenta por el intérprete\n\nAsí que a la hora de documentar es preferible abusar de estos comentarios que no utilizarlos."
  },
  {
    "objectID": "primero/clases/01-introR.html#funciones",
    "href": "primero/clases/01-introR.html#funciones",
    "title": "Introducción al lenguaje R",
    "section": "Funciones",
    "text": "Funciones\nLos comandos u órdenes elementales de R se denominan funciones. A algunas se las llama “integradas” porque están incluidas en el núcleo (R base) y sus nombres están reservados.\nTambien podemos utilizar otras pertenecientes a librerías (paquetes) que se pueden instalar y activar.\nToda función tiene un nombre y normalmente recibe argumentos o parámetros que deben ser escritos entre paréntesis y separados por comas. Incluso algunas de ellas que no tienen asociado ningún argumento necesitan finalizar con paréntesis () para ser entendidas como funciones.\nSiempre una función devuelve un resultado, un valor o realiza una acción.\n\n\n\n\n\n\n\n\n\nComo el interprete de R no permite errores en la sintaxis de las expresiones, debemos atender a los siguientes puntos a la hora de escribirlas:\n\nLa sintaxis habitual de una función y sus argumentos es la siguiente:\n\n\nfuncion(arg1, arg2, arg3,...)\n\n\nLos títulos de los argumentos pueden escribirse y mediante un igual agregar el valor correspondiente. También se puede omitir el título del argumento y escribir directamente el valor, pero en este caso, hay que respetar el orden definido por la función.\n\n\nfuncion(arg1=32, arg2=5, arg3=65,...)\n\nes igual a hacer:\n\nfuncion(32, 5, 65,...)\n\nsiempre que se respete el mismo orden.\n\nCon los argumentos se deben cumplir las mismas reglas que en todo el lenguaje. Los valores numéricos, lógicos, especiales y objetos van escritos en forma directa y cuando escribimos caracteres (texto) van necesariamente encerrados entre comillas.\n\n\nfuncion(arg1=3, arg2=NA, arg3=TRUE, arg4=\"less\", arg5=x,...)"
  },
  {
    "objectID": "primero/clases/01-introR.html#librerías-paquetes",
    "href": "primero/clases/01-introR.html#librerías-paquetes",
    "title": "Introducción al lenguaje R",
    "section": "Librerías (paquetes)",
    "text": "Librerías (paquetes)\nLas librerías son grupos de funciones empaquetados que se pueden instalar y utilizar en el análisis de datos. Habitualmente se agrupan por tema o similitud de funciones.\nEstos paquetes se pueden descargar directamente del repositorio oficial de CRAN en Internet (similar al uso de los repositorios de Linux) o bien descargar en formato .zip para luego instalar y usar.\nSe pueden activar y desactivar en cualquier momento del análisis.\nAlgunos poseen dependencias de otros paquetes que serán necesarios para que funcione."
  },
  {
    "objectID": "primero/clases/01-introR.html#sintaxis-errores-y-advertencias",
    "href": "primero/clases/01-introR.html#sintaxis-errores-y-advertencias",
    "title": "Introducción al lenguaje R",
    "section": "Sintaxis, errores y advertencias",
    "text": "Sintaxis, errores y advertencias\nEl lenguaje es muy preciso en su sintaxis y equivocarse en la forma de escribir una función o cualquier otro objeto produce respuestas de error del interprete de R que es habitual cuando iniciamos el aprendizaje.\nLa exactitud en la escritura de comandos y funciones incluye la distinción entre mayúsculas y minúsculas. Es decir, que no es lo mismo una ‘a’ que una ‘A’.\nExisten tres grupos de mensajes de error:\n\nerror de sintaxis\nerror de objeto no encontrado\notros errores\n\nSe dice que hay un error de sintaxis, cuando ejecutamos una línea de código que el motor de R no puede interpretar debido a que algo está mal escrito.\nHabitualmente los errores de sintaxis se deben a que falta o sobra algún elemento necesario en la estructura de una función (comas, parentesis, llaves, corchetes, comillas, etc.)\nPor ejemplo la función rep() repite valores una cantidad de veces. Tiene dos argumentos, x donde se coloca el valor a repetir y times donde se define la cantidad de veces.\n\nrep(x = 3, times = 4) #repetimos 4 veces 3 con rep()\n\n[1] 3 3 3 3\n\n\nSi nos olvidamos de cerrar el paréntesis…\n\nrep(x = 3, times = 4\n    \nError: Incomplete expression: rep(x = 3, times = 4\n\nSi nos olvidamos de separar los argumentos con la coma\n\nrep(x = 3 times = 4)\n\nError: unexpected symbol in \"rep(x =3 times\"\n\nSi en lugar de escribir x como primer argumento y escribimos otra letra…\n\nrep(y =3, times = 4)\n\nError in rep(y = 3, times = 4) : \n  attempt to replicate an object of type 'symbol'\n\nSi escribimos mal la función…\n\nREP(x =3, times = 4)\n\nError in REP(x = 3, times = 4) : no se pudo encontrar la función \"rop\"\n\nEsta última posibilidad es similar a un “objeto no encontrado” por error de sintaxis.\nLos mensajes de error en general y sobre todo al principio pueden parecer extraños y difíciles de entender, pero con un poco de práctica podemos inferir donde está el problema.\nLos errores de objetos no encontrados pueden tener una de varias causas:\n\nel nombre no se escribió correctamente (p.ej.: sintaxis, mayúsculas / minúsculas)\nel paquete o archivo que contiene el objeto no ha sido cargado\nolvidamos poner comillas en un lugar que corresponde\notros motivos posibles\n\nVolvamos al ejemplo anterior, ahora repitiendo un valor tipo character\n\nrep(x = \"A\", times = 4) #repetimos 4 veces 3 con rep()\n\n[1] \"A\" \"A\" \"A\" \"A\"\n\n\nSi olvidamos las comillas…\n\nrep(x = A, times = 4) #repetimos 4 veces 3 con rep()\n\nError: objeto 'A' no encontrado\n\nAdvertencias\nUna advertencia no es algo tan serio, como un error, o al menos no lo parece, ya que esta permite que la función se ejecute igual. Pero puede ocurrir que ignorar una advertencia llegue a ser algo muy serio, si esto implica que la salida de la función es equivocada.\nPor lo tanto, es una buena política entender los mensajes de advertencia para ver si indican problemas para preocuparnos o no.\nResumiendo:"
  },
  {
    "objectID": "primero/clases/01-introR.html#creación-de-objetos",
    "href": "primero/clases/01-introR.html#creación-de-objetos",
    "title": "Introducción al lenguaje R",
    "section": "Creación de objetos",
    "text": "Creación de objetos\nTodas las declaraciones donde se crean objetos, tienen este símbolo de asignación &lt;-.\n\nnombre_objeto &lt;- valor\n\nVeámoslo en un ejemplo:\n\na &lt;- 1\n\nEn este caso asignamos el valor 1 al objeto a. El objeto a es un vector de una posición (un solo valor).\nSi llamasemos al objeto a, el interprete nos devuelve el valor asignado previamente.\n\na\n\n[1] 1\n\n\nObservemos que además de devolvernos el valor aparece delante un 1 entre corchetes [1].Este número es la ubicación o índice del comienzo del objeto, que en este caso tiene una sola posición."
  },
  {
    "objectID": "primero/clases/01-introR.html#estructuras-de-datos",
    "href": "primero/clases/01-introR.html#estructuras-de-datos",
    "title": "Introducción al lenguaje R",
    "section": "Estructuras de datos",
    "text": "Estructuras de datos\nLos objetos contenedores de datos más simples pertenecen a cinco clases que se denominan atómicas y que son los siguientes tipos de datos:\n\ninteger (números enteros)\nnumeric / double (números reales)\ncomplex (números complejos)\nchacacter (cadena de caracteres)\nlogical (lógicos o booleanos – toman valores por si o no)\n\n\n\n\n\n\n\n\n\n\nSin embargo, cada una de estas clases de datos no se encuentran de manera aislada, sino encapsulados dentro de la clase de objeto operacional más básica del lenguaje a la que se denomina vector.\nVector\nUn vector es un conjunto de valores (números o símbolos), todos del mismo tipo ordenados de la forma (elemento 1, elemento 2, … , elemento \\(n\\)) y \\(n\\) es la longitud o tamaño del vector.\nSurge de la definición dos términos importantes: el tipo y la longitud.\nTodos los objetos de datos tienen estos dos atributos intrínsecos.\n\nel tipo, que puede ser integer, numeric, chacacter, complex y logical\nla longitud, que es el número de elementos que contiene el objeto.\n\nEl vector más simple es el que contiene un dato, podría ser numérico de un solo dígito. El tipo sería numeric y la longitud 1.\n\nvec1 &lt;- 1\nvec1\n\n[1] 1\n\n\nOtro vector más grande por ejemplo podría ser (1,5,2). En este caso también es del tipo numeric pero tiene una longitud de 3 elementos (3 posiciones que integran el vector).\n\nvec2 &lt;- c(1,5,2)\nvec2\n\n[1] 1 5 2\n\n\nComo vemos, para concatenar estos tres valores numéricos usamos la forma c(). Esta c es una función de R, justamente para concatenar. (todo lo que aparece siempre antes de paréntesis es una función). Dentro de la función los valores van separados por comas.\nAquí podemos señalar otra característica, según la definición de vector, la colección de elementos se encuentra ordenada, por lo que en nuestro ejemplo la primera posición la ocupa el 1, la segunda el 5 y la tercera el 2. Como el orden importa, si tuviese otro vector (5,1,2), a pesar de tener los mismos elementos no sería el mismo vector porque están ordenados de forma diferente.\nPara ver la longitud del vector usamos:\n\nlength(vec2)\n\n[1] 3\n\n\nNos informa que vec2 tiene 3 elementos.\nAsimismo podemos ver que los datos almacenados en este segundo ejemplo cumplen con la definición en lo que respecta al tipo de dato, ya que cada elemento es del mismo tipo (numeric).\nPara conocer la clase del dato ejecutamos:\n\nclass(vec2)\n\n[1] \"numeric\"\n\n\nVeamos un ejemplo de asignación de otro tipo de dato atómico, como es el character:\n\nvec3 &lt;- \"Hola\"\nvec3\n\n[1] \"Hola\"\n\n\nSiempre que escribamos contenido de tipo caracter debemos hacerlo entre comillas. En este caso generamos el vector vec3 con el contenido “Hola”. A pesar de ser una palabra que, por supuesto, esta compuesta de varios caracteres, dentro del vector vec3 esta ocupa una sola posición.\n\nlength(vec3)\n\n[1] 1\n\n\nRespecto a la clase del dato si usamos la función class() tendremos:\n\nclass(vec3)\n\n[1] \"character\"\n\n\nDataframe\nUn dataframe es un objeto cuya finalidad es contener conjuntos de datos. Se asemeja a una tabla que tiene filas y columnas (dos dimensiones), donde cada columna puede almacenar elementos de diferentes tipos.\nAdemás las columnas suelen tener nombres únicos y podemos referenciarlas por estos nombres, como si fueran variables del conjunto de datos.\nEs el tipo de objeto que utilizamos para almacenar información leída de tablas de datos provenientes de archivos externos (formato texto separado por comas, Excel, etc) y con las cuales acostumbramos a trabajar en el análisis.\nDesde el punto de vista de su estructura, todo dataframe esta conformado por una serie de vectores de la misma longitud ubicados verticalmente uno al lado de otro.\nPodemos verlo en la siguiente porción de código:\n\nHC &lt;- c(\"F324\", \"G21\", \"G34\", \"F231\")\nedad &lt;- c(34,32,34,54)\nsexo &lt;- c(\"M\", \"H\", \"H\", \"M\")\n\ndf1 &lt;- data.frame(HC, edad, sexo)\n\ndf1\n\n    HC edad sexo\n1 F324   34    M\n2  G21   32    H\n3  G34   34    H\n4 F231   54    M\n\n\nCreamos tres vectores con datos de supuestos individuos, su historia clinica, la edad y el sexo. Luego mediante la función data.frame() “unimos” esos vectores en forma vertical para formar un dataframe de 3 variables y 4 observaciones.\nExisten otras estructuras de datos que aparecen en la siguiente figura. Las más habituales en nuestro trabajo son los vectores y los dataframes."
  },
  {
    "objectID": "primero/clases/01-introR.html#operadores-en-r",
    "href": "primero/clases/01-introR.html#operadores-en-r",
    "title": "Introducción al lenguaje R",
    "section": "Operadores en R",
    "text": "Operadores en R\nAdemás de funciones, el lenguaje R cuenta con operadores similares a otros lenguajes de programación, que permiten realizar operaciones con datos.\n\nR como calculadora\nEl lenguaje R cuenta con operadores aritméticos de uso relativamente intuitivo, que permiten realizar operaciones matemáticas como si usasemos una calculadora.\n\n\n\n\n\n\n\n\n\n\n# suma\n2 + 5\n\n[1] 7\n\n# resta\n3 - 2\n\n[1] 1\n\n# multiplicación\n9 * 3\n\n[1] 27\n\n# división\n10 / 2\n\n[1] 5\n\n# potenciación\n5 ^ 2\n\n[1] 25\n\n\nNota: observarán que el interprete del lenguaje al devolvernos un valor en consola lo muestra con una notación inicial de un 1 encerrado entre corchetes [1]. Este número es el índice del vector que nos está mostrando R y que siempre comienza con 1. Si la cantidad de elementos de un vector mostrados por la consola superase el ancho de la pantalla, entonces el listado seguiría debajo y al comienzo de la nueva línea veríamos otro número entre corchetes que sería el indice de ese primer valor. Veamos un ejemplo:\n\n\n [1] 0.10 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24\n[16] 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39\n[31] 0.40 0.41 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.50 0.51 0.52 0.53 0.54\n[46] 0.55 0.56 0.57 0.58 0.59 0.60 0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69\n[61] 0.70 0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.80 0.81 0.82 0.83 0.84\n[76] 0.85 0.86 0.87 0.88 0.89 0.90\n\n\nEl 0.25 que es primer valor de la segunda fila esta en la posición 16 de ese vector de números. Y, por ejemplo, el 0.70 en la posición 61.\nPara otras operaciones matemáticas como la raíz cuadrada o el valor absoluto de un múmero, existen funciones específicas incluídas en R base.\n\n# radicación (raíz cuadrada)\nsqrt(9)\n\n[1] 3\n\n# valor absoluto\nabs(-3)\n\n[1] 3\n\n\nTambién se pueden hacer operaciones con los objetos que almacenan a estos valores numéricos asignados:\n\n# a contiene el valor 3\na &lt;- 3\n\n# b contiene el valor 6\nb &lt;- 6\n\n# aplicamos una fórmula determinada\n(a + b) * b\n\n[1] 54\n\n\nY funciona con objetos como los vectores que contienen más de un elemento, aplicando artimética vectorial, donde las operaciones se realizan elemento a elemento.\n\n# creamos el vector a con 3 elementos\na &lt;- c(1, 2, 3)\n\n# ejecutamos una operación matemática a todos los elementos de a\na * 3\n\n[1] 3 6 9\n\n\nO bien, con operaciones entre objetos, donde se las operaciones se realizan entre los elementos de la misma posición:\n\n# creamos el vector a con 3 elementos\na &lt;- c(1, 2, 3)\n\n# ejecutamos una operación matemática a todos los elementos de a * a\na * a\n\n[1] 1 4 9\n\n\nMediante sum() se puede hacer sumatorias de elementos en vectores numéricos.\n\n# creamos el vector a con 3 elementos\na &lt;- c(1, 2, 3)\n\n# realizamos una sumatoria de todos los elementos de a\nsum(a)\n\n[1] 6\n\n\nOtra función muy utilizada es la que permite que redondeemos valores con decimales.\n\n## redondeamos definiendo 2 digitos decimales\n\nround(23.76859, digits = 2)\n\n[1] 23.77"
  },
  {
    "objectID": "primero/clases/01-introR.html#concatenación-y-secuencias-regulares",
    "href": "primero/clases/01-introR.html#concatenación-y-secuencias-regulares",
    "title": "Introducción al lenguaje R",
    "section": "Concatenación y secuencias regulares",
    "text": "Concatenación y secuencias regulares\nYa usamos la función c() para concatenar elementos. Habitualmente cuando deseemos crear vectores con más de un elemento vamos a recurrir a esta función.\n\n# vector numérico de 4 elementos\nc(6, 3, 6, 8)\n\n[1] 6 3 6 8\n\n# vector caracter de 2 elementos\nc(\"Hola\", \"Chau\")\n\n[1] \"Hola\" \"Chau\"\n\n\nExiste otra forma de concatenar elementos a partir de un operador de rango. Produce un intervalo secuencial de enteros que puede ser ascendente o descendente. El operador es : y se usa de la siguiente forma:\n\n# ascendente\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# descendente\n10:1\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nOtra manera es por medio de la función seq() que tiene como argumentos principales from, to y by\n\n# secuencia de 1 a 20 cada 2\nseq(from = 1, to = 20, by = 2)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\nAlgunos otros ejemplos de la misma función pueden ser:\n\n# secuencia de 0.1 a 0.9 cada 0.1\nseq(from = 0.1, to = 0.9, by = 0.1)\n\n[1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n\n# secuencia de -5 a 5 cada 1\nseq(from = -5, to = 5, by = 1)\n\n [1] -5 -4 -3 -2 -1  0  1  2  3  4  5\n\n# secuencis de 300 a 0 cada 50 (se escribe -50 porque es descendente)\nseq(from = 300, to = 0, by = -50)\n\n[1] 300 250 200 150 100  50   0\n\n\nFinalmente la última posibilidad que vamos a mostrar es la función rep() que repite valores. Su forma más sencilla es rep(x, times = Nº) que coloca un Nº de repeticiones de x, una tras otra.\nAlgunos ejemplos de la función:\n\n# repetimos 5 veces el número 2\nrep(x = 2, times = 5)\n\n[1] 2 2 2 2 2\n\n# combinada con el operador de rango\nrep(1:4, 5)  \n\n [1] 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4\n\n# combinada con la función de concatenación\nrep(c(4.5,6.8,7.2), 2) \n\n[1] 4.5 6.8 7.2 4.5 6.8 7.2\n\n\nTambién existen operadores relacionales y conectores lógicos que vamos a ver más adelante, cuando por ejemplo, necesitemos construir condiciones para filtrar subconjuntos de datos."
  },
  {
    "objectID": "primero/clases/01-introR.html#valores-especiales-en-r",
    "href": "primero/clases/01-introR.html#valores-especiales-en-r",
    "title": "Introducción al lenguaje R",
    "section": "Valores especiales en R",
    "text": "Valores especiales en R\nExisten algunos valores especiales para datos con expresiones reservadas en R, entre ellos encontramos los valores NA, NaN, Inf y NULL.\n\n\n\n\n\n\n\n\n\nEl más relevante de estos valores especiales es el NA que sirve para indicar la inexistencia de valor."
  },
  {
    "objectID": "primero/clases/03-introTidy.html#introducción",
    "href": "primero/clases/03-introTidy.html#introducción",
    "title": "Tidyverse",
    "section": "Introducción",
    "text": "Introducción\nTidyverse es el nombre que se ha dado al conjunto de paquetes desarrollados a partir de la inciativa de Hadley Wickham (jefe científico de Posit -antes RStudio-) y su equipo, para ciencia de datos con R.\nEstos paquetes están diseñados para funcionar juntos y comparten una misma filosofía, que se puede consultar en The tidy tools manifesto.\nLos cuatro principios básicos en los que se basa son:\n\nReutilizar las estructuras de datos\nResolver problemas complejos combinando varias piezas sencillas\nUtilizar programación funcional\nDiseñado para humanos\n\nLos paquetes incluidos en el tidyverse tienen como objetivo cubrir todas las fases del análisis de datos dentro de R: importar datos, ponerlos en formato ordenado (tidy data), buscar relaciones entre ellos (mediante su transformación, visualización y creación de modelos) y comunicar los resultados.\nLa palabra “tidy” se puede traducir como “ordenado” y refiere a que los datos deben cumplir con una estructura determinada donde:\n\nCada variable es una columna de la tabla de datos.\nCada observación es una fila de la tabla de datos.\nCada tabla responde a una unidad de observación o análisis.\n\n\n\n\n\n\n\n\n\n\nAdemás de los paquetes principales que realizan estas funciones, al instalar el tidyverse también se proporcionan otros que ayudan a trabajar con fechas, cadenas de caracteres o factores siguiendo los mismos principios.\nUna de las interesantes incorporaciones transversales en el ambiente tidyverse es el uso de tuberías (pipe en inglés).\nUna tubería conecta un trozo de código con otro mediante el conector %&gt;% que surge del paquete magrittr que permite transformar llamadas de funciones anidadas (con muchos paréntesis) en una simple serie de operaciones que son más fáciles de escribir y comprender. Este aporte fue tan importante que el equipo de desarrolladores que mantiene el lenguaje R incorporó la idea a partir de la versión 4.1.0 de 2021, agregando la funcionalidad nativa con el operador |&gt;.\nNota: durante el curso pueden llegar a coexistir ambas tuberías, dado que funcionan igual. De todas maneras, al utilizar versiones actualizadas del lenguaje preferimos utilizar la tubería nativa que es más eficiente que la propia del tidyverse.\nLa idea de tubería responde al principio donde cada función es un paso y la forma de trabajar se puede ver en el siguiente esquema general:\n\n\n\n\n\n\n\n\n\nBase gramatical\nLa intención de los desarrolladores para este conjunto de paquetes es lograr incorporar una gramática a la sintaxis de las funciones y sus argumentos buscando un entendimiento semántico más claro.\nUna prueba de ello, es que la mayoría de las funciones son verbos que se entrelazan con objetos y argumentos que permiten construir “frases”."
  },
  {
    "objectID": "primero/clases/03-introTidy.html#el-paquete-de-paquetes",
    "href": "primero/clases/03-introTidy.html#el-paquete-de-paquetes",
    "title": "Tidyverse",
    "section": "El paquete de paquetes",
    "text": "El paquete de paquetes\nEl paquete tidyverse nucleo actual (versión 2.0.0) se puede descargar del repositorio oficial CRAN mediante menú Packages de RStudio o ejecutando en consola:\n\ninstall.packages(\"tidyverse\")\n\nSe activa, como cualquier otro paquete, mediante:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::extract() masks dlookr::extract()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nObservamos que nos informa sobre la versión del paquete, el listado de paquetes que acabamos de activar sólo llamando a tidyverse y una serie de conflictos de nombres de funciones.\nEsto es muy habitual cuando activamos varios paquetes, dado que las funciones que se encuentran dentro de ellos pueden llamarse iguales.\nPor ejemplo, existe en el paquete base stats y en el paquete dplyr (que es parte de tidyverse) una función llamada filter(), por lo tanto al activar tidyverse nos informa de esta manera: dplyr::filter() masks stats::filter()\nEn este caso, cuando necesitemos asegurarnos que la función que deseamos ejecutar pertenece a determinado paquete, es recomendable escribirla de la siguiente forma:\n\nnombre_paquete::nombre_función\n\nstats::filter() para la función filter() del paquete stats\ndplyr::filter() para la función filter() del paquete dplyr\nLos paquetes incluidos que se instalan en esta versión son 31:\n\ntidyverse_packages()\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\nExisten otros paquetes (la cantidad crece con el tiempo) que son creados bajo la misma filosofía pero no están incluidos. En esos casos hay que instalarlos y activarlos individualmente.\nPara profundizar sobre tidyverse se puede visitar el sitio https://www.tidyverse.org/ y la primera versión del libro traducido al español r4ds. La segunda versión está disponible en inglés en r4ds(2e)"
  },
  {
    "objectID": "primero/clases/03-introTidy.html#lectura-y-escritura-de-datos",
    "href": "primero/clases/03-introTidy.html#lectura-y-escritura-de-datos",
    "title": "Tidyverse",
    "section": "Lectura y escritura de datos",
    "text": "Lectura y escritura de datos\n\nPaquete readr\nreadr contiene funciones similares a las de la familia read.table() de R base pero desarrollados bajo el ecosistema tidyverse.\nLos archivos de texto plano (ASCII y otras codificaciones) son universalmente utilizados por la mayoría de los gestores de bases de datos y/o planillas de cálculo. Generalmente encontrados con extensiones .txt o .csv (por comma-separated values) son el tipo de archivo de datos más habitual dentro del lenguaje R.\nEstos datos planos tienen dos peculiaridades:\n\nLa cabecera (en inglés header)\nEl caracter o símbolo separador que indica la separación de columnas: pueden estar separadas por comas, puntos y comas, por tabulación, etc…\n\nLa cabecera puede existir o no, y de existir puede ser simple o compleja. La inclusión o no de la cabecera se maneja desde los argumentos col_names y skip.\nCon col_names = TRUE incluimos la primer fila como cabecera (nombre de las columnas) y en FALSE la salteamos.\nCon skip = 0 la lectura de produce desde la primer fila (se puede omitir), pero si la cabecera fuese compleja con varias filas entre títulos y subtítulos, debemos indicar cuantas filas iniciales se “saltea”. Por ejemplo con skip = 5 se saltea las primeras 5 filas del archivo.\nEl otro elemento a tener en cuenta es el caracter separador que utiliza el archivo para indicar cuando comienza una nueva columna (variable).\nGeneralmente los separadores más comunes son: la coma (,), el punto y coma (;), el tabulador (TAB), el espacio ( ), el caracter pipe (|), entre otros posibles.\nAlgunas de las funciones del paquete asumen un separador particular. Por caso read_csv() lee separados por coma y read_tsv() separado por tabulaciones, pero la función read_delim() permite que definamos el separador a través del argumento delim =.\nEn forma detallada el paquete readr soporta siete formatos de archivo a partir de siete funciones:\n\nread_csv(): archivos separados por comas (CSV)\nread_tsv(): archivos separados por tabulaciones\nread_delim(): archivos separados con delimitadores generales\nread_fwf(): archivos con columnas de ancho fijo\nread_table(): archivos formato tabla con columnas separadas por espacios\nread_log(): archivos log web\n\nEn comparación con las funciones base de R, las funciones de readr:\n\nUsan un esquema de nombres consistente de parámetros\nSon más rápida.\nAnalizan eficientemente los formatos de datos comunes, incluyendo fecha/hora.\nMuestran una barra de progreso si la carga va a llevar un tiempo. (para archivos grandes)\n\nViene incluida dentro de la instalación de tidyverse y se activa con él, pero también permite activarse solo:\n\nlibrary(readr)\n\nAlgunos ejemplos de sintaxis:\n\nLeemos un archivo sin cabecera separado por comas\n\n\nread_csv(\"datos/ejemplo-datos.csv\", col_names = F)\n\n# A tibble: 6 × 5\n     X1 X2      X3       X4    X5        \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt; &lt;date&gt;    \n1     9 Leone   Fernando M     1958-12-24\n2    26 Salem   Esteban  M     1954-01-21\n3    35 Orduna  Nicolas  M     1993-06-27\n4    48 Manueli Viviana  F     1965-06-21\n5    49 Orozco  Laura    F     1993-08-15\n6    55 Umpier  Leopoldo M     1952-10-11\n\n\n\nLeemos el mismo archivo con cabecera y separado por punto y comas\n\n\nread_csv2(\"datos/ejemplo-datos-header.csv\", col_names = T)\n\n# A tibble: 6 × 5\n   Iden Apellido Nombre   Sexo  FNac      \n  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;date&gt;    \n1     9 Leone    Fernando M     1958-12-24\n2    26 Salem    Esteban  M     1954-01-21\n3    35 Orduna   Nicolas  M     1993-06-27\n4    48 Manueli  Viviana  F     1965-06-21\n5    49 Orozco   Laura    F     1993-08-15\n6    55 Umpier   Leopoldo M     1952-10-11\n\n\n\nLeemos el archivo con cabecera separado por tabulaciones\n\n\nread_tsv(\"datos/ejemplo-datos-header2.csv\", col_names = T)\n\nRows: 6 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (3): Apellido, Nombre, Sexo\ndbl  (1): Iden\ndate (1): FNac\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 6 × 5\n   Iden Apellido Nombre   Sexo  FNac      \n  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;date&gt;    \n1     9 Leone    Fernando M     1958-12-24\n2    26 Salem    Esteban  M     1954-01-21\n3    35 Orduna   Nicolas  M     1993-06-27\n4    48 Manueli  Viviana  F     1965-06-21\n5    49 Orozco   Laura    F     1993-08-15\n6    55 Umpier   Leopoldo M     1952-10-11\n\n\nObservemos que cada vez que hacemos una lectura la función se encarga de analizar (parse) el tipo de dato que hay en cada columna. En esta última ocasión además, devuelve un listado con el resultado del análisis antes de mostrar la tabla importada.\nLos posibles tipos de datos son los atómicos del lenguaje más algún agregado: character, integer, numeric, double, logical y date/time.\nPor ejemplo, en la tabla leída anteriormente las columnas donde hay números enteros fueron reconocidos como double (&lt;dbl&gt;), los que tienen algún caracter como character (&lt;chr&gt;) y las fechas como date (&lt;date&gt;).\nAhora escribimos la sintaxis para leer un archivo con cabecera compleja (la tabla comienza en la fila 9) separado por |.\n\nread_delim(\"datos/ejemplo-datos-header-skip.txt\", \n           col_names = T, \n           skip = 8,      # salteamos las primeras 8 filas\n           delim = \"|\")\n\n# A tibble: 6 × 5\n   Iden Apellido Nombre   Sexo  FNac      \n  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;     \n1     9 Leone    Fernando M     24/12/1958\n2    26 Salem    Esteban  M     21/01/1954\n3    35 Orduna   Nicolas  M     27/06/1993\n4    48 Manueli  Viviana  F     21/06/1965\n5    49 Orozco   Laura    F     15/08/1993\n6    55 Umpier   Leopoldo M     11/10/1952\n\n\n\nEn estos ejemplos visualizamos el contenido de los archivos leídos en consola con el propósito de mostrar como trabajan las funciones, pero en la práctica cada vez que importemos datos de un archivo debemos asignar su salida a un nombre, que será el nombre del dataframe que reciba los datos dentro de nuestra sesión de trabajo. (&lt;-)\n\n\nFunciones de escritura\nDentro del paquete coexisten funciones espejo de escritura para las posibilidades de lectura más relevantes. Así encontramos estos cuatro:\n\nwrite_csv(): escribe archivos separados por comas (csv)\nwrite_csv2(): escribe archivos separados por punto y comas (csv)\nwrite_tsv(): escribe archivos separados por tabulaciones\nwrite_delim(): escribe archivos separados con delimitadores definidos por el usuario\n\nLos argumentos son generales y para el caso del último más extensos, dado que hay que definir cual es el separador que deseamos en el archivo.\n\nargs(write_delim)\n\nfunction (x, file, delim = \" \", na = \"NA\", append = FALSE, col_names = !append, \n    quote = c(\"needed\", \"all\", \"none\"), escape = c(\"double\", \n        \"backslash\", \"none\"), eol = \"\\n\", num_threads = readr_threads(), \n    progress = show_progress(), path = deprecated(), quote_escape = deprecated()) \nNULL\n\n\nPor ejemplo para exportar un conjunto de datos en texto plano al que denominaremos ejemplo.csv con separador punto y coma y cabecera incluida podemos hacer:\n\nwrite_delim(x = datos, file = \"ejemplo.csv\", delim = \";\")\n\no más sencillo:\n\nwrite_csv2(datos, \"ejemplo.csv\")\n\n\n\n\nPaquete readxl\nUno de los formatos de documentos más comunes en los que se almacenan datos son las hojas de cálculo, en particular, las creadas con el programa Excel de Microsoft Office.\nEl paquete readxl es parte del ecosistema tidyverse y permite leer este tipo de archivos.\nPosee compatibilidad con hojas de cálculo de Excel 97-03, de extensión .xls, y con hojas de cálculo de las versiones más recientes de Excel, de extensión, .xlsx\nLa primera función interesante es excel_sheets(), útil para conocer y listar los nombre de las hojas contenidas dentro de un archivo (libro) Excel.\nPor ejemplo, supongamos que tenemos un archivo denominado datos.xlsx y queremos saber por cuantas hojas está compuesto y que nombre tienen.\n\nlibrary(readxl) # hay que activarlo independientemente de tidyverse\n\nexcel_sheets(\"datos/datos.xlsx\")\n\n[1] \"diabetes\"   \"vigilancia\" \"mortalidad\"\n\n\nObtenemos de esta manera información sobre el archivo. Hay tres hojas llamadas diabetes, vigilancia y mortalidad.\nPara poder leer cada una de estas hojas de datos debemos usar la función read_excel(), que tiene los siguientes argumentos:\n\nargs(read_excel)\n\nfunction (path, sheet = NULL, range = NULL, col_names = TRUE, \n    col_types = NULL, na = \"\", trim_ws = TRUE, skip = 0, n_max = Inf, \n    guess_max = min(1000, n_max), progress = readxl_progress(), \n    .name_repair = \"unique\") \nNULL\n\n\nDonde los más relevantes son:\npath: nombre del archivo y la ubicación (si fuese necesaria) entre comillas\nsheet: nombre de la hoja o número de ubicación\ncol_names: si se activa toma la primer fila como nombres de columnas (variables)\nskip: permite saltear una cantidad determinada de filas antes de comenzar la lectura\nEn primer lugar, cuando ejecutamos esta función, llama a otra denominada excel_format() que determina frente a que formato de archivo estamos. Si es un Excel tipo .xsl o tipo .xlsx. En relación a esta respuesta, luego aplica la función específica para cada caso - read_xls() o readxlsx().\nTodas estas funciones mencionadas en el procedimiento que sigue read_excel() se pueden utilizar en forma específica.\nContinuemos con el archivo datos.xlsx y procedamos a leer los datos de su primer hoja, llamada diabetes.\n\ndiabetes &lt;- read_excel(path = \"datos/datos.xlsx\", \n                       sheet = \"diabetes\",\n                       col_names = T)\n\nhead(diabetes) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 8\n    A1C  hba1 GLUCB   SOG Tol_Glucosa    DM    SM  HOMA\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  6.17   7.9   101   122 IFG             0     1  4.04\n2  5.58   7.2   103   100 IFG             0     0  5.03\n3  5.38   7.1   103    90 IFG             0     1  2.92\n4  5.38   6.6   109    96 IFG             0     1  4.79\n5  5.19   6.3   107    69 IFG             0     1  3.06\n6  4.89   6      NA   117 IFG             0     0  5.77\n\n\nObservemos que en los argumentos escribimos el nombre del archivo que se encuentra en nuestro proyecto y por lo tanto en nuestra carpeta activa, el nombre de la hoja y nos aseguramos que la primer fila representa a la cabecera de la tabla (sus nombres de variables).\nComo el paquete readxl se inscribe dentro del universo tidyverse el formato de salida es un dataframe/tibble. En este caso de 23 observaciones por 8 variables.\nAhora leamos la segunda hoja de nombre vigilancia.\n\nvigilancia &lt;- read_excel(path = \"datos/datos.xlsx\", \n                         sheet = 2, \n                         col_names = F)\n\nhead(vigilancia) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 9\n   ...1 ...2        ...3      ...4  ...5  ...6  ...7 ...8  ...9                 \n  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                \n1   875 09/28/2015  2015 544080000     1    31     1 F     VIGILANCIA EN SALUD …\n2   875 42317       2015 544080000     1    35     1 F     VIGILANCIA EN SALUD …\n3   875 42317       2015 544080000     1    47     1 F     VIGILANCIA EN SALUD …\n4   307 09/26/2015  2015 544005273     1    23     1 M     VIGILANCIA INTEGRADA…\n5   307 09/24/2015  2015 544005273     1    19     1 M     VIGILANCIA INTEGRADA…\n6   875 09/28/2015  2015 544080000     1    63     1 F     VIGILANCIA EN SALUD …\n\n\nCentremos nuestra mirada en los argumentos anteriores: en lugar del nombre de la hoja usamos un 2 que es su ubicación (la segunda hoja del archivo Excel) y configuramos a col_names con F (false) porque el conjunto de datos no tiene cabecera.\nCuando ocurre esta situación donde la tabla no tiene nombre de columnas readxl le asigna nombres del tipo ...1, ...2, ...x\nFinalmente leemos la última hoja disponible del archivo.\n\nmortalidad &lt;- read_excel(path = \"datos/datos.xlsx\", \n                         sheet = \"mortalidad\",\n                         col_names = T, \n                         skip = 1)\n\nhead(mortalidad) # mostramos las 6 primeras observaciones\n\n# A tibble: 5 × 10\n  grupo_edad grupo.I.1.1 grupo.II.1.1 grupo.III.1.1 grupo.I.2.1 grupo.II.2.1\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1 30-44               41          202           222         539         1438\n2 45-59               99         1071           181         759         6210\n3 60-69              114         1782           119         985         9238\n4 70-79              221         2336           119        1571        12369\n5 80+                362         2492            81        2523        14642\n# ℹ 4 more variables: grupo.III.2.1 &lt;dbl&gt;, grupo.I.3.1 &lt;dbl&gt;,\n#   grupo.II.3.1 &lt;dbl&gt;, grupo.III.3.1 &lt;dbl&gt;\n\n\nLo novedoso de esta lectura es el argumento skip = 1 que debimos incorporar dado que, en este caso, la hoja de Excel comienza con una línea de título que no pertenece al conjunto de datos. También que el argumento sheet permite el nombre de la hoja elegida entre comillas.\nRetomando los argumentos generales de la función podemos mencionar estos otros:\nn_max: número máximo de filas leídas\nrange: rango de celdas a leer (definidas como se suele usar en Excel, por ej: B3:D87)\ncol_types: especificación del tipo de dato para cada columna leída. Se pueden utilizar los tipos habituales “numeric”, “logical”, “text”, “date”, etc. Existen dos tipos específicos más: “skip” que saltea la lectura de la columna y “guess” que permite que la función decida cual es el formato adecuado de importación. Este último es el modo predeterminado cuando no especificamos el argumento.\nna: caracter o vector que deseamos se interprete como valor perdido (missing). Por defecto las celdas vacías se interpretan de esta forma y se le asigna NA"
  },
  {
    "objectID": "primero/clases/03-introTidy.html#gestión-de-datos-con-el-paquete-dplyr",
    "href": "primero/clases/03-introTidy.html#gestión-de-datos-con-el-paquete-dplyr",
    "title": "Tidyverse",
    "section": "Gestión de datos con el Paquete dplyr",
    "text": "Gestión de datos con el Paquete dplyr\nEl paquete dplyr es parte del universo tidyverse que fue desarrollado por Hadley Wickham a partir de optimizar una versión del paquete plyr.\nLa contribución significativa del paquete es proporcionar una “gramática” (funciones-verbos) para la manipulación y operaciones de datos que lo hace más fácil de entender.\nLas funciones clave del paquete, responden a las siguientes acciones (verbos):\n\nselect(): devuelve un conjunto de columnas (variables)\nrename(): renombra variables en una conjunto de datos\nfilter(): devuelve un conjunto de filas (observaciones) según una o varias condiciones lógicas\narrange(): reordena filas de un conjunto de datos\nmutate(): añade nuevas variables/columnas o transforma variables existentes\nsummarise()/summarize(): genera resúmenes estadísticos de diferentes variables en el conjunto de datos.\ngroup_by(): agrupa un conjunto de filas seleccionado, en un conjunto de filas de resumen de acuerdo con los valores de una o más columnas o expresiones.\ncount(): contabiliza valores que se repiten, es decir genera tabla de frecuencias.\n\n\nArgumentos comúnes en las funciones dplyr\nTodas las funciones, básicamente, tienen en común una serie de argumentos.\n\nEl primer argumento es el nombre del conjunto de datos (objeto donde esta nuestra tabla de datos)\nLos otros argumentos describen que hacer con el conjunto de datos especificado en el primer argumento, podemos referirnos a las columnas en el objeto directamente sin utilizar el operador $, es decir sólo con el nombre de la columna/variable.\nEl valor de retorno es un nuevo conjunto de datos.\nLos conjunto de datos deben estar bien organizados/estructurados, es decir debe existir una observación por columna y, cada columna representar una variable, medida o característica de esa observación. Es decir, debe cumplir con tidy data.\n\n\n\nActivación del paquete\ndplyr está incluído en el paquete tidyverse, por lo que se encuentra disponible si tenemos activado a este último.\nTambién se puede activar en forma independiente, aunque no es necesario si ya activamos tidyverse:\n\nlibrary(dplyr)\n\n\n\nConjunto de datos para ejemplo\nVisualizar y entender el funcionamiento de estos “verbos” de manipulación es posible si ejemplificamos su aplicación. Por este motivo vamos a leer un conjunto de datos que servirá para ejercitar las funciones del paquete.\n\ndatos &lt;- read_csv(\"datos/noti-vih.csv\") # asignamos la lectura a datos\n\nRows: 48 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): jurisdiccion\ndbl (3): año, casos, pob\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(datos) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 CABA          2015   901  3054237\n4 CABA          2016   427  3050000\n5 Catamarca     2015    69   396552\n6 Catamarca     2016    51   401575\n\n\nLa tabla de datos “noti-vih.csv” contiene datos de notificación de vih por jurisdicción de Argentina para los años 2015 y 2016.\n\n\nFunción select()\nEsta función selecciona las variables que especificamos devolviendo un conjunto de datos “recortado por columna”.\nselect() utiliza un minilenguaje conciso que facilita hacer referencia a las variables según su nombre, ubicación, condición o tipo.\nAlguno de sus operadores son:\n\n: para seleccionar un rango de variables consecutivas.\n- para evitar seleccionar la variable que sigue al signo\n! para tomar el complemento de un conjunto de variables.\n\nVeamos algunas aplicaciones de estas “ayudas” para hacer selecciones.\nTodas las variables menos pob\n\ndatos |&gt;  \n  select(-pob)\n\n# A tibble: 48 × 3\n   jurisdiccion   año casos\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513\n 2 Buenos Aires  2016   957\n 3 CABA          2015   901\n 4 CABA          2016   427\n 5 Catamarca     2015    69\n 6 Catamarca     2016    51\n 7 Chaco         2015    15\n 8 Chaco         2016     9\n 9 Chubut        2015   110\n10 Chubut        2016    89\n# ℹ 38 more rows\n\n\nOtra forma para el mismo resultado anterior (mediante el operador rango :)\n\ndatos |&gt;  \n  select(jurisdiccion:casos)\n\n# A tibble: 48 × 3\n   jurisdiccion   año casos\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513\n 2 Buenos Aires  2016   957\n 3 CABA          2015   901\n 4 CABA          2016   427\n 5 Catamarca     2015    69\n 6 Catamarca     2016    51\n 7 Chaco         2015    15\n 8 Chaco         2016     9\n 9 Chubut        2015   110\n10 Chubut        2016    89\n# ℹ 38 more rows\n\n\nLas variables jurisdiccion y casos\n\ndatos |&gt;  \n  select(jurisdiccion, casos)\n\n# A tibble: 48 × 2\n   jurisdiccion casos\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 Buenos Aires  1513\n 2 Buenos Aires   957\n 3 CABA           901\n 4 CABA           427\n 5 Catamarca       69\n 6 Catamarca       51\n 7 Chaco           15\n 8 Chaco            9\n 9 Chubut         110\n10 Chubut          89\n# ℹ 38 more rows\n\n\nOtra forma para el mismo resultado anterior (mediante números de columna):\n\ndatos |&gt;  \n  select(1, 3)\n\n# A tibble: 48 × 2\n   jurisdiccion casos\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 Buenos Aires  1513\n 2 Buenos Aires   957\n 3 CABA           901\n 4 CABA           427\n 5 Catamarca       69\n 6 Catamarca       51\n 7 Chaco           15\n 8 Chaco            9\n 9 Chubut         110\n10 Chubut          89\n# ℹ 38 more rows\n\n\nTodas las variables pasando año a la primera columna\n\ndatos |&gt;  \n  select(\"año\", everything())\n\n# A tibble: 48 × 4\n     año jurisdiccion casos      pob\n   &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  2015 Buenos Aires  1513 16626374\n 2  2016 Buenos Aires   957 16789474\n 3  2015 CABA           901  3054237\n 4  2016 CABA           427  3050000\n 5  2015 Catamarca       69   396552\n 6  2016 Catamarca       51   401575\n 7  2015 Chaco           15  1153846\n 8  2016 Chaco            9  1125000\n 9  2015 Chubut         110   567010\n10  2016 Chubut          89   577922\n# ℹ 38 more rows\n\n\nEsta última función everything(), pasada como argumento, es una de las posibles funciones llamadas “ayudantes de selección”, entre las cuales se encuentra:\n\nstarts_with(): selecciona todas las columnas que comiencen con el patrón indicado.\nends_with(): selecciona todas las columnas que terminen con el patrón indicado.\ncontains(): selecciona las columnas que posean el patrón indicado.\nmatches(): similar a contains(), pero permite poner una expresión regular.\nall_of(): selecciona las variables pasadas en un vector (todos los nombres deben estar presentes o devuelve un error)\nany_of(): idem anterior excepto que no se genera ningún error para los nombres que no existen.\nnum_range(): selecciona variables con nombre combinados con caracteres y números (ejemplo: num_range(“x”, 1:3) selecciona las variables x1, x2 y x3.\nwhere(): aplica una función a todas las variables y selecciona aquellas para las cuales la función regresa TRUE (por ejemplo: is.numeric() para seleccionar todas las variables numéricas)\ngroup_cols(): selecciona todas las columnas de agrupación.\n\nTodas estas funciones son muy útiles a la hora de seleccionar el conjunto de variables necesarias no solo para un select() básico sino también cuando necesitemos aplicar operaciones simultáneas y/o pivotear tablas de datos que necesiten garantizar formato ordenado (tidy-data).\n\n\nFunción rename()\nEsta función es una extensión de select(), dado que esta última permite cambiar el nombre de variables pero no es muy útil porque descarta todas las variables que no se mencionan explícitamente. En cambio rename() renombra variables mientras que mantiene las demás no mencionadas.\nPor ejemplo, cambiamos el nombre de la variable pob por población.\n\ndatos |&gt; \n  rename(\"población\" = pob)\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos población\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 Buenos Aires  2015  1513  16626374\n 2 Buenos Aires  2016   957  16789474\n 3 CABA          2015   901   3054237\n 4 CABA          2016   427   3050000\n 5 Catamarca     2015    69    396552\n 6 Catamarca     2016    51    401575\n 7 Chaco         2015    15   1153846\n 8 Chaco         2016     9   1125000\n 9 Chubut        2015   110    567010\n10 Chubut        2016    89    577922\n# ℹ 38 more rows\n\n\n\n\nFunción filter()\nAsí como la función select() es utilizada para seleccionar columnas, la función filter() hace lo propio con las filas del conjunto de datos, produciendo un subconjunto de observaciones.\nVeamos un ejemplo sencillo sobre nuestros datos:\n\ndatos |&gt; \n  filter(jurisdiccion == \"Tucuman\")\n\n# A tibble: 2 × 4\n  jurisdiccion   año casos     pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Tucuman       2015   258 1592593\n2 Tucuman       2016   246 1618421\n\n\nUtiliza los mismos operadores de comparación propios del lenguaje R\n\n\n\nComparación\n\n\n\n\n\n&lt;\nmenor a\n\n\n&gt;\nmayor a\n\n\n==\nigual a\n\n\n&lt;=\nmenor o igual a\n\n\n&gt;=\nmayor o igual a\n\n\n!=\nno igual a\n\n\n%in%\nes parte de\n\n\nis.na\nes NA\n\n\n!is.na\nno es NA\n\n\n\nLo mismo con los operadores lógicos que se utilizan como conectores entre las expresiones.\n\n\n\nLógicos\n\n\n\n\n\n&\nAND booleano\n\n\n|\nOR booleano\n\n\nxor\nOR exclusivo\n\n\n!\nNOT\n\n\nany\ncualquier TRUE\n\n\nall\ntodos TRUE\n\n\n\nCuando usamos múltiples argumentos separados por coma dentro de filter() se combinan con un conector AND, es decir cada expresión debe ser verdadera para que una fila sea incluida en la salida.\nPor ejemplo:\nFiltramos a las observaciones que cumplan con la condición que casos sea mayor a 100 y población sea menor a 1000000\n\ndatos |&gt; \n  filter(casos &gt; 100, pob &lt; 1000000)\n\n# A tibble: 7 × 4\n  jurisdiccion   año casos    pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Chubut        2015   110 567010\n2 Jujuy         2015   160 727273\n3 Jujuy         2016   133 734807\n4 Neuquen       2015   109 619318\n5 Neuquen       2016   101 627329\n6 Rio Negro     2015   112 700000\n7 Rio Negro     2016   105 709459\n\n\nPara combinaciones dentro de una misma variable debemos utilizar el conector OR (|) o más útil el operador %in%.\nFiltramos a las jurisdicciones “Buenos Aires” y “La Pampa”\n\ndatos |&gt; \n  filter(jurisdiccion == \"Buenos Aires\" | jurisdiccion == \"La Pampa\")\n\n# A tibble: 4 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 La Pampa      2015    57   343373\n4 La Pampa      2016    67   345361\n\n\n\ndatos |&gt; \n  filter(jurisdiccion %in% c(\"Buenos Aires\", \"La Pampa\"))\n\n# A tibble: 4 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 La Pampa      2015    57   343373\n4 La Pampa      2016    67   345361\n\n\nFiltramos las observaciones de 2016 con casos mayores a 200 utilizando el conector AND (&). Es el mismo resultado que si utilizamos una coma.\n\ndatos |&gt; \n  filter(año == \"2016\" & casos &gt; 200)\n\n# A tibble: 6 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2016   957 16789474\n2 CABA          2016   427  3050000\n3 Cordoba       2016   368  3607843\n4 Mendoza       2016   254  1909774\n5 Salta         2016   230  1352941\n6 Tucuman       2016   246  1618421\n\n\nFiltramos las observaciones inversas a la anterior mediante xor(), que selecciona los valores de año y casos exclusivos (es decir que no se den ambos en TRUE).\n\ndatos |&gt; \n  filter(xor(año == \"2016\", casos &gt; 200))\n\n# A tibble: 25 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374\n 2 CABA          2015   901  3054237\n 3 Catamarca     2016    51   401575\n 4 Chaco         2016     9  1125000\n 5 Chubut        2016    89   577922\n 6 Cordoba       2015   468  3572519\n 7 Corrientes    2016    99  1076087\n 8 Entre Rios    2016   109  1329268\n 9 Formosa       2016    60   582524\n10 Jujuy         2016   133   734807\n# ℹ 15 more rows\n\n\n\n\nFunción arrange()\nLa función arrange() se utiliza para ordenar las filas de un conjunto de datos de acuerdo a una o varias columnas/variables. Por defecto, el ordenamiento es ascendente alfanumérico.\nOrdenamos la tabla datos por la variable pob (forma ascendente predeterminada):\n\ndatos |&gt; \n  arrange(pob)\n\n# A tibble: 48 × 4\n   jurisdiccion       año casos    pob\n   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Tierra del Fuego  2015    36 152542\n 2 Tierra del Fuego  2016    34 156682\n 3 Santa Cruz        2015    65 320197\n 4 Santa Cruz        2016    59 329609\n 5 La Pampa          2015    57 343373\n 6 La Pampa          2016    67 345361\n 7 La Rioja          2015    41 369369\n 8 La Rioja          2016     6 375000\n 9 Catamarca         2015    69 396552\n10 Catamarca         2016    51 401575\n# ℹ 38 more rows\n\n\nPara ordenar en forma descendente podemos utilizar desc() dentro de los argumentos de arrange():\n\ndatos |&gt; \n  arrange(desc(pob))\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2016   957 16789474\n 2 Buenos Aires  2015  1513 16626374\n 3 Cordoba       2016   368  3607843\n 4 Cordoba       2015   468  3572519\n 5 Santa Fe      2016   170  3400000\n 6 Santa Fe      2015   301  3382022\n 7 CABA          2015   901  3054237\n 8 CABA          2016   427  3050000\n 9 Mendoza       2016   254  1909774\n10 Mendoza       2015   316  1880952\n# ℹ 38 more rows\n\n\nPodemos combinar ordenamientos. Por ejemplo, en forma alfabética ascendente para jusrisdiccion y luego numérica descendente para casos.\n\ndatos |&gt; \n  arrange(jurisdiccion, desc(casos))\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374\n 2 Buenos Aires  2016   957 16789474\n 3 CABA          2015   901  3054237\n 4 CABA          2016   427  3050000\n 5 Catamarca     2015    69   396552\n 6 Catamarca     2016    51   401575\n 7 Chaco         2015    15  1153846\n 8 Chaco         2016     9  1125000\n 9 Chubut        2015   110   567010\n10 Chubut        2016    89   577922\n# ℹ 38 more rows\n\n\n\n\nFunción mutate()\nEsta función nos proporciona computar tranformaciones de variables en un conjunto de datos. A menudo, tendremos la necesidad de modificar variables existentes o crear nuevas variables que se calculan a partir de las que tenemos, mutate() nos ofrece una interface clara para realizar este tipo de operaciones.\nPor ejemplo, nos puede interesar calcular tasas crudas para cada jurisdicción y año, en función de los casos y el total de población.\n\ndatos |&gt; \n  mutate(tasa = casos/pob*100000)\n\n# A tibble: 48 × 5\n   jurisdiccion   año casos      pob  tasa\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374  9.10\n 2 Buenos Aires  2016   957 16789474  5.70\n 3 CABA          2015   901  3054237 29.5 \n 4 CABA          2016   427  3050000 14   \n 5 Catamarca     2015    69   396552 17.4 \n 6 Catamarca     2016    51   401575 12.7 \n 7 Chaco         2015    15  1153846  1.30\n 8 Chaco         2016     9  1125000  0.8 \n 9 Chubut        2015   110   567010 19.4 \n10 Chubut        2016    89   577922 15.4 \n# ℹ 38 more rows\n\n\nObservemos que la función realiza el cálculo (en este caso tasas crudas por 100000 habitantes) e incorpora una nueva variable por cada observación con el resultado.\nTambién se pueden construir múltiples variables en la misma expresión, solamente separadas por comas.\n\ndatos |&gt; \n  mutate(tasaxcien_mil = casos/pob*100000, \n         tasaxdiez_mil = casos/pob*10000)\n\n# A tibble: 48 × 6\n   jurisdiccion   año casos      pob tasaxcien_mil tasaxdiez_mil\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374          9.10         0.910\n 2 Buenos Aires  2016   957 16789474          5.70         0.570\n 3 CABA          2015   901  3054237         29.5          2.95 \n 4 CABA          2016   427  3050000         14            1.4  \n 5 Catamarca     2015    69   396552         17.4          1.74 \n 6 Catamarca     2016    51   401575         12.7          1.27 \n 7 Chaco         2015    15  1153846          1.30         0.130\n 8 Chaco         2016     9  1125000          0.8          0.08 \n 9 Chubut        2015   110   567010         19.4          1.94 \n10 Chubut        2016    89   577922         15.4          1.54 \n# ℹ 38 more rows\n\n\nSi necesitemos que estas dos nuevas variables queden dentro de la tabla de datos y no solo mostrarla en consola como hasta ahora, debemos utilizar el operador de asignación:\n\ndatos &lt;- datos |&gt; \n  mutate(tasaxcien_mil = casos/pob*100000, \n         tasaxdiez_mil = casos/pob*10000)\n\nLa propiedad imprescindible es que la función debe poder vectorizar: debe tomar un vector de valores como entrada, y devolver un vector con el mismo número de valores que la salida.\nNo hay forma de enumerar todas las funciones posibles que se podría usar, pero mencionaremos algunas que pueden ser útiles:\n\nOperadores aritméticos: +, -, *, /, ^.\nAritmética modular: %/% (división entera) y %% (resto), donde \\(x == y * (x \\ \\%/\\% \\ y) + (x\\ \\%\\% \\ y)\\). La aritmética modular es una herramienta útil porque te permite dividir números enteros en porciones.\nFunciones matemáticas: log(), log2(), log10(), exp(), sqrt(), abs(), etc\nValores acumulados: R proporciona funciones para ejecutar sumas, productos, mínimos y máximos acumulados: cumsum(), cumprod(), cummin(), cummax(); y dplyr proporciona cummean() para promedios acumulados.\nClasificaciones (ranking): hay una serie de funciones de clasificación, por ejemplo min_rank(). Genera el tipo de clasificación habitual (1º, 2º, etc). El valor predeterminado relaciona los valores más pequeños a rangos pequeños; podemos usar desc(x) para invertir la relación (valores más grandes a rangos más pequeños)\n\nSi utilizamos el mismo nombre de una variable incluída dentro de la tabla de datos, estaremos sobrescribiendola (se usa cuando transformamos una variable, por ejemplo: le cambiamos su tipo de character a factor). Para que la variable sea nueva debe nombrarse con un nombre que no exista previamente dentro de la tabla de datos.\n\n\nFunciones condicionales\nDentro un mutate(), algunas veces vamos a necesitar agrupar, agregar o discretizar variables continuas donde generemos variables dicotómicas o politómicas.\nEstas funciones que llamaremos “condicionales”, dado que utilizan condiciones para decidir que valor tomar, no se limitan a la tarea de construir agrupamientos de variables cuantitativas sino que sirven para cualquier situación donde a partir de una o más condiciones se produzcan una o más valores como respuesta.\n\nCondicional simple - función if_else()\nPara salidas dicotómicas tenemos la función condicional if_else() derivada de la simplificación del IF condicional que existe en todos los lenguajes de programación.\nSupongamos que creamos una nueva variable dentro del dataframe datos que se llama variable_nueva de tipo cualitativa y queremos que la misma tome valores a partir del cumplimiento de una condición de una variable cuantitativa existente denominada var1.\nSi los valores de var1 son mayores a 10, entonces variable_nueva, tomará el valor “mayor a 10”, en caso contrario, tomará el valor “menor o igual a 10”\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"mayor a 10\", \n                                  false = \"menor o igual a 10\"))\n\nif_else() tiene tres argumentos obligatorios, el primero siempre es una condición, el segundo y el tercero son los valores que tomará la nueva variable si esa condición se cumple o no se cumple.\nHabitualmente decimos que en este proceso dicotomizamos una variable, dado que el resultado posible consta siempre de 2 valores.\nLos valores de salida de esta función pueden ser de variado tipo (caracter, numerico o logico) aunque si estamos discretizando una variable cuantitativa generalmente construimos una variable resultado cualitativa ordinal. Es común que esta variable salida sea tipo character (observar que las nuevas categorías van encerradas entre comillas).\nAhora bien, al ser ordinal estas categorías de la variable_nueva deben “ordenarse” en la forma de los valores de la variable, pero el lenguaje R no sabe con que estamos trabajando y respeta siempre el ordenamiento alfanumérico. Por lo tanto, en este ejemplo las categorías se van a estar ordenando al reves del orden numérico natural (de menor a mayor).\n“mayor a 10” se ordena alfabéticamente antes de “menor o igual a 10”, porque luego del empate de las letras m, le siguen la a en el primer caso y la e en el segundo.\nPara ordenar estas categorías debemos transformar la variable de caracter a factor. Esto se puede hacer en un solo paso dentro del mutate:\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"mayor a 10\", \n                                   false = \"menor o igual a 10\"),\n         variable_nueva = factor(variable_nueva, \n                                 levels = c(\"menor o igual a 10\",\n                                            \"mayor a 10\")))\n\nOtra forma más artesanal, igualmente válido, es “forzar” el ordenamiento con las categorías así:\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"2.mayor a 10\", \n                                  false = \"1.menor o igual a 10\"))\n\nAquí agregamos números iniciales a las etiquetas de las categorías para darle el orden que deseamos, sin necesidad de convertir a factor.\n\n\nCondicional multiple\nEn salidas politómicas a partir de variables cuantitativas tenemos varias opciones dependiendo de si los intervalos de clase a construir son regulares o irregulares.\n\n\nFunción cut_interval()\ntidyverse ofrece la función cut_interval() para la creación de intervalos regulares.\nEs una adptación de la función cut() de R base para tidy data y sus argumentos son similares.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = cut_interval(x = var1, \n                                  length = 10,\n                                  right = T,\n                                  labels = T,\n                                  ordered_result = F))\n\nLos argumentos obligatorios y opcionales de la función cut() son:\n\nx: [obligatorio] El conjunto de datos numéricos de entrada (variable cuantitativa continua)\nlength: [obligatorio] la longitud de cada intervalo regular\nright: [opcional] Indica si los intervalos son cerrados a la derecha o viceversa. Por defecto vale TRUE (cerrados a derecha)\nlabels: [opcional] Etiquetas de los intervalos automáticas o numéricas. Valor predeterminado TRUE (intervalos matemáticos)\nordered_result: [opcional] - determina si el resultado es un factor ordenado. Por defecto vale FALSE (la salida es tipo caracter)\n\nLos argumentos opcionales no son necesarios definirlos siempre y cuando los valores por defecto son los que sirven para la tarea.\n\n\nFunción case_when()\nCuando las condiciones no son simples, es decir, el resultado no es dicotómico y además los intervalos son irregulares, utilizamos la función case_when() que es una vectorización de la función if_else().\nSupongamos que no queremos agrupar la variable en dos valores, sino en 3 grupos irregulares.\nEsquema básico de funcionamiento:\n\n# var1 es una variable cuantitativa de números enteros \n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n    var1 &gt;= 0 & var1 &lt; 25  ~  \"Grupo1\", \n    var1 &gt; 24 & var1 &lt; 65  ~    \"Grupo 2\", \n    var1 &gt;= 65             ~    \"Grupo 3\"))\n\nExiste una condición por cada grupo creado, como si fuese un if_else() donde el valor declarado siempre es el verdadero. Se utilizan operadores de comparación como mayor ( &gt; ), menor ( &lt; ) y/o igual ( = ) y conectores lógicos como & ( AND ). En cada línea va una virgulilla similar a la usada en la sintaxis formula ( ~ ) y luego la etiqueta que tomarán las observaciones que cumplan con esa condición en la nueva variable (grupo_var).\nEsta evaluación es secuencial y su funcionamiento provoca que el usuario del lenguaje tenga el control de lo que esta sucediendo, por lo que cualquier mala definición de las condiciones puede provocar resultados incorrectos.\nSi incorporamos el argumento .default podemos indicar que valor toma si no se cumple ninguna de las condiciones anteriores.\nPor ejemplo, podríamos tener algun valor perdido (NA) en var1 y queremos que la variable grupo_var etiquete esos valores perdidos como “Sin dato”:\n\n# var1 es una variable cuantitativa de números enteros con algun valor NA\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n        var1 &gt;= 0 & var1 &lt; 25  ~  \"Grupo1\", \n        var1 &gt; 24 & var1 &lt; 65  ~    \"Grupo 2\", \n        var1 &gt;= 65             ~    \"Grupo 3\",\n        .default = \"Sin dato\"))\n\nLas salidas son de tipo carácter (chr) y debemos manejar el ordenamiento de las etiquetas como vimos anteriormente, por medio de factores o comenzando con caracteres ordenados alfabeticamente.\nPara simplificar el trabajo de estos intervalos de clase irregulares y no provocar errores en la confección de las condiciones, tidyverse tiene a la función between().\n\n\nIntervalos - función between()\nBáicamente opera como un atajo para condiciones de intervalos. Define dentro de los argumentos los límites inferior y superior de un intervalo y se utiliza dentro de una función de condición tipo if_else() o case_when().\nAplicado sobre el ejemplo anterior se vería así:\n\n# var1 es una variable cuantitativa de números enteros con algun valor NA\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n    between(var1, 0, 24)   ~  \"Grupo1\", \n        between(var1, 25, 64)  ~    \"Grupo 2\", \n        between(var1, 65, Inf) ~    \"Grupo 3\",\n        .default = \"Sin dato\"))\n\nLos valores declarados como límites quedan incluídos siempre dentro del intervalo (son cerrados ambos). También podemos utilizar valores reservados como Inf o -Inf cuando desconocemos con que valor máximo o mínimo nos vamos a encontrar en la variable cuantitativa original.\n\n\nEjemplos con variable edad\nTomemos un caso clásico como la variable edad medida en años, variable que generalmente tenemos en toda tabla de datos vinculada a personas. En este ejemplo la variable tiene 106 observaciones.\nUna posibilidad es dicotomizarla usando el valor de la mediana que divide 2 dos partes toda la distribución.\n\ndatos |&gt; \n  summarise(mediana = median(edad))\n\n# A tibble: 1 × 1\n  mediana\n    &lt;dbl&gt;\n1      56\n\n\nAplicando el valor 56 dentro de un if_else podriamos hacer:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"mayor a la mediana\", \n                                  false = \"menor o igual a la mediana\"))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                    n\n  &lt;chr&gt;                      &lt;int&gt;\n1 mayor a la mediana            52\n2 menor o igual a la mediana    54\n\n\nObservamos en el conteo que grupo_edad1 se construyó adecuadamente pero el orden de los niveles no es correcto si queremos que siga el ordenamiento natural de edad (de menor a mayor).\nUna de las formas que vimos es convertir a factor:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"mayor a la mediana\", \n                                  false = \"menor o igual a la mediana\"),\n         grupo_edad1 = factor(grupo_edad1, \n                                 levels = c(\"menor o igual a la mediana\",\n                                            \"mayor a la mediana\")))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                    n\n  &lt;fct&gt;                      &lt;int&gt;\n1 menor o igual a la mediana    54\n2 mayor a la mediana            52\n\n\nVemos que en el conteo el formato de la variable ya no es chr sino fct y el orden de las etiquetas siguen la forma “menor a mayor”.\nOtra forma es:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"2.mayor a la mediana\", \n                                  false = \"1.menor o igual a la mediana\"))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                      n\n  &lt;chr&gt;                        &lt;int&gt;\n1 1.menor o igual a la mediana    54\n2 2.mayor a la mediana            52\n\n\nSi en cambio necesitamos que los grupos sean mas de dos y que estos intervalos de clase sean regulares, podemos usar cut_interval\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;fct&gt;       &lt;int&gt;\n1 [0,10]          3\n2 (10,20]         3\n3 (20,30]         2\n4 (30,40]         3\n5 (40,50]        13\n6 (50,60]        52\n7 (60,70]        27\n8 (70,80]         3\n\n\nLa salida muestra 8 grupos etarios con etiquetas ordenadas con notación matemática, donde un corchete indica que el límite del intervalo es cerrado, es decir contiene el valor y un paréntesis es abierto y no lo hace.Así es que el primer grupo va de 0 a 10 años y el segundo de 11 a 20.\nEstos sucede así porque en forma predeterminada el argumento right está en TRUE. Veamos que pasa si lo cambiamos a FALSE:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    right = F))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;fct&gt;       &lt;int&gt;\n1 [0,10)          3\n2 [10,20)         3\n3 [20,30)         2\n4 [30,40)         3\n5 [40,50)        10\n6 [50,60)        48\n7 [60,70)        32\n8 [70,80]         5\n\n\nEn esta salida el primer grupo va de 0 a 9 y el segundo de 10 a 19.\nHasta ahora la variable grupo_edad2 es de tipo caracter, pero si deseamos que la salida sea factor podemos incorporar el argumento ordered_result en TRUE.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    ordered_result = T))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;ord&gt;       &lt;int&gt;\n1 [0,10]          3\n2 (10,20]         3\n3 (20,30]         2\n4 (30,40]         3\n5 (40,50]        13\n6 (50,60]        52\n7 (60,70]        27\n8 (70,80]         3\n\n\nConstruimos así una variable factor ordenada .\nPor último, con el argumento labels en FALSE hacemos que las etiquetas de los 8 grupos sean numéricas.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    labels = F))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n        &lt;int&gt; &lt;int&gt;\n1           1     3\n2           2     3\n3           3     2\n4           4     3\n5           5    13\n6           6    52\n7           7    27\n8           8     3\n\n\nOtro ejemplo, podría ser aplicando case_when() donde discretizamos la edad en 4 grupos irregulares, forzando sus etiquetas para lograr el orden adecuado.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo3 = case_when(\n    edad &lt; 13              ~ \"1.Niño\",\n    edad &gt; 12 & edad &lt; 26  ~ \"2.Adolescente\",\n    edad &gt; 25 & edad &lt; 65  ~ \"3.Adulto_joven\",\n    edad &gt; 64              ~ \"4.Adulto_mayor\"\n  ))\n\ndatos |&gt; \n  count(grupo3)   \n\n# A tibble: 4 × 2\n  grupo3             n\n  &lt;chr&gt;          &lt;int&gt;\n1 1.Niño             3\n2 2.Adolescente      5\n3 3.Adulto_joven    86\n4 4.Adulto_mayor    12\n\n\nSi no hubiesemos etiquetado con los numeros por delante el orden alfabético hacía que Niño fuese a parar al final del conteo.\nDe la misma forma pero más sencillo y controlado es:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo3 = case_when(\n    between(edad, 0, 12)   ~ \"1.Niño\",\n    between(edad, 13, 25)  ~ \"2.Adolescente\",\n    between(edad, 26, 64)  ~ \"3.Adulto_joven\",\n    between(edad, 65, Inf) ~ \"4.Adulto_mayor\"\n  ))\n\ndatos |&gt; \n  count(grupo3)  \n\n# A tibble: 4 × 2\n  grupo3             n\n  &lt;chr&gt;          &lt;int&gt;\n1 1.Niño             3\n2 2.Adolescente      5\n3 3.Adulto_joven    86\n4 4.Adulto_mayor    12\n\n\n\n\n\nFunción summarise()\nLa función summarise() (se puede escribir también summarize()) resume variables de un conjunto de datos.\n\ndatos |&gt; \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos))\n\n# A tibble: 1 × 2\n  promedio_casos casos_totales\n           &lt;dbl&gt;         &lt;dbl&gt;\n1           192.          9211\n\n\nSu uso es muy interesante cuando la combinamos con group_by() (función que detallaremos luego). Esta situación permite estratificar los resultados por grupos específicos.\nPor ejemplo, podemos agrupar el por año y simultáneamente aplicar el mismo summarise() anterior.\n\ndatos |&gt;  \n  group_by(año) |&gt;  \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos))\n\n# A tibble: 2 × 3\n    año promedio_casos casos_totales\n  &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1  2015           224.          5369\n2  2016           160.          3842\n\n\nEl resultado es una tabla con dos filas, una para cada grupo (año 2015 y año 2016) con los valores promedio y casos totales respectivos.\nAlgunas de las funciones del R base que se pueden utilizar dentro de los argumentos de esta función son:\n\nmin() mínimo\nmax() máximo\nmean() media\nmedian() mediana\nvar() varianza\nsd() desvío\nsum() sumatoria\n\nOtras funciones que se pueden incorporar las provee el mismo paquete dplyr, por ejemplo:\n\nfirst() primer valor en el vector\nlast() último valor en el vector\nn() número de valores en el vector\nn_distinct() números de valores distintos en el vector\n\nDesde la versión 1.4.0 de dplyr la función summarise() incorpora un nuevo argumento para agrupamientos temporales. El argumento .by = trabaja igual que un group_by() previo pero lo hace solo para realizar el calculo definido dentro del resumen evitando que el dataframe de salida mantenga el agrupamiento.\nLa estructura básica de la función actualizada es:\n\ndatos |&gt; \n  summarise(\n    var_resumen = funcion(var),\n    .by = var_grupo\n  )\n\nAplicada en el ejemplo previo:\n\ndatos |&gt;  \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos),\n            .by = año)\n\n# A tibble: 2 × 3\n    año promedio_casos casos_totales\n  &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1  2015           224.          5369\n2  2016           160.          3842\n\n\n\n\nFunción group_by()\nDecíamos recién que la función group_by() es útil cuando trabaja conjuntamente con summarise() dado que agrupa un conjunto de filas seleccionado en un conjunto de filas de resumen de acuerdo con los valores de una o más columnas o expresiones.\nPara ejemplificar su trabajo asociado obtendremos una nueva tabla con el cálculo de las tasas crudas para cada jurisdicción por año (similar al ejemplo de la aplicación de mutate():\n\ndatos |&gt; \n  group_by(jurisdiccion, año) |&gt;  \n  summarise(tasa = casos/pob*100000)\n\n# A tibble: 48 × 3\n# Groups:   jurisdiccion [24]\n   jurisdiccion   año  tasa\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  9.10\n 2 Buenos Aires  2016  5.70\n 3 CABA          2015 29.5 \n 4 CABA          2016 14   \n 5 Catamarca     2015 17.4 \n 6 Catamarca     2016 12.7 \n 7 Chaco         2015  1.30\n 8 Chaco         2016  0.8 \n 9 Chubut        2015 19.4 \n10 Chubut        2016 15.4 \n# ℹ 38 more rows\n\n\nEn la mayoría de estos ejemplos la salida es directa, es decir no construimos nuevos objetos contenedores de los datos producidos y vemos los resultados en consola o en el visualizador de RStudio. Pero en muchas situaciones vamos a necesitar generar nuevos conjunto de datos con las transformaciones realizadas. Si en alguna de estas ocasiones llegamos a agrupar datos mediante group_by() y posteriormente necesitamos volver a tener la información desagrupada existe una función vinculada denominada ungroup() que vamos a necesitar aplicar o bien si no se desea tener el agrupamiento de forma fija se puede usar el argumento .by = del summarise() como mostramos anteriormente.\n\n\nCombinaciones\nEn los ejemplos anteriores vimos como se van integrando alguna de las funciones mediante el uso de la tubería %&gt;% o |&gt;. La idea detrás de la búsqueda gramatical del paquete es poder enlazar las acciones para construir oraciones más complejas.\nUn ejemplo que podría integrar gran parte de los visto sería:\nObtener una nueva tabla con las tasas crudas de casos notificados de VIH, por año y jurisdicción, mayores a 20 x 100000 habitantes ordenadas de mayor a menor.\n\ndatos |&gt;                                   # siempre partimos de los datos\n  group_by(año, jurisdiccion) |&gt;           # agrupamos\n  summarise(tasa = casos/pob*100000) |&gt;    # resumimos\n  filter(tasa &gt; 20) |&gt;                     # filtramos\n  arrange(desc(tasa))                       # ordenamos   \n\n# A tibble: 5 × 3\n# Groups:   año [2]\n    año jurisdiccion      tasa\n  &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1  2015 CABA              29.5\n2  2015 Tierra del Fuego  23.6\n3  2015 Jujuy             22.0\n4  2016 Tierra del Fuego  21.7\n5  2015 Santa Cruz        20.3\n\n\nObservemos que una buena manera de construir el código es respetar un salto de línea para cada término de la oración para una lectura más clara.\nDemostramos así la potencialidad que tienen estas funciones combinadas donde en esta situación integramos las funciones group_by(), summarise() , filter() y arrange() en una misma operación.\n\n\nFunción count()\nEsta última función que presentamos permite contar rápidamente los valores únicos de una o más variables.\nProduce fácilmente tablas de frecuencias absolutas que luego posibilitan construir frecuencias relativas.\nLa aplicamos sobre la variable jurisdiccion de datos\n\ndatos |&gt; \n  count(jurisdiccion)\n\n# A tibble: 24 × 2\n   jurisdiccion     n\n   &lt;chr&gt;        &lt;int&gt;\n 1 Buenos Aires     2\n 2 CABA             2\n 3 Catamarca        2\n 4 Chaco            2\n 5 Chubut           2\n 6 Cordoba          2\n 7 Corrientes       2\n 8 Entre Rios       2\n 9 Formosa          2\n10 Jujuy            2\n# ℹ 14 more rows\n\n\nTiene un par de argumentos opcionales:\n\nname: es el nombre de la columna con el conteo. Por defecto se llama n\nsort: ordena la tabla de frecuencia de mayor a menor\nwt: se puede opcionalmente incorporar una variable con la ponderación (factor de expansión) para el calculo de la frecuencia."
  },
  {
    "objectID": "primero/clases/03-introTidy.html#gráficos-estadísticos-con-ggplot2",
    "href": "primero/clases/03-introTidy.html#gráficos-estadísticos-con-ggplot2",
    "title": "Tidyverse",
    "section": "Gráficos estadísticos con ggplot2",
    "text": "Gráficos estadísticos con ggplot2\nggplot2 es un paquete que se autodefine como librería para “crear elegantes visualizaciones de datos usando una gramática de gráficos”\nPropone una forma intuitiva de construir gráficos basada en The Grammar of Graphics, a partir de utilizar capas y un sistema apoyado en tres componentes básicos:\n\ndatos\ncoordenadas\nobjetos geométricos\n\nLa estructura para construir un gráfico es la siguiente:\n\n\n\n\n\n\n\n\n\n\nAnatomía de gráficos con ggplot2\nEl paquete se basa en una gramática de gráficos que puede ser entendida a partir de conocer sus componentes:\n\n\n\n\n\n\n\n\n\n\ndata es aquél conjunto de datos que vamos a graficar, con toda la información pertinente para realizar el gráfico.\naes reducción de aesthetic mapping o mapeo estético en el que se puede declarar todo lo que puede ser visible de un gráfico.\ngeoms son representaciones para dibujar gráficos (puntos, líneas, cajas, entre otros).\nstats son aquellas transformaciones estadísticas que le hacemos a los datos. Nos ayudan a hacer un resumen del conjunto de datos para visualizar mejor (por ejemplo, la media o la mediana como estadísticas de tendencia central).\nscales facilitan colorear (o escalar) los datos según distintas variables. Dibujan los ejes y las leyendas.\ncoordinate Systems es el sistema de coordenadas para el mapeo del gráfico en un plano bidimensional.\nfacets nos permiten partir el conjunto de datos según factores para graficar en viñetas separadas creando matrices gráficas.\nthemes son conjuntos de características gráficas que permiten controlar la apariencia general de todos los elementos que no son datos (por ejemplo, el color del fondo o el tipo de fuente).\n\nAntes de comenzar a explicar cada componente vamos a leer un conjunto de datos que nos permita mostrar los ejemplos gráficos.\n\nlibrary(tidyverse)\n\nfacultad &lt;- read_csv(\"datos/facultad.csv\") # lectura\n\nhead(facultad) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 18\n     HC SEXO   EDAD ANT_DIABETES ANT_TBC ANT_CANCER ANT_OBESIDAD ANT_ECV ANT_HT\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt; \n1 26880 M        17 NO           NO      NO         SI           NO      SI    \n2 26775 M        18 SI           NO      NO         NO           NO      NO    \n3 26877 M        18 SI           NO      SI         NO           NO      SI    \n4 26776 M        18 NO           NO      NO         SI           SI      NO    \n5 26718 M        18 NO           NO      NO         NO           NO      SI    \n6 26738 M        18 NO           NO      NO         NO           NO      SI    \n# ℹ 9 more variables: ANT_COL &lt;chr&gt;, FUMA &lt;chr&gt;, EDADINI &lt;dbl&gt;, CANTIDAD &lt;dbl&gt;,\n#   COL &lt;dbl&gt;, PESO &lt;dbl&gt;, TALLA &lt;dbl&gt;, SIST &lt;dbl&gt;, DIAST &lt;dbl&gt;\n\n\nEl archivo leído se llama facultad.csv y contiene información de salud sobre ingresantes a una facultad tales como sexo, edad, talla y peso, entre otras. (son datos ficticios con fines docentes).\n\n\nMapeo estético (aesthetic mapping) y objetos geométricos (geom)\nDecíamos que aes() hace referencia al contenido estético del gráfico. Es decir, la función le brinda indicios a ggplot2 sobre cómo dibujar los distintas líneas, formas, colores y tamaños.\nEs importante notar que aes() crea una nueva capa en relación a las variables y agrega leyendas a los gráficos. Al incorporar aes() al llamado de ggplot() estamos compartiendo la información estética en todas las capas. Si deseamos que esa información sólo esté en una de las capas, debemos usar aes() en la capa correspondiente.\nVeamos como funciona y sus diferencias.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO)) # solo la capa estética aes()\n\n\n\n\n\n\n\n\n\n\nEste gráfico solo contiene los ejes que especificamos (PESO y TALLA) pero no contiene los datos. Si deseamos incorporarlos agregamos una capa de puntos con geom_point() a través del símbolo +.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO))  + \n  geom_point()                    # agregamos la capa geométrica de puntos\n\n\n\n\n\n\n\n\n\n\nPodemos diferenciar los puntos según se traten de ingresantes mujeres y hombres, asociando el argumento color dentro de aes() con la variable SEXO.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO, color = SEXO)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nEstos gráficos también posibilitan el agregado de otra capa geométrica, por ejemplo rectas de regresión para cada grupo según sexo.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO, color = SEXO)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")            # agregamos una segunda capa geométrica \n\n\n\n\n\n\n\n\n\n\nEsta función geom_smooth() posee distintos métodos y en este ejemplo utilizamos el de regresión lineal entre talla y peso junto a sus intervalos de confianza.\nA continuación vamos a ver que diferencias existen cuando aes() se encuentra dentro del ggplot() y cuando se ubica en otras capas de funciones como en geom_point()\nDecíamos anteriormente que al incorporar aes() al llamado de ggplot() estamos compartiendo la información estética en todas las capas.\nEntonces si quitamos aes() de allí y lo ubicamos en una capa única, esta configuración deja de afectar al conjunto del gráfico.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO)) + \n  geom_point(aes(color = SEXO)) + # color esta definido en el aes() \n                                  # de la capa geométrica\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\nEn este ejemplo, aes() para el color solo se ubica dentro de geom_point() y por lo tanto dibuja los puntos con sus respectivos colores, pero no afecta a la capa de geom_smooth() produciendo solo una línea de regresión para el conjunto de puntos.\nEs decir que geom_smooth() no recibe la orden de agrupar según SEXO, a raíz de no haber definido color dentro del aes() general.\nEste comportamiento nos permite gran versatilidad en los gráficos que realicemos.\nAlgunas otras funciones de geom_ son:\ngeom_line(), para líneas\ngeom_boxplot(), para boxplot\ngeom_histogram() para histogramas\ngeom_density() para curvas de densidad\ngeom_bar() para barras\nEstas funciones geométricas aplicadas sobre los mismos datos definen el tipo de gráfico.\nPara ejemplificar, podemos gráficar dos variables como SEXO y TALLA generando una base a la que sumaremos capas diferentes de geom():\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, color = SEXO)) + \n  geom_point()                # capa geométrica de puntos\n\n\n\n\n\n\n\n\n\n\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, color = SEXO)) + \n  geom_boxplot()            # capa geométrica de boxplot\n\n\n\n\n\n\n\n\n\n\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, color = SEXO)) + \n  geom_jitter()               # capa geométrica jitter (entramado de puntos)\n\n\n\n\n\n\n\n\n\n\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, fill = SEXO)) + \n  geom_violin()            # capa geométrica de violin\n\n\n\n\n\n\n\n\n\n\nObservemos que en este último gráfico cambiamos, dentro de aes(), color por fill. Mientras que color define el color del contorno del polígono, la línea de una recta o curva y los puntos, fill define el relleno de los objetos como es el caso de los violines construidos o cualquier elemento geométrico de polígono.\n\n\nEscalas (scale)\nLas configuraciones que se pueden realizar con scale son numerosas. Entre ellas encontramos cambios de color de contorno y relleno, cambios de posición, de tamaño y tipo de línea.\nEl argumento para modificar valores de escala comienzan siempre con con scale_ (por ejemplo scale_fill_ )\nSigamos trabajando con el conjunto de datos leído para mostrar ejemplos de gráficos donde agregamos capas de escala para color de relleno. ( scale_fill_brewer() )\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, fill = SEXO)) + \n  geom_boxplot() +\n  scale_fill_brewer(palette = \"Oranges\")   # paleta de los naranjas\n\n\n\n\n\n\n\n\n\n\nEn este ejemplo aplicamos una capa scale_fill_brewer() con una paleta de colores (Oranges) que se vincula con el argumento fill de aes() y definen los colores del boxplot.\nLo mismo hacemos para una gama de grises mediante scale_fill_grey()\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, fill = SEXO)) + \n  geom_boxplot() +\n  scale_fill_grey(start = 0.4, end = 0.8)   # paleta de los grises\n\n\n\n\n\n\n\n\n\n\nOtro uso de escalas, esta vez aplicado a los ejes, es la inversión del eje x.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO, color = SEXO)) +\n  geom_point() +\n  scale_x_reverse()     # escala inversa de x\n\n\n\n\n\n\n\n\n\n\nComo se observa en el gráfico la inclusión de scale_x_reverse() provoca que la escala x se invierta, quedando la TALLA ordenada de mayor a menor.\nPor último, otro ejemplo interesante es aplicado a escalas de etiquetado de ejes. Volvamos al ejemplo reciente de boxplot con relleno en escala de grises, su eje y se dibuja predeterminado desde 130 a casi 200 cms con cortes cada 5 cms y etiquetas cada 10 cms.\nCon escalas continuas manuales de la forma scale_*_continuos() podemos personalizar el eje y.\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, fill = SEXO)) + \n  geom_boxplot() +\n  scale_fill_grey(start = 0.4, end = 0.8)   +\n  scale_y_continuous(breaks = seq(130,200,2))\n\n\n\n\n\n\n\n\n\n\nEn este caso particular definimos un eje y con etiquetas de 2 en 2, mediante la línea scale_y_continuous(breaks = seq(130,200,2))\n\n\nTransformaciones estadísticas (stat)\nAlgunos gráficos no requieren de transformaciones estadísticas, en cambio, otros como boxplot, histogramas, etc poseen valores predeterminados de stat que pueden ser modificados.\nEstos valores se encuentra en forma de argumentos dentro de la función geométrica, por ejemplo para los histograma el argumento bins define la cantidad de intervalos de clase.\n\nfacultad |&gt; \n  ggplot(aes(EDAD)) +\n    geom_histogram(bins = nclass.Sturges(facultad$EDAD), fill = \"Blue\")\n\n\n\n\n\n\n\n\n\n\nVemos que el gráfico se construyó utilizando la regla de Sturges para determinar la cantidad de intervalos de clase para la variable EDAD. (función nclass.Sturges())\nOtras transformaciones estadísticas se incorporan como capas independientes, por ejemplo si queremos agregar los valores de media a los boxplot de talla según sexo construidos anteriormente.\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, fill = SEXO)) + \n  geom_boxplot() +\n  scale_fill_brewer(palette = \"Greens\") +\n  stat_summary(fun = mean, color = \"darkred\", geom = \"point\", \n               shape = 18, size = 3)\n\n\n\n\n\n\n\n\n\n\nAquí la capa completa surge a partir de la función stat_summary(), con argumentos que indican que se aplique la función mean. Incluye también la definición del objeto geométrico (point) que representa el valor de media (color, forma y tamaño)\n\n\nFacetado (facet)\nCon facet es posible separar gráficos en distintas ventanas o viñetas, creando matrices de gráficos separados por grupos de datos, a partir de la estratificación, en función de diferentes categorías de una variable cualitativa.\nEste comportamiento es sumamente útil cuando tenemos más de una variable categórica o cuando deseamos utilizar color para simbolizar otra variable.\nggplot ofrece dos posibilidades de hacer el facetado:\n\nfacet_wrap() – define subgrupos a partir de los niveles de una sola variable categórica\nfacet_grid() – define subgrupos a partir del cruce de dos variables de categóricas.\n\nUna aplicación de facet_wrap() podría ser que el primer gráfico que hicimos de dispersión de puntos con las variables TALLA y PESO se visualice en dos gráficos distintos según cada categoría de SEXO.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO, color = SEXO)) +\n     geom_point() +\n     facet_wrap(~SEXO)\n\n\n\n\n\n\n\n\n\n\nUsamos facet_grid() para crear una matriz producto del cruce de las variables FUMA y SEXO.Dentro de la cuadrícula graficaremos histogramas de la variable PESO coloreados por SEXO.\n\nfacultad |&gt; \n  ggplot(aes(PESO, fill = SEXO)) +\n     geom_histogram(bins = nclass.Sturges(facultad$PESO)) +\n     scale_fill_brewer(palette = \"Set1\") +\n     facet_grid(SEXO ~ FUMA)\n\n\n\n\n\n\n\n\n\n\nSi observamos las 4 líneas que integran todas las capas del código de ggplot notaremos que estamos integrando varias de las funciones que fuimos mostrando.\nSe hace imposible generar todas combinaciones posibles dada la variedad y extensión de argumentos que posee el paquete. De todas formas, el objetivo de este material es entender la base de funcionamiento, es decir la estructura “gramatical” que proponen sus autores.\n\n\nSistema de coordenadas (Coordinate Systems)\nEn algunas ocasiones puede que necesitemos introducir modificaciones en el sistema de coordinadas predeterminado.\nSobre las coordenadas cartesianas iniciales se puede invertir la orientación para que, por ejemplo, las barras se dibujen horizontales.\n\nfacultad |&gt; \n  ggplot(aes(SEXO, fill = SEXO)) +\n     scale_fill_brewer(palette = \"Set2\") +\n     geom_bar() +\n     coord_flip()   # invierte disposición de ejes\n\n\n\n\n\n\n\n\n\n\n\n\nTemas (themes)\nEl paquete ofrece un conjunto reducido de temas gráficos. El tema por defecto o inicial es theme_gray() pero se puede modificar a partir de agregar una capa de tema dentro de la estructura ggplot.\nA modo de ejemplo repetimos el último gráfico con el tema blanco y negro ( theme_bw() ):\n\nfacultad |&gt; \n  ggplot(aes(SEXO, fill = SEXO)) +\n     scale_fill_brewer(palette = \"Set2\") +\n     geom_bar() +\n     coord_flip() +\n     theme_bw()  # tema blanco y negro\n\n\n\n\n\n\n\n\n\n\nOtro tema que podemos utilizar es theme_dark() que tiene un fondo gris oscuro.\n\nfacultad |&gt; \n  ggplot(aes(SEXO, fill = SEXO)) +\n     scale_fill_brewer(palette = \"Set2\") +\n     geom_bar() +\n     coord_flip() +\n     theme_dark()\n\n\n\n\n\n\n\n\n\n\nEl siguiente cuadro muestra el nombre y presentación de los temas que contiene el paquete.\n\n\n\n\n\n\n\n\n\nContinuando con cuestiones estéticas en otra capa se pueden definir etiquetas, como título, subtítulo y nombres de ejes.\nLa forma de la función con argumentos básicos es labs( x = “Etiqueta X\", y = “Etiqueta Y\", title =“Título del gráfico\", subtitle = \"Subtítulo del gráfico\")\nAdemás se utiliza la función theme() para configurar el tipo de fuente y tamaño, entre otras opciones posibles.\n\nfacultad |&gt; \n  ggplot(aes(SEXO, fill = SEXO)) +\n     scale_fill_brewer(palette = \"Set2\") +\n     geom_bar() +\n     coord_flip() +\n     labs(y = \"Cantidad\", title = \"Distribución de Sexo\") +\n     theme(plot.title=element_text(face=\"italic\", size=16)) \n\n\n\n\n\n\n\n\n\n\n\n\nPaquete esquisse\nEsquisse es un paquete que contiene una aplicación asistente para crear gráficos ggplot2 de forma interactiva. Basta con arrastrar y soltar las variables para asignarlas a diferentes estéticas.\nPodemos visualizar rápidamente los datos de acuerdo con su tipo, exportarlos en varios formatos y recuperar el código para reproducir el gráfico.\nEl paquete se instala mediante el menú Packages de RStudio o ejecutando:\n\ninstall.packages(\"esquisse\")\n\nLuego se puede acceder a la aplicación por medio del acceso Addins\n\n\n\n\n\n\n\n\n\no ejecutando en consola esquisser()\nTambién se puede agregar el nombre de la tabla de datos dentro de los paréntesis\n\nesquisser(datos)\n\nPara más información consultar en la viñeta del paquete en CRAN."
  },
  {
    "objectID": "primero/clases/03-introTidy.html#uniones-en-datos-relacionales",
    "href": "primero/clases/03-introTidy.html#uniones-en-datos-relacionales",
    "title": "Tidyverse",
    "section": "Uniones en datos relacionales",
    "text": "Uniones en datos relacionales\nExisten situaciones donde debemos analizar datos que se encuentran en diferentes tablas.\nCon el fin de responder a nuestras preguntas de interés en ocasiones deberemos unirlas previamente.\nDe manera general, se le llama datos relacionales a esas múltiples tablas de datos que provienen muchas veces de sistemas de bases de datos construidas bajo el modelo relacional o bien cuando las tablas de datos tienen fuentes distintas pero comparten alguna variable común que permita “conectarlas”.\nUn ejemplo recurrente sucede cuando necesitamos calcular la tasa de algún evento de salud y tenemos en una tabla el conteo (dato agregado) del evento (numerador) y en otra el conteo de la población en riesgo (denominador).\n\nTipos de operaciones\nPara trabajar con datos relacionales necesitamos de funciones-verbos que vinculen pares de tablas.\nLas tres familias de funciones del paquete dplyr diseñadas para trabajar con datos relacionales son:\n\nUniones de transformación (del inglés mutating joins), agregan nuevas variables a una tabla a partir de observaciones coincidentes de otra tabla.\nUniones de filtro (del inglés filtering joins), filtran observaciones de una tabla en función de la coincidencia o no coincidencia de otra tabla.\nOperaciones en filas y columnas, sirven para unir tablas por columnas o por filas.\n\n\n\nClaves\n\nLas variables usadas para conectar cada par de variables se llaman claves (del inglés key)\nUna clave es una variable (o un conjunto de variables) que identifican de manera única una observación.\n\nExisten dos tipos de claves:\n\nUna clave primaria identifica únicamente una observación en su propia tabla.\nUna clave foránea únicamente identifica una observación en otra tabla.\n\nUna vez que identificadas las claves primarias en las tablas, es una buena práctica verificar que identifican de forma única cada observación. Una forma de hacerlo es usar count() con las claves primarias y buscar las entradas con n mayor a uno:\n\ndatos |&gt; \n  count(clave_primaria) |&gt; \n  filter(n &gt; 1)\n\nLa salida debería mostrar que no hay ninguna observación que cumpla la condición de n &gt; 1, es decir todas las observaciones tienen una sola clave primaria unívoca.\nEn ocasiones podemos tener claves primarias compuestas por más de una variable. Tendremos que utilizar entonces esta combinación de variables a la vez en las uniones que realicemos.\nOtra situación inversa es no tener ninguna variable como clave primaria, aunque sepamos que cada observación pertenece a una misma unidad de análisis pero de elementos (sujetos, etc) diferentes. Aquí se puede usar la función row_number() que numera en orden ascendente las observaciones de la tabla y almacena esta numeración en una variable, creando una clave subrogada.\n\ndatos &lt;- datos |&gt; \n  mutate(clave = row_number()) \n\n\n\nUniones de transformación\nLa forma más simple de unión es la unión interior (del inglés inner join). Una unión interior une pares de observaciones siempre que sus claves sean iguales.\nUnión interior\nUna unión interior mantiene las observaciones que aparecen en ambas tablas. La estructura del código sirve de base para las demás uniones:\n\ndatos_x |&gt; \n  inner_join(datos_y, by = \"variable_clave\") \n\n\n\n\n\n\nLa propiedad más importante de una unión interior es que las filas no coincidentes no se incluyen en el resultado\nUniones exteriores\nUna unión exterior mantiene las observaciones que aparecen en al menos una de las tablas.\n\nUna unión izquierda (left join) mantiene todas las observaciones en x.\n\n\n\n\n\n\n\nUna unión derecha (right join) mantiene todas las observaciones en y.\n\n\n\n\n\n\n\nUna unión completa (full join) mantiene todas las observaciones en x e y.\n\n\n\n\n\n\nEstas uniones funcionan agregando una observación “virtual” adicional a cada tabla. Esta observación tiene una clave que siempre coincide (de no haber otras claves coincidentes) y un valor que se llena con NA.\nOtra forma de ilustrar diferentes tipos de uniones es mediante un diagrama de Venn.\n\n\n\n\n\nSin embargo, tiene una limitante importante: un diagrama de Venn no puede mostrar qué ocurre con las claves que no identifican de manera única una observación.\n\n\nClaves duplicadas\nHasta ahora todas las situaciones han asumido que las claves son únicas. Pero esto no siempre es así.\nExisten dos posibilidades habituales:\n\nUna tabla tiene claves duplicadas producto de una relación uno a varios.\n\n\n\n\n\n\n\nAmbas tablas tienen claves duplicadas (producto de una relación real varios a varios o por algún “error”)\n\n\n\n\n\n\nSiempre que unimos claves duplicadas, obtenemos todas las posibles combinaciones, es decir, el producto cartesiano\n\n\nVariables claves\nLa forma común del argumento by = donde se define/n la/s variable/s clave/s es igualarlo al nombre la variable o variables concatenadas con c() que deberán tener el mismo nombre en las dos tablas a unir.\nOtra maneras de conectar las tablas sería:\n\nSin definir by = o bien by = NULL, que de forma predeterminada utiliza todas las variables que se llamen de la misma forma (respetando mayúsculas y minúsculas). Esta se denomina unión natural.\nUtilizar la función join_by() en el argumento by = que nos da la posibilidad de declarar cuales son las variables de unión cuando estas tengan nombres distintos en cada tabla.\n\n\ndatos_x |&gt; \n  inner_join(datos_y, \n             by = join_by(var_clave_x == var_clave_y)) \n\nObserven que la igualdad de las variables claves de x e y es un operador de comaparación ==\nEn caso que hubiese más de una variable clave de unión se puede hacer:\n\ndatos_x |&gt; \n  inner_join(datos_y, \n             by = join_by(var1_clave_x == var1_clave_y,\n                          var2_clave_x == var2_clave_y,)) \n\n\n\nUniones de filtro\nLa función semi_join() mantiene todas las observaciones de la tabla x donde la clave coincide con la clave de la tabla y\n\n\n\n\n\nPara hacer lo inverso, anti_join() descarta todas las observaciones de la tabla x donde la clave coincide con la clave de la tabla y\n\n\n\n\n\n\n\nUnión por filas y por columnas\nEn algunas ocasiones necesitamos unir tablas que tienen formatos particulares por medio de filas o por medio de columnas.\nLas funciones de dplyr para esta tarea son:\n\nbind_rows() Une una tabla debajo de otra. Aplica cuando tenemos la misma estructura en tabla de datos divida en varios archivos (por ejemplo, producto de carga simultánea de datos en diferentes computadoras con diferentes data-entry)\nbind_cols() Une una tabla al lado de la otra. Es peligroso su uso si la confundimos con las uniones de transformación porque perdemos integridad de datos en las observaciones. Sirve sólo si el “orden” de las observaciones pueden garantizar la misma identidad de las partes a unir."
  },
  {
    "objectID": "index.html#descripción",
    "href": "index.html#descripción",
    "title": "Gestión de Datos",
    "section": "Descripción",
    "text": "Descripción\nEste curso…..\nInstructor:\n\nChristian Ballejo"
  },
  {
    "objectID": "index.html#bibliografía",
    "href": "index.html#bibliografía",
    "title": "Gestión de Datos",
    "section": "Bibliografía",
    "text": "Bibliografía\nR for Data Science (2e)\nEpiRhandbook en español\nData Visualization"
  },
  {
    "objectID": "index.html#temario",
    "href": "index.html#temario",
    "title": "Gestión de Datos",
    "section": "Temario",
    "text": "Temario\n\n\n\n\n\nFecha\n\n\nTema\n\n\nLectura\n\n\nDiapositiva\n\n\nPráctica\n\n\nRecursos\n\n\n\n\n\n\n01/10/2024\n\n\nBienvenida\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n01/10/2024\n\n\nDatos - Parte 1\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n03/10/2024\n\n\nDatos - Parte 2\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n08/10/2024\n\n\nDatos - Parte 3\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n10/10/2024\n\n\nLenguaje R\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n10/10/2024\n\n\nRStudio\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n10/10/2024\n\n\nTidyverse\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n15/10/2024\n\n\nImportación y exportación de archivos"
  },
  {
    "objectID": "primero/clases/00-datos.html",
    "href": "primero/clases/00-datos.html",
    "title": "Gestión de datos",
    "section": "",
    "text": "La gestión de datos vinculada a procesos de investigación o vigilancia epidemiológica implica la organización, el almacenamiento, la preservación y la difusión de los datos antes de iniciar la etapa de análisis final.\nLos datos de los estudios de investigación incluyen los materiales generados o recopilados a lo largo de un proceso de investigación. Como podemos imaginar, esta amplia definición incluye mucho más que la gestión de conjuntos de datos digitales. También incluye archivos físicos, documentación, cuestionarios, grabaciones y más. En definitiva, es una tarea importante que comienza mucho antes de que se recopilen los datos, durante la fase de planificación, y continúa mucho después de que finaliza un proyecto de investigación durante la fase de archivo y uso compartido."
  },
  {
    "objectID": "primero/clases/00-datos.html#ciencia-abierta",
    "href": "primero/clases/00-datos.html#ciencia-abierta",
    "title": "Gestión de datos",
    "section": "Ciencia abierta",
    "text": "Ciencia abierta\nCon el auge tecnológico de los últimos años surgió un creciente interés en las prácticas de ciencia abierta, donde compartir datos bien gestionados y documentados ayuda a generar confianza en el proceso de investigación. Compartir datos curados de manera reproducible es “un fuerte indicador para los colegas investigadores de rigor, confiabilidad y transparencia en la investigación científica” según (Alston and Rick 2021). También permite que otros repliquen y aprendan de su trabajo, validen sus resultados para fortalecer la evidencia, así como también detecten potencialmente errores en su trabajo, evitando que se tomen decisiones basadas en datos incorrectos. Compartir sus datos con suficiente documentación y metadatos estandarizados también puede conducir a una mayor colaboración y un mayor impacto ya que los colaboradores pueden acceder y comprender sus datos con facilidad.\nLa ciencia abierta tiene como objetivo hacer que la investigación y la difusión científicas sean accesibles para todos, lo que hace absolutamente necesaria la necesidad de buenas prácticas de gestión de datos.\nOrganizaciones, como el Centro para la Ciencia Abierta (Center for Open Science) https://www.cos.io, se han convertido en un conocido defensor de la ciencia abierta, ofreciendo el Marco de Ciencia Abierta (OSF por Open Science Framework) como una herramienta para promover la ciencia abierta a lo largo de todo el ciclo de vida de la investigación."
  },
  {
    "objectID": "primero/clases/00-datos.html#marcos-existentes---fair",
    "href": "primero/clases/00-datos.html#marcos-existentes---fair",
    "title": "Gestión de datos",
    "section": "Marcos existentes - FAIR",
    "text": "Marcos existentes - FAIR\nEn 2016, se publicaron los Principios FAIR en Scientific Data (Wilkinson 2016), que describen cuatro principios rectores para la gestión y administración de datos científicos. Estos principios se crearon para mejorar y respaldar la reutilización de datos académicos, específicamente la capacidad de las máquinas para acceder y leer datos. Son la base de cómo se deben compartir públicamente todos los datos digitales.\nLos principios son:\nF: Findable (Localizable)\nTodos los datos deben poder encontrarse mediante un identificador persistente y contar con metadatos completos que permitan realizar búsquedas. Estas prácticas ayudan al descubrimiento de información a largo plazo y proporcionan citas registradas.\nA: Accessible (Accesible)\nLos usuarios deberían poder acceder a sus datos. Esto puede significar que sus datos estén disponibles en un repositorio o a través de un sistema de solicitudes. Como mínimo, un usuario debería poder acceder a los metadatos, incluso si los datos reales no están disponibles abiertamente.\nI: Interoperable\nSus datos y metadatos deben utilizar vocabularios y formatos estandarizados. Tanto los humanos como las máquinas deben poder leer e interpretar sus datos. Las licencias no deben suponer una barrera para su uso. Los datos deben estar disponibles en formatos abiertos a los que se pueda acceder mediante cualquier software (por ejemplo, csv, txt, etc).\nR: Reusable (Reutilizable)\nPara brindar contexto para la reutilización de sus datos, sus metadatos deben brindar información sobre la procedencia de los datos, brindar una descripción del proyecto, una descripción general del flujo de trabajo de los datos y los autores a los que se debe citar para una atribución adecuada. También debe tener licencias claras para el uso de los datos."
  },
  {
    "objectID": "primero/clases/00-datos.html#conceptos-básicos-de-un-conjunto-de-datos",
    "href": "primero/clases/00-datos.html#conceptos-básicos-de-un-conjunto-de-datos",
    "title": "Gestión de datos",
    "section": "Conceptos básicos de un conjunto de datos",
    "text": "Conceptos básicos de un conjunto de datos\nUn dato contiene la mínima unidad de información y desde la óptica informática es una representación simbólica (numérica, alfabética, etc) de un atributo o característica de una entidad. Para nosotros el dato siempre representa el valor / medida (variables cuantitativas) o modalidad / categoría (variables cualitativas) de una variable.\nDentro de la investigación cuantitativa, generalmente trabajamos con datos digitales en forma de un conjunto de datos, una colección estructurada de datos.\nUn conjunto de datos mínimo está organizado en un formato rectangular que permite que la información sea legible por la computadora. Los conjuntos de datos rectangulares, también llamados tabulares, se componen de columnas y filas y se asocian a una unidad de investigación u observación.\n\n\n\n\n\nid\nsexo\nedad\npeso\ntalla\ntrabaja\n\n\n\n\n1\nM\n76\n71\n167.0\nFALSE\n\n\n2\nM\n68\n71\n164.0\nFALSE\n\n\n3\nM\n50\n79\n164.0\nFALSE\n\n\n4\nM\n49\n71\n164.0\nTRUE\n\n\n5\nM\n51\n87\n167.5\nTRUE\n\n\n6\nM\n68\n75\n170.0\nFALSE\n\n\n\n\n\n\nColumnas\nLas columnas del conjunto de datos representan las variables o atributos constarán de los siguientes tipos de variables:\nVariables recopiladas\nSon variables recogidas de un instrumento (cuestionario estrcuturado, etc) en fuentes primarias o fuente secundarias (externa).\nVariables creadas\nEstos pueden ser variables construidas o pueden ser variables derivadas o indicadores con fines de resumen (llamada también información agregada), como medias, proporciones, tasas, etc.\nVariables de identificación\nTambién debe incluir valores que identifiquen de forma únivoca a los sujetos en sus datos (por ejemplo, el DNI o historia clínica u otro identificador ad hoc si se desea preservar la identidad).\n\nAtributos de columna\nLas columnas o variables de su conjunto de datos también tienen los siguientes atributos:\nNombres de variables\nUn nombre de variable es la representación corta de la información contenida en una columna.\nLos nombres de las variables deben ser únicos. Ningún nombre de variable en un conjunto de datos puede repetirse.\nTipos de variables\nEl tipo de una variable determina los valores permitidos para una variable, las operaciones que se pueden realizar en la variable y cómo se almacenan los valores.\nAlgunos ejemplos de tipos son numéricos, de caracteres (también llamados texto o string), de fecha o lógicos (valores True y False). Los tipos también se pueden definir de forma más específica según sea necesario (por ejemplo, continuos o categóricos).\nValores variables\nLos valores de las variables hacen referencia a la información contenida en cada columna. En cada variable se puede configurar los valores permitidos predeterminados en forma de validación a la carga de datos.\nAlgunos ejemplos de configuración de valores permitidos para diferentes tipos de variables incluyen:\nVariable de caracter categórico: “sí” | “no”\nVariable numérica entera: 1 a 100\nFecha variable: 01/10/2024 a 31/12/2024\nVariable de carácter de texto libre: se permite cualquier valor\nCualquier cosa fuera de los valores o rangos esperados se considera un error.\nEtiquetas variables\nUna etiqueta de variable es la descripción legible por humanos de lo que representa una variable.\nEsta puede ser una etiqueta con la definición de la variable o directamente la pregunta que vincula la variable con el cuestionario de origen.\n\n\n\nFilas\nLas filas del conjunto de datos representan a los sujetos (también llamados registros u observaciones) de sus datos. Los sujetos de su conjunto de datos pueden ser personas, hogares, ubicaciones como países o provincias, etc.\n\n\nCeldas\nA la intersección entre una columna y una fila la llamamos celda. En cada una de ellas puede haber solo un valor del tipo definido en la columna y que representa al sujeto de la fila."
  },
  {
    "objectID": "primero/clases/00-datos.html#fuentes-de-datos-primaria-y-secundaria",
    "href": "primero/clases/00-datos.html#fuentes-de-datos-primaria-y-secundaria",
    "title": "Gestión de datos",
    "section": "Fuentes de datos primaria y secundaria",
    "text": "Fuentes de datos primaria y secundaria\nEl término datos primarios se refiere a datos recolectados por el investigador por primera vez. Esta situación requiere que se diseñen adecuadamente los instrumentos de recolección y la carga de datos que conlleva la necesidad de contar con una gran cantidad de recursos (tiempo, mano de obra y presupuesto).\nPor otra parte, también requiere de un proceso de limpieza y depuración para tratar, previo al análisis, los datos crudos.\nEn cambio, las fuentes secundarias implican información que ya ha sido recopilada y registrada por otra/s persona/s diferente al analista, generalmente para un propósito que no está relacionado con el análisis actual.\nUn ejemplo en el mundo epidemiológico son las encuestas nacionales de factores de riesgo (ENFR) que el Ministerio de Salud de la Nación Argentina en conjunto con el INDEC llevó a cabo en 2005, 2009, 2013 y 2018. Estas tablas de datos de fuente secundaria están disponibles en el sitio del INDEC"
  },
  {
    "objectID": "primero/clases/00-datos.html#fuentes-de-datos-primaria-y-secundaria-1",
    "href": "primero/clases/00-datos.html#fuentes-de-datos-primaria-y-secundaria-1",
    "title": "Gestión de datos",
    "section": "Fuentes de datos primaria y secundaria",
    "text": "Fuentes de datos primaria y secundaria\nInstrumentos de recolección de datos - Cuestionario estructurado - Tipo de preguntas - Validación - estándares Ética - Consentimientos - confidencialidad - sensibilidad - anonimización Recolección electrónica - Bases de datos (relacional / no relacional) - nombre de variables - codificación de valores - diccionario de datos - prueba piloto\nPlanificación de la gestión de datos (documentación, guías de estilo, etc) Proyectos - estructura de directorios y archivos - metadatos - buenas practicas Captura de datos - Formatos de archivos - formato largo / ancho - variables identificadoras - clave primaria / foránea - uniones\nDepuración y validación de datos\nAlmacenamiento, seguridad, colaboración y archivo de datos\n\nAnálisis - Softwares y lenguajes disponibles"
  },
  {
    "objectID": "primero/clases/00-datos.html#bases-de-datos",
    "href": "primero/clases/00-datos.html#bases-de-datos",
    "title": "Gestión de datos",
    "section": "Bases de datos",
    "text": "Bases de datos\nHasta ahora hemos estado hablando de un conjunto de datos independiente. Sin embargo, es más probable que el proyecto de investigación esté compuesto por varios conjuntos de datos, dependiendo del diseño de estudio y de las diferentes dimensiones de abordaje (por ejemplo, cuestionarios clínicos y de laboratorio). En algún momento, lo más probable es que necesitemos vincular esos conjuntos de datos.\nPara pensar en cómo vincular datos, necesitamos discutir dos cosas: el diseño de la base de datos y la estructura de los datos.\n\n\n\n\n\n\nUna base de datos es “una colección organizada de datos almacenados como múltiples conjuntos de datos”\n\n\n\nEn la terminología de bases de datos, cada conjunto de datos que tenemos se considera una “tabla”. Cada tabla incluye una o más variables que definen de forma única las filas de sus datos (es decir, una clave principal). Las tablas también pueden contener variables asociadas con valores únicos en otra tabla (es decir, claves externas). Este juego de claves principal-externa sirve para “conectar” las tablas de forma horizontal sin perder integridad.\n\n\n\n\n\n\nEs importante tener en cuenta que si no tiene identificadores únicos comunes en todas las tablas, como en el caso de los datos anónimos, no podremos unir datos horizontalmente.\n\n\n\nExiste otra forma de unión de tablas que llamaremos uniones verticales y sucede cuando debemos anexar o apilar datos de un conjunto con otro que siempre deberá tener la misma estructura, es decir los mismo nombres de variables y tipo de datos."
  },
  {
    "objectID": "primero/clases/00-datos.html#instrumentos-de-recolección-de-datos",
    "href": "primero/clases/00-datos.html#instrumentos-de-recolección-de-datos",
    "title": "Gestión de datos",
    "section": "Instrumentos de recolección de datos",
    "text": "Instrumentos de recolección de datos\nLas tablas de datos son producto del almacenamiento de la información que proviene muchas veces de los instrumentos de recolección más comunes en la investigación cuantitativa: el cuestionario estructurado.\nLa forma en que recibimos las variables de análisis tendrán su origen en la confección de estos cuestionarios. Por lo que la construcción de estos instrumentos de recolección nacen pensando en los componentes del dato científico.\nUn dato científico esta compuesto por una unidad de observación, dimensiones de análisis que definen variables de estudio, valores o categorías conceptuales que luego se operacionalizan en indicadores que terminaran siendo los datos que encontramos en las tablas.\nLa unidad de observación es la entidad que deseamos estudiar, es decir, aquella que se observa para efectuar mediciones o para clasificarla en categorías. También se denomina unidad de análisis o unidad experimental y se define acompañada de un tiempo y espacio identificable.\nPor ejemplo, en grandes encuestas como la ENFR tenemos varias unidades de observación: vivienda, hogar, jefe de hogar y persona encuestada.\nEstas unidades de observación fueron abordadas en un espacio específico, domicilio-ciudad-departamento-conglomerado-provincia del país y en un tiempo determinado (encuestas de 2005, 2009, 2013 y 2018).\nLas variables o dimensiones de análisis constituyen los aspectos de las unidades de observación que se han seleccionado para examinar o estudiar, de acuerdo a los problemas e hipótesis de investigación. Concretamente son aquellos atributos, propiedades o características observables de las diferentes unidades de observación.\nPor ejemplo, las variables recabadas en la ENFR son: edad, sexo, nivel de instrucción, actividad física, consumo de alcohol, consumo de tabaco, etc.\nAlgunas de estas variables son simples o directas como la edad donde solo hay que aclarar en que unidad se la está midiendo. Edad en años o edad en meses, etc.\nOtras son constructos más complejos donde para aprehender el concepto buscado se necesitan de una serie de preguntas / variables individuales que recaban información sobre distintas dimensiones del problema. Es el caso, por ejemplo de consumo de alcohol donde podemos consultar sobre si toma, cuando lo hace, cuanto bebe, que bebe, etc.\nMuchas de estas preguntas estan validadas por estudios previos y se copian con la misma estructura en diseños de cuestionarios nuevos para aprovechar la garantía de la validación y la comparabilidad que permite hacerlo.\nCuando hablamos de definiciones operacionales o indicadores vinculados a las variables conceptuales nos referimos a los procedimientos para “medir” a estas variables. Existen variables formuladas en términos abstractos o conceptuales con cierta complejidad que deben descomponerse en varias dimensiones y deben operacionalizarse para poder medirlas.\n\n\n\n\n\n\nUn ejemplo de operacionalización para la variable Hacinamiento es definir el indicador como:\n“Cantidad de personas por cuarto, informadas por algún respondente del hogar”\n\nHasta 3 personas por cuarto es “Sin hacinamiento”\nMás de 3 personas por cuarto es “Con hacinamiento”\n\n\n\n\nPor otra parte, hallamos diferentes tipos de preguntas en un cuestionario estructurado producto de este proceso operacional que va a condicionar la forma de nuestras variables digitales incluidas en la tabla de datos.\nHay preguntas cerradas con valores o códigos establecidos, preguntas abiertas que son muy difíciles de analizar en el ámbito cuantitativo o mixtas donde aparece una opción otro/a que se agrega a las respuestas válidas.\nTenemos también preguntas de respuesta simple, donde solo una es posible y otras de respuesta múltiple donde se puede marcar más de una respuesta simultánea. Esta situación hace que en la construcción de nuestra tabla de datos cada respuesta se refleje como una variable por si o no, produciendo posteriormente un análisis de mayor complejidad.\nSiempre las preguntas cerradas deberán cumplir con dos cualidades particulares, ser exahustivas y excluyentes.\nExahustiva, significa que dentro de las opciones válidas predeterminadas tendremos que tener la posibilidad de abarcar todas las posibles respuestas del entrevistado. Esto provoca que muchas veces aparezcan las opciones, “Sin dato”, “No sabe/No contesta” u “Otro/a”.\nExcluyente, es que no pueden coexistir dos respuestas simultáneamente. Si se produce, entonces habrá que construir variables de respuesta múltiple.\nJunto a las preguntas y sus valores se acompaña la clasificación de variables y definición de escalas. Las variables pueden ser clasificadas en:\n\n\n\nEscala\nEjemplo\n\n\n\n\nNominal\nFuma: “si” - “no”\n\n\nOrdinal\nNivel de ingresos: “Alto” - “Medio” - “Bajo”\n\n\nIntervalo\nHora del día: “0:00”…“24:00”\n\n\nRazón\nPeso (Kgrs): 0….a n\n\n\n\nOtras escalas especiales son las de Likert, Guttman, visuales análogas, etc\nEn muchas oportunidades encontramos en las tablas de datos provenientes de cuestionarios variables codificadas. La codificación es la tarea de asignar códigos a las distintas respuestas de las preguntas del cuestionario y obtener así los distintos valores de las variables con los que se construye la matriz de datos.\nEs necesario estar atento a esta situación porque en algunas tablas de datos de fuente secundaria se suele asignar valores extremos en la escala numérica de variables con este tipo de dato, por ejemplo en la ENFR utilizan 9, 99, 999 dependiendo de los dígitos que tenga la variable para referirse a categorías tipo Ns/Nc o sin dato.\nTodo lo desarrollado anteriormente nos lleva a que cada tabla de datos que construyamos nosotros mismos o las tablas provenientes de fuentes secundarias deben estar acompañadas de diccionario de datos o cuadros de operacionalización donde esten definidas las características, valores legales y codificación de cada variable de estudio.\nVer Manual de uso de la base de datos usuario ENFR 2018"
  },
  {
    "objectID": "primero/clases/00-datos.html#consideraciones-éticas",
    "href": "primero/clases/00-datos.html#consideraciones-éticas",
    "title": "Gestión de datos",
    "section": "Consideraciones éticas",
    "text": "Consideraciones éticas\nNuestras tablas de datos suelen contener información de sujetos humanos lo que conlleva a la responsabilidad de proteger a esos datos. Los datos de humanos pueden contener información identificable que aumenta el riesgo de que los participantes puedan ser revelados en un conjunto de datos. Habitualmente también contienen información sobre temas sensibles vinculado a la salud lo que aumenta aún más los riesgos si se identifica a los participantes.\nCuando se trabaja con sujetos humanos, hay dos tipos de identificadores que se pueden recopilar en el estudio: directos e indirectos.\nLos identificadores directos son exclusivos de un individuo y se pueden utilizar para identificar a un participante. Los identificadores indirectos no son necesariamente exclusivos de un individuo en particular, pero si se combinan con otra información se pueden utilizar para identificar a un participante.\nLa Oficina de Ética de Investigación Humana de la Universidad de Carolina del Norte define 4 tipos de archivos de datos en función a la identifcación personal:\n\nIdentificable: los datos incluyen información de identificación personal. Es común que los datos crudos sin procesar de un estudio de investigación sean identificables.\nCodificado: en este tipo de archivo de datos, se ha eliminado o distorsionado la información de identificación personal y se han reemplazado los nombres por un código (es decir, un identificador único del participante). La única forma de vincular los datos con un individuo es a través de ese código. El archivo de código de identificación (clave de vinculación) se almacena por separado de los datos de investigación. Los datos codificados son, por lo general, el tipo de archivo que se crea después de limpiar los datos sin procesar del estudio (clean_data).\nDesidentificado: en este tipo de archivo, se ha eliminado o distorsionado la información de identificación y los datos ya no se pueden volver a asociar con la persona subyacente (la clave de vinculación ya no existe). Esto es lo que se crea normalmente cuando se comparten públicamente los datos de un estudio de investigación.\nAnónimo: en un conjunto de datos anónimo, nunca se recopila información de identificación, por lo que debería haber poco o ningún riesgo de identificar a un participante específico.\n\n\nSensibilidad\nLos datos suelen clasificarse en función del nivel de sensibilidad. Estos niveles de sensibilidad determinan cómo se pueden recopilar, almacenar y compartir los datos, así como cuál debe ser la respuesta ante cualquier violación de datos. Si bien existe variación, aquí se presenta un resumen general de cómo se puede categorizar la información.\n\nSensibilidad baja: se considera que estos datos no presentan riesgo o que presentan un riesgo bajo si se divulgan. Por lo general, esto incluye datos anónimos y no identificados que no contienen información altamente sensible.\nSensibilidad moderada: Se considera que estos datos tienen un riesgo moderado si se divulgan, lo que significa que podrían afectar negativamente a las personas. Estos datos pueden incluir información identificable o información que podría permitir volver a identificar a los participantes dentro de los propios datos o utilizando una fuente externa. Por lo general, se exige que estos datos se mantengan confidenciales por ley u otros acuerdos. Estos datos deben protegerse contra el acceso no autorizado.\nAlta sensibilidad: estos datos deben estar sujetos a las medidas de seguridad más estrictas y podrían causar un gran daño si se divulgan. Estos datos incluyen información personal identificable o información que podría permitir que los participantes sean reidentificados, así como información privada o altamente sensible (por ejemplo, registros médicos) y, por lo general, se exige que se mantengan confidenciales por ley u otros acuerdos. Estos datos deben protegerse contra el acceso no autorizado."
  },
  {
    "objectID": "primero/clases/00-datos.html#plan-de-gestión-de-datos",
    "href": "primero/clases/00-datos.html#plan-de-gestión-de-datos",
    "title": "Gestión de datos",
    "section": "Plan de gestión de datos",
    "text": "Plan de gestión de datos\nUn plan de gestión de datos es un documento complementario sobre cómo se planea recopilar, almacenar, gestionar y compartir los productos de datos de investigación.\nEs oportuno que acompañe o sea parte del protocolo de investigación o del manual de procedimiento de un programa de vigilancia epidemiológica y puede contener los siguientes items:\n\nDescripción de los datos que se compartirán\n\n\n¿Cuál es la fuente de los datos? (por ejemplo, encuestas, datos existentes, sistemas de vigilancia, etc)\n¿Cómo se limpiarán y conservarán los datos antes de compartirlos?\n¿Cuál será el nivel de agregación? (por ejemplo, nivel de elemento, datos resumidos, solo metadatos)\n\nEs posible que sea necesario compartir los conjuntos de datos de un proyecto de diferentes maneras debido a razones legales, éticas o técnicas.\n\n¿Se compartirán datos tanto brutos como limpios?\n\n\nFormato de los datos a compartir\n\n\n¿Los datos estarán en formato electrónico?\n¿Se proporcionará en un formato no propietario? (por ejemplo, csv)\n¿Se proporcionará más de un formato? (por ejemplo, xlsx y csv)\n¿Se necesitan herramientas para manipular o reproducir datos compartidos? (por ejemplo, software, código)\n\nProporcione detalles sobre esas herramientas (por ejemplo, cómo se puede acceder a ellas, número de versión, sistema operativo requerido).\n\n\n\nDocumentación a compartir\n\n\n¿Qué documentación compartirás?\n\nConsidere la documentación a nivel de proyecto, de conjunto de datos y de variable.\n\n¿En qué formato estará su documentación? (por ejemplo, csv, pdf)\n\n\nNormas\n\n\n¿Planea utilizar algún estándar para cuestiones como metadatos, recopilación de datos o formato de datos?\n\n\nConservación de datos\n\n\n¿Dónde se archivarán los datos internamente?\n\nMedidas de seguridad y accesos\n\n¿Se archivarán los datos para compartirlos públicamente? ¿Dónde?\n¿Cuáles son las características deseables del repositorio? (por ejemplo, identificadores únicos y persistentes asignados a los datos, metadatos recopilados, procedencia de los registros, opciones de licencia)\n¿Cuándo depositará sus datos de estudio en el repositorio y durante cuánto tiempo permanecerán accesibles los datos?\n¿Cómo permitirá la reutilización de datos?\n\n\nConsideraciones sobre acceso, distribución o reutilización\n\n\n¿Existen factores legales, técnicos o éticos que afecten la reutilización, el acceso o la distribución de sus datos?\n¿Se restringirán algunos datos?\n¿Se requieren controles de acceso (por ejemplo, un acuerdo de uso de datos)?\n\n\nProtección de la privacidad y la confidencialidad\n\n\n¿Los participantes firman acuerdos de consentimiento informado? ¿El consentimiento comunica cómo se espera que se utilicen y compartan los datos de los participantes? ¿Cómo evitará la divulgación de información de identificación personal cuando comparta datos?\n\n\nSeguridad de los datos\n\n\n¿Cómo se mantendrá la seguridad y la integridad de los datos durante un proyecto? (por ejemplo, considere el almacenamiento, el acceso, la copia de seguridad y la transferencia de datos)\n\n\nFunciones y responsabilidades\n\n\n¿Cuáles son los roles del personal en la gestión y preservación de datos?\n¿Quién garantiza la accesibilidad, fiabilidad y calidad de los datos?\n¿Existe un plan si un miembro principal del equipo abandona el proyecto o la institución?"
  },
  {
    "objectID": "primero/clases/00-datos.html#planificación-de-la-gestión-de-datos",
    "href": "primero/clases/00-datos.html#planificación-de-la-gestión-de-datos",
    "title": "Gestión de datos",
    "section": "Planificación de la gestión de datos",
    "text": "Planificación de la gestión de datos\nPlanificar las etapas del proceso de investigación o del protocolo de trabajo habitual en la vigilancia epidemiológica consiste en decidir y documentar los pasos a seguir por todo el equipo durante el estudio.\nLa reproducibilidad comienza en la fase de planificación y por lo tanto habrá que dedicar tiempo para crear, documentar y capacitar al personal en estándares de gestión de datos antes de que comience su proyecto, dado que ayuda a garantizar que los procesos se implementen con fidelidad y se puedan replicar de manera consistente.\nUn ejemplo relacionado a esta planificación que es recurrente en todos los casos es la limpieza de datos.\n\nPlan de limpieza de datos\nUn plan de limpieza de datos es una propuesta escrita que describe cómo planeamos transformar los datos sin procesar en datos limpios y utilizables. Este documento no contiene código y no depende de habilidades técnicas. Es necesario sobre todo si compartimos el trabajo con otros integrantes o bien la información se recolecta o recibe de forma periódica (por ejemplo en vigilancia epidemiológica). Dado que este documento describe las transformaciones previstas para cada conjunto de datos sin procesar, permite que cualquier miembro del equipo brinde comentarios sobre el proceso de limpieza de datos.\nUn ejemplo de un plan simple de limpieza de datos para un archivo de datos cualquiera:\n\n1. Importar datos crudos\n2. Visualizar datos (filas y columnas)\n3. Remover registros duplicados en caso de existir (usando las reglas del caso, duplicados completos o por claves)\n4. Anonimizar datos \n5. Renombrar variables basado en el diccionario de datos\n6. Diagnosticar variables (tipos, inconsistencias, etc)\n7. Depurar datos diagnosticados\n8. Detección de valores perdidos (missing)\n9. Creación de variables construidas (clasificación, cálculo, agrupamientos, etc)\n10. Exportar datos limpios en el formato elegido \n\nAsí como se desarrolla este plan de limpieza se definen otros planes para la recolección, análisis, comunicación, publicación, etc."
  },
  {
    "objectID": "primero/clases/00-datos.html#guía-de-estilo",
    "href": "primero/clases/00-datos.html#guía-de-estilo",
    "title": "Gestión de datos",
    "section": "Guía de estilo",
    "text": "Guía de estilo\nLas guías de estilo crean estandarización dentro y entre proyectos. Los beneficios de usarlas de manera consistente mejora la interpretación de las estructuras del proyecto y organiza mejor la información, así como también aumentan la reproducibilidad e interoperabilidad.\nSon muy útiles para proyectos colaborativos o integrados por muchas personas. Se pueden crear para proyectos individuales, pero también se pueden crear a nivel de equipo para que se apliquen en todos los proyectos.\n\nBuenas prácticas\nAntes de profundizar en las partes de una guía de estilo, hay algunas cosas que debemos saber sobre cómo las computadoras leen los nombres para comprender el “por qué” detrás de algunas de estas prácticas.\n\nEvite los espacios.\n\n\nLas operaciones de línea de comandos y algunos sistemas operativos no las admiten, por lo que es mejor evitarlas por completo. Las direcciones web URL tampoco.\nEl guión bajo (_) y el guion (-) son generalmente buenos delimitadores para usar en lugar de espacios.\n\n\nCon excepción de (_) y (-), evite los caracteres especiales en directorios y nombres de archivos.\n\n\nLos ejemplos incluyen, entre otros ?, ., *, , /, +, ’, &, “.\nLas computadoras asignan un significado específico a muchos de estos caracteres especiales.\nEvite caracteres acentuados y eñes\n\n\nExisten varias convenciones de nomenclatura que puedes elegir para añadir a tu guía de estilo. El uso de estas convenciones te ayuda a ser coherente con los delimitadores y las mayúsculas, lo que no solo hace que tus nombres sean más legibles para los humanos, sino que también permite que tu computadora lea y busque nombres más fácilmente.\nOrdenado de manera útil, donde se tenga en cuenta la clasificación alfanumérica y el completado de ceros a la izquierda cuando hay más de un dígito. Utilización del estándar ISO 8601 para fechas (AAAA-MM-DD).\nLa longitud de los caracteres es importante. Las computadoras no pueden leer nombres que superen una determinada longitud de caracteres. Esto se aplica a las rutas de archivos, los nombres de archivos y los nombres de variables.\n\n\n\nEstructura de directorio\nAl decidir cómo estructuramos los directorios del proyecto (la organización de carpetas y archivos dentro de un sistema operativo), hay varias cosas que debemos considerar.\nCarpetas\nEn primer lugar, pensemos en organizar el directorio en una estructura de carpetas jerárquica para delinear claramente los segmentos del proyecto y mejorar la capacidad de búsqueda.\nAl crear la estructura de carpetas, buscamos un equilibrio entre una estructura profunda y una superficial.\n\nSi es demasiado superficial, habrá demasiados archivos en una carpeta, lo cual resulta difícil de clasificar.\nSi la ruta es demasiado profunda, se necesitarán demasiados clics para llegar a un archivo, y las rutas de archivo pueden tener demasiados caracteres. Una ruta de archivo incluye la longitud completa de las carpetas y el nombre del archivo. (por ejemplo, el límite de ruta de Windows es de 260 caracteres).\n\nConsidere establecer un límite de caracteres en los nombres de las carpetas (nuevamente para reducir los problemas al alcanzar los límites de caracteres de la ruta).\n\nHaga que los nombres de sus carpetas sean significativos y fáciles de interpretar.\nNo utilice espacios en los nombres de sus carpetas.\nUtilice (_) o (-) para separar palabras.\nCon excepción de (-) y (_), no utilice caracteres especiales en los nombres de sus carpetas.\nSea coherente con los delimitadores y el uso de mayúsculas y minúsculas. Siga una convención de nomenclatura existente.\nSi prefiere que sus carpetas aparezcan en un orden específico, agregue el número de orden al comienzo del nombre de la carpeta, con ceros a la izquierda para garantizar una clasificación adecuada (01_, 02_).\n\nUn ejemplo de estructura de directorios completa de un proyecto podría ser el siguiente:\n\n\nnombre_proyecto/\n├── 01_planificacion\n|   ├── proyecto\n|   |   ├── fuentes\n|   |   |   └── ...\n|   ├── reuniones\n|   |   ├── minutas\n|   |   |   └── ...\n|   └── ...\n├── 02_documentacion\n|   ├── formularios\n|   |   └── ...\n|   ├── diccionarios_datos\n|   |   └── ...\n|   ├── protocolo\n|   └── ...\n├── 03_recoleccion_datos\n|   ├── materiales\n|       └── ...\n├── 04_seguimiento\n│   ├── cronograma\n|       └── ...\n├── 05_datos\n│   ├── cohorte1\n│   |   ├── pacientes\n|   |   |   ├── encuesta\n|   |   |   |   ├── datos_limpios\n|   |   |   |   |   ├── archivos\n|   |   |   |   |   |   └── log.txt\n|   |   |   |   ├── datos_crudos\n|   |   |   |   |   ├── archivos\n|   |   |   |   |   |   └── log.txt\n|   |   |   |   └── ...  \n|   |   |   └── ... \n|   |   └── ...\n|   └── ...   \n└── ...\n\nArchivos\nA menudo tenemos apuro por guardar nuestros archivos y tal vez no consideramos lo poco claros que serán los nombres para los futuros usuarios (incluidos nosotros mismos).\nNuestros nombres de archivos por sí solos deberían poder responder preguntas como:\n\n¿Qué son estos documentos?\n¿Cuando se crearon estos documentos?\n¿Cuál documento es la versión más reciente?\n\nUna guía de estilo de nombres de archivos nos ayuda a nombrar los archivos de una manera que nos permita responder a estas preguntas. Podemos tener una guía de nombres de archivos general o guías de nombres de archivos para diferentes propósitos que requieren diferentes estrategias de organización (por ejemplo, una guía de nombres para notas de reuniones de proyectos, otra guía de nombres para archivos de datos de proyectos). Repasemos varias convenciones que se deben tener en cuenta al nombrar los archivos.\n\nQue los nombres sean descriptivos (un usuario debe poder comprender el contenido del archivo sin abrirlo).\nNo se debe utilizar ninguna información de identificación personal en un nombre de archivo (por ejemplo, nombre del participante).\nNunca utilice espacios entre palabras.\nUtilice (-) o (_) para separar palabras.\nCon excepción de (_) y (-), nunca utilice caracteres especiales.\nSea coherente con los delimitadores y el uso de mayúsculas y minúsculas. Siga una convención de nomenclatura existente.\nConsidere limitar la cantidad de caracteres permitidos para evitar alcanzar el límite de su ruta.\nFormatee las fechas de forma uniforme y no utilice barras diagonales (/) para separar partes de una fecha. Es conveniente formatear las fechas utilizando la norma ISO 8601 de una de estas dos maneras: AAAA-MM-DD o AAAAMMDD\nAl versionar manualmente los nombres de archivos, elija un indicador consistente para usar. Un método consiste es añadir un número al nombre del archivo. Con este método, considere rellenar a la izquierda los números individuales con un 0 para mantener el nombre del archivo con la misma longitud a medida que crece (v01, v02). Otro método es agregar una fecha al nombre del archivo, utilizando el estándar ISO 8601.\nSi sus archivos necesitan ejecutarse en un orden secuencial, agregue el número de orden al comienzo del nombre del archivo, con ceros a la izquierda para garantizar una clasificación adecuada (01_, 02_).\nMantenga metadatos redundantes (información) en el nombre del archivo. Esto reduce la confusión si alguna vez mueves un archivo a una carpeta diferente o envías un archivo a un colaborador. También permite realizar búsquedas en tus archivos. Por ejemplo, coloque siempre la palabra “raw” (crudo) o “clean” (limpio) en un nombre de archivo de datos, incluso si el archivo está alojado en una carpeta “raw” o “clean”.\nElija un orden para los metadatos del nombre del archivo (por ejemplo, proyecto -&gt; tiempo -&gt; participante -&gt; instrumento).\n\nAlgunos ejemplos de nombres de archivos:\n\n01_proy1_depuracion-datos_v06.R\n02_proy1_modelos-ajustados_2024-09-11.R\nfig01_barras-grupo_etario.png\ntabla_poblacion_indec.xlsx\n\n\n\nVariables\nEl mismo cuidado o aplicación de las buenas prácticas vistas hasta el momento aplican en la elección de los nombres de variables de las tablas de datos.\nHay dos tipos de reglas: las que son requisitos no negociables que realmente deberían incluirse en la guía de estilo (si no se sigue estas reglas, enfrentaremos serios problemas de interpretación tanto para los humanos como para las máquinas) y las sugerencias de mejores prácticas que se recomiendan pero no son obligatorias.\nObligatorio\n\nNo nombre una variable con ninguna palabra clave o función reservada y utilizada en ningún lenguaje de programación (como if, for, repeat).\nEstablecer un límite de caracteres (La mayoría de los programas estadísticos tienen un límite de caracteres en los nombres de las variables.) Considere el equilibrio entre el límite de caracteres y la interpretación.\nNo utilice espacios ni caracteres especiales, excepto (_). No están permitidos en la mayoría de los programas. Incluso el (-) no está permitido en programas como R y SPSS ya que puede confundirse con un signo menos. Si bien (.) está permitido en R y SPSS, no está permitido en Stata, por lo que es mejor evitar su uso.\nNo comience el nombre de una variable con un número. Esto no está permitido en muchos programas estadísticos.\n\nSugerido\n\nEvite agregar acentos y eñes a las palabras que use como nombre de variable.\nTrate que todas las tablas tengan un identificador único de observación o registro. Si no está vinculado específicamente a cada unidad de análisis, genere uno arbitrario pero que identifique cada observación (suelen usarse ID numéricos secuenciales).\nPreste atención al uso de minúsculas y mayúsculas. La mayoría de los lenguajes de análisis son sensibles a estas diferencias.\nSi hay variables producto de preguntas con respuestas múltiples, comience los nombres de variables asociadas con el mismo prefijo (sintomas_fiebre, sintomas_vomitos, sintomas_mialgias).\nSepare con prefijos y sufijos los nombres de las variables que pertenecen a distintos bloques de una encuesta o a diferentes tipos de participantes. Por ejemplo en las ENFR los prefijos denotan el bloque de la encuesta, BI_ = Bloque Individual, BH_ = Bloque Hogar y el sufijo _J identifica variables del jefe de hogar.\n\nAlgunos ejemplos de nombres de variables:\n\nbi_hi_01 = bloque hogar -&gt; ingresos del hogar -&gt; pregunta 01 \nrango_edad_j = rango de edad -&gt; jefes de hogar\nnivel_instruccion_agrupado -&gt; variable agrupada - nivel de instruccion\ncondicion_actividad_c -&gt; variable construida - condicion de actividad\n\n\n\nCodificación de valores\nSe pueden definir codificaciones que sigan el esquema propuesto dentro del diccionario de datos de la tabla. En algunas ocasiones, variables de interes dicotómica que luego darán lugar a análisis de regresión suelen declararse con 1 para el Si y 0 para el No, orientandose el valor al proceso de funciones de regresión logistica de lenguajes como R.\nAlgunas pautas a considerar en esta tarea son:\n\nLos códigos deben ser únicos. Asignamos “sí” = 1 | “no” = 0 y evitamos “sí” = 1 | “no” = 1\nLos códigos deben ser consistentes dentro de una variable. Para sexo asignamos “masculino” = ‘m’ y evitamos que “masculino” = ‘m’ o ‘M’ o ‘Masculino’ o ‘masculino’ dado que para la maquina terminarán siendo valores distintos por el uso de minúscula y mayúscula.\nLos códigos deben ser consistentes en todo el proyecto. Si asignamos “sí” = 1 | “no” = 0 como valor para todos los elementos de sí/no, evitamos asignar “sí” = 1 | “no” = 0 para algunas variables y “sí” = 1 | “no” = 2 para otras.\nAlineamos los códigos con las opciones de respuesta lo mejor posible. Asignar “ninguno” = 0 | “1” = 1 | “2” = 2 | “3 o más” = 3 y evitamos “ninguno” = 1 | “1” = 2 | “2” = 3 | “3 o más” = 4\nLos códigos de escala tipo Likert deben ordenarse lógicamente. Asignamos “totalmente en desacuerdo” = 1 | “en desacuerdo” = 2 | “de acuerdo” = 3 | “totalmente de acuerdo” = 4 y evitamos “totalmente en desacuerdo” = 1 | “en desacuerdo” = 3 | “de acuerdo” = 4 | “totalmente de acuerdo” = 2\n\nRespecto a los valores faltantes hay una variedad de estilos, pero se pueden resumir en dos opciones generales:\n\nPodemos elegir dejar todos los valores faltantes en blanco.\n\n\nLa ventaja de esta opción es que no hay posibilidad de que los códigos de valores faltantes asignados (por ejemplo, -999) se confundan con valores reales. La preocupación con este método es que no hay manera de discernir si el valor realmente falta, o fue borrado por accidente u omitido durante el ingreso de datos.\n\n\nLa otra opción es definir códigos faltantes y agregarlos a los datos.\n\n\nEste código puede ser numérico (por ejemplo, “faltante” = 99 o -999) o de caracteres (por ejemplo, “faltante” = ‘Sin dato’) y puede ser un código uniforme aplicado a todos los datos faltantes, o puede ser varios códigos asignados para diferentes tipos de datos faltantes.\nUna ventaja de este método es que elimina la incertidumbre que teníamos con las celdas en blanco. Si se completa un valor, ahora tenemos la certeza de que no se eliminó ni se omitió durante la entrada de datos.\nOtro beneficio es que esto le permite especificar razones distintas para los datos faltantes (por ejemplo, “Sin dato” = 99, “Ilegible” = 98) si eso es importante para su estudio.\nEl mayor problema que puede ocurrir con este método es que sus códigos podrían confundirse con valores reales (si alguien no conoce la documentación sobre valores faltantes) o si usa un valor que no coincide con su tipo de variable, entonces introduce nuevos problemas de tipo de variable (por ejemplo, si se usa ‘NULL’ en una variable numérica, esa variable ya no será numérica) o se calculo la media de edad con valores 999 que no son reales y van a sesgar el resultado."
  },
  {
    "objectID": "primero/clases/00-datos.html#formatos-de-archivos",
    "href": "primero/clases/00-datos.html#formatos-de-archivos",
    "title": "Gestión de datos",
    "section": "Formatos de archivos",
    "text": "Formatos de archivos\nSi el proyecto de datos esta vinculado a la recolección propia, es decir a una fuente primaria de información, es recomendable que el/los archivo/s sea alguno de los formatos abiertos de texto plano con separadores. Estos archivos son universales, conocidos como valores separados por coma (csv), que utilizan separadores clásicos como (,) coma, (;) punto y coma, (tab) tabulaciones u otro simbolo a elección (por ejemplo, los archivos de la ENFR tienen la (|) barra verticual como separador de columnas).\nLas extensiones de estos archivos generalmente son .csv o .txt, o alguna otra pero el contenido siempre es texto plano que puede leerse desde cualquier block de notas.\nEn el caso que los datos provengan de una fuente secundaria es posible que el formato de los archivos sea de de un tipo específico que tendrá relación con el software donde se hizo la carga de datos o bien en el formato que los responsables de la recolección eligieron para compartir la información.\nHabitualmente los archivos .xls / .xlsx (Microsoft Excel), .dbf (database), .accdb (Microsoft Access) son usados en archivos creados dentro de proyectos sencillos donde las planillas de calculo o programa de bases de datos se pueden correr en computadoras personales.\nSi los datos fuern procesados previamente por algun software estadístico puede que los archivos compartidos tengan formato .sas7bdat (SAS), .sav (SPSS), dta (Stata) o .RData (R).\nTambién podemnos llegar a encontrar archivos .json (acrónimo de JavaScript Object Notation, ‘notación de objeto de JavaScript’) que es un formato abierto de texto sencillo o .xml(del inglés eXtensible Markup Language, traducido como ‘Lenguaje de Marcas Extensible’)."
  },
  {
    "objectID": "primero/clases/00-datos.html#almacenamiento-y-seguridad",
    "href": "primero/clases/00-datos.html#almacenamiento-y-seguridad",
    "title": "Gestión de datos",
    "section": "Almacenamiento y seguridad",
    "text": "Almacenamiento y seguridad\nA medida que comenzamos a recopilar datos, es importante tener una estructura bien planificada para almacenarlos de forma segura y trabajar con ellos durante el estudio activo. Hay varios objetivos que debemos tener en cuenta al configurar el sistema de almacenamiento y seguridad de archivos:\n\nSeguridad: garantizar que sus archivos no se pierdan, corrompan o editen inesperadamente.\n\nPara cumplir con este punto se establecen formas y protocolos que se ejecuten periódicamente de copias de seguridad que pueden realizarse en discos rígidos, espacios en un servidor central o servicios online tipo Google Drive, Dropbox, etc que deberan contar con los accesos restringidos a los usuarios autorizados del proyecto.\n\nConfidencialidad: asegurarse de que personas no autorizadas no vean ni accedan a información confidencial.\n\nNo solo estamos hablando de los archivos electrónicos producto de la recolección de datos sino también de los formularios, cuestionarios, planillas o cualquier otro dispositivo en papel que tenga información de identificación y/o sensible de participantes.\nArmarios con cerraduras y espacios físicos con medidas de seguridad son recomendados en estas situaciones. Lo mismo respecto del lugar donde se encuentra la o las computadoras del equipo de trabajo, sus pendrive y discos rígidos externos.\n\nAccesibilidad y usabilidad de los archivos: asegurarse de que el equipo de trabajo pueda encontrar los archivos fácilmente y que pueda comprender qué contienen.\n\nExisten varias formas de lograr este objetivo y deberá evaluarse durante la planificación. Se pueden usar espacios de colaboración tipo Google Drive o proyectos privados de sistema de control de versiones como GitHub o GitLab. Dependerá de las capacidades de los integrantes del equipo y del nivel de comodidad buscado."
  },
  {
    "objectID": "primero/clases/00-datos.html#depuración-de-datos",
    "href": "primero/clases/00-datos.html#depuración-de-datos",
    "title": "Gestión de datos",
    "section": "Depuración de datos",
    "text": "Depuración de datos\nIncluso con los esfuerzos de recopilación y captura de datos mejor diseñados, los datos aún requieren al menos un poco de procesamiento adicional antes de que estén en un formato que le permita compartir con confianza. Lo que se haga en la fase de procesamiento de datos, o limpieza de datos, dependerá en gran medida de las transformaciones planificadas para sus datos, así como del nivel de garantía de calidad y procesos de control implementados durante la recopilación y captura.\nEn situaciones donde los datos provienen de fuentes secundarias, las hay con garatía de calidad y también sin controles como la información que sale de muchos sistemas de vigilancia epidemiológica (por ejemplo, el SNVS del SISA).\nLa limpieza de datos es el proceso de organizar y transformar datos sin procesar en un conjunto de datos al que se puede acceder y analizar fácilmente. Esta etapa puede dar como resultado esencialmente dos tipos diferentes de conjuntos de datos: un conjunto de datos curado para fines de intercambio de datos generales y un conjunto de datos limpio para un análisis específico.\nUn conjunto de datos limpio para el intercambio significa que incluye toda la muestra del estudio (no se elimina a nadie), todos los datos faltantes siguen etiquetados como faltantes (no se realiza ninguna imputación) y no se han calculado variables específicas del análisis. Cualquier limpieza adicional se realiza en otra fase de limpieza durante los análisis.\nSe puede pensar en los datos en tres fases distintas:\n\nDatos brutos\n\n\nEste es el archivo sin procesar que proviene directamente de su fuente de recopilación o captura de datos. Si sus datos se recopilan electrónicamente, este es el archivo que extrae de su herramienta. Si sus datos se recopilan en papel, estos son los datos que se han ingresado en un formato legible por máquina. Si tiene una fuente de datos secundaria, este es el archivo que descarga o recibe del proveedor externo.\nEstos datos normalmente no se comparten fuera del equipo de investigación, ya que suelen contener información identificable y a menudo es necesario procesarlos más para que un usuario final pueda descifrarlos.\n\n\nDatos depurados del estudio\n\n\nÉste es el conjunto de datos que se puede compartir públicamente.\n\n\nDatos analíticos\n\n\nEste conjunto de datos se crea a partir del conjunto depurado de datos (ya sea por su equipo o por otros investigadores), pero se modifica aún más para un análisis específico. Este conjunto de datos normalmente también se puede compartir públicamente en un repositorio (por ejemplo Zenodo) en el momento de la publicación para permitir la replicación del análisis asociado. Aquí aparecen las variables creadas en el análisis, posibles eliminaciones de observaciones y/o variables e imputaciones de valores perdidos.\n\n\n\n\n\n\nflowchart TB\n  A[Datos crudos] --&gt; B[Datos limpios]\n  B --&gt; C[Datos analíticos]\n\n\n\n\n\n\n\nCriterios de calidad\nAntes de limpiar nuestros datos, debemos tener un entendimiento compartido sobre cómo esperamos que se vean una vez que se depuren, que aseguren una determinada calidad.\nLos siguientes son criterios posibles de limpieza:\n\nCompleto\n\n\nLa cantidad de filas en su conjunto de datos debe coincidir con la cantidad de formularios completados registrados en su base de datos de seguimiento de participantes. Esto significa que todos los formularios que recopiló se capturaron (ya sea que se ingresaron o se recuperaron). También significa que eliminó todos los datos extraños que no pertenecen (por ejemplo, duplicados, participantes que no están en la muestra final, etc).\nLa cantidad de columnas de sus datos coincide con la cantidad de variables que tiene en su diccionario de datos (es decir, no se eliminaron variables accidentalmente). De manera similar, no debería haber datos faltantes inesperados para las variables (es decir, si se recopilaron los datos, deberían existir en su conjunto de datos).\nPuede haber observaciones y/o variables eliminadas, pero a partir de una decisión consciente y debidamente documentada.\n\n\nVálido\n\n\nLas variables se ajustan a las restricciones que ha establecido en su diccionario de datos (por ejemplo, tipos de variables, valores y rangos de variables permitidos, la falta de elementos a nivel de elemento se alinea con las reglas del universo de variables y los patrones de omisión definidos)\n\n\nPreciso\n\n\nMuchas veces no hay forma de saber si un valor es verdadero o no. Sin embargo, es posible utilizar su conocimiento implícito de un participante o una fuente de datos para descubrir valores erróneos.\n\n\nCoherente\n\n\nLos valores de las variables se miden, formatean o categorizan de manera consistente dentro de una columna (por ejemplo, todos los valores de la fecha de la encuesta tienen el formato AAAA-MM-DD).\nEn colecciones repetidas del mismo formulario, todas las variables se nombran, miden, formatean o codifican de manera consistente (por ejemplo, las categorías y/o códigos cargados en las variables son las del diccionario de datos).\n\n\nAnonimizado\n\n\nSi se promete confidencialidad a los participantes, es necesario anonimizar los datos. En las primeras fases de limpieza, esto simplemente significa que se eliminan todos los identificadores directos de los datos y se reemplazan con códigos de estudio (es decir, identificador único del participante). Antes de compartir públicamente los datos, puede ser necesario un trabajo adicional para eliminar también los identificadores indirectos.\n\n\nInterpretable\n\n\nLas variables se nombran para que coincidan con el diccionario de datos y esos nombres son legibles tanto para humanos como para máquinas. Según sea necesario, se agregan etiquetas de variables y valores como metadatos integrados para facilitar la interpretación.\n\n\nAnalizable\n\n\nEl conjunto de datos tiene un formato rectangular (filas y columnas), legible por máquina y cumple con las reglas básicas de organización de datos."
  },
  {
    "objectID": "primero/clases/00-datos.html#softwares-y-lenguajes-de-análisis",
    "href": "primero/clases/00-datos.html#softwares-y-lenguajes-de-análisis",
    "title": "Gestión de datos",
    "section": "Softwares y lenguajes de análisis",
    "text": "Softwares y lenguajes de análisis\n(documentación, guías de estilo, etc) Proyectos - estructura de directorios y archivos - metadatos - buenas practicas Captura de datos - Formatos de archivos\nDepuración y validación de datos\nAlmacenamiento, seguridad, colaboración y archivo de datos\n\nAnálisis - Softwares y lenguajes disponibles"
  },
  {
    "objectID": "primero/clases/00-datos.html#softwares-y-lenguajes-de-análisis-estadístico",
    "href": "primero/clases/00-datos.html#softwares-y-lenguajes-de-análisis-estadístico",
    "title": "Gestión de datos",
    "section": "Softwares y lenguajes de análisis estadístico",
    "text": "Softwares y lenguajes de análisis estadístico\nEn el ámbito cuantitativista del mundo epidemiológico se utilizan diversos paquetes estadísticos. Un paquete estadístico es un programa informático que está especialmente diseñado para resolver problemas en el área de la estadística, que estos casos aplicamos a estudios epidemiológicos.\nLos paquetes más sencillos tienen interfaz gráfica por ventanas, lo que implica facilidad de uso y aprendizaje pero un mayor encorsetamiento a la hora de hacer cálculos que el programa no tenga predefinidos. Los programas más complejos exigen conocer su lenguaje de programación, pero suelen ser mucho más flexibles al poderse incluir en ellos librerías con funciones, tests o contrastes que no traen instalados por defecto.\nExisten multitud de paquetes informáticos, tanto de software privado como de software libre y/o open source, dentro de los cuales encontramos:\n\n\n\nInterfaz gráfica (GUI)\nInterfaz de línea de comando (CLI)\n\n\n\n\nExcel\nLenguaje R\n\n\nSPSS\nStata\n\n\nEpiDat\nLenguaje Python\n\n\nEpiInfo\nSAS\n\n\nStata\nLenguaje Julia\n\n\nSAS\nPSPP\n\n\nStatgraphics\n\n\n\nMinitab\n\n\n\nPSPP\n\n\n\n\nAlgunos poseen tanto interfaz gráfica como de línea de comando, aunque no llegan a ser un lenguaje de programación. Cada una con sus ventajas y desventajas, suele ser más veloz el aprendizaje de los paquetes gráficos pero también limitados a la hora de hacer cosas más complejas. La curva de aprendizaje de los lenguajes de programación como R, Python o Julia es lenta pero a su vez no tiene límites respecto del tipo de análisis que necesitemos."
  },
  {
    "objectID": "primero/clases/00-datos.html#bibliografía",
    "href": "primero/clases/00-datos.html#bibliografía",
    "title": "Gestión de datos",
    "section": "Bibliografía",
    "text": "Bibliografía"
  },
  {
    "objectID": "primero/clases/05-datosPerdidos.html",
    "href": "primero/clases/05-datosPerdidos.html",
    "title": "Datos perdidos (missing)",
    "section": "",
    "text": "Cuando trabajamos con datos los valores perdidos o faltantes (conocidos en inglés como missing) pueden constituir un serio problema en nuestras variables por lo que deben explorarse y manejarse cuidadosamente en las etapas iniciales del análisis.\nEstos datos pueden faltar por muchas razones, pero generalmente se suelen agrupar en dos categorías: valores faltantes informativos y valores faltantes aleatorios. Los informativos implican una causa estructural, ya sea por deficiencias en la forma en que se recopilaron los datos o por anomalías en el entorno de observación. Los aleatorios son aquellos que tienen lugar independientemente del proceso de recopilación de datos.\nDependiendo de si los valores faltantes son de uno u otro tipo, se procederá de una u otra manera. A los informativos, en general, se les puede asignar un valor concreto (por ejemplo, “Ninguno” o “Sin dato”), ya que este valor puede convenir tenerlo como una categoría más de la variable. Los aleatorios, en cambio, pueden manejarse mediante la eliminación o la imputación.\nResumiendo, las tareas habituales respecto a estos valores consisten en:\nRespecto a la imputación existen numerosa bibliografía sobre diversos algoritmos que no vamos a incluir en este curso."
  },
  {
    "objectID": "primero/clases/05-datosPerdidos.html#detectar-observaciones-incompletas-valores-missing",
    "href": "primero/clases/05-datosPerdidos.html#detectar-observaciones-incompletas-valores-missing",
    "title": "Datos perdidos (missing)",
    "section": "Detectar observaciones incompletas (valores missing)",
    "text": "Detectar observaciones incompletas (valores missing)\nEl lenguaje R gestiona a los datos perdidos mediante el valor especial reservado NA de Not Available (No disponible),\nEn principio, sólo vamos a enfocarnos en como podemos utilizar algunas funciones del lenguaje para detectarlos y contabilizarlos. A partir de su identificación decidiremos que hacer con ellos, dependiendo de su cantidad y extensión, es decir, si los valores faltantes son la mayoría de una variable o la mayoría de una observación o bien si representan la falta de respuesta de una pregunta, con lo cual convenga etiquetarlos.\nUna manera de abordar esta tarea con R base para una variables es hacer la sumatoria de valores NA, usando la función de identificación is.na().\nPara ejemplificar, tomamos una tabla de datos de vigilancia con 200 observaciones y 56 variables.\n\ndatos |&gt; \n  summarise(Cantidad_NA = sum(is.na(FECHA_FIN_TRAT)))\n\n# A tibble: 1 × 1\n  Cantidad_NA\n        &lt;int&gt;\n1         142\n\n\nLa consulta dice que hay 142 observaciones vacías en la variable FECHA_FIN_TRAT. Lo malo es que debemos hacer esta tarea variable por variable, lo que resulta muy trabajoso.\nTambién la función summary() aplicada sobre el dataframe completo informa la cantidad de NA de variables cuantitativas, lógicas y fecha, pero no lo hace con las de tipo caracter.\n\nsummary(datos)\n\n     SEXO           FECHA_NACIMIENTO              EDAD_DIAGNOSTICO\n Length:200         Min.   :1934-12-13 00:00:00   Min.   : 0.00   \n Class :character   1st Qu.:1973-11-06 12:00:00   1st Qu.:23.00   \n Mode  :character   Median :1989-07-27 00:00:00   Median :33.00   \n                    Mean   :1985-12-04 18:14:24   Mean   :37.02   \n                    3rd Qu.:1999-11-17 12:00:00   3rd Qu.:49.00   \n                    Max.   :2023-05-05 00:00:00   Max.   :88.00   \n                                                                  \n   GRUPEDAD         PROVINCIA_RESIDENCIA ID_PROV_INDEC_RESIDENCIA\n Length:200         Length:200           Length:200              \n Class :character   Class :character     Class :character        \n Mode  :character   Mode  :character     Mode  :character        \n                                                                 \n                                                                 \n                                                                 \n                                                                 \n DEPARTAMENTO_RESIDENCIA ID_DEPTO_INDEC_RESIDENCIA LOCALIDAD_RESIDENCIA\n Length:200              Length:200                Length:200          \n Class :character        Class :character          Class :character    \n Mode  :character        Mode  :character          Mode  :character    \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n ESTABLECIMIENTO_SALUD ESTABLECIMIENTO_CARGA PROVINCIA_CARGA   \n Length:200            Length:200            Length:200        \n Class :character      Class :character      Class :character  \n Mode  :character      Mode  :character      Mode  :character  \n                                                               \n                                                               \n                                                               \n                                                               \n DEPTO_CARGA        ESTAB_CLINICA      DEPTO_CLINICA          PPL           \n Length:200         Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n SERVICIO_PENITENCIARIO FECHA_APERTURA               \n Length:200             Min.   :2021-09-20 00:00:00  \n Class :character       1st Qu.:2023-04-12 18:00:00  \n Mode  :character       Median :2023-07-16 00:00:00  \n                        Mean   :2023-07-14 09:07:12  \n                        3rd Qu.:2023-10-18 12:00:00  \n                        Max.   :2024-04-18 00:00:00  \n                                                     \n FECHA_NOTIFICACION            MOTIVO_CONSULTA    CLASIFICACION_MANUAL\n Min.   :2023-01-03 00:00:00   Length:200         Length:200          \n 1st Qu.:2023-04-03 12:00:00   Class :character   Class :character    \n Median :2023-07-03 00:00:00   Mode  :character   Mode  :character    \n Mean   :2023-07-01 12:36:00                                          \n 3rd Qu.:2023-10-03 00:00:00                                          \n Max.   :2023-12-27 00:00:00                                          \n                                                                      \n CLASIF_INICIO_TRAT ID_PULMONAR             FIS                        \n Length:200         Length:200         Min.   :2020-12-20 00:00:00.00  \n Class :character   Class :character   1st Qu.:2023-02-20 00:00:00.00  \n Mode  :character   Mode  :character   Median :2023-05-12 12:00:00.00  \n                                       Mean   :2023-05-10 05:22:06.31  \n                                       3rd Qu.:2023-08-09 18:00:00.00  \n                                       Max.   :2023-12-21 00:00:00.00  \n                                       NA's   :48                      \n ID_EXTRAPULMONAR   FECHA_INICIO_SINTOMA             RESULTADO_RX      \n Length:200         Min.   :2022-08-15 00:00:00.00   Length:200        \n Class :character   1st Qu.:2023-03-01 00:00:00.00   Class :character  \n Mode  :character   Median :2023-05-17 12:00:00.00   Mode  :character  \n                    Mean   :2023-05-28 01:50:46.15                     \n                    3rd Qu.:2023-08-09 00:00:00.00                     \n                    Max.   :2023-12-26 00:00:00.00                     \n                    NA's   :44                                         \n Bacteriologia      Baciloscopia         Cultivo          PRUEBA_RESISTENCIA\n Length:200         Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n RESISTENCIA           Droga           Tipo_Resistencia  \n Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n ESTABLECIMIENTO_MUESTRA DEPARTAMENTO_MUESTRA ESTABLECIMIENTO_DIAG\n Length:200              Length:200           Length:200          \n Class :character        Class :character     Class :character    \n Mode  :character        Mode  :character     Mode  :character    \n                                                                  \n                                                                  \n                                                                  \n                                                                  \n DEPARTAMENTO_DIAG   Prueba_VIH            VIH           \n Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n TRATAMIENTO_ANTIRRETROVIRAL Diag_rapido        Resultado_diag_rapido\n Length:200                  Length:200         Length:200           \n Class :character            Class :character   Class :character     \n Mode  :character            Mode  :character   Mode  :character     \n                                                                     \n                                                                     \n                                                                     \n                                                                     \n   EMBARAZO           DIABETES         CONSUMO_PROB_DROGAS ENF_RESP_CRONICA  \n Length:200         Length:200         Length:200          Length:200        \n Class :character   Class :character   Class :character    Class :character  \n Mode  :character   Mode  :character   Mode  :character    Mode  :character  \n                                                                             \n                                                                             \n                                                                             \n                                                                             \n    COVID           SE_DECLARA_PUEBLO_INDIGENA  ETNIA        \n Length:200         Length:200                 Mode:logical  \n Class :character   Class :character           NA's:200      \n Mode  :character   Mode  :character                         \n                                                             \n                                                             \n                                                             \n                                                             \n  TABAQUISMO        ALCOHOLISMO         ESTAB_TTO        \n Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n FECHA_INICIO_TRAT                FECHA_FIN_TRAT                  \n Min.   :2023-01-03 00:00:00.00   Min.   :2023-03-09 00:00:00.00  \n 1st Qu.:2023-03-20 00:00:00.00   1st Qu.:2023-08-21 00:00:00.00  \n Median :2023-07-02 00:00:00.00   Median :2023-10-23 12:00:00.00  \n Mean   :2023-06-28 21:42:25.22   Mean   :2023-10-23 02:04:08.27  \n 3rd Qu.:2023-10-05 00:00:00.00   3rd Qu.:2024-01-11 12:00:00.00  \n Max.   :2024-01-08 00:00:00.00   Max.   :2024-04-05 00:00:00.00  \n NA's   :43                       NA's   :142                     \n RESULTADO_TRATAMIENTO\n Length:200           \n Class :character     \n Mode  :character     \n                      \n                      \n                      \n                      \n\n\nMás completo y en una sola línea la función find_na() del paquete dlookr muestra el porcentaje de valores perdidos en todas las variables de una tabla de datos y se complementa con el gráfico de barras de pareto plot_na_pareto().\n\nlibrary(dlookr)\n\nfind_na(datos, rate = T) # argumento rate = T muestra % de valores NA\n\n                       SEXO            FECHA_NACIMIENTO \n                        0.0                         0.0 \n           EDAD_DIAGNOSTICO                    GRUPEDAD \n                        0.0                         0.0 \n       PROVINCIA_RESIDENCIA    ID_PROV_INDEC_RESIDENCIA \n                        0.0                         0.0 \n    DEPARTAMENTO_RESIDENCIA   ID_DEPTO_INDEC_RESIDENCIA \n                        4.5                         0.0 \n       LOCALIDAD_RESIDENCIA       ESTABLECIMIENTO_SALUD \n                        0.0                         0.0 \n      ESTABLECIMIENTO_CARGA             PROVINCIA_CARGA \n                        0.0                         0.0 \n                DEPTO_CARGA               ESTAB_CLINICA \n                        0.0                        10.0 \n              DEPTO_CLINICA                         PPL \n                       10.0                         0.0 \n     SERVICIO_PENITENCIARIO              FECHA_APERTURA \n                        0.0                         0.0 \n         FECHA_NOTIFICACION             MOTIVO_CONSULTA \n                        0.0                        90.5 \n       CLASIFICACION_MANUAL          CLASIF_INICIO_TRAT \n                        0.0                         0.0 \n                ID_PULMONAR                         FIS \n                        0.0                        24.0 \n           ID_EXTRAPULMONAR        FECHA_INICIO_SINTOMA \n                        0.0                        22.0 \n               RESULTADO_RX               Bacteriologia \n                        0.0                         0.0 \n               Baciloscopia                     Cultivo \n                        0.0                         0.0 \n         PRUEBA_RESISTENCIA                 RESISTENCIA \n                        0.0                         0.0 \n                      Droga            Tipo_Resistencia \n                        0.0                         0.0 \n    ESTABLECIMIENTO_MUESTRA        DEPARTAMENTO_MUESTRA \n                       36.0                        36.0 \n       ESTABLECIMIENTO_DIAG           DEPARTAMENTO_DIAG \n                       38.0                        38.0 \n                 Prueba_VIH                         VIH \n                        0.0                         0.0 \nTRATAMIENTO_ANTIRRETROVIRAL                 Diag_rapido \n                       99.5                         0.0 \n      Resultado_diag_rapido                    EMBARAZO \n                        0.0                         0.0 \n                   DIABETES         CONSUMO_PROB_DROGAS \n                        0.0                         0.0 \n           ENF_RESP_CRONICA                       COVID \n                        0.0                        99.5 \n SE_DECLARA_PUEBLO_INDIGENA                       ETNIA \n                        0.0                       100.0 \n                 TABAQUISMO                 ALCOHOLISMO \n                        0.0                         0.0 \n                  ESTAB_TTO           FECHA_INICIO_TRAT \n                       17.5                        21.5 \n             FECHA_FIN_TRAT       RESULTADO_TRATAMIENTO \n                       71.0                         0.0 \n\n\n\nplot_na_pareto(datos, \n               only_na = T) # argumento only_na = T muestra variables solo con algún valor NA"
  },
  {
    "objectID": "primero/clases/05-datosPerdidos.html#gestión-de-nas-con-naniar",
    "href": "primero/clases/05-datosPerdidos.html#gestión-de-nas-con-naniar",
    "title": "Datos perdidos (missing)",
    "section": "Gestión de NA’s con naniar",
    "text": "Gestión de NA’s con naniar\n\n\n\n\n\nEl paquete naniar es un paquete que reúne funciones diseñadas para el manejo de valores faltantes pensado para una gestión completa.\n\nlibrary(naniar)\n\nSus caracteristicas generales son:\n\nProporciona funciones analíticas y visuales de detección y gestión\nEs compatible con el mundo “tidy” de tidyverse\nAborda las relaciones o estructura de la falta de datos.\nPosibilita el trabajo de imputación (no tratado en este curso)\n\nDe las muchas funciones que tiene el paquete seleccionamos algunas para mostrar que son muy útiles para una tarea básica.\nLa función miss_var_summary() proporciona un resumen sobre los valores NA en cada variable del dataframe similar a find_na() que vimos anterioremente pero con una salida en forma de tabla y un recento absoluto, además de porcentual.\n\nmiss_var_summary(datos)\n\n# A tibble: 56 × 3\n   variable                    n_miss pct_miss\n   &lt;chr&gt;                        &lt;int&gt;    &lt;num&gt;\n 1 ETNIA                          200    100  \n 2 TRATAMIENTO_ANTIRRETROVIRAL    199     99.5\n 3 COVID                          199     99.5\n 4 MOTIVO_CONSULTA                181     90.5\n 5 FECHA_FIN_TRAT                 142     71  \n 6 ESTABLECIMIENTO_DIAG            76     38  \n 7 DEPARTAMENTO_DIAG               76     38  \n 8 ESTABLECIMIENTO_MUESTRA         72     36  \n 9 DEPARTAMENTO_MUESTRA            72     36  \n10 FIS                             48     24  \n# ℹ 46 more rows\n\n\nPor el lado gráfico, ofrece la función gg_miss_var() que representa la información de la tabla anterior pero a través de un gráfico lollipop horizontal de tipo ggplot2.\n\ngg_miss_var(datos, \n            show_pct = T) # muestra valores en porcentajes\n\n\n\n\n\n\n\n\nHay otra viaulización muy interesante porque muestra las relaciones de los valores ausentes de las variables cuya función se llama gg_miss_upset() y genera un gráfico Upset en función de la existencia de valores NA.\n\ngg_miss_upset(datos) \n\n Por defecto, construye el gráfico tomando las primeras 10 variables de la tabla de datos con valores NA de forma decreciente. Esto se puede modificar cambiando el argumentos nset =.\nTiene dos entradas para su lectura. En la parte inferior izquierda nos muestra los nombres de las variables con valores NA ordenadas de menor a mayor medida en una escala absoluta. El gráfico de barras principal, ordenado de forma predeterminada de mayor a menor, informa sobre las cantidades absolutas de valores NA de las combinaciones que aperecen debajo del eje x del gráfico.\nPor ejemplo, la variable ETNIA tiene todos sus observaciones como NA y la variable COVID casi lo mismo, mientras que la variable FIS cerca de 50.\nPodemos eliminar del gráfico a esas dos variables con casi todos los valores NA, usando formas de tidyverse previas dado que las funciones de naniar son compatibles.\n\ndatos |&gt; \n  select(-ETNIA, -COVID) |&gt; \n  gg_miss_upset() \n\n\nAl quitar esas dos variables, aparecen dos nuevas con cantidades menores de NA que FIS (FECHA_INICIO_TRAT y FECHA_INICIO_SINTOMA), es decir siguen siendo 10 por defecto.\nSi miramos los datos faltantes con estructura notamos que la combinación más frecuente de NA combinados es FECHA_FIN_TRAT, MOTIVO_CONSULTA y TRATAMIENTO_ANTIRETROVIRAL con 39 observaciones a las que le faltan valores en las tres variables simultáneamente."
  },
  {
    "objectID": "primero/clases/05-datosPerdidos.html#reemplazo-de-valores",
    "href": "primero/clases/05-datosPerdidos.html#reemplazo-de-valores",
    "title": "Datos perdidos (missing)",
    "section": "Reemplazo de valores",
    "text": "Reemplazo de valores\nEl paquete tiene además dos funciones de reemplazo que funcionan como herramientas antagónicas.\nreplace_with_na() reemplaza valores o etiquetas específicas con valores NA y replace_na_with() hace lo contrario, reemplaza valores NA con valores específicos, como “Sin dato” por ejemplo.\nLa primera función trabaja sobre el dataframe completo adignando valores NA en la categoría o valor que le indiquemos.\nPor ejemplo, la variable ID_PROV_INDEC_RESIDENCIA no tiene valores perdidos pero si hay una categoría/código desconocido (“00”), entonces podemos decirle que ese código sea NA.\n\ndatos |&gt; \n  summarise(Cantidad_NA = sum(is.na(ID_PROV_INDEC_RESIDENCIA)))\n\n# A tibble: 1 × 1\n  Cantidad_NA\n        &lt;int&gt;\n1           0\n\ndatos |&gt; \n   replace_with_na(replace = list(ID_PROV_INDEC_RESIDENCIA = \"00\")) |&gt;     \n  summarise(Cantidad_NA = sum(is.na(ID_PROV_INDEC_RESIDENCIA)))\n\n# A tibble: 1 × 1\n  Cantidad_NA\n        &lt;int&gt;\n1           2\n\n\nreplace_na_with() etiqueta valores faltantes con categorías definidas que serán tenidas en cuenta a la hora de hacer tablas u otras operaciones. Esta función se utiliza dentro de mutate() del tidyverse.\nLa variable MOTIVO_CONSULTA tiene 181 valores NA que serán etiquetados como “Sin dato” de esta forma:\n\ndatos |&gt; \n  count(MOTIVO_CONSULTA)\n\n# A tibble: 4 × 2\n  MOTIVO_CONSULTA              n\n  &lt;chr&gt;                    &lt;int&gt;\n1 Contacto                     2\n2 Examen de Salud              1\n3 Sintomático Respiratorio    16\n4 &lt;NA&gt;                       181\n\ndatos |&gt; \n  mutate(MOTIVO_CONSULTA = replace_na_with(MOTIVO_CONSULTA, \n                                           \"Sin dato\")) |&gt; \n  count(MOTIVO_CONSULTA)\n\n# A tibble: 4 × 2\n  MOTIVO_CONSULTA              n\n  &lt;chr&gt;                    &lt;int&gt;\n1 Contacto                     2\n2 Examen de Salud              1\n3 Sin dato                   181\n4 Sintomático Respiratorio    16"
  },
  {
    "objectID": "primero/clases/05-datosPerdidos.html#eliminación-de-valores-na",
    "href": "primero/clases/05-datosPerdidos.html#eliminación-de-valores-na",
    "title": "Datos perdidos (missing)",
    "section": "Eliminación de valores NA",
    "text": "Eliminación de valores NA\nCuando decidimos eliminar valores NA de alguna variable, salvo que se quite la variable entera, tenemos que tener en cuenta que perdemos la observación completa, incluso valores válidos que se encuentran en otras variables.\nR base tiene una función llamada na.omit() que omite toda observación donde al menos haya un solo NA en alguna variable.\n\nna.omit(datos)\n\n# A tibble: 0 × 56\n# ℹ 56 variables: SEXO &lt;chr&gt;, FECHA_NACIMIENTO &lt;dttm&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;dttm&gt;, …\n\n\nAplicar esta función sobre el dataframe datos produce que no quede ninguna observación, dado que vimos que la variable ETNIA tenía sus doscientos valores vacíos.\nUna función superadora es drop_na() de tidyr que pertenece a tidyverse, porque omite observaciones que tengan variables que definamos, por ejemplo:\n\ndatos |&gt; \n  drop_na(ETNIA)\n\n# A tibble: 0 × 56\n# ℹ 56 variables: SEXO &lt;chr&gt;, FECHA_NACIMIENTO &lt;dttm&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;dttm&gt;, …\n\ndatos |&gt; \n  drop_na(FIS)\n\n# A tibble: 152 × 56\n   SEXO  FECHA_NACIMIENTO    EDAD_DIAGNOSTICO GRUPEDAD PROVINCIA_RESIDENCIA\n   &lt;chr&gt; &lt;dttm&gt;                         &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;               \n 1 M     1948-06-22 00:00:00               74 70-74    Tierra del Fuego    \n 2 F     1981-06-20 00:00:00               41 40-44    Buenos Aires        \n 3 F     1989-03-30 00:00:00               33 30-34    Buenos Aires        \n 4 M     2006-11-17 00:00:00               16 15-19    Chaco               \n 5 M     1993-06-02 00:00:00               29 25-29    Jujuy               \n 6 M     1989-04-08 00:00:00               33 30-34    Buenos Aires        \n 7 F     1977-07-30 00:00:00               45 45-49    Buenos Aires        \n 8 F     2008-01-10 00:00:00               15 15-19    Chaco               \n 9 M     1987-11-27 00:00:00               35 35-39    Buenos Aires        \n10 F     2002-12-21 00:00:00               20 20-24    Buenos Aires        \n# ℹ 142 more rows\n# ℹ 51 more variables: ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;dttm&gt;, …\n\n\nEn el ejemplo anterior aplicamos la función sobre la variable ETNIA y FIS, en el primer caso omite todas las observaciones y en el segundo caso 48 observaciones, mostrando las 152 restantes sin NA en la variable.\nPor último, debemos saber que eliminar observaciones por valores faltantes reduce la potencia de cualquier test de hipotesis o modelo que hagamos porque se reduce el tamaño de la muestra."
  },
  {
    "objectID": "primero/clases/06-depuracion.html",
    "href": "primero/clases/06-depuracion.html",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "",
    "text": "En el ámbito de los proyectos de análisis de datos, el preprocesamiento, también conocido como preparación de datos, es una etapa crucial que precede al análisis propiamente dicho. Esta fase esencial tiene como objetivo acondicionar los datos para su posterior análisis, garantizando su confiabilidad e integridad.\nLas tareas de preprocesamiento son específicas para cada conjunto de datos y dependen de los objetivos del proyecto y las técnicas de análisis que se emplearán. Sin embargo, existen tareas comunes que son aplicables a la mayoría de los casos, entre las que se encuentran el diagnóstico y la limpieza de datos."
  },
  {
    "objectID": "primero/clases/06-depuracion.html#exploración-y-diagnóstico-de-datos",
    "href": "primero/clases/06-depuracion.html#exploración-y-diagnóstico-de-datos",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "Exploración y diagnóstico de datos",
    "text": "Exploración y diagnóstico de datos\nLa etapa de diagnóstico de datos es fundamental para comprender la estructura y características del conjunto de datos que se va a analizar. Esta fase involucra una serie de tareas esenciales, como:\nAnálisis de la estructura de la tabla de datos: Esta tarea implica comprender la organización de los datos, identificando las variables, sus tipos de datos y la distribución de los registros. Es relevante vincular este proceso con el “diccionario de datos” de la tabla o base, ya sea de fuente secundaria o creada por nosotros mismos.\nVerificación del tipo de dato de cada variable de interés: Es crucial determinar el tipo de dato de cada variable (numérica, categórica, fecha-hora, etc.) para aplicar las técnicas de análisis adecuadas.\nDetección de valores faltantes: La presencia de valores faltantes puede afectar significativamente los resultados del análisis. Es importante identificar estos valores y determinar la mejor manera de manejarlos (eliminación, imputación, etc.).\nIdentificación de las categorías de las variables cualitativas: En el caso de variables categóricas, es necesario identificar las categorías existentes y evaluar su distribución.\nAnálisis de los mínimos y máximos de valores de cada variable cuantitativa: Para variables numéricas, es importante determinar los valores mínimos y máximos para detectar posibles valores atípicos o errores de entrada.\nExisten diversas herramientas y funciones que facilitan la etapa de diagnóstico de datos. En este curso, se presentarán algunas de las funciones más útiles de paquetes de R."
  },
  {
    "objectID": "primero/clases/06-depuracion.html#skimr",
    "href": "primero/clases/06-depuracion.html#skimr",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "Skimr",
    "text": "Skimr\n\n\n\n\n\nEste paquete tiene funciones diseñadas para obtener un resumen rápido de la estructura de tablas de datos y son compatibles con el ecosistema tidyverse.\nLa función principal del paquete es skim y puede ser aplicada a todo el dataframe o bien a una variable o a un grupo de ellas.\n\nProporciona un conjunto más amplio de estadísticas que summary(), incluyendo valores faltantes, completos, número total (n) y desvío estándar (sd).\nInforma de cada tipo de dato por separado.\nManeja fechas, valores lógicos y otros tipos.\n\nTrabajemos con skimr sobre un conjunto de datos provenientes de la vigilancia del SNVS.\n\nlibrary(skimr)\n\nskim(datos)\n\n\nData summary\n\n\nName\ndatos\n\n\nNumber of rows\n200\n\n\nNumber of columns\n56\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n47\n\n\nDate\n7\n\n\nlogical\n1\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSEXO\n0\n1.00\n1\n1\n0\n3\n0\n\n\nGRUPEDAD\n0\n1.00\n3\n5\n0\n18\n0\n\n\nPROVINCIA_RESIDENCIA\n0\n1.00\n4\n16\n0\n18\n0\n\n\nID_PROV_INDEC_RESIDENCIA\n0\n1.00\n2\n2\n0\n18\n0\n\n\nDEPARTAMENTO_RESIDENCIA\n9\n0.96\n4\n26\n0\n81\n0\n\n\nID_DEPTO_INDEC_RESIDENCIA\n0\n1.00\n2\n5\n0\n89\n0\n\n\nLOCALIDAD_RESIDENCIA\n0\n1.00\n4\n57\n0\n106\n0\n\n\nESTABLECIMIENTO_SALUD\n0\n1.00\n11\n82\n0\n125\n0\n\n\nESTABLECIMIENTO_CARGA\n0\n1.00\n5\n82\n0\n117\n0\n\n\nPROVINCIA_CARGA\n0\n1.00\n4\n16\n0\n17\n0\n\n\nDEPTO_CARGA\n0\n1.00\n4\n22\n0\n70\n0\n\n\nESTAB_CLINICA\n20\n0.90\n11\n76\n0\n112\n0\n\n\nDEPTO_CLINICA\n20\n0.90\n4\n23\n0\n73\n0\n\n\nPPL\n0\n1.00\n2\n2\n0\n2\n0\n\n\nSERVICIO_PENITENCIARIO\n0\n1.00\n2\n19\n0\n7\n0\n\n\nMOTIVO_CONSULTA\n181\n0.09\n8\n24\n0\n3\n0\n\n\nCLASIFICACION_MANUAL\n0\n1.00\n10\n67\n0\n9\n0\n\n\nCLASIF_INICIO_TRAT\n0\n1.00\n5\n34\n0\n6\n0\n\n\nID_PULMONAR\n0\n1.00\n2\n15\n0\n3\n0\n\n\nID_EXTRAPULMONAR\n0\n1.00\n5\n31\n0\n13\n0\n\n\nRESULTADO_RX\n0\n1.00\n9\n28\n0\n8\n0\n\n\nBacteriologia\n0\n1.00\n8\n15\n0\n3\n0\n\n\nBaciloscopia\n0\n1.00\n8\n15\n0\n6\n0\n\n\nCultivo\n0\n1.00\n8\n26\n0\n7\n0\n\n\nPRUEBA_RESISTENCIA\n0\n1.00\n2\n15\n0\n2\n0\n\n\nRESISTENCIA\n0\n1.00\n15\n25\n0\n4\n0\n\n\nDroga\n0\n1.00\n2\n26\n0\n6\n0\n\n\nTipo_Resistencia\n0\n1.00\n2\n10\n0\n4\n0\n\n\nESTABLECIMIENTO_MUESTRA\n72\n0.64\n5\n102\n0\n73\n0\n\n\nDEPARTAMENTO_MUESTRA\n72\n0.64\n5\n32\n0\n46\n0\n\n\nESTABLECIMIENTO_DIAG\n76\n0.62\n5\n160\n0\n62\n0\n\n\nDEPARTAMENTO_DIAG\n76\n0.62\n5\n37\n0\n39\n0\n\n\nPrueba_VIH\n0\n1.00\n2\n15\n0\n2\n0\n\n\nVIH\n0\n1.00\n8\n15\n0\n3\n0\n\n\nTRATAMIENTO_ANTIRRETROVIRAL\n199\n0.01\n2\n2\n0\n1\n0\n\n\nDiag_rapido\n0\n1.00\n2\n2\n0\n2\n0\n\n\nResultado_diag_rapido\n0\n1.00\n15\n62\n0\n9\n0\n\n\nEMBARAZO\n0\n1.00\n2\n15\n0\n3\n0\n\n\nDIABETES\n0\n1.00\n2\n2\n0\n2\n0\n\n\nCONSUMO_PROB_DROGAS\n0\n1.00\n2\n15\n0\n2\n0\n\n\nENF_RESP_CRONICA\n0\n1.00\n2\n15\n0\n2\n0\n\n\nCOVID\n199\n0.01\n2\n2\n0\n1\n0\n\n\nSE_DECLARA_PUEBLO_INDIGENA\n0\n1.00\n2\n15\n0\n2\n0\n\n\nTABAQUISMO\n0\n1.00\n2\n15\n0\n2\n0\n\n\nALCOHOLISMO\n0\n1.00\n2\n15\n0\n2\n0\n\n\nESTAB_TTO\n35\n0.82\n11\n76\n0\n102\n0\n\n\nRESULTADO_TRATAMIENTO\n0\n1.00\n6\n22\n0\n7\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nFECHA_NACIMIENTO\n0\n1.00\n1934-12-13\n2023-05-05\n1989-07-27\n198\n\n\nFECHA_APERTURA\n0\n1.00\n2021-09-20\n2024-04-18\n2023-07-16\n151\n\n\nFECHA_NOTIFICACION\n0\n1.00\n2023-01-03\n2023-12-27\n2023-07-03\n147\n\n\nFIS\n48\n0.76\n2020-12-20\n2023-12-21\n2023-05-12\n116\n\n\nFECHA_INICIO_SINTOMA\n44\n0.78\n2022-08-15\n2023-12-26\n2023-05-17\n116\n\n\nFECHA_INICIO_TRAT\n43\n0.78\n2023-01-03\n2024-01-08\n2023-07-02\n119\n\n\nFECHA_FIN_TRAT\n142\n0.29\n2023-03-09\n2024-04-05\n2023-10-23\n52\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\nETNIA\n200\n0\nNaN\n:\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nEDAD_DIAGNOSTICO\n0\n1\n37.02\n18.63\n0\n23\n33\n49\n88\n▂▇▅▃▁\n\n\n\n\n\nLa salida completa de skim() separa los resultados por partes. Un resumen de datos inicial, donde vemos la cantidad de filas y columnas con la frecuencia de tipo de variable. Luego le siguen tablas con información descriptiva univariada, donde podemos ver que dependiendo del tipo de variable nos muestra diferentes estadísticos y hasta un mini histograma en el caso de las numéricas."
  },
  {
    "objectID": "primero/clases/06-depuracion.html#dlookr",
    "href": "primero/clases/06-depuracion.html#dlookr",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "dlookr",
    "text": "dlookr\n\n\n\n\n\nEl paquete se define como una “colección de herramientas que permiten el diagnóstico, la exploración y la transformación de datos”.\nEl diagnóstico de datos proporciona información y visualización de valores faltantes, valores atípicos y valores únicos y negativos para ayudarle a comprender la distribución y la calidad de sus datos.\nContiene funciones, compatibles con tidyverse, que nos facilitan ver la calidad de nuestros datos, además de otras que tienen por objetivo la exploración y su transformación.\nEntre estas funciones encontramos:\n\ndiagnose()\nPermite diagnosticar variables del dataframe y devuelve como resultado: el tipo de dato de la variable, la cantidad de valores faltantes, su porcentaje, la cantidad de valores únicos y su tasa (valores únicos/observaciones). Lo observamos en forma de tabla interactiva:\n\nlibrary(dlookr)\n\ndiagnose(datos)\n\n\n\n\n\n\n\nAl ser compatible con tidyverse se puede editar antes o después de la función, por ejemplo si quisiéramos filtrar variables con valores faltantes (de mayor a menor):\n\ndiagnose(datos) |&gt; \n  select(!starts_with(\"unique\")) |&gt; \n  filter(missing_count &gt; 0) |&gt; \n  arrange(desc(missing_count))\n\n# A tibble: 16 × 4\n   variables                   types     missing_count missing_percent\n   &lt;chr&gt;                       &lt;chr&gt;             &lt;int&gt;           &lt;dbl&gt;\n 1 ETNIA                       logical             200           100  \n 2 TRATAMIENTO_ANTIRRETROVIRAL character           199            99.5\n 3 COVID                       character           199            99.5\n 4 MOTIVO_CONSULTA             character           181            90.5\n 5 FECHA_FIN_TRAT              Date                142            71  \n 6 ESTABLECIMIENTO_DIAG        character            76            38  \n 7 DEPARTAMENTO_DIAG           character            76            38  \n 8 ESTABLECIMIENTO_MUESTRA     character            72            36  \n 9 DEPARTAMENTO_MUESTRA        character            72            36  \n10 FIS                         Date                 48            24  \n11 FECHA_INICIO_SINTOMA        Date                 44            22  \n12 FECHA_INICIO_TRAT           Date                 43            21.5\n13 ESTAB_TTO                   character            35            17.5\n14 ESTAB_CLINICA               character            20            10  \n15 DEPTO_CLINICA               character            20            10  \n16 DEPARTAMENTO_RESIDENCIA     character             9             4.5\n\n\n\n\ndiagnose_category()\nAsí como existe diagnose() como una función general, también hay funciones que sirven para el diagnóstico específico por tipo de dato.\ndiagnose_category() lo hace con las variables categóricas, es decir de caracter, de factor y de factor ordenado, mostrando información de cada categoría de cada variable (N, frecuencia, proporción y ranking).\n\ndatos|&gt; \n diagnose_category()\n\n\n\n\n\n\n\n\n\ndiagnose_numeric()\nPara variables numéricas tenemos a diagnose_numeric() que nos brinda estadísticos resumen descriptivos univariados.\n\ndatos|&gt; \n diagnose_numeric()\n\n\n\n\n\n\n\nObservamos que sobre la única variable numérica de datos nos calcula el mínimo, primer cuartil, media, mediana, tercer cuartil, máximo, la cantidad de ceros, la cantidad de números negativos y la cantidad de datos atípicos."
  },
  {
    "objectID": "primero/clases/06-depuracion.html#diagnose_outlier",
    "href": "primero/clases/06-depuracion.html#diagnose_outlier",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "diagnose_outlier()",
    "text": "diagnose_outlier()\nSobre los datos atípicos diagnose_outlier() nos amplía la información:\n\ndatos|&gt; \n diagnose_outlier()\n\n\n\n\n\n\n\nAquí la variable EDAD_DIAGNOSTICO no tiene datos atípicos por lo que el conteo y proporción es de cero, la media de los outlier no existe y la media contando y no contando estos outlier da lo mismo (37,02)"
  },
  {
    "objectID": "primero/clases/06-depuracion.html#plot_outlier",
    "href": "primero/clases/06-depuracion.html#plot_outlier",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "plot_outlier()",
    "text": "plot_outlier()\nAgreguemos algún dato atípico a EDAD_DIAGNOSTICO para poder mostrar este gráfico.\n\ndatos[10, \"EDAD_DIAGNOSTICO\"] &lt;- 105  # cambiamos la edad de la observación 10 \n\n\ndatos |&gt; \n  plot_outlier(EDAD_DIAGNOSTICO) \n\n\n\n\n\n\n\n\nEl gráfico siempre se va a producir si al menos tenemos un dato atípico en la variable. Grafica un boxplot e histograma contando los valores outlier que la variable tenga y otro quitándolos.\n\nOtras funciones del paquete\ndlookr tiene muchas otras funciones, como find_na() y plot_pareto_na() vistas en el documento sobre datos faltantes, o de análisis descriptivo más completo que mostraremos más adelante.\nTambién hay algunas que tienen como objetivo la conversión de datos y/o la imputación de datos ausentes, que no trabajaremos en el curso pero pueden encontrarse en el sitio del desarrollador https://choonghyunryu.github.io/dlookr/index.html"
  },
  {
    "objectID": "primero/clases/06-depuracion.html#depuración-de-datos",
    "href": "primero/clases/06-depuracion.html#depuración-de-datos",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "Depuración de datos",
    "text": "Depuración de datos\n\n\n\n\n\nUna vez finalizado el diagnóstico de datos, se procede a la etapa de depuración, donde se corrigen los errores identificados y se prepara el conjunto de datos para su análisis. La depuración involucra técnicas como la eliminación de valores faltantes, la corrección de errores de entrada, la transformación de variables y el manejo de valores atípicos.\nUn flujo de trabajo modelo partiendo de datos crudos y terminando en datos limpios es el siguiente:\n\n\n\n\n\nDurante este proceso puede haber múltiples situaciones dependiendo de la calidad original de los datos crudos, desde carecer de encabezados o contener tipos de datos incorrectos, pasando por tener que corregir etiquetas de categorías incorrectas, etc.\nLas herramientas de dplyr en tidyverse nos van a facilitar esta tarea que suele ocupar entre un 70 y 80% del tiempo de trabajo cuando analizamos datos."
  },
  {
    "objectID": "primero/clases/06-depuracion.html#gestión-de-duplicados",
    "href": "primero/clases/06-depuracion.html#gestión-de-duplicados",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "Gestión de duplicados",
    "text": "Gestión de duplicados\nUn caso habitual con el que debemos lidiar es el tener observaciones duplicadas, total o parcialmente. Por este motivo, debemos conocer las características de la o las tablas con las que estamos trabajando, es decir, si las observaciones tiene claves unívocas, si estas observaciones se pueden repetir, si la relación es uno a uno o uno a varios cuando hay más de una tabla relacionada, etc.\nEntonces, el primer paso será asegurarnos que los datos cumplen con el criterio que conocemos haciendo una detección de observaciones y/o partes de observaciones (variables clave) que se encuentran duplicadas.\nLuego, hay diferentes tareas que se pueden realizar para gestionar estos datos duplicados, cuando su existencia no es la esperada:\n\nEliminación de duplicados a partir de observaciones únicas.\nRecortar tabla de datos para eliminar duplicados\nMarcar duplicados (conservando duplicados en la tabla)\n\nLa función get_dupes() del paquete janitor es muy útil porque identifica estas repeticiones.\n\nlibrary(janitor)\n\ndatos |&gt; \n  get_dupes(everything())\n\n# A tibble: 0 × 57\n# ℹ 57 variables: SEXO &lt;chr&gt;, FECHA_NACIMIENTO &lt;date&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;, …\n\n\nAplicada sobre el dataframe entero detecta aquellas observaciones que sean iguales en todas sus observaciones. Esto es difícil que pase pero puede suceder cuando por alguna falla técnica el sistema desde donde se obtienen los datos duplica registros completos.\nOtra posibilidad es utilizar la variable que es clave en la tabla de datos o las variables que constituyen una clave combinada.\nPor ejemplo, en este caso, usemos una serie de variables como SEXO, FECHA_NACIMIENTO, ID_PROV_INDEC_RESIDENCIA e ID_DEPTO_INDEC_RESIDENCIA para ver si hay observaciones donde estos datos se repitan.\n\ndatos |&gt; \n  get_dupes(SEXO, FECHA_NACIMIENTO, \n            ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA)\n\n# A tibble: 2 × 57\n  SEXO  FECHA_NACIMIENTO ID_PROV_INDEC_RESIDENCIA ID_DEPTO_INDEC_RESIDENCIA\n  &lt;chr&gt; &lt;date&gt;           &lt;chr&gt;                    &lt;chr&gt;                    \n1 M     1947-06-29       90                       90063                    \n2 M     1947-06-29       90                       90063                    \n# ℹ 53 more variables: dupe_count &lt;int&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, DEPARTAMENTO_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;,\n#   FECHA_NOTIFICACION &lt;date&gt;, MOTIVO_CONSULTA &lt;chr&gt;, …\n\n\nEncontramos dos observaciones que tienen los mismo valores en esta combinación de variables. Un hombre nacido el 29/06/1947 en la provincia de Tucumán, en el departamento Lules.\nSupongamos que no puede existir dos veces la misma persona en la tabla y que, además para confirmar esto tenemos alguna variable más segura como el DNI, por ejemplo.\n\nEliminación de duplicados por observaciones únicas\nPara eliminar filas duplicadas en una tabla de datos podemos utilizar la función distinct() de dplyr.\nLa función tiene un argumento denominado .keep_all que permite valores TRUE o FALSE. Si se iguala a TRUE se mantienen en el resultado todas las variables que son parte de la tabla, aunque estas no estén declaradas dentro del distinct().\nPor defecto, este argumento se encuentra igualado a FALSE.\n\nnrow(datos)\n\n[1] 200\n\ndatos |&gt; \n  distinct(SEXO, FECHA_NACIMIENTO, ID_PROV_INDEC_RESIDENCIA, \n           ID_DEPTO_INDEC_RESIDENCIA, \n           .keep_all = T)\n\n# A tibble: 199 × 56\n   SEXO  FECHA_NACIMIENTO EDAD_DIAGNOSTICO GRUPEDAD PROVINCIA_RESIDENCIA\n   &lt;chr&gt; &lt;date&gt;                      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;               \n 1 M     1948-06-22                     74 70-74    Tierra del Fuego    \n 2 F     1981-06-20                     41 40-44    Buenos Aires        \n 3 F     1989-03-30                     33 30-34    Buenos Aires        \n 4 M     2006-11-17                     16 15-19    Chaco               \n 5 M     1993-06-02                     29 25-29    Jujuy               \n 6 M     1989-04-08                     33 30-34    Buenos Aires        \n 7 F     1977-07-30                     45 45-49    Buenos Aires        \n 8 M     1968-04-09                     54 50-54    Misiones            \n 9 F     2008-01-10                     15 15-19    Chaco               \n10 M     1987-11-27                    105 35-39    Buenos Aires        \n# ℹ 189 more rows\n# ℹ 51 more variables: ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;, …\n\n\nObservamos que las 200 observaciones distinct() nos devuelve 199. Eliminó una de las dos que tenían duplicadas esa serie de variables definidas, pero no podemos controlar cuál de ellas elimina.\n\n\nEliminación de duplicados por recorte de observaciones\nRecortar es similar a filtrar, la diferencia está en que se filtra por condiciones y recortamos por posiciones.\nLa familia de funciones de dplyr que se puede utilizar para recortar es slice_*().\nEstas funciones pueden ser muy útiles si se aplican a un dataframe agrupado porque la operación de recorte se realiza en cada grupo por separado.\nPor ejemplo, podemos usar la FECHA_NOTIFICACION para seleccionar la mas vieja. Esto se hace combinado group_by() y slice_min() (observación con el valor mínimo)\n\ndatos |&gt; \n  get_dupes(SEXO, FECHA_NACIMIENTO, \n             ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA) |&gt; \n  select(SEXO, FECHA_NACIMIENTO, FECHA_NOTIFICACION)\n\n# A tibble: 2 × 3\n  SEXO  FECHA_NACIMIENTO FECHA_NOTIFICACION\n  &lt;chr&gt; &lt;date&gt;           &lt;date&gt;            \n1 M     1947-06-29       2023-03-10        \n2 M     1947-06-29       2023-02-24        \n\ndatos |&gt; \n  group_by(SEXO, FECHA_NACIMIENTO, \n           ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA) |&gt; \n  slice_min(FECHA_NOTIFICACION) |&gt; \n  filter(SEXO == \"M\", FECHA_NACIMIENTO == dmy(\"29/06/1947\")) |&gt; \n  select(SEXO, FECHA_NACIMIENTO, FECHA_NOTIFICACION) |&gt; \n  ungroup()\n\nAdding missing grouping variables: `ID_PROV_INDEC_RESIDENCIA`,\n`ID_DEPTO_INDEC_RESIDENCIA`\n\n\n# A tibble: 1 × 5\n  ID_PROV_INDEC_RESIDENCIA ID_DEPTO_INDEC_RESIDENCIA SEXO  FECHA_NACIMIENTO\n  &lt;chr&gt;                    &lt;chr&gt;                     &lt;chr&gt; &lt;date&gt;          \n1 90                       90063                     M     1947-06-29      \n# ℹ 1 more variable: FECHA_NOTIFICACION &lt;date&gt;\n\n\n\n\nMarcar duplicados\nSi, en cambio, lo que buscamos es mantener a todas las observaciones de la tabla pero marcar aquellos que consideramos duplicados podemos hacer:\n\nRecortar el dataframe original a sólo las filas para el análisis. Guardar los ID de este dataframe reducido en un vector.\nEn el dataframe original, creamos una variable de marca usando una función condicional, basándonos si el ID está presente en el dataframe reducido (vector de ID anterior).\n\nPrimer paso, en esta tabla no existe un ID único por lo que vamos a crear una clave subrogada.\n\ndatos &lt;- datos |&gt; \n  mutate(ID = row_number())\n\nAhora usaremos este ID para crear un vector con los números de las dos observaciones anteriores que están duplicadas.\n\nID_duplicados &lt;- datos |&gt; \n  get_dupes(SEXO, FECHA_NACIMIENTO, \n             ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA) |&gt; \n  pull(ID)\n\nID_duplicados\n\n[1]  44 166\n\n\nFinalmente aplicamos este vector con una función como if_else() para marcar con una X en la variable duplicado.\n\ndatos &lt;- datos |&gt; \n  mutate(duplicado = if_else(ID %in% ID_duplicados, \"X\", NA))\n\nLuego podriamos filtrar los duplicados directamente\n\ndatos |&gt; \n  filter(duplicado == \"X\")\n\n# A tibble: 2 × 58\n  SEXO  FECHA_NACIMIENTO EDAD_DIAGNOSTICO GRUPEDAD PROVINCIA_RESIDENCIA\n  &lt;chr&gt; &lt;date&gt;                      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;               \n1 M     1947-06-29                     75 75-79    Tucumán             \n2 M     1947-06-29                     75 75-79    Tucumán             \n# ℹ 53 more variables: ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;,\n#   FECHA_NOTIFICACION &lt;date&gt;, MOTIVO_CONSULTA &lt;chr&gt;, …"
  },
  {
    "objectID": "primero/clases/06-depuracion.html#datos-ordenados",
    "href": "primero/clases/06-depuracion.html#datos-ordenados",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "Datos ordenados",
    "text": "Datos ordenados\nLas tablas de datos con la que trabajamos dentro de tidyverse deben cumplir con ciertas características de los “datos ordenados” (tidy data).\nLlamamos tidy data cuando:\n\nCada variable está en una columna\nCada observación está en una fila\nCada celda del cruce entre una columna y una fila es un valor\nCada tabla pertenece a una unidad de observación\n\n\n\n\n\n\nA veces las tablas se parecen a esto:\n\n\n\n\n\ncountry\n2010\n2011\n2012\n2013\n\n\n\n\nArgentina\n40374224\n40728738\n41086927\n41446246\n\n\nBrazil\n195210154\n196935134\n198656019\n200361925\n\n\nUruguay\n3371982\n3383486\n3395253\n3407062\n\n\n\n\n\n\n\nCumple con las reglas de “datos ordenados”?\nNo. \nNo lo hace porque lo que vemos como cabecera de columnas en 2010, 2011, etc. son categorías de la variable año (year) y no nombres de variables.\nEn cambio esta tabla, aunque tenga la misma información, si cumple con el formato ordenado.\n\n\n\n\n\ncountry\nyear\npopulation\n\n\n\n\nArgentina\n2010\n40374224\n\n\nArgentina\n2011\n40728738\n\n\nArgentina\n2012\n41086927\n\n\nArgentina\n2013\n41446246\n\n\nBrazil\n2010\n195210154\n\n\nBrazil\n2011\n196935134\n\n\nBrazil\n2012\n198656019\n\n\nBrazil\n2013\n200361925\n\n\nUruguay\n2010\n3371982\n\n\nUruguay\n2011\n3383486\n\n\nUruguay\n2012\n3395253\n\n\nUruguay\n2013\n3407062\n\n\n\n\n\n\n\nGeneralmente los problemas comunes en tabla “desordenadas” de datos son:\n\nUna variable se extiende por varias columnas.\nUna observación está dispersa entre múltiples filas\n\nEl paquete tidyr de tidyverse resuelve estos problemas y mediante sus funciones pivot_ nos permite pivotear las tablas a lo “ancho” o “largo”.\n\nFunción pivot_longer() - Convierte nombres de columnas en valores de una nueva variable.\nFunción pivot_wider() - Convierte valores de una variable en columnas nuevas.\n\nPara pasar de formato ancho a largo, es decir cuando los valores de una variable se extiende por varias columnas, se utilizan como mínimo estos argumentos:\n\ntabla_ancho |&gt; \n  pivot_longer(cols = -paises,        # todas las columnas -paises\n               names_to = \"anio\",     # nombre de la columna de los nombres\n               values_to = \"casos\")   # nombre la columna de los valores\n\n\n\n\n\n\nEl formato inverso, cuando una observación está dispersa entre múltiples filas, sería:\n\ntabla_largo |&gt; \n  pivot_wider(names_from = tipo,    # nombres de los valores de tipo\n              values_from = casos)  # valores de los valores de casos"
  },
  {
    "objectID": "primero/clases/07-visualizacion.html",
    "href": "primero/clases/07-visualizacion.html",
    "title": "Visualización de datos",
    "section": "",
    "text": "“Un simple gráfico ha brindado más información a la mente del analista de datos que cualquier otro dispositivo”. — John Tukey\nLa visualización de datos puede ser un medio muy eficaz para identificar patrones en los datos y transmitir un mensaje.\nEl objetivo científico de cualquier visualización es permitir al lector comprender datos y extraer información intuitivamente, de la forma más precisa y eficiente.\nGeneralmente construimos visualizaciones para dos fines:\nComo parte del análisis exploratorio (EDA) para descubrir y describir patrones en los datos o para presentar y comunicar, logrando transmitir el mensaje de forma clara y atractiva.\nEs importante, al crear una visualización, considerar las características del público objetivo. La interpretación está en el ojo del espectador, y una visualización sólo logrará transmitir su mensaje si se diseña teniendo en cuenta a su audiencia.\nUna visualización de datos exitosa logra:\nPor estas razones, las visualizaciones de datos son elementos clave en cualquier tipo de publicación: artículos científicos, presentaciones, posters, etc\nLas tablas también son una forma de visualizar datos y resúmenes estadísticos. Suelen ser componentes igualmente importantes en una publicación y en algunos casos, una tabla puede visualizar los datos mejor que un gráfico."
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#principios-y-elementos-de-las-visualizaciones",
    "href": "primero/clases/07-visualizacion.html#principios-y-elementos-de-las-visualizaciones",
    "title": "Visualización de datos",
    "section": "Principios y elementos de las visualizaciones",
    "text": "Principios y elementos de las visualizaciones\nLas visualizaciones de datos deben tener un propósito que no debemos de perder de vista en el proceso de construcción.\nPodría decirse que un propósito general de una visualización es comparar grupos de datos, como datos sobre pacientes que reciben diferentes tratamientos. Una buena elección de ejes, límites de ejes, etiquetas y símbolos puede facilitar sustancialmente la identificación de patrones en los datos, mientras que una mala elección de cualquiera de estos elementos puede dificultar sustancialmente la extracción de información.\n\nElementos gráficos\nVarios elementos de una visualización pueden contribuir a la eficacia con la que se puede mostrar a la información, pero básicamente todos están compuestos por signos visuales y geométricas primitivas.\n\n\n\n\n\nCuando seleccionamos un tipo de gráfico estadístico como un gráfico de barras, un boxplot o una dispersión de puntos estamos usando varios de estos signos visuales como líneas, puntos, areas, con colores, tamaños y posiciones diferentes."
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#elegir-un-tipo-de-visualización",
    "href": "primero/clases/07-visualizacion.html#elegir-un-tipo-de-visualización",
    "title": "Visualización de datos",
    "section": "Elegir un tipo de visualización",
    "text": "Elegir un tipo de visualización\nChristian Hennig, profesor de estadística de la Universidad de Bolonia, sugiere resolver las siguientes preguntas:\n\n\n¿El objetivo del gráfico es descubrir algo (“gráfico de análisis EDA”) o dejar claro algo a los demás?\n¿Qué quieres saber?\n¿Quién es la audiencia del gráfico?\n\n\n\nTipos de gráfico\nLos posibles tipos de gráfico están relacionados a las características de los datos, cuantas variables necesito mostrar, de que tipo son y que cualidad de esas variables me interesa.\nEl sitio From Data to Viz muestra una serie de árboles de decisión, cada uno de los cuales conduce a diferentes formatos de gráficos recomendados según el tipo de datos seleccionados (numéricos, categóricos, etc.)."
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#gramática-de-gráficos",
    "href": "primero/clases/07-visualizacion.html#gramática-de-gráficos",
    "title": "Visualización de datos",
    "section": "Gramática de gráficos",
    "text": "Gramática de gráficos\nLa llamada “La gramática de gráficos” define un conjunto de reglas para construir gráficos estadísticos combinando diferentes tipos de capas, de manera similar a la gramática lingüística.\nEsta idea fue propuesta por Leland Wilkinson en su publicación de 2005 (The Grammar of Graphics - Statistics and Computing - USA).\nLa publicación inspiró a los desarrolladores del paquete ggplot2, el primer paquete del universo tidyverse lanzado en 2007, que se basa en un sistema de capas. El “gg” en el nombre se refiere a la “gramática de los gráficos” utilizada para construir las figuras.\n\n\n\n\n\nSegún la idea de Wilkinson, que aplica ggplot2, todo gráfico parte de los datos que queremos visualizar y vamos enlazando diferentes capas estéticas con elementos geométricos, escalas, ejes, facetas y temas.\nggplot2 necesita de tres componentes básicos y obligatorios para generar una visualización:\n\nDatos con estructura “ordenada”\nMapeo estético (aesthetic) de los datos\nObjeto geométrico que da nombre al tipo de gráfico\n\nSubyace siempre:\n\nCoordenadas que organizan los objetos geométricos\n\nY se le puede agregar:\n\nEscalas (scale) definen el rango de valores de las estéticas\nFacetas que agrupan en subgráficos\nTemas estéticos preconfigurados (themes)\n\nLa sintaxis básica de los tres elementos necesarios es:\n\n[dataframe] |&gt;  \n  ggplot(mapping = aes(&lt;MAPEO&gt;)) +\n  geom_xxx()\n\nObservamos que las capas del ggplot se añaden con un signo +, a diferencia de las tuberías que conectan otras funciones de tidyverse.\nAlgunas de las capas posteriores que son opcionales:\n\n[dataframe] |&gt;  \n  ggplot(mapping = aes(x = [x-varible],\n                       y = [y-variable])) +\n  geom_xxx() +\n  scale_x_...() +\n  scale_y_...() +\n  scale_fill_...() +\n  otras capas más\n\nEl mapeo estético permite definir el rol que cada variable representa en el gráfico. Los roles comunes son: eje x, eje y, color de contorno y color de relleno. Existen otros especiales como de text,agrupamiento u opacidad.\nLa simultáneidad de variables provoca que se puedan realizar gráficos con 2, 3 o n variables.\nPor supuesto que esta definición conecta con el elemento geométrico seleccionado. Por ejemplo, si el elemento geométrico es un geom_point() generamos un diagrama de dispersión de puntos y para esto necesitamos definir como mínimo una variable en el eje x y otra en el eje y que deberán ser numéricas. También podríamos definir alguna variable que mapee el color de los puntos, es decir una tercera variable participante."
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#ejemplo-de-gráfico-de-dispersión",
    "href": "primero/clases/07-visualizacion.html#ejemplo-de-gráfico-de-dispersión",
    "title": "Visualización de datos",
    "section": "Ejemplo de gráfico de dispersión",
    "text": "Ejemplo de gráfico de dispersión\nNada mejor que ver un ejemplo para explicar el funcionamiento del sistema gráfico de ggplot2. Realicemos paso a paso un gráfico de dispersión de puntos:\nTenemos estos datos ficticios para probar el paquete.\n\ndatos\n\n# A tibble: 51 × 3\n       x     y z    \n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n 1     2     1 A    \n 2     5     2 A    \n 3     7     2 A    \n 4     4     2 A    \n 5     1     3 A    \n 6     8     4 A    \n 7     1     4 A    \n 8     9     5 A    \n 9     2     5 A    \n10     6     5 A    \n# ℹ 41 more rows\n\n\nA partir de datos vamos a conectar mediante una tubería a la función ggplot(), que tiene como argumento obligatorio mapping. Dentro del argumento se utiliza la función aes() para las definiciones estéticas que “mapeen” la o las variables del dataframe datos.\nDefinimos que la variable x se grafique en el eje x y la variable y lo haga en el eje y. Por supuesto que las coordenadas que utilice el gráfico serán cartesianas.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y))\n\n\n\n\n\n\n\n\nObservemos que tanto x como y aparecen en cada eje como etiqueta y que las escalas se generan automáticamente a partir de las escalas de las variables. Dentro del lienzo gris del plot no se visualiza aún ningún elemento geométrico.\nAgreguemos la primer capa en el ggplot para indicarle que elemento geométrico usaremos. En este caso geom_point() define una capa de puntos. La capa geométrica le da forma y nombre al tipo de gráfico.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y)) + \n  geom_point(size = 3)\n\n\n\n\n\n\n\n\nSe puede hacer participar a otra variable más que mapeamos con el color de los puntos. En este caso la variable categórica z de datos.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 3)\n\n\n\n\n\n\n\n\nNotemos que cuando mapeamos variables lo hacemos dentro de la función aes() del mapping del ggplot. Esta función permite mapear ejes, colores de contorno y relleno, opacidades, entre otros elementos graficos.\nSi en lugar de mapear una variable queremos definir un color fijo para un elemento gráfico debemos escribirlo fuera del aes(). Por ejemplo, para que todos los puntos sean color azul debemos escribir el argumento color = “blue” dentro del geom_point() directamente. Además cambiamos el tamaño y forma del punto.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y)) + \n  geom_point(color = \"blue\", shape = 17, size = 3)\n\n\n\n\n\n\n\n\nLas formas de puntos surgen de esta tabla numerada.\n\n\n\n\n\nLos mapeos declarados en la función ggplot() principal son globales, es decir que aplican a todas las capas con elementos geométricos posteriores. Para mostrar su efecto agregamos una capa de recta de regresión (en este caso con el método de regresión lineal).\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nEl gráfico muestra que para cada conjunto de puntos (categoría A y B de la variable z) de dibuja una recta distinta respectando la declaración global del aes().\nEn cambio, si a la variable z la declarásemos solo en una de las capas geométricas (por ejemplo la de puntos), obtendríamos una sola recta de regresión, dado que esa definición termina siendo local y no global.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y)) + \n  geom_point(aes(color = z), size = 3) +           # estética local (solo en puntos)\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#estéticas",
    "href": "primero/clases/07-visualizacion.html#estéticas",
    "title": "Visualización de datos",
    "section": "Estéticas",
    "text": "Estéticas\nObservamos que la estética de un gráfico refiere a alguna propiedad visual que representa a los datos que estamos mostrando gráficamente.\nLos argumentos posibles dentro de aes() son:\ncolor = color de la línea de contorno de un polígono tipo barra, boxplot, etc., o el color de punto y lineas.\nfill = el color de relleno de polígonos (por ejemplo, de una barra, boxplot, áreas, etc)\nshape = formas que representan un punto (estrella, triángulo, cuadrado, círculo, etc)\nsize = tamaño del geom (por ejemplo, grosor de línea, tamaño de punto)\nalpha = transparencia (1 = opaco, 0 = invisible)\nwidth = ancho de las columnas de un gráfico de barras\nlinetype = tipo de línea (por ejemplo, sólida, discontinua, punteada)"
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#capa-geométrica",
    "href": "primero/clases/07-visualizacion.html#capa-geométrica",
    "title": "Visualización de datos",
    "section": "Capa geométrica",
    "text": "Capa geométrica\nAnteriormente decíamos que el tipo de gráfico que queremos construir se decide por el elemento geométrico utilizado en la estructura del ggplot.\nEntre las funciones más utilizadas tenemos:\n\n\n\nGráfico\nFunción\n\n\n\n\nÁrea\ngeom_area()\n\n\nDensidad\ngeom_density()\n\n\nPolígono de frecuencia\ngeom_freqpoly()\n\n\nHistograma\ngeom_histogram()\n\n\nQQ-Plot\ngeom_qq()\n\n\nBarras\ngeom_bar()\n\n\nPuntos\ngeom_point()\n\n\nLínea regresión\ngeom_smooth()\n\n\nLíneas\ngeom_line()\n\n\nBoxplot\ngeom_boxplot()\n\n\nViolin plot\ngeom_violin()\n\n\nBarras de error\ngeom_errorbar()\n\n\nDotplot\ngeom_dotplot()\n\n\nPuntos al azar\ngeom_jitter()\n\n\nTexto\ngeom_text()\n\n\nEtiquetas\ngeom_label()\n\n\n\nMuchas de estas funciones se utilizan simultáneamente en capas diferentes del gráfico, por ejemplo podemos hacer un gráfico de barras con una capa de etiquetas. Algunas de las funciones se construyen con estéticas cuantitativas (boxplot) o categóricas (barras), pero también se pueden combinar (por ejemplo, un boxplot por cada categoría de una variable cualitativa).\nTambién se pueden activar otros paquetes que extienden la idea del ggplot para crear gráficos con otras capas, como heatmap, ridgeline, dispersión de puntos con barras marginales, rain plot, treemaps, waffles, Upset, etc.\nLas estéticas van a cambiar en base al elemento geométrico elegido. En un diagrama de puntos puede que usemos size, color, shape para el tamaño, el color y la forma del punto respectivamente y en un gráfico de barras podemos usar fill y width para el color de relleno y el ancho de la barra, por ejemplo."
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#ejes",
    "href": "primero/clases/07-visualizacion.html#ejes",
    "title": "Visualización de datos",
    "section": "Ejes",
    "text": "Ejes\nLos gráficos con coordenadas cartesianas tienen dos ejes. Estos se pueden configurar mediante las capas scale_x_* y scale_y_*. Hay escalas para distintos tipos de datos y ggplot implementa funciones con sufijos como:\n\ncontinuous: valores continuos\ndate: valores tipo fecha\ndatetime: valores fecha y hora\nlog10: valores logaritmicos\ndiscrete: valores discretos\n\nEstas funciones tienen argumentos comunes para definir los límites (limits), el titulo (name) y los cortes que queremos para las marcas del eje (breaks).\nEn ocasiones necesitamos construir gráficos con doble eje y, es decir visualizar simultáneamente dos variables relacionadas con el mismo eje x donde cada una tiene una escala diferente.\nAlgunas de esta funciones de escala traen un argumento especial llamado sec.axis = que se puede combinar con la función de ggplot del mismo nombre (sec_axis()) para definir ese segundo eje que será representado en el extremo derecho del gráfico.\nsec_axis() no permite construir un eje y completamente nuevo. Simplemente construye uno basado en el primero, aplicando una transformación matemática, como el logaritmo o la raíz cuadrada.\nHabrá que tener en cuenta que las magnitudes de escala de ambas capas sean consistentes para lograr una visualización armoniosa."
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#facetas",
    "href": "primero/clases/07-visualizacion.html#facetas",
    "title": "Visualización de datos",
    "section": "Facetas",
    "text": "Facetas\nLas facetas son una herramienta poderosa en ggplot2 que permite dividir un gráfico en múltiples paneles, cada uno mostrando la información para un subgrupo específico de los datos. Esto resulta particularmente útil para explorar la interacción entre dos o más variables categóricas, facilitando la identificación de patrones y tendencias que podrían pasar desapercibidos en un gráfico único.\nLas facetas se implementan principalmente mediante dos funciones: facet_wrap() y facet_grid().\n\nfacet_wrap() organiza los paneles por una única variable categórica, creando filas o columnas de gráficos según el número de niveles de la variable.\nfacet_grid() utiliza dos variables categóricas para organizar los paneles en una cuadrícula, permitiendo explorar la interacción entre ambas variables.\n\nLas facetas no solo mejoran la organización de la información, sino que también incrementan la claridad y la legibilidad de los gráficos, especialmente cuando se trata de conjuntos de datos con múltiples categorías. Además, permiten crear gráficos más compactos y eficientes en cuanto al espacio, aprovechando al máximo el área disponible.\nCon los datos anteriores podemos utilizar la variable z para sumar una capa de facetas.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 3) +  \n  facet_wrap(~z) # formato columnas"
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#colores",
    "href": "primero/clases/07-visualizacion.html#colores",
    "title": "Visualización de datos",
    "section": "Colores",
    "text": "Colores\nOtro elemento esencial para lograr gráficos atractivos son los colores. ggplot2 ofrece una amplia gama de funciones scale_* que permiten personalizar y controlar el uso del color en cada componente del gráfico.\n\nPaletas de colores\nggplot2 proporciona paletas predeterminadas para diferentes tipos de datos, como Set1, Set2, Darked, etc.\nAdemás, existen paquetes externos como RColorBrewer y viridis que ofrecen una amplia variedad de paletas de colores adicionales. La elección de la paleta dependerá del tipo de datos, la estética deseada y el mensaje que se quiere transmitir con el gráfico.\nUn sitio útil que muestra paquetes de paletas de colores es Palette finder. Esos paquetes deben ser instalados y activados previamente para poder utilizar sus colores.\n\n\nFunciones scale_*\nExisten dos funciones scale_*() principales que permiten ajustar el uso del color en las partes de los elementos gráficos:\n\nscale_color_*(): Define la paleta de colores y la asignación de colores de contorno o elementos tipo puntos y lineas.\nscale_fill_*(): Controla el color de relleno para elementos como barras o áreas.\n\nEl asterisco se reemplaza por nombres que refieren a una característica de la escala y el tipo de variable asociada:\nscale_color_discrete() para variables categóricas\nscale_fill_continuous() para variables cuantitativas continuas\nscale_color_manual() para definir colores en forma manual\nR es compatible con muchos formatos de colores. Tiene 657 colores bajo nombres que se pueden visualizar mediante la ejecución de la función colors(), también se puede convocar mediante números y expande sus posibilidades a partir del formato hexadecimal hasta 16.777.216 combinaciones.\nLa página ColorHexa entre otras similares ofrecen seleccionar colores visualmente y copiar el código hexadecimal correspondiente.\nOtra cuestión a tener en cuenta es la accesibilidad para personas daltónicas, es decir utilizar paletas de colores amigables que garanticen que la información sea accesible para todxs. Un paquete en R que aborda este tema es colorBlindness."
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#coordenadas",
    "href": "primero/clases/07-visualizacion.html#coordenadas",
    "title": "Visualización de datos",
    "section": "Coordenadas",
    "text": "Coordenadas\nEs muy fácil invertir un gráfico. La función de coordenadas coord_flip() es todo lo que se necesita para hacerlo. Esto es útil con gráficos de barras para dibujarlas horizontales, por ejemplo. También funciona con cualquier otro tipo de capa geométrica.\nSi necesitamos ajustar un eje con respecto a otro (relación de aspecto del sistema de coordenadas cartesianas) se puede aplicar coord_fixed().\nTomando el diagrama de dispersión previo:\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 2) +\n  coord_fixed(ratio = 1/3) \n\n\n\n\n\n\n\n\nTambién se puede transformar a las coordenadas cartesianas en polares con coord_polar() para la construcción de gráficos circulares como de torta/sectores o similares."
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#personalización",
    "href": "primero/clases/07-visualizacion.html#personalización",
    "title": "Visualización de datos",
    "section": "Personalización",
    "text": "Personalización\nLa función theme() de ggplot2 brinda el poder de personalizar cada aspecto de la estética de un gráfico.\nCon theme() se puede modificar elementos como:\n\nFuentes: Selecciona las fuentes para títulos, etiquetas y textos del gráfico.\nLeyenda: Controla la posición, el formato y el estilo de la leyenda.\nEjes: Personaliza el grosor, el color, las marcas y las etiquetas de los ejes.\nTítulo: Define el estilo y la ubicación del título del gráfico.\nCuadrícula (grid): Controla la apariencia de la cuadrícula de fondo, incluyendo su color, grosor y tipo de línea.\n\nLos argumentos de la función theme() comienzan con un nombre del elemento en cuestión y le siguen nombres relacionados a caracteristicas de esos elementos.\nPor ejemplo, para los ejes, el argumento axis.* tiene nombres como title, text, ticks, line que se igualan a funciones tipo element_line() para personalización de líneas, element_text() para textos, etc.\nHagamos un pequeño ejemplo con el gráfico de puntos que desarrollamos en el documento.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 3) +\n  labs(title = \"Grafico de puntos\", # titulo de grafico\n       x = \"Eje x\", # titulo de eje x\n       y = \"Eje y\") + # titulo de eje y\n  scale_colour_brewer(palette = \"Set1\", # paleta Set1 en color\n                      name = \"Variable z\") + \n  theme(axis.title.x = element_text(face = \"bold\"), # titulo de eje x en negrita\n        axis.title.y = element_text(color = \"red\"), # titulo de eje y color rojo\n        axis.text.x = element_text(size = 8), # texto de eje x tamaño 7 pts\n        axis.text.y = element_text(face = \"italic\"), # texto de eje y en itálica\n        legend.title = element_text(size = 14), # titulo de leyenda tamaño 12 pts\n        plot.title = element_text(size = 18, face = \"bold\")) # titulo de grafico tamaño 16 pts y negrita\n\n\n\n\n\n\n\n\nPersonalizar temas permite mantener un estilo consistente en diferentes gráficos para crear una experiencia visual uniforme y mejorar su legibilidad.\nEs muy útil almacenar la personalización y aplicarla a los gráficos donde la necesitamos.\n\nmi_tema &lt;- theme(axis.title.x = element_text(face = \"bold\"), \n        axis.title.y = element_text(color = \"red\"),\n        axis.text.x = element_text(size = 8), \n        axis.text.y = element_text(face = \"italic\"), \n        legend.title = element_text(size = 14), #\n        plot.title = element_text(size = 18, face = \"bold\")) \n\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 3) +\n  labs(title = \"Grafico de puntos\", # titulo de grafico\n       x = \"Eje x\", # titulo de eje x\n       y = \"Eje y\") + # titulo de eje y\n  scale_colour_brewer(palette = \"Set1\", # paleta Set1 en color\n                      name = \"Variable z\") + \n  mi_tema\n\n\n\n\n\n\n\n\nSe sugiere comenzar con personalizaciones simples y avanzar gradualmente a modificaciones más complejas de forma progresiva."
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#exportación",
    "href": "primero/clases/07-visualizacion.html#exportación",
    "title": "Visualización de datos",
    "section": "Exportación",
    "text": "Exportación\nLa función ggsave() exporta los graficos generados por ggplot2 en distintos formatos, tamaños y resoluciones.\nLa sintaxis con los argumentos opcionales es:\n\nggsave(filename,               # nombre del archivo\n  plot = last_plot(),          # nombre del objeto gráfico\n  device = NULL,               # formato de salida \"jpeg\", \"png\", \"tiff\", \"pdf\", etc\n  width = NA,                  # ancho en unidades de units\n  height = NA,                 # alto en unidades de units\n  units = c(\"in\", \"cm\", \"mm\"), # unidades de medidas\n  dpi = 300)                   # resolución de salida en dpi\n\nTambién es posible introducir las salidas gráficas en fragmentos de código de documentos Quarto para producir archivos html, pdf y docx de Microsoft Word."
  },
  {
    "objectID": "primero/clases/07-visualizacion.html#composición-de-gráficos",
    "href": "primero/clases/07-visualizacion.html#composición-de-gráficos",
    "title": "Visualización de datos",
    "section": "Composición de gráficos",
    "text": "Composición de gráficos\nDentro de los paquetes complementarios del sistema ggplot, patchwork surge como una herramienta muy útil para la composición de gráficos de manera intuitiva y eficiente. A diferencia de las funciones de facetado propias de ggplot2, patchwork se enfoca en la flexibilidad y personalización, permitiendo crear composiciones complejas con mayor control sobre la disposición y el estilo de los gráficos individuales.\nSe basa en el concepto de fragmentos que se pueden combinar, superponer y organizar libremente utilizando operadores intuitivos como +, | y ~.\n\n\n\nOperador\nFunción\n\n\n\n\n+\nCombina gráficos horizontalmente.\n\n\n|\nCombina gráficos verticalmente.\n\n\n~\nApila gráficos uno encima del otro.\n\n\n\nAdemás de la simple combinación, patchwork ofrece herramientas para personalizar el diseño de la composición final, teniendo en cuenta márgenes, espacios, alineación y proporciones.\nImaginemos que tenemos varios gráficos que visualizar combinados (en nuestro ejemplo lo haremos con el único gráfico que construimos).\n\ngrafico &lt;- datos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 2)\n\nlibrary(patchwork)\n\n(grafico + grafico) / grafico \n\n\n\n\n\n\n\n\nCombinamos mediante operadores básicos una salida de tres gráficos."
  },
  {
    "objectID": "primero/recursos/04-ajusteTasas.html",
    "href": "primero/recursos/04-ajusteTasas.html",
    "title": "Ajuste de tasas",
    "section": "",
    "text": "Las tasas de mortalidad son cocientes, y tienen como componentes: un numerador (en general el número de muertes con determinadas características del grupo de personas involucradas); un denominador (en general la población de referencia del numerador), y un factor de expansión.\nLas fuentes de información para el numerador son las estadísticas de mortalidad, mientras que para el denominador son los censos de población y sus estimaciones y proyecciones.\nEn definitiva es un indicador que presenta de forma resumida el riesgo de morir de la población general o específica.\nEl resultado obtenido de dividir el numerador por el denominador de la tasa de mortalidad se multiplica por una constante, que es el factor de expansión, a fin de no presentar un número fraccionario, difícil de trabajar e interpretar. El factor de expansión tiene como función transformar la tasa en un valor fácilmente comprensible, y su elección depende de la frecuencia del evento a que se hace referencia.\nA fin de poder realizar un análisis más preciso de los riesgos de morir, en determinados grupos de población podemos elaborar tasas de mortalidad específicas según las características de nuestro interés, como pueden ser el sexo, la edad o la causa principal de defunción, entre otros.\nEl riesgo de morir está fuertemente relacionado con la edad y las tasas de mortalidad por edad muestran riesgos aumentados en los extremos de edad de la vida, como las tasas de mortalidad en menores de un año o en mayores de 80 años, por ejemplo.\nLas tasas de mortalidad a su vez, se pueden subdividir en tasas de mortalidad generales o tasas de mortalidad ajustadas.\nUna forma de comparar las tasas de mortalidad teniendo en cuenta la diferente estructura de edad entre poblaciones o en la misma población en diferentes periodos, es utilizando tasas de mortalidad estandarizadas o tasas de mortalidad ajustadas.\nEl objetivo de la estandarización por edad es eliminar la influencia de la distinta estructura de edad sobre las tasas de mortalidad objeto de la comparación; según Last:\nEsto es debido a que, en la comparación de la mortalidad entre poblaciones distintas, la estructura de edad opera conceptualmente como un factor de confusión(Nieto F. 2003)."
  },
  {
    "objectID": "primero/recursos/04-ajusteTasas.html#método-directo",
    "href": "primero/recursos/04-ajusteTasas.html#método-directo",
    "title": "Ajuste de tasas",
    "section": "Método directo",
    "text": "Método directo\nEl método directo consiste en calcular primero el riesgo específico de muerte para cada grupo de edad. Para lograrlo, es necesario disponer de datos sobre el número de muertes ocurridas en un determinado año, para cada uno de los grupos de edad elegidos, así como la población correspondiente a cada uno de dichos grupos. Lo ideal es que los grupos de edad sean estratos lógicos y homogéneos en relación al riesgo de morir. Con fines de comparación, se pueden ajustar varias poblaciones de forma simultánea, pero a continuación se utilizará un ejemplo simplificado con solo dos poblaciones. Suponiendo que se quiera comparar dos regiones, A y B, cuyas poblaciones tienen una estructura de edad diferente, se calculan los riesgos específicos de muerte en cada grupo de edad (defunciones/población) para las regiones A y B por separado (Lineamientos Básicos Para El Análisis de La Mortalidad 2017). Luego se selecciona una población estándar. Se entiende como estándar a algo que sirve como base de comparación.\nLas poblaciones estándar para el método de ajuste directo pueden ser las siguientes:\n\nuna población enteramente artificial\nuna de las poblaciones de estudio\nla suma de las poblaciones de estudio\nuna población externa o de referencia\nuna población estándar de varianza mínima\n\nLas poblaciones externas pueden ser, por ejemplo, la población propuesta por la OMS o por la Agencia Internacional de Investigación del Cáncer (IARC).\nLa etapa siguiente consistirá en calcular, siempre para cada grupo de edad, el número de muertes esperadas en la población estándar, si la misma estuviese sujeta al riesgo específico encontrado en la población A, realizando a continuación el mismo cálculo para la población B. Por último, se suma el número de muertes esperadas en todos los grupos de edad, y el resultado se divide por la población estándar, obteniéndose así la tasa ajustada. Todos estos procedimientos deben efectuarse por separado para cada población, A y B. En el caso de que una de ellas haya sido seleccionada como población estándar, el ajuste solo será necesario para la otra (Lineamientos Básicos Para El Análisis de La Mortalidad 2017).\nEn resumen, los pasos del método directo, para la comparación de dos poblaciones A y B hipotéticas, son los siguientes:\n\nCálculo de las tasas de mortalidad reales para cada grupo de edad en la población\nElección de la población estándar\nCálculo de las defunciones esperadas para la población A, si aplico sus tasas de mortalidad reales por grupo de edad a la estructura de edad de la población estándar\nCálculo del total de defunciones esperadas en la población A, como suma de los valores obtenidos en el punto anterior\nCálculo de la tasa de mortalidad ajustada para la población A, donde el numerador estará formado por las defunciones esperadas y el denominador por la población estándar\nRealizar el mismo procedimiento para la población B.\n\nFinalmente, la tasa de mortalidad ajustada es una medida resumen, una medida única, de la experiencia de mortalidad que tendría esa población si tuviera la estructura de edad de la población estándar.\nPor último, recordar que las tasas ajustadas son tasas “artificiales” o “hipotéticas”, y sirven exclusivamente a fines de comparación entre poblaciones."
  },
  {
    "objectID": "primero/recursos/04-ajusteTasas.html#método-indirecto",
    "href": "primero/recursos/04-ajusteTasas.html#método-indirecto",
    "title": "Ajuste de tasas",
    "section": "Método indirecto",
    "text": "Método indirecto\nLa estandarización de tasas por el método indirecto es una alternativa cuando no se dispone de datos de mortalidad desglosados por estrato, en este caso por grupos de edad, o cuando el tamaño de cada grupo es muy pequeño, en cuyo caso los datos estarían sujetos a variaciones muy grandes, por el simple aumento o disminución de unas pocas muertes (Lineamientos Básicos Para El Análisis de La Mortalidad 2017).\nEn síntesis, los pasos del método indirecto, para la comparación de dos poblaciones A y B hipotéticas, son los siguientes:\n\nObtención de las defunciones reales observadas en la población A por grupos de edad\nCálculo de las tasas de mortalidad específicas por edad observadas en la población B, es decir las tasas de la población tomada como referencia.\nCálculo de las defunciones esperadas para cada grupo de edad de la población A, si se aplican las tasas de mortalidad por grupo de edad de la población B (tasas de la población de referencia) a la estructura de edad de la población A\nCálculo del total de defunciones esperadas en la población A\nCálculo de la razón de mortalidad estandarizada (RME), tomando como numerador las defunciones observadas en la población A, y como denominador, las defunciones esperadas en la población A, si tuviera la estructura de mortalidad (las tasas de mortalidad por grupo de edad) de la población B.\n\nDe esta forma, la RME es:\n\n\n\n\n\n\n“el cociente entre el número de hechos observados en el grupo o población de estudio, dividido por el número que cabría esperar si dicha población tuviera las mismas tasas específicas que la población de referencia, multiplicado por 100” (Last 1989).\n\n\n\nSe debe tener en cuenta que el ajuste por el método indirecto solo permite comparar una población con la población de la cual se obtienen las tasas de referencia. Por ejemplo, si se usa el ajuste con el método indirecto para un conjunto de unidades subnacionales (provincias de un país) y se toman como referencia las tasas de la población del país, cada unidad subnacional se puede comparar solo con la nacional. Tal cómputo daría una dimensión del riesgo de cada unidad subnacional en relación al riesgo del país (como un todo), y este riesgo de cada unidad subnacional podría encontrarse hipotéticamente en un nivel superior, igual o inferior al país. Es decir, no sería correcto comparar las unidades subnacionales entre sí utilizando el ajuste con el método indirecto en el ejemplo mencionado."
  },
  {
    "objectID": "primero/recursos/04-ajusteTasas.html#ejemplo-en-lenguaje-r",
    "href": "primero/recursos/04-ajusteTasas.html#ejemplo-en-lenguaje-r",
    "title": "Ajuste de tasas",
    "section": "Ejemplo en lenguaje R",
    "text": "Ejemplo en lenguaje R\n\nMétodo directo\nPara mostrar cómo se realiza la estandarización, compararemos tasas ajustadas de mortalidad por todas las causas durante el 2022 de la provincia de Santa Fe y de la Provincia de Buenos Aires.\nNecesitaremos las muertes ocurridas por todas las causas durante 2022 de las dos provincias por edad (en categorías de 5 años) y sexo (mujer, varón) y sus poblaciones proyectadas para ese año.\nTambién necesitamos una población de referencia, la población estándar. Para los propósitos de este ejercicio utilizaremos la población argentina de 2022.\nIniciamos activando paquetes, en este caso vamos hacerlo con tidyverse, readxl para leer archivos Excel y con un paquete específico que nos va a servir para el ajuste directo que se llama PHEindicatormethods. link documentación\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(PHEindicatormethods)\n\nLuego importamos los datos necesarios. En este caso el archivo con las defunciones 2022 y con las proyecciones poblacionales del último censo publicado (2010).\n\nguess_encoding(\"datos/def2022.csv\")\n\n# A tibble: 1 × 2\n  encoding   confidence\n  &lt;chr&gt;           &lt;dbl&gt;\n1 ISO-8859-1       0.52\n\ndefunciones &lt;- read_csv(\"datos/def2022.csv\", \n                        locale = locale(encoding = \"ISO-8859-1\"))\n\npob_INDEC &lt;- read_excel(\"datos/Base_Poblacion_Provincias_Edad_Sexo_ARG_2001_2025.xlsx\") \n\nComencemos procesando las defunciones. La estructura del archivo es:\n\nglimpse(defunciones)\n\nRows: 397,115\nColumns: 28\n$ JURI      &lt;chr&gt; \"02\", \"02\", \"02\", \"02\", \"02\", \"02\", \"02\", \"02\", \"02\", \"02\", …\n$ ANO       &lt;dbl&gt; 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, …\n$ ATENMED   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 9, 1, 1, 1, 1, …\n$ MEDSUS    &lt;chr&gt; \"1\", \"1\", \"1\", \"2\", \"1\", \"1\", \"2\", \"2\", \"2\", \"1\", \"2\", \"2\", …\n$ CODMUER   &lt;chr&gt; \"J189\", \"I509\", \"G409\", \"J129\", \"K746\", \"C700\", \"I470\", \"F03…\n$ FECDEF    &lt;chr&gt; \"04/01/2022\", \"01/11/2022\", \"12/06/2022\", \"22/12/2022\", \"28/…\n$ FECNAC    &lt;chr&gt; \"03/05/1938\", \"02/05/1954\", \"22/09/2020\", \"31/10/1932\", \"26/…\n$ EDAD      &lt;dbl&gt; 83, 68, 1, 90, 65, 48, 89, 97, 71, 91, 80, 74, 90, 89, 82, 6…\n$ UNIEDAD   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ SEXO      &lt;dbl&gt; 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, …\n$ OCLOC     &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 3, 2, 2, 1, 2, …\n$ DEPOC     &lt;chr&gt; \"999\", \"999\", \"999\", \"999\", \"999\", \"999\", \"999\", \"999\", \"999…\n$ PROVOC    &lt;chr&gt; \"02\", \"02\", \"02\", \"02\", \"02\", \"02\", \"02\", \"02\", \"02\", \"02\", …\n$ DEPRES    &lt;chr&gt; \"005\", \"001\", \"882\", \"003\", \"840\", \"861\", \"002\", \"005\", \"410…\n$ PROVRES   &lt;chr&gt; \"02\", \"02\", \"06\", \"02\", \"06\", \"06\", \"02\", \"02\", \"06\", \"06\", …\n$ PAISRES   &lt;dbl&gt; 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, …\n$ ASOCIAD   &lt;dbl&gt; 1, 9, 1, 2, 1, 2, 2, 9, 1, 1, 1, 1, 2, 1, 2, 9, 1, 1, 1, 1, …\n$ FINSTRUC  &lt;chr&gt; \"03\", \"03\", \"NULL\", \"99\", \"99\", \"05\", \"99\", \"99\", \"99\", \"99\"…\n$ FSITLABOR &lt;chr&gt; \"3\", \"2\", \"NULL\", \"9\", \"9\", \"1\", \"9\", \"9\", \"9\", \"9\", \"9\", \"9…\n$ MINSTRUC  &lt;chr&gt; \"NULL\", \"NULL\", \"06\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\"…\n$ MEDAD     &lt;chr&gt; \"NULL\", \"NULL\", \"30\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\"…\n$ MSITCONY  &lt;chr&gt; \"NULL\", \"NULL\", \"1\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\",…\n$ PINSTRUC  &lt;chr&gt; \"NULL\", \"NULL\", \"05\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\"…\n$ SITLABOR  &lt;chr&gt; \"NULL\", \"NULL\", \"1\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\",…\n$ PESONAC   &lt;chr&gt; \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NUL…\n$ PESOMOR   &lt;chr&gt; \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NUL…\n$ TIEMGEST  &lt;chr&gt; \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NUL…\n$ GRUPEDAD  &lt;chr&gt; \"23.80 a 84\", \"20.65 a 69\", \"04.1 año\", \"24.85 y más\", \"20.6…\n\n\nEn la variable ANO se encuentra el año de la defunción, esta debería ser una constante en 2022. Corroboremos que sea así:\n\ndefunciones |&gt; count(ANO)\n\n# A tibble: 1 × 2\n    ANO      n\n  &lt;dbl&gt;  &lt;int&gt;\n1  2022 397115\n\n\nEn la variable JURI tenemos el código de provincia de la jurisdicción donde ocurrió el fallecimiento. Para tomar la provincia de Santa Fe y la provincia de Buenos Aires vamos a quedarnos solo con los códigos “82” y “06”.\n\ndefunciones &lt;- defunciones |&gt; \n  filter(JURI %in% c(\"82\", \"06\"))\n\nLas variables relevantes para este trabajo son JURI, EDAD, UNIEDAD y SEXO. Recortemos el dataframe por columnas para seleccionar esas variables.\n\ndefunciones &lt;- defunciones |&gt; \n  select(JURI, EDAD, UNIEDAD, SEXO)\n\nA continuación pasemos a trabajar con el dataframe pob_INDEC. Veamos su estructura:\n\nglimpse(pob_INDEC)\n\nRows: 443,361\nColumns: 7\n$ CODIGO       &lt;chr&gt; \"06007\", \"06014\", \"06021\", \"06028\", \"06035\", \"06042\", \"06…\n$ DEPARTAMENTO &lt;chr&gt; \"Adolfo Alsina\", \"Adolfo Gonzáles Chaves\", \"Alberti\", \"Al…\n$ JURISDICCION &lt;chr&gt; \"BUE\", \"BUE\", \"BUE\", \"BUE\", \"BUE\", \"BUE\", \"BUE\", \"BUE\", \"…\n$ SEXO         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ YEAR         &lt;chr&gt; \"2001\", \"2001\", \"2001\", \"2001\", \"2001\", \"2001\", \"2001\", \"…\n$ GRUPEDAD     &lt;chr&gt; \"0-4\", \"0-4\", \"0-4\", \"0-4\", \"0-4\", \"0-4\", \"0-4\", \"0-4\", \"…\n$ POBLACION    &lt;dbl&gt; 680, 503, 361, 25617, 12567, 881, 2659, 11273, 1706, 1372…\n\n\nDe su primera variable CODIGO debemos extraer el código de provincia. En este ejemplo, “82” y “06”, perteneciente a Santa Fe y Buenos Aires respectivamente. De paso, asignamos a una nueva variable JURI (la hacemos coincidir con igual nombre que la de defunciones).\n\npoblaciones &lt;- pob_INDEC |&gt; \n  mutate(JURI = str_sub(CODIGO, 1, 2)) |&gt; \n  filter(JURI %in% c(\"82\", \"06\"))\n\nTambién debemos filtrar las observaciones del año 2022.\n\npoblaciones &lt;- poblaciones |&gt; \n  filter(YEAR == 2022)\n\nPor último, vamos a sumar poblaciones de las observaciones que son de diferentes departamentos para esas dos provincias, respetando el sexo y la edad como estructura.\n\npoblaciones &lt;- poblaciones |&gt; \n  summarise(POBLACION = sum(POBLACION),\n            .by = c(JURI, SEXO, GRUPEDAD))\n\nObservemos como nos quedó el dataframe poblaciones:\n\npoblaciones\n\n# A tibble: 68 × 4\n   JURI   SEXO GRUPEDAD POBLACION\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1 06        1 0-4         720286\n 2 82        1 0-4         136815\n 3 06        2 0-4         678714\n 4 82        2 0-4         128983\n 5 06        1 5-9         744713\n 6 82        1 5-9         138743\n 7 06        2 5-9         702793\n 8 82        2 5-9         130876\n 9 06        1 10-14       739162\n10 82        1 10-14       134392\n# ℹ 58 more rows\n\n\nAhora volvamos sobre el dataframe defunciones para construir el grupo etario a partir la edad. Hay que considerar que la edad en esta tabla se encuentra asociada a la unidad, que puede ser diferente en cada caso (años, meses, días, etc).\nNosotros necesitamos medir todo en años, porque los grupos están expresados en esa unidad cada 5 años. Además debemos hacer coincidir las etiquetas de estos grupos con las de la tabla poblaciones para posteriormente unirlas sin problemas.\n\ndefunciones &lt;- defunciones |&gt; \n1  mutate(EDAD = if_else(UNIEDAD &gt; 1,\n                        true = 0,  \n                        false = EDAD),                   \n2         GRUPEDAD = cut_interval(EDAD,\n                                 length = 5,\n                                 right = F),\n3         GRUPEDAD = as.character(GRUPEDAD),\n4         GRUPEDAD = str_sub(GRUPEDAD,\n                            start = 2, \n                            end = str_length(GRUPEDAD)-1),\n5         x = str_split_fixed(GRUPEDAD, \",\",\n                             n = 2),\n6         x2 = as.numeric(x[,2])-1,\n7         GRUPEDAD = str_c(x[,1],\"-\",x2),\n8         GRUPEDAD = if_else(EDAD &gt;= 80,\n                            true =\"80 y más\", \n                            false = GRUPEDAD)) |&gt; \n  select(!c(x, x2, EDAD, UNIEDAD))\n\n\n1\n\nSi la unidad de edad es mayor a 1 (es decir, menor a unidad de tiempo año -meses, días, etc-) le asignamos a la variable EDAD cero años.\n\n2\n\nUsamos cut_interval() para crear intervalos de clase cada 5 años (cerrados a izquierda y abiertos a derecha). Produce salidas tipo [0,5] que necesitamos convertir en etiquetas iguales a la de la variable GRUPEDAD de poblaciones, es decir 0-4.\n\n3\n\nPara lograr ese cambio y como los intervalos se producen como factor convertimos a character para poder operar con GRUPEDAD\n\n4\n\nExtraemos el contenido de GRUPEDAD evitando los corchetes y paréntesis con str_sub()\n\n5\n\nDividimos en dos partes tomando la coma como caracter divisor con str_split()\n\n6\n\nConvertimos a numérico la última parte del intervalo para restarle 1\n\n7\n\nUnimos nuevamente en GRUPEDAD concatenando las dos partes del intervalo definiendo en el medio el caracter “-” con str_c()\n\n8\n\nFinalmente, si la edad es igual o mayor a 80 años, definimos la etiqueta como “80 y más” al igual que GRUPEDAD en poblaciones.\n\n\n\n\nVeamos que nos quedó:\n\ndefunciones\n\n# A tibble: 183,814 × 3\n   JURI   SEXO GRUPEDAD\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;   \n 1 06        1 80 y más\n 2 06        2 65-69   \n 3 06        1 80 y más\n 4 06        2 80 y más\n 5 06        2 70-74   \n 6 06        2 60-64   \n 7 06        2 70-74   \n 8 06        2 75-79   \n 9 06        1 75-79   \n10 06        2 75-79   \n# ℹ 183,804 more rows\n\n\nNos falta revisar las categorías de la variable SEXO, para esto podemos hacer un count()\n\ndefunciones |&gt; \n  count(SEXO)\n\n# A tibble: 4 × 2\n   SEXO     n\n  &lt;dbl&gt; &lt;int&gt;\n1     1 90879\n2     2 92933\n3     3     1\n4     9     1\n\n\nTenemos dos categorías, la 3 y 9, con 1 sola muerte cada una que no vamos a poder contabilizar porque en poblaciones solo hay dos categorías de sexo (1 y 2)\n\ndefunciones &lt;- defunciones |&gt; \n  filter(SEXO &lt; 3)\n\nBien, ahora debemos hacer el conteo de estas defunciones en función a las tres variables participantes\n\ndefunciones &lt;- defunciones |&gt; \n  count(JURI, SEXO, GRUPEDAD, name = \"MUERTES\")\n\nLa tabla agregada de defunciones para estas dos provincias nos queda:\n\ndefunciones\n\n# A tibble: 68 × 4\n   JURI   SEXO GRUPEDAD MUERTES\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;\n 1 06        1 0-4         1413\n 2 06        1 10-14         92\n 3 06        1 15-19        435\n 4 06        1 20-24        691\n 5 06        1 25-29        806\n 6 06        1 30-34        869\n 7 06        1 35-39        907\n 8 06        1 40-44       1371\n 9 06        1 45-49       1894\n10 06        1 5-9           94\n# ℹ 58 more rows\n\n\nFinalmente debemos unir las dos tablas usando como clave JURI, SEXO y GRUPEDAD (que antes logramos que se llamaran iguales, tuvieran el mismo tipo de dato y las mismas etiquetas).\n\ndatos &lt;- defunciones |&gt; \n  inner_join(poblaciones)\n\nJoining with `by = join_by(JURI, SEXO, GRUPEDAD)`\n\n\nObservemos que no usamos ninguna definición de clave porque al coincidir sus nombres lo hace automáticamente, agregando las variables diferentes como MUERTES y POBLACION a la tabla final.\n\ndatos\n\n# A tibble: 68 × 5\n   JURI   SEXO GRUPEDAD MUERTES POBLACION\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt;\n 1 06        1 0-4         1413    720286\n 2 06        1 10-14         92    739162\n 3 06        1 15-19        435    684298\n 4 06        1 20-24        691    661069\n 5 06        1 25-29        806    661561\n 6 06        1 30-34        869    663730\n 7 06        1 35-39        907    617850\n 8 06        1 40-44       1371    598546\n 9 06        1 45-49       1894    549622\n10 06        1 5-9           94    744713\n# ℹ 58 more rows\n\n\nProbemos de calcular las tasas crudas para cada provincia.\n\ndatos |&gt; \n  group_by(JURI) |&gt; \n  summarise(MUERTES = sum(MUERTES),\n            POBLACION = sum(POBLACION),\n            Tasa_cruda = MUERTES/POBLACION*100000)\n\n# A tibble: 2 × 4\n  JURI  MUERTES POBLACION Tasa_cruda\n  &lt;chr&gt;   &lt;int&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 06     148691  17875744       832.\n2 82      35121   3590000       978.\n\n\nLas usaremos para comparar sus valores con las ajustadas, en el sentido de visualizar el cambio producido por la estandarización.\nBueno, para realizar el ajuste ya tenemos los datos de muertes y población pero nos falta aún la población estándar. Calcularemos la de Argentina para 2022 a partir de los datos importados del INDEC.\n\npob_INDEC &lt;- pob_INDEC |&gt; \n  filter(YEAR == 2022) |&gt; \n  summarise(POB_STD = sum(POBLACION),\n            .by = c(SEXO, GRUPEDAD))\n\nUnimos al dataframe datos\n\ndatos &lt;-  datos |&gt; \n  inner_join(pob_INDEC)\n\nJoining with `by = join_by(SEXO, GRUPEDAD)`\n\n\nFinalmente están los datos necesarios para el ajuste:\n\ndatos\n\n# A tibble: 68 × 6\n   JURI   SEXO GRUPEDAD MUERTES POBLACION POB_STD\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 06        1 0-4         1413    720286 1895619\n 2 06        1 10-14         92    739162 1889663\n 3 06        1 15-19        435    684298 1799316\n 4 06        1 20-24        691    661069 1787521\n 5 06        1 25-29        806    661561 1797079\n 6 06        1 30-34        869    663730 1714809\n 7 06        1 35-39        907    617850 1585535\n 8 06        1 40-44       1371    598546 1541460\n 9 06        1 45-49       1894    549622 1393202\n10 06        1 5-9           94    744713 1927834\n# ℹ 58 more rows\n\n\nNos toca aplicar la función phe_dsr() del paquete PHEindicatormethods. Su sintaxis completa es:\n\ndatos |&gt; \n  phe_dsr(\n    x = ,                   # columna con los eventos (muertes)\n    n = ,                   # columna con las poblaciones \n    stdpop = ,              # columna con la población estándar \n    stdpoptype = \"field\",   # la población estándar esta en el dataframe\n    type = \"full\",          # tipo de salida \"full\" predeterminado\n    confidence = 0.95,      # nivel de confianza de los IC 0.95 por defecto\n    multiplier = 100000)    # factor multiplicador 100000 por defecto\n\n\ndatos  |&gt; \n  group_by(JURI) |&gt; \n  phe_dsr(\n    x = MUERTES,            \n    n = POBLACION,          \n    stdpop = POB_STD,       \n    stdpoptype = \"field\",\n    type = \"standard\")   \n\n# A tibble: 2 × 6\n# Groups:   JURI [2]\n  JURI  total_count total_pop value lowercl uppercl\n  &lt;chr&gt;       &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 06         148691  17875744  809.    805.    813.\n2 82          35121   3590000  883.    874.    892.\n\n\nVisualizamos que en la salida de la función están los valores de tasas ajustadas por 100000 y los intervalos de confianza al 95% para cada jurisdicción.\nLas tasas, en general disminuyeron respecto de las crudas y ahora se pueden comparar entre sí. En 2022, la provincia de Santa Fe tuvo casi 883 fallecidos por todas las causas cada 100000 contra 809 de la provincia de Buenos Aires.\n\n\nMétodo indirecto\nAsí como la función phe_dsr() calcula las tasas ajustadas aplicando el método directo, la función calculate_ISRatio() del mismo paquete PHEindicatormethods lo hace usando el método indirecto.\nLa sintaxis completa de la función es:\n\ndatos |&gt; \n  calculate_ISRatio(\n    x =,\n    n =,\n    x_ref =,\n    n_ref =,\n    refpoptype = \"vector\",\n    type = \"full\",\n    confidence = 0.95\n)\n\nDonde los argumentos son:\n\nx: nombre de la variable que contiene los casos / eventos\nn: nombre de la variable que contiene la población\nx_ref: eventos / casos observados en la población de referencia. Puede ser una variable de datos o un vector.\nn_ref: población de referencia. Puede ser una variable de datos o un vector.\nrefpoptype: si es “field” x_ref y n_ref deberán ser variables de datos. si es “vector” busca las referencias como vectores externos; predeterminado = “vector”\ntype: define que valores muestra en el cálculo. “standard” (para sólo datos) o “full” (para datos y metadatos del calculo); predeterminado = “full”\nconfidence: nivel de confianza de los IC; 0.95 por defecto"
  },
  {
    "objectID": "primero/recursos/03-funciones.html",
    "href": "primero/recursos/03-funciones.html",
    "title": "Creación de funciones en R",
    "section": "",
    "text": "Una de las ventajas de usar lenguajes abiertos como el R es poder crear funciones.\nLas funciones nos permiten automatizar tareas comunes de una manera más potente y general que copiar y pegar.\nEscribir una función tiene tres grandes ventajas sobre usar copiar y pegar:\nSi bien hay muchas tareas que puede hacer una función, existen tres tipos muy útiles:"
  },
  {
    "objectID": "primero/recursos/03-funciones.html#esqueleto-de-una-función",
    "href": "primero/recursos/03-funciones.html#esqueleto-de-una-función",
    "title": "Creación de funciones en R",
    "section": "Esqueleto de una función",
    "text": "Esqueleto de una función\nCualquier función construida en R tiene una estructura o esqueleto similar, no importa lo que haga cuando la ejecutemos.\nTodas ellas tienen:\n\nUn nombre, que deberá cumplir con las caraterísticas que nos impone el lenguaje para nombres (no debe comenzar con un número, no debe utilizar palabras reservadas del lenguaje, no debe tener espacios entre los caracteres, etc.)\nArgumentos, puede no haber o haber varios, dependiendo de lo que se necesite para que la función trabaje. Van encerrados entre paréntesis y separados por coma.\nUn cuerpo, donde se desarrolla el código en cuestión, que se va a repetir cada vez que llamemos a la función. Este código deberá ser una abstracción generalizada de la solución al problema que abordemos para lograr que funcione en cualquier situación.\n\nLa sintaxis de creación en R es:\n\nnombre_funcion &lt;- function(variables) {\n  &lt; cuerpo de la función &gt;\n}  \n\ndonde:\n\nnombre_funcion: es el nombre que le queremos dar a la función creada\nfunction(): es la palabra reservada por el lenguaje para crear funciones\nvariables: es el espacio donde se declaran el o los argumentos con los que trabajemos. Puede, en ocasiones, no haber ninguno.\n{}: entre estas llaves se encuentra el cuerpo de la función"
  },
  {
    "objectID": "primero/recursos/03-funciones.html#funciones-vectoriales",
    "href": "primero/recursos/03-funciones.html#funciones-vectoriales",
    "title": "Creación de funciones en R",
    "section": "Funciones vectoriales",
    "text": "Funciones vectoriales\nPara explicar su funcionamiento hagamos un ejemplo sencillo:\nSupongamos que una labor habitual en nuestro trabajo sea convertir en años la diferencia entre dos fechas, por ejemplo entre la fecha de nacimiento y otra, para calcular la edad.\nQueremos construir una función que realice este trabajo, recibiendo dos fechas como vectores y devolviendo una cantidad de años como vector.\nRecurriendo a la documentación de semanas anteriores se puede ver que ejecutando la siguiente línea con funciones de lubridate se podía obtener los años en número entero:\n\ninterval(fecha_nacimiento, fecha)%/% dyears()\n\nUsemos eso para crear la función, a la que podemos llamar calculo_edad. Además le vamos a incorporar en la primera línea la activación del paquete lubridate, que necesitaremos dentro del cuerpo de la función. Para esta tarea, en lugar de library() usaremos require().\n\ncalculo_edad &lt;- function(fecha_nacimiento, fecha) {\n\nrequire(lubridate)\n  \ninterval(fecha_nacimiento, fecha)%/% dyears()\n  \n}\n\nPara probar la función creada, la aplicamos a unos datos.\n\ndatos\n\n# A tibble: 2 × 2\n  FECNAC     FECREG    \n  &lt;date&gt;     &lt;date&gt;    \n1 1954-05-23 2023-08-17\n2 2003-01-24 2023-12-04\n\n\nEsta tabla tiene dos variables de tipo Date con dos observaciones de fecha, en la primera la fecha de nacimiento y en la segunda la fecha de registro. Para crear la nueva variable Edad pondremos dentro de un mutate() la función calculo_edad escrita anteriormente.\n\ndatos |&gt; \n  mutate(Edad = calculo_edad(fecha_nacimiento = FECNAC, fecha = FECREG))\n\n# A tibble: 2 × 3\n  FECNAC     FECREG      Edad\n  &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt;\n1 1954-05-23 2023-08-17    69\n2 2003-01-24 2023-12-04    20\n\n\nObservemos que nos calcula la edad como queríamos y que los nombres de las variables con los datos no importa que no coincidan con los nombres internos definidos en los argumentos.\nQue otras consideraciones tenemos que tener en cuenta para que funcione bien? Por ejemplo que las fechas ya estén en formato Date. Que pasará si esto no sucede y son de tipo character:\n\ndatos\n\n# A tibble: 2 × 2\n  FECNAC     FECREG    \n  &lt;chr&gt;      &lt;chr&gt;     \n1 23/05/1954 17/08/2023\n2 24/01/2003 04/12/2023\n\n\n\ndatos |&gt; \n  mutate(Edad = calculo_edad(FECNAC, FECREG))\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `Edad = calculo_edad(FECNAC, FECREG)`.\nCaused by warning:\n! All formats failed to parse. No formats found.\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\n# A tibble: 2 × 3\n  FECNAC     FECREG      Edad\n  &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt;\n1 23/05/1954 17/08/2023    NA\n2 24/01/2003 04/12/2023    NA\n\n\nNos devuelve valores NA en Edad producto de un error esperable porque la función interval(), que escribimos dentro de nuestra función, necesita que los valores de fecha sean de tipo Date o date-time.\nEntonces podemos complejizar el cuerpo del código agregando algo para que resuelva este problema:\n\ncalculo_edad &lt;- function(fecha_nacimiento, fecha) {\n\nrequire(lubridate)\n  \nif (is.character(fecha_nacimiento)) {\n  fecha_nacimiento &lt;- dmy(fecha_nacimiento)\n}  \n  \nif (is.character(fecha)) {\n  fecha &lt;- dmy(fecha)\n}  \n  \ninterval(fecha_nacimiento, fecha)%/% dyears()\n  \n}\n\nVolvemos a correr la función sobre los datos con las variables en formato character:\n\ndatos |&gt; \n  mutate(Edad = calculo_edad(FECNAC, FECREG))\n\n# A tibble: 2 × 3\n  FECNAC     FECREG      Edad\n  &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt;\n1 23/05/1954 17/08/2023    69\n2 24/01/2003 04/12/2023    20\n\n\nAhora funciona bien pero así como solucionamos el tema del tipo de dato podríamos enfrentarnos a otros más, como la estructura de la fecha (si es dmy o mdy o ymd) o si el paquete lubridate no se encuentra instalado en mi sesión de R, etc.\nGeneralmente para que una función se pueda aplicar generalizadamente, como suelen ser las funciones de los paquetes publicados, necesitaremos que tenga controladas sus salidas de error lo mejor posible.\nQue vimos hasta ahora de nuevo en el código previo:\n\nFunción require() en lugar de library(): hacen lo mismo (activar un paquete) pero es preferible require() porque si un paquete no está instalado solo generará una advertencia y luego continuará ejecutando el código.\nFunción if(): es la función condicional, hermana de ifelse(), que conviene utilizar en casos donde ante una condición debemos tomar caminos diferentes. Se suelen usar en cuerpos de funciones y dentro de bucles tradicionales.\n\nUna posibilidad para manejar errores por falta de instalación de paquetes es agregar una línea inicial con un condicional que consulte si la librería lubridate se encuentra instalada, y si no es así que la instale previamente.\n\ncalculo_edad &lt;- function(fecha_nacimiento, fecha) {\n\nif (!\"lubridate\" %in% installed.packages()) {\n  install.packages(\"lubridate\")  \n}  \n  \nrequire(lubridate)\n  \nif (is.character(fecha_nacimiento)) {\n  fecha_nacimiento &lt;- dmy(fecha_nacimiento)\n}  \n  \nif (is.character(fecha)) {\n  fecha &lt;- dmy(fecha)\n}  \n  \ninterval(fecha_nacimiento, fecha)%/% dyears()\n  \n}"
  },
  {
    "objectID": "primero/recursos/03-funciones.html#funciones-de-tablas-de-datos",
    "href": "primero/recursos/03-funciones.html#funciones-de-tablas-de-datos",
    "title": "Creación de funciones en R",
    "section": "Funciones de tablas de datos",
    "text": "Funciones de tablas de datos\nRecordemos que las funciones de tablas de datos funcionan como funciones-verbos dplyr: toman un dataframe como primer argumento, algunos argumentos adicionales que dicen qué hacer con él y devuelven generalmente un dataframe.\nA diferencia del proceso para funciones vectoriales, donde los nombre de las funciones declaradas en los argumento eran reemplazados por cualquier otro nombre de las variables externas de la función, aquí necesitamos utilizar unos operadores de evaluación especiales.\nSe denomina “embracing” (abrazar) una variable al hecho de envolverla entre llaves {{ nombre_variable }}.\nAbrazar una variable le dice a dplyr que use el valor almacenado dentro del argumento y no el argumento como el nombre “literal” de la variable.\nVeamos un ejemplo de este tipo de funciones:\nCreamos una función que realice un resumen de variables cuantitativas, calculando su mínimo, máximo, media, mediana, cantidad de NA y cantidad de observaciones totales.\n\nresumen &lt;- function(datos, var) {\n\nif (!\"dplyr\" %in% installed.packages()) {\n  install.packages(\"dplyr\")  \n}  \n  \nrequire(dplyr)\n    \ndatos |&gt; summarise(\n    min = min({{ var }}, na.rm = TRUE),\n    media = mean({{ var }}, na.rm = TRUE),\n    mediana = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_NA = sum(is.na({{ var }}))\n  )\n}\n\nLo aplicamos sobre la variable Edad de unos datos de prueba.\n\ndatos |&gt; resumen(Edad)\n\n# A tibble: 1 × 6\n    min media mediana   max     n  n_NA\n  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1    18  58.6    62.5    99    67     5\n\n\nObservemos que el código principal del cuerpo de la función tiene una estructura tidyverse con funciones propias de dplyr y R base, donde el nombre de la variable declarada en los argumentos (var) se encuentra abrazada por las llaves.\n\ndatos |&gt; summarise(\n    min = min({{ var }}, na.rm = TRUE),\n    media = mean({{ var }}, na.rm = TRUE),\n    mediana = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_NA = sum(is.na({{ var }}))\n  )\n\nLa función también se puede aplicar combinada con un agrupamiento (group_by()).\n\ndatos |&gt; \n  group_by(Sexo) |&gt; \n  resumen(Edad)\n\n# A tibble: 2 × 7\n  Sexo    min media mediana   max     n  n_NA\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1 Mujer    18  55.7      57    93    31     2\n2 Varon    19  61.1      63    99    36     3"
  },
  {
    "objectID": "primero/recursos/03-funciones.html#funciones-para-gráficos",
    "href": "primero/recursos/03-funciones.html#funciones-para-gráficos",
    "title": "Creación de funciones en R",
    "section": "Funciones para gráficos",
    "text": "Funciones para gráficos\nLas funciones para gráficos son muy parecidas a las de tablas de datos, dado que utilizamos funciones de ggplot2 para graficar. La única diferencia es que la salida es un gráfico en lugar de un dataframe.\nVamos a ejemplificar creando un gráfico de barras para aprovechar a introducir un nuevo operador, necesario cuando queremos reutilizar el nombre de una variable definida por el usuario que aplica la función a la izquierda de una asignación de argumentos de tidyverse.\nEl nuevo operador, llamada morsa, se escribe := y significa igual (=). Veamoslo en acción:\n\nif (!\"tidyverse\" %in% installed.packages()) {\n  install.packages(\"tidyverse\")  \n}  \n  \nrequire(tidyverse)\n\nbarras_ordenadas &lt;- function(datos, var) {\n  datos |&gt; \n    mutate({{ var }} := fct_infreq({{ var }}))  |&gt;\n    ggplot(aes(x = {{ var }}, fill = {{ var }})) +\n    geom_bar() +\n    theme(legend.position = \"bottom\")\n}\n\nObservemos que en la línea en que usamos el mutate(), el interprete espera que definamos literalmente el nombre de la variable que recibe la operación fct_infreq() y para que esta sea igual a la variable ingresada es útil el operador morsa. (sino nos devuelve Error)\nAplicado a una variable cualitativa con varias categorías nos genera:\n\nlibrary(datos)  # activamos el paquete datos para usar el dataset encuesta\n\nencuesta |&gt; barras_ordenadas(estado_civil)"
  },
  {
    "objectID": "primero/recursos/03-funciones.html#importar-funciones-propias",
    "href": "primero/recursos/03-funciones.html#importar-funciones-propias",
    "title": "Creación de funciones en R",
    "section": "Importar funciones propias",
    "text": "Importar funciones propias\nUna de características más interesantes de las funciones creadas es que las podemos introducir en un script que llamaremos en nuestro sesión cada vez que necesitemos ejecutarlas.\nLa función source() nos permite llamar a ese o esos scripts externos y contar con las funciones a nuestra disposición.\nEntonces podemos automatizar algunas tareas, sobre todo en procesos repetitivos o que tienen un mismo procedimiento. Un ejemplo concreto en la epidemiología son las tareas vinculadas al análisis de datos provenientes de la vigilancia epidemiológica.\nLa forma de hacerlo es sencilla, si mi script de funciones se llama “funciones.R” ejecutamos:\n\nsource(\"funciones.R\")\n\nCada vez que lo hagamos dentro del script de trabajo tendremos a disposición todas las funciones que se encuentran declaradas dentro del archivo “funciones.R”."
  },
  {
    "objectID": "primero/recursos/05-resumenes.html",
    "href": "primero/recursos/05-resumenes.html",
    "title": "Resúmenes, indicadores y funciones estadísticas",
    "section": "",
    "text": "Con las herramientas conocidas hasta el momento sabemos obtener resúmenes estadísticos de variables cuantitativas usando a summarise() y estratificados a partir de group_by() o el argumento by = de summarise().\nPara variables categóricas hemos producido tablas de frecuencias con count() y cuando necesitamos calculos por fila aplicamos operadores simples como la suma o aprovechamos las funciones rowwise() y c_across().\nEn este documento explicaremos como usar otras funciones estadísticas y otros paquetes para presentar de mejor manera los resultados."
  },
  {
    "objectID": "primero/recursos/05-resumenes.html#estadísticos-compatibles-con-tidyverse",
    "href": "primero/recursos/05-resumenes.html#estadísticos-compatibles-con-tidyverse",
    "title": "Resúmenes, indicadores y funciones estadísticas",
    "section": "Estadísticos compatibles con tidyverse",
    "text": "Estadísticos compatibles con tidyverse\nEl interprete de R trae muchas funciones estadísticas descriptivas y para inferencia disponibles en su versión base pero ninguna de estas son compatibles con la filosofia de trabajo de tidyverse. Es por eso que para utilizar funciones como mean() o median() por ejemplo, debemos introducirlas dentro de estructuras como summarise(). Las funciones de este tipo trabajan sobre vectores y no tienen en cuenta a los dataframes que encapsulan a los vectores como variables.\nTenemos estos datos y vamos a calcular su media.\n\ndatos\n\n# A tibble: 10 × 1\n    Edad\n   &lt;dbl&gt;\n 1    34\n 2    56\n 3    43\n 4    21\n 5    67\n 6    89\n 7    54\n 8    32\n 9    16\n10    76\n\n\nSi lo abordamos con la sintaxis R base:\n\n# Edad es una variable de datos pero llamada así es un vector numérico\n\ndatos$Edad\n\n [1] 34 56 43 21 67 89 54 32 16 76\n\n# preguntamos si es vector\n\nis.vector(datos$Edad)\n\n[1] TRUE\n\n# ejecutamos mean() sobre ese vector\nmean(datos$Edad)\n\n[1] 48.8\n\n\nSi lo abordamos con tuberías.\n\nlibrary(tidyverse)\n\n\ndatos |&gt; \n  mean(Edad)\n\nWarning in mean.default(datos, Edad): argument is not numeric or logical:\nreturning NA\n\n\n[1] NA\n\n\nNecesitamos la función summarise() para que funcione bien.\n\ndatos |&gt; \n  summarise(media_edad = mean(Edad))\n\n# A tibble: 1 × 1\n  media_edad\n       &lt;dbl&gt;\n1       48.8\n\n\nCuando los estadísticos son más complejos que estas funciones descriptivas y devuelven un conjunto de resultados en forma de lista ni siquiera alcanza con aplicarlas dentro de un andamiaje de tidyverse como summarise().\nUn ejemplo de ello, son todas las funciones de R base para comparaciones de inferencia. Tomemos el caso de la prueba t de Student, que sirve para comparar las medias de muestras aproximadamente normales.\nLa función de R base es t.test() y sus argumentos obligatorios son x e y o bien utilizar un formato fórmula (var1 ~ var2)\nPara comparar dos conjuntos de datos con la forma x e y los datos tienen que estar en dos variables separadas y por lo tanto no cumplir con el formato “ordenado”.\n\ndatos\n\n# A tibble: 10 × 2\n   Edad1 Edad2\n   &lt;dbl&gt; &lt;dbl&gt;\n 1    34    45\n 2    56    76\n 3    43    32\n 4    21    12\n 5    67    14\n 6    89    18\n 7    54    20\n 8    32    54\n 9    16    98\n10    76    32\n\n\nAplicamos la función teniendo en cuenta que lo que ingresa en cada argumento es un vector (dataframe$variable)\n\nt.test(x = datos$Edad1, y = datos$Edad2)\n\n\n    Welch Two Sample t-test\n\ndata:  datos$Edad1 and datos$Edad2\nt = 0.73815, df = 17.458, p-value = 0.4702\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -16.11732  33.51732\nsample estimates:\nmean of x mean of y \n     48.8      40.1 \n\n\nEl resultado da un valor de probabilidad de 0,47 lo que indica que no hay diferencias significativas entre las medias de las dos muestras.\nPara usar el formato fórmula es necesario que la tabla de datos cumpla con el formato “ordenado”, quedando:\n\ndatos\n\n# A tibble: 20 × 2\n   Muestra  Edad\n     &lt;dbl&gt; &lt;dbl&gt;\n 1       1    34\n 2       1    56\n 3       1    43\n 4       1    21\n 5       1    67\n 6       1    89\n 7       1    54\n 8       1    32\n 9       1    16\n10       1    76\n11       2    45\n12       2    76\n13       2    32\n14       2    12\n15       2    14\n16       2    18\n17       2    20\n18       2    54\n19       2    98\n20       2    32\n\n\nEn este caso el t.test() lleva formula y datos en el argumento data.\n\nt.test(formula = Edad ~ Muestra, data = datos)\n\n\n    Welch Two Sample t-test\n\ndata:  Edad by Muestra\nt = 0.73815, df = 17.458, p-value = 0.4702\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -16.11732  33.51732\nsample estimates:\nmean in group 1 mean in group 2 \n           48.8            40.1 \n\n\nLo importante acá no es el resultado sino la forma en que lo devuelve. Observaran que no se trata de un formato ordenado ni se parece a una tabla. El tidyverse siempre (salvo raras excepciones, como con pull()) devuelve una tabla de datos ordenada y por eso todas estas funciones son incompatibles, aún utilizando un summarise() y nos dan error:\n\ndatos |&gt; \n  summarise(IC = t.test(Edad ~ Muestra))\n\nError in `summarise()`:\nℹ In argument: `IC = t.test(Edad ~ Muestra)`.\nCaused by error:\n! `IC` must be a vector, not a &lt;htest&gt; object.\n\n\nHace unos años a un desarrollador se le ocurrió crear un paquete que contiene todas estas funciones (y algunas más) del R base en espejo pero compatibles con tidyverse, esto es: reciben un dataframe y devuelven un dataframe.\nEl paquete se llama rstatix y provee un marco simple e intuitivo compatible con el uso de tuberías, coherente con la filosofía de diseño “tidyverse”, para realizar pruebas estadísticas descriptivas básicas y otras más avanzadas de inferencia y modelado.\nLas funciones relacionadas con la inferencia estadística, como t-test, ANOVAS, correlaciones y tamaños de efecto, así como también valores p ajustados o agregados de etiquetas de significación no serán explicados en este curso pero aquellxs estudiantes que les interese profundizar y utilizarlas le pueden sacar un provecho muy útil a este paquete, cuyo sitio es https://rpkgs.datanovia.com/rstatix/index.html.\nRespecto del ejemplo anterior la función de rstatix que reemplaza al t.test() tradicional es t_test(), es decir que al modo tidyverse reemplaza en el nombre el punto por un guión bajo (sucede en todas las funciones del paquete).\n\nlibrary(rstatix)\n\ndatos |&gt; \n  t_test(Edad ~ Muestra, conf.level = .95)\n\n# A tibble: 1 × 8\n  .y.   group1 group2    n1    n2 statistic    df     p\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Edad  1      2         10    10     0.738  17.5  0.47\n\n\nAhora si, el resultado es una tabla de 8 variables por una fila, lo que nos va a permitir poder continuar el trabajo con tuberías. Debajo seleccionamos solo la variable que queremos ver (valor de p).\n\ndatos |&gt; \n  t_test(Edad ~ Muestra, conf.level = .95) |&gt; \n  select(p)\n\n# A tibble: 1 × 1\n      p\n  &lt;dbl&gt;\n1  0.47\n\n\nDentro de los estadísticos descriptivos la función get_summary_stats() devuelve un resumen univariado para variables cuantitativas.\n\ndatos |&gt; \n  get_summary_stats(Edad)\n\n# A tibble: 1 × 13\n  variable     n   min   max median    q1    q3   iqr   mad  mean    sd    se\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Edad        20    12    98   38.5  20.8  58.8    38  26.7  44.4  26.0  5.82\n# ℹ 1 more variable: ci &lt;dbl&gt;\n\n\nY al ser compatible con tidyverse se puede estratificar con group_by().\n\ndatos |&gt; \n  group_by(Muestra) |&gt; \n  get_summary_stats(Edad)\n\n# A tibble: 2 × 14\n  Muestra variable     n   min   max median    q1    q3   iqr   mad  mean    sd\n    &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1       1 Edad        10    16    89   48.5  32.5  64.2  31.8  25.9  48.8  23.9\n2       2 Edad        10    12    98   32    18.5  51.8  33.2  23.7  40.1  28.6\n# ℹ 2 more variables: se &lt;dbl&gt;, ci &lt;dbl&gt;\n\n\nLa función freq_table() construye tablas con las variables categóricas.\n\ndatos |&gt; \n freq_table(Sexo)\n\n# A tibble: 2 × 3\n  Sexo      n  prop\n  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1 Mujer    14    70\n2 Varon     6    30\n\n\nTambién agregando otra variables que estratifiquen la salida.\n\ndatos |&gt; \n freq_table(Sexo, Fuma)\n\n# A tibble: 4 × 4\n  Sexo  Fuma      n  prop\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1 Mujer No       10  71.4\n2 Mujer Si        4  28.6\n3 Varon No        2  33.3\n4 Varon Si        4  66.7\n\n\nUna opción más completa para construir tablas y tablas de contingencia es usar la familia de funciones tabyl() del paquete janitor.\n\nlibrary(janitor)\n\ndatos |&gt; \n  tabyl(Sexo)\n\n  Sexo  n percent\n Mujer 14     0.7\n Varon  6     0.3\n\n\nCalcula las frecuencias absolutas y relativas de variables categóricas de forma similar a freq_table() pero se le pueden modificar sus argumentos y asociar otras funciones del paquete mediante tuberías para obtener mejores resultados (también es compatible con tidyverse).\n\ndatos |&gt;  \n  tabyl(Sexo) |&gt; \n  adorn_totals(where = \"row\") %&gt;% # agregamos totales \n  adorn_pct_formatting(digits = 2) # porcentaje con dos decimales\n\n  Sexo  n percent\n Mujer 14  70.00%\n Varon  6  30.00%\n Total 20 100.00%\n\n\nLa forma más adecuada de describir la relación entre dos variables categóricas es a partir de la construcción de una tabla de contingencia. Para ello se introduce en cada fila de la tabla las categorías de una de las variables y las categorías de la otra variable se asocian a cada una de las columnas de la tabla, en cada celda de la tabla aparecerá el número de observaciones correspondientes a la combinación oportuna de ambas variables. Si bien freq_table() hace lo mismo, respeta la salida ordenada lo que dificulta su lectura.\nCon la misma función tabyl() se puede realizar una tabla de contingencia, incluyendo a la variable Fuma.\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) \n\n  Sexo No Si\n Mujer 10  4\n Varon  2  4\n\n\nRecordemos que el orden dentro de los paréntesis de la función es igual al de los índices del lenguage, el primer argumento es la variable que aparecerá en las filas y el segundo la variable de las columnas. Por ese motivo, en la tabla de contingencia absoluta tenemos el Sexo en las filas y a Fuma en las columnas.\nSu salida se puede mejorar con totales por columna y que aparezca el nombre de la variable que esta en la columna:\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) |&gt; \n  adorn_title(placement = \"combined\") |&gt; \n  adorn_totals(where = \"row\")\n\n Sexo/Fuma No Si\n     Mujer 10  4\n     Varon  2  4\n     Total 12  8\n\n\nTambién haciendo que los valores sean porcentuales por fila.\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) |&gt;  \n  adorn_title(placement = \"combined\") |&gt; \n  adorn_totals(where = \"row\") |&gt;  \n  adorn_percentages(denominator = \"row\") |&gt;  #  % por fila\n  adorn_pct_formatting(digits = 2) # redondea con 2 decimales\n\n Sexo/Fuma     No     Si\n     Mujer 71.43% 28.57%\n     Varon 33.33% 66.67%\n     Total 60.00% 40.00%\n\n\nIncoporamos valores absolutos entre paréntesis.\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) |&gt;  \n  adorn_totals(where = \"row\") |&gt;  \n  adorn_percentages(denominator = \"row\") |&gt;  \n  adorn_pct_formatting(digits = 2) |&gt; \n  adorn_ns() |&gt; \n  adorn_title() \n\n              Fuma           \n  Sexo          No         Si\n Mujer 71.43% (10) 28.57% (4)\n Varon 33.33%  (2) 66.67% (4)\n Total 60.00% (12) 40.00% (8)\n\n\nEl paquete trae muchas funciones que se integran para construir tablas complejas. Más de estas opciones las pueden encontrar en el sitio oficial del paquete janitor"
  },
  {
    "objectID": "primero/recursos/05-resumenes.html#tablas-para-presentaciones",
    "href": "primero/recursos/05-resumenes.html#tablas-para-presentaciones",
    "title": "Resúmenes, indicadores y funciones estadísticas",
    "section": "Tablas para presentaciones",
    "text": "Tablas para presentaciones\nCuando necesitemos presentar resultados estadísticos combinados, producto de variables cuanti y cualitativas a la vez, podemos hechar mano a funciones del paquete gtsummary.\n\n\n\n\n\nEsta librería proporciona una forma elegante y flexible de crear tablas analíticas y de resumen, univariadas, estratificadas y complejas.\nIntegra estimaciones estadísticas predefinidas y se pueden personalizar a gusto, interactuando con otros paquetes como gt, labelled y flextable.\nEn el sitio del desarrollador (gtsummary), encontrarán mucha documentación para adecuar los requerimientos de la salida buscada.\nMostramos un ejemplo en función de los datos del archivo “base2023r.xlsx”.\n\nlibrary(readxl)\nlibrary(gtsummary)\n\n\ndatos &lt;- read_excel(\"datos/base2023r.xlsx\")\n\n\ndatos |&gt; \n  select(EDAD_DIAGNOSTICO, SEXO, MOTIVO_CONSULTA) |&gt;\n  tbl_summary()\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 200\n1\n\n\n\n\nEDAD_DIAGNOSTICO\n33 (23, 49)\n\n\nSEXO\n\n\n\n\n    A\n1 (0.5%)\n\n\n    F\n68 (34%)\n\n\n    M\n131 (66%)\n\n\nMOTIVO_CONSULTA\n\n\n\n\n    Contacto\n2 (11%)\n\n\n    Examen de Salud\n1 (5.3%)\n\n\n    Sintomático Respiratorio\n16 (84%)\n\n\n    Unknown\n181\n\n\n\n1\nMedian (Q1, Q3); n (%)\n\n\n\n\n\n\n\n\nQuizás lo mejor sea presentar los datos estratificados por sexo, por ejmplo. Además configuramos algunos argumentos mas.\n\ndatos |&gt; \n  select(EDAD_DIAGNOSTICO, SEXO, MOTIVO_CONSULTA) |&gt;\n  filter(SEXO != \"A\") |&gt; \n  tbl_summary(by = SEXO,\n              statistic = list(\n                all_continuous() ~ \"{mean} ({sd})\",\n                all_categorical() ~ \"{n} / {N} ({p}%)\"),\n              digits = all_continuous() ~ 1,\n              missing_text = \"Sin dato\") |&gt; \n  modify_header(label ~ \"**Variable**\")\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nF\nN = 68\n1\nM\nN = 131\n1\n\n\n\n\nEDAD_DIAGNOSTICO\n33.2 (19.1)\n39.1 (18.2)\n\n\nMOTIVO_CONSULTA\n\n\n\n\n\n\n    Contacto\n2 / 7 (29%)\n0 / 12 (0%)\n\n\n    Examen de Salud\n1 / 7 (14%)\n0 / 12 (0%)\n\n\n    Sintomático Respiratorio\n4 / 7 (57%)\n12 / 12 (100%)\n\n\n    Sin dato\n61\n119\n\n\n\n1\nMean (SD); n / N (%)\n\n\n\n\n\n\n\n\nEl argumento statistic permite que, mediante una lista, configuremos los estadísticos a presentar. Para todas las variables continuas seleccionamos la media (mean) y el desvío estandar (sd); para todas las variables categóricas el conteo de cada categoría y el porcentaje. Los decimales de las variables continuas quedan definidos en 1 y cuando aparezcan valores NA serán expresados con la etiqueta “Sin dato”. Por último, la cabecera de la tabla en la comuna de las variables será “Variable” en negrita.\n\nFlextable\n\n\n\n\n\nEstas tablas de presentación de resultados se pueden conectar con el paquete flextable para exportarlas en diferentes formatos, como Word, html, PDF, PowerPoint o imagen y además se vincula con el contenido en estructuras de archivos rmarkdown y/o Quarto.\nUna salida interesante es poder guardar la tabla en formato Word (.docx), porque luego podemos editarla facilmente, para esto la función as_flex_table() convierte al tbl_summary() de gtsummry en clase flextable.\n\nlibrary(flextable)\n\ntabla1 &lt;- datos |&gt; \n  select(EDAD_DIAGNOSTICO, SEXO, MOTIVO_CONSULTA) |&gt;\n  filter(SEXO != \"A\") |&gt; \n  tbl_summary(by = SEXO,\n              statistic = list(\n                all_continuous() ~ \"{mean} ({sd})\",\n                all_categorical() ~ \"{n} / {N} ({p}%)\"),\n              digits = all_continuous() ~ 1,\n              missing_text = \"Sin dato\") |&gt; \n  modify_header(label ~ \"**Variable**\") |&gt; \n  as_flex_table() |&gt; \n  autofit() |&gt;    # ajuste automático \n  theme_box()     # tema box\n\nLuego es posible exportar fácilmente una o más tablas a partir de los objetos flextables almacenados a documentos tipo html, RTF, Word, PowerPoint o PNG.\nUn ejemplo para salidas tipo Word es: save_as_docx()\n\nsave_as_docx(\n  \"tabla 1\" = tabla1, \n  path = \"/resultados/tabla_exportada.docx\")\n\nExporta el objeto tabla1 en el archivo tabla_exportada.docx dentro de la carpeta resultados.\nTodos los objetos de clase flextable están compuestos por tres partes:\n\nheader: de forma predeterminada, solo hay una fila de encabezado que contiene los nombres del dataframe.\n\nbody: la parte del cuerpo contiene datos del dataframe.\nfooter: la parte del pie de tabla no está implementada de forma predeterminada, pero puede contener notas al pie o cualquier contenido."
  },
  {
    "objectID": "primero/recursos/06-iteracion.html",
    "href": "primero/recursos/06-iteracion.html",
    "title": "Operaciones múltiples e iteración",
    "section": "",
    "text": "Muchas de las tareas que hicimos hasta ahora, ya sea transformando u obteniendo resultados resumenes de variables, las aplicamos variable a variable, es decir repitiendo las operaciones para cada una de las columnas de una tabla.\nUna premisa del tidyverse, y también de la programación en general, es no copiar y pegar el código mas de dos veces. Si bien esta práctica ahorra tiempo y no esta mal en si mismo, hacerlo suele ser una fuente de errores y además incrementa las líneas de código del script."
  },
  {
    "objectID": "primero/recursos/06-iteracion.html#estadísticos-compatibles-con-tidyverse",
    "href": "primero/recursos/06-iteracion.html#estadísticos-compatibles-con-tidyverse",
    "title": "Resúmenes, indicadores y funciones estadísticas",
    "section": "Estadísticos compatibles con tidyverse",
    "text": "Estadísticos compatibles con tidyverse\nEl interprete de R trae muchas funciones estadísticas descriptivas y para inferencia disponibles en su versión base pero ninguna de estas son compatibles con la filosofia de trabajo de tidyverse. Es por eso que para utilizar funciones como mean() o median() por ejemplo, debemos introducirlas dentro de estructuras como summarise(). Las funciones de este tipo trabajan sobre vectores y no tienen en cuenta a los dataframes que encapsulan a los vectores como variables.\nTenemos estos datos y vamos a calcular su media.\n\ndatos\n\n# A tibble: 10 × 1\n    Edad\n   &lt;dbl&gt;\n 1    34\n 2    56\n 3    43\n 4    21\n 5    67\n 6    89\n 7    54\n 8    32\n 9    16\n10    76\n\n\nSi lo abordamos con la sintaxis R base:\n\n# Edad es una variable de datos pero llamada así es un vector numérico\n\ndatos$Edad\n\n [1] 34 56 43 21 67 89 54 32 16 76\n\n# preguntamos si es vector\n\nis.vector(datos$Edad)\n\n[1] TRUE\n\n# ejecutamos mean() sobre ese vector\nmean(datos$Edad)\n\n[1] 48.8\n\n\nSi lo abordamos con tuberías.\n\nlibrary(tidyverse)\n\n\ndatos |&gt; \n  mean(Edad)\n\nWarning in mean.default(datos, Edad): argument is not numeric or logical:\nreturning NA\n\n\n[1] NA\n\n\nNecesitamos la función summarise() para que funcione bien.\n\ndatos |&gt; \n  summarise(media_edad = mean(Edad))\n\n# A tibble: 1 × 1\n  media_edad\n       &lt;dbl&gt;\n1       48.8\n\n\nCuando los estadísticos son más complejos que estas funciones descriptivas y devuelven un conjunto de resultados en forma de lista ni siquiera alcanza con aplicarlas dentro de un andamiaje de tidyverse como summarise().\nUn ejemplo de ello, son todas las funciones de R base para comparaciones de inferencia. Tomemos el caso de la prueba t de Student, que sirve para comparar las medias de muestras aproximadamente normales.\nLa función de R base es t.test() y sus argumentos obligatorios son x e y o bien utilizar un formato fórmula (var1 ~ var2)\nPara comparar dos conjuntos de datos con la forma x e y los datos tienen que estar en dos variables separadas y por lo tanto no cumplir con el formato “ordenado”.\n\ndatos\n\n# A tibble: 10 × 2\n   Edad1 Edad2\n   &lt;dbl&gt; &lt;dbl&gt;\n 1    34    45\n 2    56    76\n 3    43    32\n 4    21    12\n 5    67    14\n 6    89    18\n 7    54    20\n 8    32    54\n 9    16    98\n10    76    32\n\n\nAplicamos la función teniendo en cuenta que lo que ingresa en cada argumento es un vector (dataframe$variable)\n\nt.test(x = datos$Edad1, y = datos$Edad2)\n\n\n    Welch Two Sample t-test\n\ndata:  datos$Edad1 and datos$Edad2\nt = 0.73815, df = 17.458, p-value = 0.4702\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -16.11732  33.51732\nsample estimates:\nmean of x mean of y \n     48.8      40.1 \n\n\nEl resultado da un valor de probabilidad de 0,47 lo que indica que no hay diferencias significativas entre las medias de las dos muestras.\nPara usar el formato fórmula es necesario que la tabla de datos cumpla con el formato “ordenado”, quedando:\n\ndatos\n\n# A tibble: 20 × 2\n   Muestra  Edad\n     &lt;dbl&gt; &lt;dbl&gt;\n 1       1    34\n 2       1    56\n 3       1    43\n 4       1    21\n 5       1    67\n 6       1    89\n 7       1    54\n 8       1    32\n 9       1    16\n10       1    76\n11       2    45\n12       2    76\n13       2    32\n14       2    12\n15       2    14\n16       2    18\n17       2    20\n18       2    54\n19       2    98\n20       2    32\n\n\nEn este caso el t.test() lleva formula y datos en el argumento data.\n\nt.test(formula = Edad ~ Muestra, data = datos)\n\n\n    Welch Two Sample t-test\n\ndata:  Edad by Muestra\nt = 0.73815, df = 17.458, p-value = 0.4702\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -16.11732  33.51732\nsample estimates:\nmean in group 1 mean in group 2 \n           48.8            40.1 \n\n\nLo importante acá no es el resultado sino la forma en que lo devuelve. Observaran que no se trata de un formato ordenado ni se parece a una tabla. El tidyverse siempre (salvo raras excepciones, como con pull()) devuelve una tabla de datos ordenada y por eso todas estas funciones son incompatibles, aún utilizando un summarise() y nos dan error:\n\ndatos |&gt; \n  summarise(IC = t.test(Edad ~ Muestra))\n\nError in `summarise()`:\nℹ In argument: `IC = t.test(Edad ~ Muestra)`.\nCaused by error:\n! `IC` must be a vector, not a &lt;htest&gt; object.\n\n\nHace unos años a un desarrollador se le ocurrió crear un paquete que contiene todas estas funciones (y algunas más) del R base en espejo pero compatibles con tidyverse, esto es: reciben un dataframe y devuelven un dataframe.\nEl paquete se llama rstatix y provee un marco simple e intuitivo compatible con el uso de tuberías, coherente con la filosofía de diseño “tidyverse”, para realizar pruebas estadísticas descriptivas básicas y otras más avanzadas de inferencia y modelado.\nLas funciones relacionadas con la inferencia estadística, como t-test, ANOVAS, correlaciones y tamaños de efecto, así como también valores p ajustados o agregados de etiquetas de significación no serán explicados en este curso pero aquellxs estudiantes que les interese profundizar y utilizarlas le pueden sacar un provecho muy útil a este paquete, cuyo sitio es https://rpkgs.datanovia.com/rstatix/index.html.\nRespecto del ejemplo anterior la función de rstatix que reemplaza al t.test() tradicional es t_test(), es decir que al modo tidyverse reemplaza en el nombre el punto por un guión bajo (sucede en todas las funciones del paquete).\n\nlibrary(rstatix)\n\ndatos |&gt; \n  t_test(Edad ~ Muestra, conf.level = .95)\n\n# A tibble: 1 × 8\n  .y.   group1 group2    n1    n2 statistic    df     p\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Edad  1      2         10    10     0.738  17.5  0.47\n\n\nAhora si, el resultado es una tabla de 8 variables por una fila, lo que nos va a permitir poder continuar el trabajo con tuberías. Debajo seleccionamos solo la variable que queremos ver (valor de p).\n\ndatos |&gt; \n  t_test(Edad ~ Muestra, conf.level = .95) |&gt; \n  select(p)\n\n# A tibble: 1 × 1\n      p\n  &lt;dbl&gt;\n1  0.47\n\n\nDentro de los estadísticos descriptivos la función get_summary_stats() devuelve un resumen univariado para variables cuantitativas.\n\ndatos |&gt; \n  get_summary_stats(Edad)\n\n# A tibble: 1 × 13\n  variable     n   min   max median    q1    q3   iqr   mad  mean    sd    se\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Edad        20    12    98   38.5  20.8  58.8    38  26.7  44.4  26.0  5.82\n# ℹ 1 more variable: ci &lt;dbl&gt;\n\n\nY al ser compatible con tidyverse se puede estratificar con group_by().\n\ndatos |&gt; \n  group_by(Muestra) |&gt; \n  get_summary_stats(Edad)\n\n# A tibble: 2 × 14\n  Muestra variable     n   min   max median    q1    q3   iqr   mad  mean    sd\n    &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1       1 Edad        10    16    89   48.5  32.5  64.2  31.8  25.9  48.8  23.9\n2       2 Edad        10    12    98   32    18.5  51.8  33.2  23.7  40.1  28.6\n# ℹ 2 more variables: se &lt;dbl&gt;, ci &lt;dbl&gt;\n\n\nLa función freq_table() construye tablas con las variables categóricas.\n\ndatos |&gt; \n freq_table(Sexo)\n\n# A tibble: 2 × 3\n  Sexo      n  prop\n  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1 Mujer    14    70\n2 Varon     6    30\n\n\nTambién agregando otra variables que estratifiquen la salida.\n\ndatos |&gt; \n freq_table(Sexo, Fuma)\n\n# A tibble: 4 × 4\n  Sexo  Fuma      n  prop\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1 Mujer No       10  71.4\n2 Mujer Si        4  28.6\n3 Varon No        2  33.3\n4 Varon Si        4  66.7\n\n\nUna opción más completa para construir tablas y tablas de contingencia es usar la familia de funciones tabyl() del paquete janitor.\n\nlibrary(janitor)\n\ndatos |&gt; \n  tabyl(Sexo)\n\n  Sexo  n percent\n Mujer 14     0.7\n Varon  6     0.3\n\n\nCalcula las frecuencias absolutas y relativas de variables categóricas de forma similar a freq_table() pero se le pueden modificar sus argumentos y asociar otras funciones del paquete mediante tuberías para obtener mejores resultados (también es compatible con tidyverse).\n\ndatos |&gt;  \n  tabyl(Sexo) |&gt; \n  adorn_totals(where = \"row\") %&gt;% # agregamos totales \n  adorn_pct_formatting(digits = 2) # porcentaje con dos decimales\n\n  Sexo  n percent\n Mujer 14  70.00%\n Varon  6  30.00%\n Total 20 100.00%\n\n\nLa forma más adecuada de describir la relación entre dos variables categóricas es a partir de la construcción de una tabla de contingencia. Para ello se introduce en cada fila de la tabla las categorías de una de las variables y las categorías de la otra variable se asocian a cada una de las columnas de la tabla, en cada celda de la tabla aparecerá el número de observaciones correspondientes a la combinación oportuna de ambas variables. Si bien freq_table() hace lo mismo, respeta la salida ordenada lo que dificulta su lectura.\nCon la misma función tabyl() se puede realizar una tabla de contingencia, incluyendo a la variable Fuma.\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) \n\n  Sexo No Si\n Mujer 10  4\n Varon  2  4\n\n\nRecordemos que el orden dentro de los paréntesis de la función es igual al de los índices del lenguage, el primer argumento es la variable que aparecerá en las filas y el segundo la variable de las columnas. Por ese motivo, en la tabla de contingencia absoluta tenemos el Sexo en las filas y a Fuma en las columnas.\nSu salida se puede mejorar con totales por columna y que aparezca el nombre de la variable que esta en la columna:\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) |&gt; \n  adorn_title(placement = \"combined\") |&gt; \n  adorn_totals(where = \"row\")\n\n Sexo/Fuma No Si\n     Mujer 10  4\n     Varon  2  4\n     Total 12  8\n\n\nTambién haciendo que los valores sean porcentuales por fila.\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) |&gt;  \n  adorn_title(placement = \"combined\") |&gt; \n  adorn_totals(where = \"row\") |&gt;  \n  adorn_percentages(denominator = \"row\") |&gt;  #  % por fila\n  adorn_pct_formatting(digits = 2) # redondea con 2 decimales\n\n Sexo/Fuma     No     Si\n     Mujer 71.43% 28.57%\n     Varon 33.33% 66.67%\n     Total 60.00% 40.00%\n\n\nIncoporamos valores absolutos entre paréntesis.\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) |&gt;  \n  adorn_totals(where = \"row\") |&gt;  \n  adorn_percentages(denominator = \"row\") |&gt;  \n  adorn_pct_formatting(digits = 2) |&gt; \n  adorn_ns() |&gt; \n  adorn_title() \n\n              Fuma           \n  Sexo          No         Si\n Mujer 71.43% (10) 28.57% (4)\n Varon 33.33%  (2) 66.67% (4)\n Total 60.00% (12) 40.00% (8)\n\n\nEl paquete trae muchas funciones que se integran para construir tablas complejas. Más de estas opciones las pueden encontrar en el sitio oficial del paquete janitor"
  },
  {
    "objectID": "primero/recursos/06-iteracion.html#tablas-para-presentaciones",
    "href": "primero/recursos/06-iteracion.html#tablas-para-presentaciones",
    "title": "Resúmenes, indicadores y funciones estadísticas",
    "section": "Tablas para presentaciones",
    "text": "Tablas para presentaciones\nCuando necesitemos presentar resultados estadísticos combinados, producto de variables cuanti y cualitativas a la vez, podemos hechar mano a funciones del paquete gtsummary.\n\n\n\n\n\nEsta librería proporciona una forma elegante y flexible de crear tablas analíticas y de resumen, univariadas, estratificadas y complejas.\nIntegra estimaciones estadísticas predefinidas y se pueden personalizar a gusto, interactuando con otros paquetes como gt, labelled y flextable.\nEn el sitio del desarrollador (gtsummary), encontrarán mucha documentación para adecuar los requerimientos de la salida buscada.\nMostramos un ejemplo en función de los datos del archivo “base2023r.xlsx”.\n\nlibrary(readxl)\nlibrary(gtsummary)\n\n\ndatos &lt;- read_excel(\"datos/base2023r.xlsx\")\n\n\ndatos |&gt; \n  select(EDAD_DIAGNOSTICO, SEXO, MOTIVO_CONSULTA) |&gt;\n  tbl_summary()\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 200\n1\n\n\n\n\nEDAD_DIAGNOSTICO\n33 (23, 49)\n\n\nSEXO\n\n\n\n\n    A\n1 (0.5%)\n\n\n    F\n68 (34%)\n\n\n    M\n131 (66%)\n\n\nMOTIVO_CONSULTA\n\n\n\n\n    Contacto\n2 (11%)\n\n\n    Examen de Salud\n1 (5.3%)\n\n\n    Sintomático Respiratorio\n16 (84%)\n\n\n    Unknown\n181\n\n\n\n1\nMedian (Q1, Q3); n (%)\n\n\n\n\n\n\n\n\nQuizás lo mejor sea presentar los datos estratificados por sexo, por ejmplo. Además configuramos algunos argumentos mas.\n\ndatos |&gt; \n  select(EDAD_DIAGNOSTICO, SEXO, MOTIVO_CONSULTA) |&gt;\n  filter(SEXO != \"A\") |&gt; \n  tbl_summary(by = SEXO,\n              statistic = list(\n                all_continuous() ~ \"{mean} ({sd})\",\n                all_categorical() ~ \"{n} / {N} ({p}%)\"),\n              digits = all_continuous() ~ 1,\n              missing_text = \"Sin dato\") |&gt; \n  modify_header(label ~ \"**Variable**\")\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nF\nN = 68\n1\nM\nN = 131\n1\n\n\n\n\nEDAD_DIAGNOSTICO\n33.2 (19.1)\n39.1 (18.2)\n\n\nMOTIVO_CONSULTA\n\n\n\n\n\n\n    Contacto\n2 / 7 (29%)\n0 / 12 (0%)\n\n\n    Examen de Salud\n1 / 7 (14%)\n0 / 12 (0%)\n\n\n    Sintomático Respiratorio\n4 / 7 (57%)\n12 / 12 (100%)\n\n\n    Sin dato\n61\n119\n\n\n\n1\nMean (SD); n / N (%)\n\n\n\n\n\n\n\n\nEl argumento statistic permite que, mediante una lista, configuremos los estadísticos a presentar. Para todas las variables continuas seleccionamos la media (mean) y el desvío estandar (sd); para todas las variables categóricas el conteo de cada categoría y el porcentaje. Los decimales de las variables continuas quedan definidos en 1 y cuando aparezcan valores NA serán expresados con la etiqueta “Sin dato”. Por último, la cabecera de la tabla en la comuna de las variables será “Variable” en negrita.\n\nFlextable\n\n\n\n\n\nEstas tablas de presentación de resultados se pueden conectar con el paquete flextable para exportarlas en diferentes formatos, como Word, html, PDF, PowerPoint o imagen y además se vincula con el contenido en estructuras de archivos rmarkdown y/o Quarto.\nUna salida interesante es poder guardar la tabla en formato Word (.docx), porque luego podemos editarla facilmente, para esto la función as_flex_table() convierte al tbl_summary() de gtsummry en clase flextable.\n\nlibrary(flextable)\n\ntabla1 &lt;- datos |&gt; \n  select(EDAD_DIAGNOSTICO, SEXO, MOTIVO_CONSULTA) |&gt;\n  filter(SEXO != \"A\") |&gt; \n  tbl_summary(by = SEXO,\n              statistic = list(\n                all_continuous() ~ \"{mean} ({sd})\",\n                all_categorical() ~ \"{n} / {N} ({p}%)\"),\n              digits = all_continuous() ~ 1,\n              missing_text = \"Sin dato\") |&gt; \n  modify_header(label ~ \"**Variable**\") |&gt; \n  as_flex_table() |&gt; \n  autofit() |&gt;    # ajuste automático \n  theme_box()     # tema box\n\nLuego es posible exportar fácilmente una o más tablas a partir de los objetos flextables almacenados a documentos tipo html, RTF, Word, PowerPoint o PNG.\nUn ejemplo para salidas tipo Word es: save_as_docx()\n\nsave_as_docx(\n  \"tabla 1\" = tabla1, \n  path = \"/resultados/tabla_exportada.docx\")\n\nExporta el objeto tabla1 en el archivo tabla_exportada.docx dentro de la carpeta resultados.\nTodos los objetos de clase flextable están compuestos por tres partes:\n\nheader: de forma predeterminada, solo hay una fila de encabezado que contiene los nombres del dataframe.\n\nbody: la parte del cuerpo contiene datos del dataframe.\nfooter: la parte del pie de tabla no está implementada de forma predeterminada, pero puede contener notas al pie o cualquier contenido."
  },
  {
    "objectID": "primero/recursos/06-iteracion.html#operaciones-múltiples",
    "href": "primero/recursos/06-iteracion.html#operaciones-múltiples",
    "title": "Operaciones múltiples e iteración",
    "section": "Operaciones múltiples",
    "text": "Operaciones múltiples\n\n\n\n\n\nEl paquete dplyr de tidyverse implementa desde hace poco tiempo un esquema de trabajo para operaciones múltiples o simultáneas a través de su función across().\nEsta función se puede utilizar en estructuras de mutate() o summarise() dependiendo del resultado buscado y tiene dos partes fundamentales: la captura o selección de variables donde vamos a aplicar determinadas funciones y la declaración de las funciones a aplicar.\n\nacross()\nLa función se incorporó a partir de la versión de dplyr 1.0.0 y su sintaxis general es:\n\nacross(.cols,  \n       .fns,  \n       ...,  \n       .names)\n\ndonde los argumentos son:\n.cols = columnas a transformar\n.fns = función o funciones para aplicar a cada columna de .cols\n... = argumentos adicionales de las funciones especificadas anteriormente (ejemplo: na.rm = T)\n.names = nombres de las columnas de salida. Aquí, {.col} es un marcador especial al que se le puede agregar el sufijo deseado.\n\n\nAplicación en resúmenes\nVeamos un ejemplo de uso para situaciones donde queremos obtener resumenes simultáneos.\nTomemos la siguiente tabla de datos ficticios:\n\ndatos\n\n# A tibble: 10 × 4\n         a      b      c       d\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 -0.560   1.22  -1.07   0.426 \n 2 -0.230   0.360 -0.218 -0.295 \n 3  1.56    0.401 -1.03   0.895 \n 4  0.0705  0.111 -0.729  0.878 \n 5  0.129  -0.556 -0.625  0.822 \n 6  1.72    1.79  -1.69   0.689 \n 7  0.461   0.498  0.838  0.554 \n 8 -1.27   -1.97   0.153 -0.0619\n 9 -0.687   0.701 -1.14  -0.306 \n10 -0.446  -0.473  1.25  -0.380 \n\n\nSupongamos que queremos calcular la media de cada variable numérica, con lo que sabemos hasta ahora podríamos hacerlo repitiendo para cada variable.\n\ndatos |&gt; summarise(\n  a = mean(a),\n  b = mean(b),\n  c = mean(c),\n  d = mean(d),\n)\n\n# A tibble: 1 × 4\n       a     b      c     d\n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 0.0746 0.209 -0.425 0.322\n\n\nPero esto rompe la regla general que buscamos de nunca copiar y pegar más de dos veces, ocasionando que me pueda equivocar al editar el nombre de la variable que va en cada mean() y generando tantas líneas de código como cantidad de variables tengo.\nPara solucionarlo vamos a aplicar across() realizando el resumen simultáneo en una sola línea.\n\ndatos |&gt; summarise(\n  across(.cols = a:d, \n         .fns = mean),\n)\n\n# A tibble: 1 × 4\n       a     b      c     d\n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 0.0746 0.209 -0.425 0.322\n\n\nObservemos que el primer argumento es el rango de nombres de variables que estamos seleccionando donde aplicar la función que aperece como segundo argumento.\nEs decir, que el primer argumento de la función responde de la misma forma que la función select() y por ende, aplican también las funciones ayudantes de selección.\n\n\n\neverything(): coincide con todas las variables.\ngroup_cols(): seleccione todas las columnas de agrupación.\nstarts_with(): comienza con un prefijo.\nends_with(): termina con un sufijo.\ncontains(): contiene una cadena literal.\nmatches(): coincide con una expresión regular.\n\n\n\nnum_range(): coincide con un rango numérico como x01, x02, x03.\nall_of(): coincide con nombres de variables en un vector de caracteres. Todos los nombres deben estar presentes; de lo contrario, se generará un error de fuera de límites.\nany_of(): igual que all_of(), excepto que no se genera ningún error para los nombres que no existen.\nwhere(): aplica una función a todas las variables y selecciona aquellas para las cuales la función regresa TRUE.\n\n\n\nMostremos otra tabla de ejemplo similar a la anterior:\n\ndatos\n\n# A tibble: 10 × 5\n   grupo       a      b       c        d\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 B     -1.12    1.52   0.304   1.03   \n 2 B     -0.403  -1.55   0.448  -0.285  \n 3 A     -0.467   0.585  0.0530 -1.22   \n 4 B      0.780   0.124  0.922   0.181  \n 5 B     -0.0834  0.216  2.05   -0.139  \n 6 B      0.253   0.380 -0.491   0.00576\n 7 A     -0.0285 -0.502 -2.31    0.385  \n 8 A     -0.0429 -0.333  1.01   -0.371  \n 9 B      1.37   -1.02  -0.709   0.644  \n10 A     -0.226  -1.07  -0.688  -0.220  \n\n\nAquí datos agrega una variable categórica llamada grupo con dos valores (A y B).\nUsando group_by() combinada con una selección completa (ayudante everything) del resto de las variables obtenemos las medias por cada uno de estos grupos.\n\ndatos |&gt; \n  group_by(grupo) |&gt; \n  summarise(across(everything(), mean))\n\n# A tibble: 2 × 5\n  grupo      a       b      c      d\n  &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 A     -0.191 -0.331  -0.485 -0.357\n2 B      0.132 -0.0552  0.421  0.239\n\n\nEl argumento .cols también puede recibir construcciones booleanas utilizando los operadores conocidos como ! (negación) y conectores lógicos como & (AND) y | (OR) entre las funciones ayudantes de selección.\n\n.cols = !where(is.numeric) & starts_with(\"a\")\n\nEn este ejemplo, se seleccionan todas las columnas no numéricas, cuyo nombre comienza con “a”.\nHasta ahora vimos el ejemplo de aplicar una función simple como mean() a un grupo de variables.\nQue sucede si entre los datos de esas variables hay valores NA?\n\ndatos_na\n\n# A tibble: 5 × 4\n        a      b      c      d\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1  1.56   -1.27  NA     -0.473\n2 -0.560  NA     -1.05  -1.07 \n3 -0.230   1.22   0.238 -0.218\n4 NA      -0.446  1.29  -1.03 \n5  0.0705 -0.687 NA     -0.729\n\n\nVamos a necesitar incorporar el argumento na.rm = TRUE a la función mean() porque si no el resultado será:\n\ndatos_na |&gt; summarise(\n  across(.cols = a:d, \n         .fns = mean),\n)\n\n# A tibble: 1 × 4\n      a     b     c      d\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1    NA    NA    NA -0.703\n\n\nComo lo hacemos dentro de un across()?\nExisten dos formas sintácticas de realizarlo.\n\nUna función estilo-purrr (tidyverse) que tiene la forma ~ mean(.x, na.rm = TRUE)\nUna función anónima de R base mediante function(x) mean(x, na.rm = TRUE) o más sencilla en su forma de atajo: \\(x) mean(x, na.rm = TRUE)\n\n\n# forma tidyverse (purrr)\n\ndatos_na |&gt; \n  summarise(\n    across(a:d, ~ mean(.x, na.rm = TRUE))\n  )\n\n# A tibble: 1 × 4\n      a      b     c      d\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 0.210 -0.293 0.161 -0.703\n\n\n\n# forma R base (atajo función anómina)\n\ndatos_na |&gt; \n  summarise(\n    across(a:d, \\(x) mean(x, na.rm = TRUE))\n  )\n\n# A tibble: 1 × 4\n      a      b     c      d\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 0.210 -0.293 0.161 -0.703\n\n\nSe le llama función anónima justamente porque no hace falta ponerle nombre. Acostumbrarse a esta notación es más útil que la forma del tidyverse porque aplica también para otras funciones.\nPara incorporar más de una función dentro de across() debemos incluirlas dentro de una lista [list()]\n\ndatos_na |&gt; \n  summarise(\n    across(a:d, list(\n      media = \\(x) mean(x, na.rm = TRUE),\n      desvio = \\(x) sd(x, na.rm = TRUE),\n      n_na = \\(x) sum(is.na(x))))\n  )\n\n# A tibble: 1 × 12\n  a_media a_desvio a_n_na b_media b_desvio b_n_na c_media c_desvio c_n_na\n    &lt;dbl&gt;    &lt;dbl&gt;  &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;int&gt;\n1   0.210    0.936      1  -0.293     1.07      1   0.161     1.17      2\n# ℹ 3 more variables: d_media &lt;dbl&gt;, d_desvio &lt;dbl&gt;, d_n_na &lt;int&gt;\n\n\nLa lista contiene cada función a aplicar, bajo nombres definidos a la izquierda del igual. El resultado muestra 12 variables producto de hacer tres operaciones en cada una de las 4 variables de la tabla.\nObservemos que los nombres de las variables resultado se componen del nombre de la columna, un guión bajo y el nombre definido de la función aplicada (variable_funcion)\nLa estructura de estos nombres se pueden modificar con el argumento .names.\nEl marcador especial para el nombre de columna es {.col} y para el nombre de la función definida es {.fn}.\nPor ejemplo, podríamos invertir el orden predeterminado de los nombres del resumen (funcion_variable)\n\ndatos_na |&gt; \n  summarise(\n    across(a:d, list(\n      media = \\(x) mean(x, na.rm = TRUE),\n      n_na = \\(x) sum(is.na(x))),\n      .names = \"{.fn}_{.col}\")\n  )\n\n# A tibble: 1 × 8\n  media_a n_na_a media_b n_na_b media_c n_na_c media_d n_na_d\n    &lt;dbl&gt;  &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;\n1   0.210      1  -0.293      1   0.161      2  -0.703      0\n\n\n\n\nAplicación en conversión o creación de nuevas variables\nHasta el momento trabajamos con la función across() dentro de un resumen (summarise) pero al comienzo también dijimos que se puede utilizar para transformaciones masivas de datos.\nLa plataforma para lograr esto es mutate() y lo podemos usar modificando las variables originales o bien creando nuevas variables si cambiamos su nombre con .names.\nPara ejemplificar, aplicaremos la función coalesce() perteneciente a dplyr, para convertir los valores NA en ceros, transformando las variables originales anteriores.\n\ndatos_na |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0))\n  )\n\n# A tibble: 5 × 4\n        a      b      c      d\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1  1.56   -1.27   0     -0.473\n2 -0.560   0     -1.05  -1.07 \n3 -0.230   1.22   0.238 -0.218\n4  0      -0.446  1.29  -1.03 \n5  0.0705 -0.687  0     -0.729\n\n\nSi no agregamos ningún otro argumento el reemplazo de los valores NA por 0 se realiza en cada variable sobrescribiendo las observaciones.\nEn cambio, si queremos que coexistan las variables originales con las nuevas incluyendo estos cambios podemos declarar en el argumento .names la estructura de los nombres nuevos.\n\ndatos_na |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0),\n      .names = \"{.col}_na_cero\")\n  )\n\n# A tibble: 5 × 8\n        a      b      c      d a_na_cero b_na_cero c_na_cero d_na_cero\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1  1.56   -1.27  NA     -0.473    1.56      -1.27      0        -0.473\n2 -0.560  NA     -1.05  -1.07    -0.560      0        -1.05     -1.07 \n3 -0.230   1.22   0.238 -0.218   -0.230      1.22      0.238    -0.218\n4 NA      -0.446  1.29  -1.03     0         -0.446     1.29     -1.03 \n5  0.0705 -0.687 NA     -0.729    0.0705    -0.687     0        -0.729\n\n\nOtras conversiones posibles pueden utilizar funciones de reemplazo para variables cuantitativas como por ejemplo exp(), log(), scale(), etc. O bien convertir a factor variables character y hasta aplicar funciones condicionales como if_else() o case_when()."
  },
  {
    "objectID": "primero/recursos/06-iteracion.html#filtros-con-iteraciones",
    "href": "primero/recursos/06-iteracion.html#filtros-con-iteraciones",
    "title": "Operaciones múltiples e iteración",
    "section": "Filtros con iteraciones",
    "text": "Filtros con iteraciones\nEl paquete dplyr trae consigo algunas funciones iterativas emparentadas con across() para usar dentro de estructuras de filtro -filter()-, es el caso de if_any() e if_all().\nif_any() enmascara una repetición de OR lógicos if_all() una secuencia de AND lógicos.\nUsémoslas con los datos con los que venimos trabajando.\n\ndatos_na |&gt; \n  filter(if_any(a:d, is.na))\n\n# A tibble: 4 × 4\n        a      b     c      d\n    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1  1.56   -1.27  NA    -0.473\n2 -0.560  NA     -1.05 -1.07 \n3 NA      -0.446  1.29 -1.03 \n4  0.0705 -0.687 NA    -0.729\n\n\nDevuelve las observaciones donde en alguna de las variables encuentra algún NA.\nEs lo mismo que filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))\n\ndatos_na |&gt; \n  filter(if_all(a:d, is.na))\n\n# A tibble: 0 × 4\n# ℹ 4 variables: a &lt;dbl&gt;, b &lt;dbl&gt;, c &lt;dbl&gt;, d &lt;dbl&gt;\n\n\nDevuelve las observaciones donde en todas las variables encuentra valores NA. En este caso no hay ninguna que cumpla esa condición, por eso el resultado es un dataframe vacío.\nEs lo mismo que filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))\nUna forma rápida de armar filtros por múltiples variables escribiendo poco código.\nLas dos funciones de filtro trabajan con el mismo esquema que across(), por lo tanto se le puede aplicar una función o expresión de condición (todas deben devolver TRUE o FALSE)\n\ndatos |&gt; \n  filter(if_all(a:d, \\(x) x &gt; -0.5 & x &lt; 1))\n\n# A tibble: 2 × 5\n  grupo     a     b      c       d\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 B     0.780 0.124  0.922 0.181  \n2 B     0.253 0.380 -0.491 0.00576\n\n\nAcá el valor de cada en todas las observaciones filtradas debe estar en el rango -0,5 a 1. Hay una que cumple la condición en las 4 variables numéricas."
  },
  {
    "objectID": "primero/recursos/06-iteracion.html#operaciones-por-fila",
    "href": "primero/recursos/06-iteracion.html#operaciones-por-fila",
    "title": "Operaciones múltiples e iteración",
    "section": "Operaciones por fila",
    "text": "Operaciones por fila\nLa filosofía del tidy-data, es particularmente adecuada para realizar operaciones por columnas (variables). Todas las funciones de resúmenes toman los valores de forma vertical para realizar una operación, como si tuviesemos vectores “parados” dentro de un dataframe.\nHay algunas circunstancias que nos lleva a necesitar realizar operaciones por filas y por supuesto esto es mucho más difícil.\nEl paquete dplyr incorporó en sus últimas versiones la función rowwise() que implementa un agrupamiento por cada fila, haciendo que sea más sencillo hacer estas tareas.\nEl uso más común es hacer calculos agregados por filas (por ejemplo, calcular la media de x, y, z).\nLa apariencia de los resultados de la función son similares a group_by() donde solo vemos cambios en los metadatos del dataframe que luego van a ser aprovechados por las funciones siguientes.\nTenemos un pequeño dataframe de prueba:\n\n\n# A tibble: 2 × 3\n      x     y     z\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     3     5\n2     2     4     6\n\n\nY aplicamos la función rowwise()\n\ndf |&gt; \n  rowwise()\n\n# A tibble: 2 × 3\n# Rowwise: \n      x     y     z\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     3     5\n2     2     4     6\n\n\nLo único que vemos es la aparición de un metadatos que dice “rowwise”. Significa que las filas de la tabla está agrupadas a lo ancho y las funciones que vengan despues van a respetar este agrupamiento.\nPara ver los cambios que produce este agrupamiento veamos un ejemplo comparativo.\n\ndf |&gt;  \n  mutate(m = mean(c(x, y, z)))\n\n# A tibble: 2 × 4\n      x     y     z     m\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1     3     5   3.5\n2     2     4     6   3.5\n\ndf |&gt; \n  rowwise() |&gt; \n  mutate(m = mean(c(x, y, z)))\n\n# A tibble: 2 × 4\n# Rowwise: \n      x     y     z     m\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1     3     5     3\n2     2     4     6     4\n\n\nSi usamos mutate() con un dataframe normal, calcula la media de x, y, z tomando los valores de todas las filas. Si lo aplicamos a una tabla con rowwise, calcula la media de cada fila, tomando los valores de cada una de las tres variables.\nOpcionalmente, se puede indicar variables como “identificador”.\nEstas variables se conservan cuando se llama a un summarise() por ejemplo, por lo que se comportan de manera similar a las variables de agrupación pasadas a group_by().\nCambiamos el dataframe que ahora es:\n\n\n# A tibble: 2 × 4\n  nombre       x     y     z\n  &lt;chr&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Mercurio     1     3     5\n2 Venus        2     4     6\n\n\n\ndf |&gt; \n  rowwise() |&gt;   \n  summarise(m = mean(c(x, y, z)))\n\n# A tibble: 2 × 1\n      m\n  &lt;dbl&gt;\n1     3\n2     4\n\ndf  |&gt;  \n  rowwise(nombre) |&gt;  \n  summarise(m = mean(c(x, y, z)))\n\n`summarise()` has grouped output by 'nombre'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 2\n# Groups:   nombre [2]\n  nombre       m\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Mercurio     3\n2 Venus        4\n\n\nrowwise() es solo una forma especial de agrupación por fila, por lo que si deseamos eliminarla de una tabla, simplemente llamamos a ungroup().\n\nc_across()\nLa versión de across() para operaciones simultáneas por filas se llama c_across() y tiene los mismos fundamentos aplicados a estas situaciones, aunque es mucho más sencilla dado que no tiene argumentos extras.\nAplicada sobre el último dataframe:\n\ndf  |&gt;  \n  rowwise(nombre) |&gt;  \n  summarise(m = mean(c_across(x:z)))\n\n`summarise()` has grouped output by 'nombre'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 2\n# Groups:   nombre [2]\n  nombre       m\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Mercurio     3\n2 Venus        4\n\n\nO bien, seleccionando los tipos de datos numéricos:\n\ndf  |&gt;  \n  rowwise(nombre) |&gt;  \n  summarise(m = mean(c_across(where(is.numeric))))\n\n`summarise()` has grouped output by 'nombre'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 2 × 2\n# Groups:   nombre [2]\n  nombre       m\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Mercurio     3\n2 Venus        4\n\n\nSin duda este abordaje tiene mayor utilidad cuando las operaciones por fila contemplan muchas variables."
  },
  {
    "objectID": "primero/recursos/06-iteracion.html#bucles-tradicionales",
    "href": "primero/recursos/06-iteracion.html#bucles-tradicionales",
    "title": "Operaciones múltiples e iteración",
    "section": "Bucles tradicionales",
    "text": "Bucles tradicionales\nUn bucle es una estructura de control que permite ejecutar un conjunto de instrucciones repetidamente mientras se cumple una condición específica. Los bucles, se encuentran en todos los lenguajes de programación y se utilizan para automatizar tareas repetitivas (iterar).\nEl lenguaje R también los implementa en sus paquetes base y dispone de tres de ellos:\n\nfor(): estructura de control de flujo de iteración a partir de una secuencia de elementos\n\n\nwhile(): estructura de control de flujo de iteración mientras una condición es verdadera\n\n\nrepeat(): estructura de control de flujo de iteración de repetición y control manual con break\n\n\nBucle for\nLa idea principal de este bucle es repetir un bloque de código un número específico de veces o para cada elemento en objeto (vector, etc).\nSu esquema de funcionamiento es el siguiente:\n\n\n\n\n\nLa estructura sintáctica viene dada por un snippet que RStudio escribe por nosotros:\n\nfor (variable in vector) {\n  \n}\n\nUn ejemplo sencillo que muestra su funcionamiento puede ser.\n\nfor (i in 1:5) {\n  cat(\"El valor de i es:\", i, \"\\n\")\n}\n\nEl valor de i es: 1 \nEl valor de i es: 2 \nEl valor de i es: 3 \nEl valor de i es: 4 \nEl valor de i es: 5 \n\n\nLo que estamos haciendo es recorriendo un vector numérico de 5 posiciones, declarado bajo el nombre de i y luego entre llaves se encuentra el código que escribe en pantalla un texto fijo que incluye a los valores de i en cada repetición.\nEl mismo formato de bucle puede recorrer posiciones y/o elementos de un objeto de la siguiente forma:\n\nx &lt;- c(6, 4, 3, 8)\n\nfor (i in 1:length(x)) {\n  print(x[i]*4)     # utiliza la i para recorrer los elementos de x por su indice\n}\n\n[1] 24\n[1] 16\n[1] 12\n[1] 32\n\n\nRecorre el vector x y multiplica cada elemento por 4. Lo mismo que hace R vectorizadamente de manera simple.\n\nx * 4\n\n[1] 24 16 12 32\n\n\nPor supuesto que la mayoría de las tareas que R ejecuta de forma vectorizada hace que no tengamos que usar esta forma de bucle para operaciones comunes pero, a veces cuando el código dentro de las llaves es extenso y complejo será necesario.\n\n\nBucle while\nEste bucle se repite mientras la condición especificada es evaluada como verdadera (TRUE). Si en algún momento la condición se evalúa como falsa (FALSE), el bucle se detiene y la ejecución continúa con el código después del bucle.\nSu esquema de funcionamiento es el siguiente:\n\n\n\n\n\nSu snippet es:\n\nwhile (condition) {\n  \n}\n\nUn ejemplo posible muestra que primero inicializamos una variable i que servirá como contador, luego escribimos una condición en el inicio del bucle indicando que recién saldremos de él cuando esta variable sea igual a 6 y finalmente dentro de las llaves armamos el código que se va a repetir no olvidando de la sumatoria del contador i.\n\ni &lt;- 1\n\nwhile (i &lt;= 5) {\n  cat(\"El valor de i es:\", i, \"\\n\")\n  i &lt;- i + 1\n}\n\nEl valor de i es: 1 \nEl valor de i es: 2 \nEl valor de i es: 3 \nEl valor de i es: 4 \nEl valor de i es: 5 \n\n\nEl último de los bucles, repeat() no tiene automatizada su salida y necesita que incorporemos dentro de su cuerpo entre llaves la función break a partir de alguna condición (se suele utilizar la estructura condicional if()). Esta forma de trabajo lo hace peligroso porque suelen generar bucles infinitos de donde no hay salida, salvo la interrupción abrupta del interprete.\nDado que su construcción es muy artesanal no vamos a mostrarlo en este documento. Su uso no será necesario durante el curso y probablemente no lo necesiten aplicar en el futuro."
  },
  {
    "objectID": "primero/recursos/06-iteracion.html#mapeos-con-purrr",
    "href": "primero/recursos/06-iteracion.html#mapeos-con-purrr",
    "title": "Operaciones múltiples e iteración",
    "section": "Mapeos con purrr",
    "text": "Mapeos con purrr\nEl patrón de iterar sobre un vector o variable, hacer algo con cada elemento u observación y almacenar los resultados es tan común que el paquete purrr incluído en tidyverse aporta una familia de funciones dedicadas a esta tarea.\nHay una función para cada tipo de output:\nmap() crea una lista. map_lgl() crea un vector lógico. map_int() crea un vector de enteros. map_dbl() crea un vector de numérico (double). map_chr() crea un vector de caracteres. map_df() crea un dataframe\nCada función map, mapea, es decir, toma un vector como input, aplica una función a cada elemento y luego devuelve un nuevo vector que tiene la misma longitud (y los mismos nombres) que el input. El tipo de vector está determinado por el sufijo de la función map.\n\n\n\n\n\nSu estructura sintáctica es:\n\nmap(.x = , \n    .f = , \n    ... = )\n\nDonde en .x es un vector, un data-frame o lista, .f es la función a aplicar y ... son otros argumentos opcionales.\nLas funciones map tienen un nivel superior de abstracción y puede llevar mucho tiempo entender cómo funcionan.\nAlgunos usuarios evitan los bucles tradicionales porque son lentos o “viejos”, pero esto no es así. Las principales ventajas de usar funciones como map() no es la velocidad, sino la claridad: hacen que tu código sea más fácil de escribir y leer.\nUnos ejemplos simples de uso son:\n\n# a partir del dataframe datos utilizado anteriormente\n\ndatos\n\n# A tibble: 10 × 5\n   grupo       a      b       c        d\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 B     -1.12    1.52   0.304   1.03   \n 2 B     -0.403  -1.55   0.448  -0.285  \n 3 A     -0.467   0.585  0.0530 -1.22   \n 4 B      0.780   0.124  0.922   0.181  \n 5 B     -0.0834  0.216  2.05   -0.139  \n 6 B      0.253   0.380 -0.491   0.00576\n 7 A     -0.0285 -0.502 -2.31    0.385  \n 8 A     -0.0429 -0.333  1.01   -0.371  \n 9 B      1.37   -1.02  -0.709   0.644  \n10 A     -0.226  -1.07  -0.688  -0.220  \n\nmap_dbl(.x = datos, .f = mean)\n\nWarning in mean.default(.x[[i]], ...): argument is not numeric or logical:\nreturning NA\n\n\n       grupo            a            b            c            d \n          NA  0.002867988 -0.165413060  0.058542390  0.000676731 \n\n\nCalcula la media por cada una de las variables numéricas. Como la variable grupo no lo es me devuelve una advertencia y un NA como resultado.\nSi quisiera evitarlo podemos hacer.\n\nmap_dbl(.x = datos |&gt; select(-grupo), \n        .f = mean)\n\n           a            b            c            d \n 0.002867988 -0.165413060  0.058542390  0.000676731 \n\n\nObserven que dentro del argumento .x construimos una estructura con tuberías donde seleccionamos a todas las variables menos a grupo (esto se puede hacer en los argumentos de muchas funciones)."
  },
  {
    "objectID": "primero/recursos/06-iteracion.html#aplicación-de-un-bucle-tradicional",
    "href": "primero/recursos/06-iteracion.html#aplicación-de-un-bucle-tradicional",
    "title": "Operaciones múltiples e iteración",
    "section": "Aplicación de un bucle tradicional",
    "text": "Aplicación de un bucle tradicional\nMostramos un ejemplo posible donde necesitamos aplicar un bucle para iterar una serie de repeticiones.\nEste ejemplo consiste en leer un archivo habitual en el trabajo epidemiológico como son las proyecciones poblacionales que publica el INDEC luego de cada censo. En este caso particular son proyecciones que van desde 2010 a 2040 para las 24 provincias de Argentina por quinquenios y sexo.\nLa tabla tiene este formato:\n\n\n\n\n\nCada provincia se ubica en una hoja del archivo Excel y la estructura de las proyecciones no tiene un formato que reconozcamos como ordenado. El objetivo es producir un dataframe donde nos queden 4 variables (Edad, Sexo, Provincia, Poblacion) con los datos de las proyecciones para 2024.\nLo primero que vamos hacer es almacenar en un vector los nombres de las hojas del archivo. Usando la función excel_sheets() extraemos estos codigo-nombres (la expresión de índices [-(1:2)] sirve para omitir los nombres de la primera hoja oculta que tiene el archivo llamada “GraphData” y la segunda donde esta el total país).\n\nlibrary(readxl)\n\nhojas &lt;- excel_sheets(\"datos/c2_proyecciones_prov_2010_2040.xls\")[-(1:2)]\n\nNos va a quedar el vector hojas con los nombres de las 24 provincias que figuran en las hojas Excel.\n\nhojas\n\n [1] \"02-CABA\"                \"06-BUENOS AIRES\"        \"10-CATAMARCA\"          \n [4] \"14-CÓRDOBA\"             \"18-CORRIENTES\"          \"22-CHACO\"              \n [7] \"26-CHUBUT\"              \"30-ENTRE RÍOS\"          \"34-FORMOSA\"            \n[10] \"38-JUJUY\"               \"42-LA PAMPA\"            \"46-LA RIOJA\"           \n[13] \"50-MENDOZA\"             \"54-MISIONES\"            \"58-NEUQUÉN\"            \n[16] \"62-RÍO NEGRO\"           \"66-SALTA\"               \"70-SAN JUAN\"           \n[19] \"74-SAN LUIS\"            \"78-SANTA CRUZ\"          \"82-SANTE FE\"           \n[22] \"86-SANTIAGO DEL ESTERO\" \"90-TUCUMÁN\"             \"94-TIERRA DEL FUEGO\"   \n\n\nPara aprovechar el contenido vamos a construir otro vector con los códigos solos. Aplicamos la función str_sub() sobre hojas.\n\nprovincias &lt;- str_sub(hojas, start = 1, end = 2)\n\n\nprovincias \n\n [1] \"02\" \"06\" \"10\" \"14\" \"18\" \"22\" \"26\" \"30\" \"34\" \"38\" \"42\" \"46\" \"50\" \"54\" \"58\"\n[16] \"62\" \"66\" \"70\" \"74\" \"78\" \"82\" \"86\" \"90\" \"94\"\n\n\nA continuación vamos a necesitar separar la parte que no se repite y la parte que si. Por ejemplo, la columna donde está la edad cada 5 años es una parte fija que no necesaria volver a leer en cada hoja del archivo, en cambio las poblaciones si varían entre provincia y provincia.\n\ngrupo_edad &lt;- read_excel(\"datos/c2_proyecciones_prov_2010_2040.xls\", \n                         sheet = 2, range = \"A36:A56\", col_names = F)  |&gt;  \n  rename(\"Edad\" = \"...1\")\n\nLeemos el archivo “c2_proyecciones_prov_2010_2040.xls” en su segunda hoja (la primera era la occulta) y con el rango “A36:A56”. Desactivamos nombres de columnas y renombramos con el nombre Edad. Podríamos haber leído cualquiera de las 24 hojas porque la columna de edad es la misma para todas.\n\ngrupo_edad\n\n# A tibble: 21 × 1\n   Edad \n   &lt;chr&gt;\n 1 0-4  \n 2 5-9  \n 3 10-14\n 4 15-19\n 5 20-24\n 6 25-29\n 7 30-34\n 8 35-39\n 9 40-44\n10 45-49\n# ℹ 11 more rows\n\n\nNos queda un dataframe de nombre grupo_edad con 1 variable (Edad) y 21 observaciones.\nAhora, antes de comenzar con las repeticiones del bucle, debemos estructurar el dataframe contenedor de estas lecturas iterativas.\n\npoblacion &lt;- data.frame(Varon = NA, Mujer = NA, Provincia = NA, Edad = NA)\n\nCreamos poblacion como un dataframe con 4 variables Varon, Mujer, Provincia y Edad con datos vacíos (NA).\n\npoblacion\n\n  Varon Mujer Provincia Edad\n1    NA    NA        NA   NA\n\n\nEstamos en condiciones de utilizar un bucle for para ir rellenando el dataframe poblacion con las lecturas del archivo Excel.\n\nfor (i in 1:length(hojas)) {\n  datai &lt;- read_excel(\"datos/c2_proyecciones_prov_2010_2040.xls\", \n                     sheet = hojas[i], range = \"K64:L84\", col_names = F)\n  \n  datai &lt;- datai |&gt; mutate(Provincia = provincias[i]) |&gt; \n             rename(\"Varon\" = \"...1\",\n                    \"Mujer\" = \"...2\") |&gt; \n             bind_cols(grupo_edad) \n  \n  poblacion &lt;- poblacion  |&gt;  bind_rows(datai)\n}\n\nAnalicemos la estructura del for() y el contenido del cuerpo encerrado entre llaves:\n\nUtilizamos la longitud del vector hojas para que la cantidad de repeticiones del bucle sea igual a la cantidad de hojas del archivo (serán 24 repeticiones, 1 por hoja)\n\n\n1:length(hojas)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n\n\n\nLa primera línea del cuerpo crea el objeto datai que lee las poblaciones para el año 2024 de varones y mujeres usando un rango que deberemos construir mirando las ubicaciones dentro del archivo Excel. Además usamos la variable i del for() para recorrer el vector hojas que tiene el nombre de cada una de las 24 provincias idénticas a las hojas del archivo, por lo que en la vuelta 1 leera el rango de la hoja 02-CABA, en la segunda la de 06-BUENOS AIRES y así hasta la última (94-TIERRA DEL FUEGO).\nLa segunda estructura de código agrega a datai el código de la provincia en cada repetición recorriendo con la variable i el vector provincias. Luego renombra las cabeceras sin nombre para Varon y Mujer y finalmente une por columna con bind_cols() las edades. Esta forma es la misma en nombre de variables, posición y tipo de datos que el contenedor creado previamente (poblacion).\nPor último, une por filas con bind_rows() a datai con poblacion.\n\nLa operación construye un dataframe con dimensiones [ 505, 4 ], es decir, 505 observaciones por 4 variables.\nHay dos problemas finales para resolver, uno es que la primera observación es la de valores NA que usamos cuando creamos el contenedor.\n\npoblacion |&gt; slice(1:4)\n\n   Varon Mujer Provincia  Edad\n1     NA    NA      &lt;NA&gt;  &lt;NA&gt;\n2 101130 95310        02   0-4\n3 101700 96044        02   5-9\n4 100390 95056        02 10-14\n\n\nCon drop_na() la podemos eliminar sin mayores problemas.\n\npoblacion &lt;- poblacion |&gt; drop_na() # eliminamos primera linea con NA\n\nEl otro inconveniente es que la tabla final no cumple con los datos ordenados, porque Varon y Mujer no deberían ser nombres de variables sino categorías de la variable Sexo.\nAplicamos lo que sabemos de pivoteos con tidyr para arreglarlo.\n\npoblacion &lt;- poblacion |&gt; \n               pivot_longer(cols = c(Varon, Mujer), \n                            names_to = \"Sexo\",\n                            values_to = \"Poblacion\")\n\nEl resultado final es la tabla buscada con poblaciones proyectada por el INDEC de las 24 provincias por sexo y grupos de edades quinquenales en formato tidy-data:\n\npoblacion\n\n# A tibble: 1,008 × 4\n   Provincia Edad  Sexo  Poblacion\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 02        0-4   Varon    101130\n 2 02        0-4   Mujer     95310\n 3 02        5-9   Varon    101700\n 4 02        5-9   Mujer     96044\n 5 02        10-14 Varon    100390\n 6 02        10-14 Mujer     95056\n 7 02        15-19 Varon    101138\n 8 02        15-19 Mujer     96827\n 9 02        20-24 Varon     97411\n10 02        20-24 Mujer     96051\n# ℹ 998 more rows"
  },
  {
    "objectID": "primero/recursos/06-iteracion.html#aplicación-de-una-iteración-map",
    "href": "primero/recursos/06-iteracion.html#aplicación-de-una-iteración-map",
    "title": "Operaciones múltiples e iteración",
    "section": "Aplicación de una iteración map",
    "text": "Aplicación de una iteración map\nImaginemos que tenemos varios archivos de datos con la misma estructura producto de la vigilancia epidemiológica o de un estudio de cohorte donde cada uno de ellos pertenece a un mes. Para analizar todo un año en una sola tabla final, deberíamos leer 12 archivos de nombres diferentes y luego unir los datos uno debajo del otro.\nQueremos hacer este trabajo pero simplificando el proceso agilizando el proceso de lectura y obtener una sola tabla con todas las observaciones generando un id que almacene el mes al que pertenece.\nVamos a hacer uso de la función dis_ls() del paquete fs (file system) que es muy útil cuando debemos hacer operaciones con carpetas y archivos de sistema desde el código (en este caso Windows).\n\nlibrary(fs)\n\nCon la función dir_ls() obtenemos listados de directorio (similar a dir() de la línea de comandos de Windows).\nSi en la carpeta están solos los archivos de datos no hay que aclarar nada más pero si hay otros se puede usar el argumento glob para definir un patrón de búsqueda. Para que esto funcione bien los archivos tienen que tener un mismo formato en su nombre. Por ejemplo, aprovechando el formato de estos archivos vamos a usar el patrón “datos_*” dentro de una subcarpeta denominada datos.\n\narchivos &lt;- dir_ls(path = \"datos\", \n                   glob = \"datos/datos_*\") \n  \narchivos\n\ndatos/datos_abril_vigilancia.csv      datos/datos_agosto_vigilancia.csv     \ndatos/datos_diciembre_vigilancia.csv  datos/datos_enero_vigilancia.csv      \ndatos/datos_febrero_vigilancia.csv    datos/datos_julio_vigilancia.csv      \ndatos/datos_junio_vigilancia.csv      datos/datos_marzo_vigilancia.csv      \ndatos/datos_mayo_vigilancia.csv       datos/datos_noviembre_vigilancia.csv  \ndatos/datos_octubre_vigilancia.csv    datos/datos_septiembre_vigilancia.csv \n\n\nQuedaron almacenados en el vector archivos los 12 nombres de los archivos mensuales. Observemos que tienen el formato “datos_mes_vigilancia.csv” y además nos dicen que son de texto plano con separador coma.\nA continuación aplicaremos la función map_df() del paquete purrr junto a la función read_csv() para repetir las lecturas de estos archivos agregando el nombre de cada uno a las observaciones de la tabla final.\n\ndatos &lt;- archivos |&gt; \n           map_df(read_csv, .id = \"archivo\")\n\nLa primera variable que tendrá el mismo nombre que definimos en el argumento .id es el nombre completo del archivo fuente.\n\ndatos |&gt; count(archivo)\n\n# A tibble: 12 × 2\n   archivo                                   n\n   &lt;chr&gt;                                 &lt;int&gt;\n 1 datos/datos_abril_vigilancia.csv        157\n 2 datos/datos_agosto_vigilancia.csv       157\n 3 datos/datos_diciembre_vigilancia.csv    157\n 4 datos/datos_enero_vigilancia.csv        157\n 5 datos/datos_febrero_vigilancia.csv      157\n 6 datos/datos_julio_vigilancia.csv        157\n 7 datos/datos_junio_vigilancia.csv        157\n 8 datos/datos_marzo_vigilancia.csv        157\n 9 datos/datos_mayo_vigilancia.csv         157\n10 datos/datos_noviembre_vigilancia.csv    157\n11 datos/datos_octubre_vigilancia.csv      157\n12 datos/datos_septiembre_vigilancia.csv   157\n\n\nEn estos datos de ejemplo ficticios hay 157 observaciones de cada uno de los meses, pero en la realidad estas cantidades seguramente son variantes.\nPara resolver el problema de que nos quede solamente el nombre del mes usaremos la función separate_wider_delim() de tidyr indicando que separe el nombre con el delimitador “_” y con el argumento names me quede la parte del medio con nombre mes y se deshaga de las constantes “datos” y “vigilancia”.\n\ndatos |&gt; \n  separate_wider_delim(cols = archivo, \n                       delim = \"_\", \n                       names = c(NA, \"mes\", NA)) |&gt; \n  count(mes)\n\n# A tibble: 12 × 2\n   mes            n\n   &lt;chr&gt;      &lt;int&gt;\n 1 abril        157\n 2 agosto       157\n 3 diciembre    157\n 4 enero        157\n 5 febrero      157\n 6 julio        157\n 7 junio        157\n 8 marzo        157\n 9 mayo         157\n10 noviembre    157\n11 octubre      157\n12 septiembre   157\n\n\nLa estructura completa unida por tuberías nos quedaría:\n\ndatos &lt;- dir_ls(path = \"datos\", glob = \"datos/datos_*\")  |&gt; \n  map_df(read_csv, .id = \"archivo\") |&gt; \n  separate_wider_delim(cols = archivo, \n                       delim = \"_\", \n                       names = c(NA, \"mes\", NA)) \n\nEl resultado final es que leímos 12 archivos (podrían ser muchos más, todos los que quisiéramos) en tan solo 3 líneas de código unidas por dos tuberías.\n\ndatos\n\n# A tibble: 1,884 × 19\n   mes      HC SEXO   EDAD ANT_DIABETES ANT_TBC ANT_CANCER ANT_OBESIDAD ANT_ECV\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;  \n 1 abril 26880 M        17 NO           NO      NO         SI           NO     \n 2 abril 26775 M        18 SI           NO      NO         NO           NO     \n 3 abril 26877 M        18 SI           NO      SI         NO           NO     \n 4 abril 26776 M        18 NO           NO      NO         SI           SI     \n 5 abril 26718 M        18 NO           NO      NO         NO           NO     \n 6 abril 26738 M        18 NO           NO      NO         NO           NO     \n 7 abril 26836 M        18 NO           NO      NO         NO           NO     \n 8 abril 26823 M        18 NO           NO      SI         NO           SI     \n 9 abril 26711 M        18 NO           NO      SI         SI           NO     \n10 abril 26852 M        18 NO           NO      SI         NO           NO     \n# ℹ 1,874 more rows\n# ℹ 10 more variables: ANT_HT &lt;chr&gt;, ANT_COL &lt;chr&gt;, FUMA &lt;chr&gt;, EDADINI &lt;dbl&gt;,\n#   CANTIDAD &lt;dbl&gt;, COL &lt;dbl&gt;, PESO &lt;dbl&gt;, TALLA &lt;dbl&gt;, SIST &lt;dbl&gt;, DIAST &lt;dbl&gt;"
  },
  {
    "objectID": "primero/clases/08-quarto.html",
    "href": "primero/clases/08-quarto.html",
    "title": "Documentos de Quarto",
    "section": "",
    "text": "Quarto ofrece un marco de creación unificado para la ciencia de datos, que combina código, resultados del código y escritura. Es decir, combina un lenguaje de programación (R, en nuestro caso pero podríamos usar otros lenguajes como python o julia) con un lenguaje de documentación (markdown + otras utilidades).\nLos documentos de Quarto son totalmente reproducibles y admiten docenas de formatos de salida, como archivos HTML, PDF, Word, presentaciones y más.\nLos archivos Quarto están diseñados para usarse de tres maneras:\n\nComunicar resultados y nuestras conclusiones (sin mostrar el código detrás del análisis).\nColaborar con otros científicos de datos que trabajen en el mismo proyecto o estén interesados en nuestro trabajo (aquí seguramente incluimos el código).\nComo un entorno en el que hacer ciencia de datos, como un cuaderno de laboratorio moderno donde podemos registrar no solo lo que hicimos, sino también lo que pensamos.\n\nHeredan lo mejor de los 10 años de desarrollo acumulado, dado que los documentos tienen muchas similitudes pero con la ventaja de integrar otras herramientas que surgieron como extensiones de Rmarkdown."
  },
  {
    "objectID": "primero/clases/08-quarto.html#introducción",
    "href": "primero/clases/08-quarto.html#introducción",
    "title": "Documentos de Quarto",
    "section": "",
    "text": "Quarto ofrece un marco de creación unificado para la ciencia de datos, que combina código, resultados del código y escritura. Es decir, combina un lenguaje de programación (R, en nuestro caso pero podríamos usar otros lenguajes como python o julia) con un lenguaje de documentación (markdown + otras utilidades).\nLos documentos de Quarto son totalmente reproducibles y admiten docenas de formatos de salida, como archivos HTML, PDF, Word, presentaciones y más.\nLos archivos Quarto están diseñados para usarse de tres maneras:\n\nComunicar resultados y nuestras conclusiones (sin mostrar el código detrás del análisis).\nColaborar con otros científicos de datos que trabajen en el mismo proyecto o estén interesados en nuestro trabajo (aquí seguramente incluimos el código).\nComo un entorno en el que hacer ciencia de datos, como un cuaderno de laboratorio moderno donde podemos registrar no solo lo que hicimos, sino también lo que pensamos.\n\nHeredan lo mejor de los 10 años de desarrollo acumulado, dado que los documentos tienen muchas similitudes pero con la ventaja de integrar otras herramientas que surgieron como extensiones de Rmarkdown."
  },
  {
    "objectID": "primero/clases/08-quarto.html#conceptos-básicos",
    "href": "primero/clases/08-quarto.html#conceptos-básicos",
    "title": "Documentos de Quarto",
    "section": "Conceptos básicos",
    "text": "Conceptos básicos\nQuarto es un software que se instala independientemente de R y Rstudio. En si mismo funciona con una interfaz de línea de comandos (CLI).\nSu sitio web es https://quarto.org/ y el acceso a la descarga ese encuentra en Get Started. Una vez descargado el ejecutable su instalación es sencilla y similar a cualquier aplicación de Windows.\nLas últimas versiones de RStudio ya lo tienen integrado, al igual que markdown y Pandoc, por lo que vamos a utilizarlo directamente sin necesidad de aprendernos los comandos nativos de su línea de comandos.\nCabe destacar que Quarto se encuentra en pleno desarrollo y es habitual que se publiquen versiones actualizadas que incluyen avances y nuevas tecnologías. Estas nuevas versiones demoran un tiempo en aparecer incluídas en RStudio, por lo que se sugiere actualizarlo individualmente."
  },
  {
    "objectID": "primero/clases/08-quarto.html#anatomía-de-un-documento-quarto",
    "href": "primero/clases/08-quarto.html#anatomía-de-un-documento-quarto",
    "title": "Documentos de Quarto",
    "section": "Anatomía de un documento Quarto",
    "text": "Anatomía de un documento Quarto\nLos archivos fuentes de Quarto tienen extensión .qmd y sus partes fundamentales son:\n\n\n\n\n\n\nEditor Visual:\nRStudio incorporó un editor gráfico de archivos Quarto, similar a un editor de texto como Word. En lugar de código en texto plano con sus marcas, vemos un aspecto más visual con un menú que permite integrar imágenes, tablas, títulos, colores, etc.\n\n\nCabecera YAML:\nEsta cabecera inicia todo documento Quarto y contiene los metadatos del archivo con las opciones de configuración generales. Es el lugar donde se define que tipo de documento estamos produciendo (html, pdf, etc).\nYAML es un lenguaje de marcas ligero del cual utilizaremos algunas opciones.\n\n\nEncabezados (títulos) y Outline:\nLos documentos Quarto contienen un formato jerárquico con cabeceras que permiten dar estructura al contenido. Además, mientras se escribe, genera un índice (outline) a la derecha del script con el cual nos movemos rápidamente por el documento\n\n\nTexto en markdown\nNo solo se puede incluir texto plano acompañado de marcas que le dan un formato particular, sino también embeber imágenes, tablas, fragmentos estéticos diferentes, etc.\n\n\nFragmentos de código (chunk)\nEn estas secciones delimitadas se incluye el código que se ejecuta (y también puede ser mostrado) en el documento final. Estos chunk, como se denominan en inglés, pueden ser de diferentes lenguajes (en nuestro caso utilizaremos habitualmente el lenguaje R)."
  },
  {
    "objectID": "primero/clases/08-quarto.html#editor-visual-de-rstudio",
    "href": "primero/clases/08-quarto.html#editor-visual-de-rstudio",
    "title": "Documentos de Quarto",
    "section": "Editor visual de RStudio",
    "text": "Editor visual de RStudio\nEl editor visual proporciona una interfaz sencilla para la creación de documentos de Quarto. En el fondo, el texto de los documentos de Quarto (archivos .qmd) se escribe en lenguaje Markdown, un conjunto ligero de marcas para formatear archivos de texto sin formato. De hecho, Quarto utiliza Markdown de Pandoc (una versión ampliada de Markdown que Quarto entiende), incluidas tablas, citas, referencias cruzadas, notas al pie, listas de definiciones, atributos, HTML/TeX sin formato y más, así como compatibilidad con la ejecución de celdas de código y la visualización de su salida en línea. Si bien Markdown está diseñado para ser fácil de leer y escribir, requiere aprender una nueva sintaxis, por lo tanto conviene utilizar las herramientas del modo visual."
  },
  {
    "objectID": "primero/clases/08-quarto.html#edición-en-código-fuente",
    "href": "primero/clases/08-quarto.html#edición-en-código-fuente",
    "title": "Documentos de Quarto",
    "section": "Edición en código fuente",
    "text": "Edición en código fuente\nEl modo source (fuente) sirve para editar el documento en markdown puro con todas sus marcas sin la ayuda del modo visual. Para aquellos acostumbrados a sus sintaxis posibilita escribir directamente con la estructura adecuada y depurar sus errores.\nAhora bien, cuando trabajamos en el editor visual aunque nos muestre los elementos con el formato de salida, en realidad en el documento guarda su contenido en Markdown simple y se puede alternar entre los editores visuales y de source para ver y editar el contenido usando cualquiera de las herramientas."
  },
  {
    "objectID": "primero/clases/08-quarto.html#fragmentos-de-código",
    "href": "primero/clases/08-quarto.html#fragmentos-de-código",
    "title": "Documentos de Quarto",
    "section": "Fragmentos de código",
    "text": "Fragmentos de código\nPara ejecutar código dentro de un documento de Quarto, es necesario insertar un fragmento.\nLas tres formas de hacerlo son:\n\nUsar el atajo de teclado Ctrl + Alt + I.\nPulsar el icono del botón “Insert” en la barra de herramientas del editor.\nEscribir manualmente los delimitadores de fragmentos ```{r} y ```.\n\nEl código que se incluye tiene las misma características que el código de un script común de R. Lo que si hay que tener en cuenta es que la activación de paquetes y la lectura de archivos debe ser explícita dentro del documento, es decir aunque tengamos algún paquete activo en la sesión de trabajo o datos leídos en el entorno de trabajo, si estos no figuran dentro de algún fragmento del documento (por ejemplo, porque se ejecutaron en consola directamente) al momento de renderizar vamos a tener la devolución de un error.\n\nOpciones de fragmentos\nDentro de los fragmentos de código se puede declarar metadatos llamados opciones de ejecución.\nEl formato sintáctico en Quarto tiene la forma #| y suele encabezar el fragmento.\n\n```{r}\n#| echo: fenced\n\n1 + 1\n```\n\nEn el ejemplo anterior echo: fenced es una opción de ejecución que como metadato asociado al código provoca que en el documento renderizado dicho código se muestre junto al resultado incluída la opción de ejecución.\nEl motor Knitr incluído en RStudio es el que proporciona casi 60 opciones de ejecución que se pueden usar para personalizar los fragmentos de código.\nLa lista completa de códigos se puede ver en https://yihui.org/knitr/options.\nAlgunas de las opciones más importantes para controlar bloques son:\n\neval: false Evita que se evalúe el código (y, obviamente, si no se ejecuta el código, no se generarán resultados). Esto es útil para mostrar código de ejemplo o para deshabilitar un bloque grande de código sin comentar cada línea.\ninclude: false Ejecuta el código, pero no muestra el código ni los resultados en el documento final. Puede servir para tareas internas.\necho: false Evita que el código, pero no los resultados, aparezcan en el archivo final.\nmessage: false o warning: false Evita que aparezcan mensajes o advertencias en el archivo terminado.\nresults: hide Oculta la salida impresa; fig-show: hide Oculta los gráficos.\nerror: true Hace que la renderización continúe incluso si el código devuelve un error."
  },
  {
    "objectID": "primero/clases/08-quarto.html#formatos",
    "href": "primero/clases/08-quarto.html#formatos",
    "title": "Documentos de Quarto",
    "section": "Formatos",
    "text": "Formatos\nLos formatos de salida de Quarto son bien variados y todos se definen dentro del encabezado YAML del documento.\nDe forma predeterminada la salida es HTML y una cabecera básica sería:\n\n---\ntitle: \"Título del documento\"\nformat: html\n---\n\nEn esta misma cabecera se incluyen también las opciones de salida o renderizado, por ejemplo:\n\n---\ntitle: \"Título del documento\"\nformat: \n  html:\n    toc: true\n    toc_float: true\n---\n\nLa salida será un archivo html con tabla de contenidos (toc) flotante.\nOtros formatos posibles son:\n\nDocumentos\n\npdf crea un PDF con LaTeX (un sistema de diseño de documentos de código abierto)\ntypst crea un PDF con typst (un sistema de composición moderno y sencillo de documentos pdf)\ndocx construye documentos de Microsoft Word ( .docx).\nodt construye documentos OpenDocument Text ( .odt).\nrtf construye documentos con formato de texto enriquecido ( .rtf).\n\n\n\nPresentaciones\n\nrevealjs Presentación HTML con RevealJS\npptx Presentación de Powerpoint\nbeamer Presentación en PDF con LaTeX Beamer.\n\nExisten numerosas opciones relacionadas al tipo de salida propuesta que se pueden encontrar en cada apartado de la guía oficial de Quarto."
  },
  {
    "objectID": "primero/clases/08-quarto.html#tableros-dashboard-de-quarto",
    "href": "primero/clases/08-quarto.html#tableros-dashboard-de-quarto",
    "title": "Documentos de Quarto",
    "section": "Tableros (dashboard) de Quarto",
    "text": "Tableros (dashboard) de Quarto\nA partir de la versión 1.4, Quarto incorpora la creación de tableros (dashboard). Con una forma de producción sencilla que tiene varios elementos similares a los utilizados por el paquete flexdashboard de RMarkdown.\nLos tableros pueden ser estáticos o interactivos, se les puede incluir una gran variedad de componentes como dispositivos externos provenientes de htmlwidgets y sus diseños suelen ser flexibles y adaptativos (los componentes se redimensionan de forma inteligente para llenar el navegador y se adaptan para su visualización en dispositivos móviles)."
  },
  {
    "objectID": "primero/clases/08-quarto.html#cabecera-yaml-1",
    "href": "primero/clases/08-quarto.html#cabecera-yaml-1",
    "title": "Documentos de Quarto",
    "section": "Cabecera YAML",
    "text": "Cabecera YAML\nLa cabecera que define un tablero tiene el formato configurado en dashboard.\n---\nformat: dashboard\n---\nAlgunas opciones de ejecución YAML son similares a las conocidas para otros documentos: title, author, theme, toc, otras son particulares de este formato: orientation, scrolling, expandable, nav-buttons, etc.\nCuando el tablero tiene componentes de interactividad debemos indicar en la cabecera el motor Shiny que manejará el código, de la siguiente forma:\n---\nformat: dashboard\nserver: shiny\n---\n\n\n\n\n\n\nEn tableros con componentes interactivos htmlwidgets basados en JavaScript u Observable JS no hace falta incluir nada especial en la cabecera."
  },
  {
    "objectID": "primero/clases/08-quarto.html#componentes-de-un-tablero",
    "href": "primero/clases/08-quarto.html#componentes-de-un-tablero",
    "title": "Documentos de Quarto",
    "section": "Componentes de un tablero",
    "text": "Componentes de un tablero\nLos componentes básicos de un tablero son:\n\nBarra de navegación (páginas):\nSuele ser la barra superior horizontal donde incluimos el ícono, título y autor junto con enlaces a subpáginas (si se define más de una página).\nAquí un ejemplo de barra de navegación:\n\n\n\n\n\n\n\nBarras laterales, filas y columnas y conjuntos de pestañas:\nEn estas barras se ubican muchas veces las entradas (inputs) interactivas.\nAdemás se pueden agregar filas y columnas con encabezados markdown (atributos opcionales para controlar la altura, el ancho, etc.) y conjuntos de pestañas para dividir aún más el contenido.\n\n\n\n\n\n\n\nTarjetas (gráficos, tablas, cajas de valores, contenido):\nLas tarjetas (cards) son contenedores para resultados de celdas y texto markdown de formato libre. El contenido de las tarjetas normalmente se asigna a las celdas de su documento fuente.\nEn estas celdas se suele incluir valores, tablas, gráficos, elementos dinámicos o interactivos. Algunos formatos vienen previamente soportados como las cajas de valores (valuebox)"
  },
  {
    "objectID": "primero/clases/08-quarto.html#diseño",
    "href": "primero/clases/08-quarto.html#diseño",
    "title": "Documentos de Quarto",
    "section": "Diseño",
    "text": "Diseño\nA la combinación de barras y tarjetas con su ubicación y orientación la llamamos diseño del tablero.\nEl diseño va a estar dado por los distintos componentes que deseemos mostrar. Mientras las páginas se declaran con encabezados 1 (#) los bloques fila o columna se hacen con encabezados 2 (##), a los cuales se le puede agregar definición de ancho con width o alto con height.\nLas barras laterales se arman con encabezados 1 (#) con estilo .sidebar y las pestañas con encabezados 2 y estilo .tabset.\nAlgunos ejemplos:\nBarra lateral\n---\ntitle: \"Mi Tablero\"\nformat: dashboard\n---\n\n# Pagina 1\n\n## {.sidebar}\n\n```{r}\n\n```\n\n## Column\n\n```{r}\n\n```\n\n```{r}\n\n```\n\n\n\n\n\nFilas\n---\ntitle: \"Mi Tablero\"\nformat: dashboard\n---\n\n## Row {height=70%}\n\n```{r}\n```\n\n## Row {height=30%}\n\n```{r}\n```\n\n```{r}\n```\n\n\n\n\n\nColumnas\n---\ntitle: \"Mi Tablero\"\nformat: dashboard\n---\n\n## Column {width=60%}\n\n```{r}\n```\n\n## Column {width=40%}\n\n```{r}\n```\n\n```{r}\n```\n\n\n\n\n\nPestañas\n---\ntitle: \"Mi Tablero\"\nformat: dashboard\n---\n\n## Row\n\n```{r}\n```\n\n## Row {.tabset}\n\n```{r}\n#| title: Chart 2\n```\n\n```{r}\n#| title: Chart 3\n```"
  },
  {
    "objectID": "primero/clases/08-quarto.html#tarjetas",
    "href": "primero/clases/08-quarto.html#tarjetas",
    "title": "Documentos de Quarto",
    "section": "Tarjetas",
    "text": "Tarjetas\nLas tarjetas son la unidad fundamental de visualización dentro de los tableros.\nPueden encerrar tanto texto markdown como código que produzca alguna salida tipo valor, tabla o gráfico.\n::: {.card}\n\nAquí va el contenido de la tarjeta. Puede ser un markdown directo o la salida de código.\n\n```{r}\n\n```\n\n:::\nLas cajas de valor son tarjetas especiales que se declaran con el estilo reservado .valuebox.\n\n::: {.valuebox}\nFecha actual\n\n2024-09-20\n:::\nTambién se pueden declarar con metadatos dentro del bloque de código:\n#| content: valuebox\n#| title: \"Caja de valor\"\nn &lt;- mtcars |&gt; \n  tibble::as_tibble() |&gt; \n  dplyr::count() |&gt; \n  dplyr::pull(n)\n\nlist(\n  icon = \"trash\",\n  color = \"red\",\n  value = n\n)\n\n\n\n\n\n\nAquí se incluyen también dispositivos con cierta interactividad directa como son los htmlwidgets o si se conoce el lenguaje, código de Observable JS.\nLa galería de widgets disponibles en la actualidad cuenta con 132 dispositivos que se puede ver en https://gallery.htmlwidgets.org/"
  },
  {
    "objectID": "primero/clases/08-quarto.html#interactividad",
    "href": "primero/clases/08-quarto.html#interactividad",
    "title": "Documentos de Quarto",
    "section": "Interactividad",
    "text": "Interactividad\nLos documentos que tienen elementos interactivos de R utilizan Shiny como servidor. Shiny es una librería para producir aplicaciones interactivas bajo R y recientemente en python.\nAnteriormente vimos que la cabecera YAML tiene que tener la opción server: shiny para que este se encuentre activo y pueda utilizarse dentro del tablero.\nLa estructura de Shiny necesita de dos componentes:\n\nla interfaz de usuario (ui)\nel servidor Shiny\n\nEl funcionamiento interno es tipo cliente/servidor, donde en la interfaz de usuario se ubican los inputs con los que el usuario se vincula y del lado del servidor se responde a los cambios de esas entradas.\nGeneralmente los inputs van dentro de la barra lateral y el server se declara como contexto en los fragmentos de código. Por ejemplo:\n\n## {.sidebar}\n\n```{r}\nselectInput(\n    \"variableChoice\",\n    \"Seleccione una variable:\",\n    choices = names(mtcars)\n  )\n```\n\n## Row\n\n```{r}\n#| context: server\n\noutput$variablePlot &lt;- renderPlot({\n  yVar &lt;- mtcars[[input$variableChoice]]\n  plot(mtcars$index, yVar)\n})\n```\n\nEste código tiene un input de selección en la barra lateral, donde el usuario puede seleccionar una variable del dataset mtcars, y un fragmento de contexto servidor donde renderiza un gráfico de dispersión en base a la variable elegida (input$variableChoice)."
  },
  {
    "objectID": "primero/clases/08-quarto.html#inputs",
    "href": "primero/clases/08-quarto.html#inputs",
    "title": "Documentos de Quarto",
    "section": "Inputs",
    "text": "Inputs\nLas entradas de Shiny son funciones que sirven para crear elementos de interfaz de usuario que solicitan al usuario valores de entrada o interacción.\nAlgunos de sus inputs básicos son:\n\n\n\n\n\nBotones, casillas de verificación (sola o múltiples), ingreso de fechas, números y texto, rangos, cajas de selección, barras de desplazamiento, etc son algunos de los muchos dispositivos que vienen ya preparados.\nLa referencia a esas funciones las podrán encontrar en https://shiny.posit.co/r/reference/shiny/latest/."
  },
  {
    "objectID": "primero/clases/08-quarto.html#temas",
    "href": "primero/clases/08-quarto.html#temas",
    "title": "Documentos de Quarto",
    "section": "Temas",
    "text": "Temas\nDe la misma forma que en los productos Quarto anteriores se pueden definir temas estéticos preconfigurados o personalizar uno propio, mediante la declaración en la cabecera YAML de theme:.\nEntre los predeterminados, encontramos 25 posibles (Bootswatch project): lumen, materia, minty, slate son alguno de ellos.\nPara personalizar un tema se procede a utilizar archivos css o scss (Sass). Bootstrap define más de 1400 variables Sass que controlan fuentes, colores, relleno, bordes y mucho más. Se pueden ver todas las variables aquí:\nhttps://github.com/twbs/bootstrap/blob/main/scss/_variables.scss\nPara personalizar un tema Bootstrap existente con un conjunto propio de variables o reglas, solo definimos el tema base y luego los archivos de tema personalizados:\n\ntheme:\n  - cosmo\n  - custom.scss\n\nEl archivo de personalización Sass custom.scss podría ser:\n/*-- scss:defaults --*/\n$h2-font-size:          1.6rem !default;\n\n\n/*-- scss:rules --*/\nh1, h2, h3, h4, h5, h6 {\n  text-shadow: -1px -1px 0 rgba(0, 0, 0, .3);\n}\nDonde en la sección indicada por /*-- scss:defaults --*/ pertenece a las variables ($h2-font-size: tamaño de fuente en encabezado 2) y la sección de reglas (donde van las reglas CSS normales) está indicada por el /*-- scss:rules --*/ (text-shadow: -1px -1px 0 rgba(0, 0, 0, .3); sombreado en encabezados desde 1 al 6).\nNaturalmente, también se puede crear un tema totalmente personalizado y proporcionar solo eso (en este caso, se hereda el tema Bootstrap predeterminado):\n\ntheme: custom.scss\nLas variables Sass más comunes estan publicadas en: https://quarto.org/docs/dashboards/theming.html#sass-variables\nMas información sobre temas HTML en https://quarto.org/docs/output-formats/html-themes-more.html"
  },
  {
    "objectID": "primero/clases/08-quarto.html#publicación",
    "href": "primero/clases/08-quarto.html#publicación",
    "title": "Documentos de Quarto",
    "section": "Publicación",
    "text": "Publicación\nLos tableros suelen ser simplemente páginas HTML estáticas, por lo que se pueden implementar en cualquier servidor web.\nEstos tableros, a su vez si se combinan con una lectura periódica de la fuente de datos pueden mostrar actualizaciones según vayan variando esos datos. A esto se le llama tablero programado (por ejemplo, a través de una tarea cron).\nTambién se pueden parametrizar, a traves de parameters en la cabecera YAML o bien pasar a ser tableros completamente interactivos con Shiny, donde se requiere un servidor especial para su implementación.\nRStudio trae incorporado en su IDE accesos directos de publicación a Posit Connect Cloud mediante el botón , dado que pertenece a la misma empresa Posit. Sus servicios son los que mejor se adaptan a los requerimientos de usuarios que producen estos documentos pero con planes comerciales.\nOtras opciones de sitios que publican tableros estáticos gratuitamente son:\n\nQuarto Pub\n\nEs un servicio gratuito de publicación de contenido hecho en Quarto. Además de tableros se puede alojar blogs, sitios web, libros, presentaciones y otros documentos.\nEstas publicaciones serán siempre visibles por cualquier usuario de Internet, no pueden tener más de 100 Mb y poseen un ancho de banda de navegación de 10 Gb por mes.\nSe puede publicar mediante el comando quarto publish en la Terminal. Deberá tener una cuenta a su nombre que podrá obtener en https://www.quarto.pub. La dirección creada agrega como dominio quarto.pub a su nombre de usuario y luego la dirección al sitio creado (puede tener varios). La administración se realiza desde el propio sitio web.\nMás información en https://quarto.org/docs/publishing/quarto-pub.html\n\nConfluence\n\nAtlassian Confluence es una plataforma de publicación que soporta la colaboración en equipo.\nQuarto proporciona la cpacidad de publicar documentos individuales, así como proyectos compuestos por múltiples documentos en Confluence Spaces.\nConfluence cuenta con una variedad de opciones de alojamiento que incluyen planes de suscripción gratuitos y pagos.\nSe puede publicar mediante el comando quarto publish confluence en la Terminal de RStudio, siempre y cuando contemos con una cuenta configurada.\nPara más información ver en https://quarto.org/docs/publishing/confluence.html\n\nGitHub Pages\n\nEs un servicio de alojamiento de sitios web que le permite publicar contenido basado en código fuente administrado dentro de un repositorio de GitHub.\nLos repositorios GitHub se alojan en una plataforma online de desarrollo de software basada en la nube que permite a los desarrolladores almacenar, compartir y trabajar juntos en proyectos de código abierto. GitHub utiliza un sistema de control de versiones llamado Git para alojar los proyectos y llevar un registro de los cambios. Esto permite colaborar y realizar cambios en los proyectos compartidos, al tiempo que mantienen un seguimiento detallado del progreso.\nTambién se puede publicar mediante el comando quarto publish gh-pages en la Terminal de RStudio, mientras exista la cuenta y repositorio del proyecto y esté habilitada la opción de GitHub Pages.\nPara más información leer https://quarto.org/docs/publishing/github-pages.html\nEn el caso de tableros interactivos, que necesiten de un servidor Shiny, se puede usar versiones en la nube tipo:\n\nshinyapps.io\n\nShiny Apps de Posit es un sitio de alojamiento con recursos de servidor para aplicaciones interactivas Shiny.\nEl plan gratuito consta de un máximo de 5 aplicaciones subidas y 25 horas activas (uso de la aplicación). Luego posee planes comerciales con mayores recursos.\nLa publicación viene integrada con RStudio y utiliza el paquete rsconnect para realizar las tareas necesarias.\n\nHugging Face\n\nHugging Face es una plataforma open source de ciencia de datos y machine learning que proporciona herramientas para construir, entrenar y desplegar soluciones de aprendizaje automático. Como repositorio es similar a GitHub y tiene un servicio de Spaces donde se pueden publicar aplicaciones Shiny mediante tecnología Docker.\nO instalación de servidores locales como Shiny Server (open-source), que seguramente necesitará de personal formado como Administrador de TI y disponer de un servidor linux con conexión simétrica a Internet y firewall, entre otros recursos."
  },
  {
    "objectID": "primero/recursos/01-hojaEstilo.html",
    "href": "primero/recursos/01-hojaEstilo.html",
    "title": "Lectura de un archivo de datos de texto plano",
    "section": "",
    "text": "R es bastante indulgente con la forma en que escribimos código (a diferencia de otros lenguajes como Python, donde contar mal los espacios puede arruinar el trabajo).\nTodas estas cosas harán exactamente lo mismo:\n\nmpg |&gt; \n  filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; \n  filter(cty &gt; 10, \n         class == \"compact\")\n\nmpg |&gt; filter(cty&gt;10, class==\"compact\")\n\nfilter(mpg,cty&gt;10,class==\"compact\")\n\nmpg |&gt; \nfilter(cty &gt; 10, \n                        class == \"compact\")\n\nfilter ( mpg,cty&gt;10,     class==\"compact\" )\n\nPero es evidente que sólo algunas de esas porciones de código (las primeras tres) son más fáciles de leer.\nPara ayudar a mejorar la legibilidad y facilitar el compartir código con otros, existe una guía de estilo no oficial para escribir código R. Es bastante breve y tiene muchos ejemplos de buenas y malas formas de escribir código (nombrar variables, manejar líneas largas, usar niveles de sangría adecuados, etc.).\nSu enlace es https://style.tidyverse.org/\nRStudio tiene una forma integrada de reidentar el código. Si seleccionamos la porción que deseamos y presionamos el atajo de teclado Ctrl + i (en Windows) R reformateará el código por nosotros. No siempre es perfecto, pero es realmente útil para lograr la sangría correcta sin tener que presionar manualmente espacio muchas veces."
  },
  {
    "objectID": "primero/recursos/01-hojaEstilo.html#convenciones-de-estilo-r",
    "href": "primero/recursos/01-hojaEstilo.html#convenciones-de-estilo-r",
    "title": "Lectura de un archivo de datos de texto plano",
    "section": "",
    "text": "R es bastante indulgente con la forma en que escribimos código (a diferencia de otros lenguajes como Python, donde contar mal los espacios puede arruinar el trabajo).\nTodas estas cosas harán exactamente lo mismo:\n\nmpg |&gt; \n  filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; filter(cty &gt; 10, class == \"compact\")\n\nmpg |&gt; \n  filter(cty &gt; 10, \n         class == \"compact\")\n\nmpg |&gt; filter(cty&gt;10, class==\"compact\")\n\nfilter(mpg,cty&gt;10,class==\"compact\")\n\nmpg |&gt; \nfilter(cty &gt; 10, \n                        class == \"compact\")\n\nfilter ( mpg,cty&gt;10,     class==\"compact\" )\n\nPero es evidente que sólo algunas de esas porciones de código (las primeras tres) son más fáciles de leer.\nPara ayudar a mejorar la legibilidad y facilitar el compartir código con otros, existe una guía de estilo no oficial para escribir código R. Es bastante breve y tiene muchos ejemplos de buenas y malas formas de escribir código (nombrar variables, manejar líneas largas, usar niveles de sangría adecuados, etc.).\nSu enlace es https://style.tidyverse.org/\nRStudio tiene una forma integrada de reidentar el código. Si seleccionamos la porción que deseamos y presionamos el atajo de teclado Ctrl + i (en Windows) R reformateará el código por nosotros. No siempre es perfecto, pero es realmente útil para lograr la sangría correcta sin tener que presionar manualmente espacio muchas veces."
  },
  {
    "objectID": "primero/recursos/01-hojaEstilo.html#elementos-importantes",
    "href": "primero/recursos/01-hojaEstilo.html#elementos-importantes",
    "title": "Lectura de un archivo de datos de texto plano",
    "section": "Elementos importantes",
    "text": "Elementos importantes\nNota: Aunque preferimos que se cumplan las recomendaciones, nunca vamos a calificar estos detalles. Si en algun TP se envía algo como filter(mpg,cty&gt;10,class==“compact”), seguramente podríamos recomendar agregar espacios, pero no va a afectar la corrección del trabajo.\n\nEspaciado\nColoque espacios después de las comas\n\n# Bien\nfilter(mpg, cty &gt; 10)\n\n# Mal\nfilter(mpg , cty &gt; 10)\nfilter(mpg ,cty &gt; 10)\nfilter(mpg,cty &gt; 10)\n\nColoque espacios alrededor de operadores como +, -, &gt;, =, etc.:\n\n# Bien\nfilter(mpg, cty &gt; 10)\n\n# Mal\nfilter(mpg, cty&gt;10)\nfilter(mpg, cty&gt; 10)\nfilter(mpg, cty &gt;10)\n\nNo coloque espacios alrededor de paréntesis que sean parte de funciones:\n\n# Bien\nfilter(mpg, cty &gt; 10)\n\n# Mal\nfilter (mpg, cty &gt; 10)\nfilter ( mpg, cty &gt; 10)\nfilter( mpg, cty &gt; 10 )\n\n\n\nLíneas largas\nEn general, es una buena práctica no tener líneas de código muy largas. Una buena sugerencia es mantener las líneas con un máximo de 80 caracteres. En lugar de contar caracteres a mano, en RStudio vaya a Tools &gt; Global Options &gt; Code &gt; Display y seleccione la casilla Show margin. Ahora deberías ver una línea muy delgada que indica 80 caracteres.\nConviene agregar saltos de línea dentro de líneas de código más largas. Los saltos de línea deben ir después de las comas y cosas como los argumentos de la función deben alinearse dentro de la función:\n\n# Bien\nfilter(mpg, cty &gt; 10, class == \"compact\")\n\n# Bien\nfilter(mpg, cty &gt; 10, \n       class == \"compact\")\n\n# Bien\nfilter(mpg,\n       cty &gt; 10,\n       class == \"compact\")\n\n# Mal\nfilter(mpg, cty &gt; 10, class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \"suv\", \"2seater\", \"minivan\"))\n\n# Bien\nfilter(mpg, \n       cty &gt; 10, \n       class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \n                    \"suv\", \"2seater\", \"minivan\"))\n\n\n\nTuberías (%&gt;% o |&gt;) y capas en ggplot2 (+)\nColoque cada capa de un gráfico ggplot en líneas separadas, con el + al final de la línea y debajo sangría de dos espacios:\n\n# Bien\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() +\n  geom_smooth() +\n  theme_bw()\n\n# Mal\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() + geom_smooth() +\n  theme_bw()\n\n# Muy mal\nggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw()\n\n# Tan mal y no funciona\nggplot(mpg, aes(x = cty, y = hwy, color = class))\n  + geom_point()\n  + geom_smooth() \n  + theme_bw()\n\nColoque cada paso de una tubería en líneas separadas, con el %&gt;% o |&gt; al final de la línea y debajo una sangría de dos espacios:\n\n# Bien\nmpg |&gt; \n  filter(cty &gt; 10) |&gt; \n  group_by(class) |&gt; \n  summarize(avg_hwy = mean(hwy))\n\n# Mal\nmpg |&gt; filter(cty &gt; 10) |&gt; group_by(class) |&gt; \n  summarize(avg_hwy = mean(hwy))\n\n# Muy mal\nmpg |&gt; filter(cty &gt; 10) |&gt; group_by(class) |&gt; summarize(avg_hwy = mean(hwy))\n\n# Tan mal que no funciona\nmpg |&gt; \n  filter(cty &gt; 10)\n  |&gt; group_by(class)\n  |&gt; summarize(avg_hwy = mean(hwy))\n\n\n\nComentarios\nLos comentarios deben comenzar con un símbolo de comentario y un solo espacio: #\n\n# Bien\n\n#Mal\n\n    #Mal\n\nSi el comentario es muy corto (y no provoca que se supere los 80 caracteres en la línea), se puede incluir en la misma línea del código, separado por al menos dos espacios (funciona con un espacio, pero usando un par puede mejorar la legibilidad):\n\nmpg %&gt;% \n  filter(cty &gt; 10) %&gt;%  # filtro filas donde cty es 10 o más\n  group_by(class) %&gt;%  # estratifica por class\n  summarize(avg_hwy = mean(hwy))  # resume la media de hwy por cada grupo\n\nSe puede agregar espacios adicionales para alinear los comentarios en línea, si lo deseamos:\n\nmpg %&gt;% \n  filter(cty &gt; 10) %&gt;%            # filtro filas donde cty es 10 o más\n  group_by(class) %&gt;%             # estratifica por class\n  summarize(avg_hwy = mean(hwy))  # resume la media de hwy por cada grupo\n\nSi el comentario es muy largo, podemos dividirlo en varias líneas. RStudio tiene una herramienta en Code &gt; Reflow Comment que lo automatiza."
  }
]