[
  {
    "objectID": "primero/recursos/02-lectura.html",
    "href": "primero/recursos/02-lectura.html",
    "title": "Lectura de un archivo de datos de texto plano",
    "section": "",
    "text": "Anteriormente dijimos que para leer o importar datos de un archivo de datos con texto plano separado por comas vamos a utilizar alguna de las funciones del paquete readr del tidyverse.\nPero para saber cual es la función adecuada y para adaptar sus argumentos correctamente vamos a necesitar conocer la configuración del archivo de datos.\nEn este paso a paso, mostraremos las etapas a ejecutar ante una situación de lectura.\nEn primer lugar, es deseable que conozcamos previamente los archivos con los cuales trabajamos, o bien si son archivos de datos que se reciben de alguna fuente externa vengan acompañados de un diccionario de datos con especificaciones técnicas del propio archivo como de sus variables.\nUn ejemplo de esto es el detalle técnico de la tabla de datos que figura en el documento usuario de la Encuesta Nacional de Factores de Riesgo que vemos debajo:\n\n\n\n\n\n\n\n\n\nEsta información nos dice que el archivo es de texto plano, utiliza como delimitador de columna a la barra vertical, que la primera línea lleva los nombres de las variables y que la codificación (encoding) de los caracteres tiene el estándar UTF-8.\nEn función de estos datos podríamos componer nuestra lectura de la siguiente forma:\n\nenfr &lt;- read_delim(file = \"ENFR2013_base_usuario.txt\", \n                   delim = \"|\", \n                   locale = locale(encoding = \"UTF-8\"))\n\nAunque es el estándar predeterminado, completamos el argumento del encoding a propósito para mostrar como se vincula cada parte de la función con la información del archivo de datos.\nSi no llegasemos a disponer de esta información es muy posible que debamos investigar el archivo que deseamos importar para saber sus características.\nEn este documento utilizaremos el archivo def2022.csv con las defunciones del año 2022 producido por la DEIS."
  },
  {
    "objectID": "primero/recursos/02-lectura.html#introducción",
    "href": "primero/recursos/02-lectura.html#introducción",
    "title": "Lectura de un archivo de datos de texto plano",
    "section": "",
    "text": "Anteriormente dijimos que para leer o importar datos de un archivo de datos con texto plano separado por comas vamos a utilizar alguna de las funciones del paquete readr del tidyverse.\nPero para saber cual es la función adecuada y para adaptar sus argumentos correctamente vamos a necesitar conocer la configuración del archivo de datos.\nEn este paso a paso, mostraremos las etapas a ejecutar ante una situación de lectura.\nEn primer lugar, es deseable que conozcamos previamente los archivos con los cuales trabajamos, o bien si son archivos de datos que se reciben de alguna fuente externa vengan acompañados de un diccionario de datos con especificaciones técnicas del propio archivo como de sus variables.\nUn ejemplo de esto es el detalle técnico de la tabla de datos que figura en el documento usuario de la Encuesta Nacional de Factores de Riesgo que vemos debajo:\n\n\n\n\n\n\n\n\n\nEsta información nos dice que el archivo es de texto plano, utiliza como delimitador de columna a la barra vertical, que la primera línea lleva los nombres de las variables y que la codificación (encoding) de los caracteres tiene el estándar UTF-8.\nEn función de estos datos podríamos componer nuestra lectura de la siguiente forma:\n\nenfr &lt;- read_delim(file = \"ENFR2013_base_usuario.txt\", \n                   delim = \"|\", \n                   locale = locale(encoding = \"UTF-8\"))\n\nAunque es el estándar predeterminado, completamos el argumento del encoding a propósito para mostrar como se vincula cada parte de la función con la información del archivo de datos.\nSi no llegasemos a disponer de esta información es muy posible que debamos investigar el archivo que deseamos importar para saber sus características.\nEn este documento utilizaremos el archivo def2022.csv con las defunciones del año 2022 producido por la DEIS."
  },
  {
    "objectID": "primero/recursos/02-lectura.html#separador-o-delimitador-de-columnas",
    "href": "primero/recursos/02-lectura.html#separador-o-delimitador-de-columnas",
    "title": "Lectura de un archivo de datos de texto plano",
    "section": "Separador o delimitador de columnas",
    "text": "Separador o delimitador de columnas\nLa primera cosa que podemos hacer con un archivo de texto plano es abrirlo con un software tipo block de notas o con el mismo RStudio para saber cual es el caracter que utiliza como separador de columnas.\nCuando el archivo tiene extensión csv generalmente el separador puede ser coma o punto y coma. Pero recién vimos que la extensión puede ser txt y el separador, alguno de los caracteres habituales (espacio, tabulación, etc).\nDesde RStudio, cuando se pulsa el botón izquierdo del mouse sobre el archivo de datos que aparece en el panel Files, se abre una ventana emergente que nos ofrece la posibilidad de visualizarlo en el editor (“View File”). Si el archivo es muy pesado (mayor a 5 Mb) RStudio nos avisará que no lo puede hacer porque excede su capacidad, entonces deberemos hacerlo desde un programa similar al Block de Notas de Windows que trabaja con texto plano.\nVeríamos algo así:\n\n\n\n\n\n\n\n\n\nPodemos identificar claramente que el caracter que se repite como delimitador es la coma (,). Si hubiese datos numéricos con decimales, también es importante identificar cual es el separador de decimales (en los casos de delimitadores de columna con coma se utiliza el punto para los decimales).\nTambién se puede advertir que la primera línea corresponde a los nombres de las columnas (variables) de nuestra tabla de datos.\nCon esta información seleccionaremos como función de lectura a read_csv() que tiene estos valores de separadores como predeterminados."
  },
  {
    "objectID": "primero/recursos/02-lectura.html#encoding",
    "href": "primero/recursos/02-lectura.html#encoding",
    "title": "Lectura de un archivo de datos de texto plano",
    "section": "Encoding",
    "text": "Encoding\nPara conocer cual es la codificación del archivo podemos usar una función del paquete readr, llamada guess_encoding().\n\nlibrary(tidyverse)\n\nguess_encoding(\"datos/def2022.csv\")\n\n# A tibble: 1 × 2\n  encoding   confidence\n  &lt;chr&gt;           &lt;dbl&gt;\n1 ISO-8859-1       0.52\n\n\nEl resultado nos informa del estándar ISO-8859-1 con una confianza del 52 %. Existen muchos estandares como posibilidad en el mundo informático, aunque el predeterminado de RStudio es el UTF-8.\nA partir de tener esta información podemos configurar el argumento necesario para hacer una lectura correcta de los caracteres especiales que puede tener el archivo.\n\ndef2022 &lt;- read_csv(\"datos/def2022.csv\", \n                 locale = locale(encoding = \"ISO-8859-1\"))\n\nRows: 397115 Columns: 28\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): JURI, MEDSUS, CODMUER, FECDEF, FECNAC, DEPOC, PROVOC, DEPRES, PROV...\ndbl  (8): ANO, ATENMED, EDAD, UNIEDAD, SEXO, OCLOC, PAISRES, ASOCIAD\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLa ejecución de la función nos confirma que se realizó usando:\n\nla coma como delimitador.\nque se importaron 397115 filas y 28 columnas.\ndetectó 20 variables de tipo character y 8 numéricas (double)\n\nVeamos 10 observaciones para verificar la lectura:\n\n\n# A tibble: 10 × 28\n   JURI    ANO ATENMED MEDSUS CODMUER FECDEF    FECNAC  EDAD UNIEDAD  SEXO OCLOC\n   &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 02     2022       1 1      J189    04/01/20… 03/05…    83       1     2     1\n 2 02     2022       1 1      I509    01/11/20… 02/05…    68       1     1     1\n 3 02     2022       1 1      G409    12/06/20… 22/09…     1       1     2     2\n 4 02     2022       1 2      J129    22/12/20… 31/10…    90       1     2     2\n 5 02     2022       1 1      K746    28/09/20… 26/02…    65       1     1     2\n 6 02     2022       1 1      C700    12/06/20… 25/02…    48       1     2     2\n 7 02     2022       1 2      I470    27/03/20… 09/09…    89       1     1     2\n 8 02     2022       1 2      F03X    05/02/20… 14/09…    97       1     2     2\n 9 02     2022       1 2      I470    30/01/20… 08/07…    71       1     2     1\n10 02     2022       1 1      J189    28/09/20… 21/09…    91       1     1     2\n# ℹ 17 more variables: DEPOC &lt;chr&gt;, PROVOC &lt;chr&gt;, DEPRES &lt;chr&gt;, PROVRES &lt;chr&gt;,\n#   PAISRES &lt;dbl&gt;, ASOCIAD &lt;dbl&gt;, FINSTRUC &lt;chr&gt;, FSITLABOR &lt;chr&gt;,\n#   MINSTRUC &lt;chr&gt;, MEDAD &lt;chr&gt;, MSITCONY &lt;chr&gt;, PINSTRUC &lt;chr&gt;,\n#   SITLABOR &lt;chr&gt;, PESONAC &lt;chr&gt;, PESOMOR &lt;chr&gt;, TIEMGEST &lt;chr&gt;,\n#   GRUPEDAD &lt;chr&gt;\n\n\nHacer coincidir el encoding del archivo con el definido en la lectura hace que los caracteres se importen adecuadamente y no tengamos inconvenientes con caracteres especiales como vocales acentuadas, eñes u otras situaciones."
  },
  {
    "objectID": "primero/clases/04-tipos.html#exploración-de-datos",
    "href": "primero/clases/04-tipos.html#exploración-de-datos",
    "title": "Gestión de tipos de datos",
    "section": "Exploración de datos",
    "text": "Exploración de datos\nEl primer paso en la exploración de un conjunto de datos es conocer su estructura y tamaño.\nEl tamaño está definido por la cantidad de observaciones (filas) y la cantidad de variables (columnas).\nLlamamos estructura a la forma en se organizan sus variables, sus tipos de datos y sus categorías/valores.\nVamos a utilizar un dataframe de ejemplo con variedad en sus tipos de datos. Para ver su estructura en R base tenemos la función str()\n\nstr(datos)\n\n'data.frame':   74 obs. of  7 variables:\n $ id     : int  1 2 3 4 5 6 7 8 9 10 ...\n $ sexo   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ edad   : num  76 68 50 49 51 68 70 64 60 57 ...\n $ peso   : num  71 71 79 71 87 75 80 83 69 73 ...\n $ talla  : num  167 164 164 164 168 ...\n $ trabaja: logi  FALSE FALSE FALSE TRUE TRUE FALSE ...\n $ fecha  : Date, format: \"2020-10-20\" \"2020-10-20\" ...\n\n\nNos informa que la tabla tiene 74 observaciones y 7 variables con su tipo de dato al lado.\nEn R base los tipos de datos son:\n\nint (integer): números enteros\nnum (numeric): números reales\nchr (character): caracteres (texto)\nlogi (logical): valores lógicos\nDate: fechas\nfct (factor): factores\n\nEn tidyverse, la función que reemplaza a str() es glimpse():\n\nglimpse(datos)\n\nRows: 74\nColumns: 7\n$ id      &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…\n$ sexo    &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", NA, \"F\", \"F\", \"M\", \"F\"…\n$ edad    &lt;dbl&gt; 76, 68, 50, 49, 51, 68, 70, 64, 60, 57, 83, 76, 27, 34, 17, 45…\n$ peso    &lt;dbl&gt; 71.0, 71.0, 79.0, 71.0, 87.0, 75.0, 80.0, 83.0, 69.0, 73.0, 60…\n$ talla   &lt;dbl&gt; 167.0, 164.0, 164.0, 164.0, 167.5, 170.0, 166.0, 160.0, 160.0,…\n$ trabaja &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, NA, TRUE, TRUE, TRUE, …\n$ fecha   &lt;date&gt; 2020-10-20, 2020-10-20, 2020-10-20, 2020-11-05, 2020-11-05, 2…\n\n\nParece idéntica pero tiene una ventaja cuando la tabla de datos tiene muchas variables. La lista de respuesta de str() se trunca y no nos deja visualizar la totalidad de columnas, cosa que si hace glimpse().\nPor otra parte vamos a encontrar distintas definiciones para los tipos de datos, del modo tidyverse:\n\nnum para a ser dbl (double): números reales\nlogi para a ser lgl (logical): valores lógicos\n\nY se incluyen un tipo nuevo:\n\ndttm (date-time): fechas y horas\n\nEsta exploración inicial de la estructura generalmente viene acompañada por el “diccionario de datos” (codebook) asociado a la tabla de datos, ya sea que esta tabla provenga de un proyecto de investigación propio (fuente primaria), producto de una fuente secundaria o de un sistema de vigilancia epidemiológica."
  },
  {
    "objectID": "primero/clases/04-tipos.html#comprobación-y-coerción-de-tipos-de-datos",
    "href": "primero/clases/04-tipos.html#comprobación-y-coerción-de-tipos-de-datos",
    "title": "Gestión de tipos de datos",
    "section": "Comprobación y coerción de tipos de datos",
    "text": "Comprobación y coerción de tipos de datos\nLa mayoría de las funciones producen un error cuando el tipo de datos que esperan no coincide con los que pasamos como argumentos. En esta situación seguiremos el siguiente camino:\n\nComprobar el tipo de datos utilizando las funciones is.*(), que nos responden con un valor lógico (TRUE si el tipo de dato coincide y FALSE si no lo hace). Si el tipo de dato coincide con el formato esperado por el argumento de la función, entonces podemos aplicarla, de lo contrario necesitaremos continuar:\nForzar el tipo de datos deseado coercionando con funciones de la familia as.*(), que fuerzan el tipo de datos, siempre y cuando esto devuelva valores correctos. Por ejemplo, no podremos obtener valores correctos si intento coercionar caracteres a tipos numéricos.\n\n\n# Ejmeplo coercionando la variable sexo de caracter a factor\n\nas.factor(datos$sexo) # llamamos a la variable con el formato &lt;dataframe&gt;$&lt;variable&gt;\n\n [1] M    M    M    M    M    M    M    M    &lt;NA&gt; F    F    M    F    F    F   \n[16] F    F    M    M    M    M    M    M    F    M    F    &lt;NA&gt; M    F    M   \n[31] F    F    M    F    F    F    M    M    M    M    M    F    M    F    M   \n[46] M    F    M    F    &lt;NA&gt; M    M    M    F    M    M    M    M    M    F   \n[61] F    M    F    F    M    M    F    F    F    M    M    M    M    M   \nLevels: F M\n\n# detecta que hay dos niveles o categorías posibles (F y M) \n\nis.factor(as.factor(datos$sexo))\n\n[1] TRUE\n\n# nos confirma que los datos se coercionaron a factor\n\n\nTransformar el tipo de dato a partir de aplicar funciones específicas incluidas en paquetes que gestionan datos especiales, como por ejemplo las fechas (el paquete lubridate del tidyverse, que conoceremos más adelante, se ocupa de esto)\n\nA continuación se muestra una lista con los tipos más importantes que se pueden comprobar o forzar a partir de funciones de R base:\n\n\n\nTipo\nComprobación\nCoerción\n\n\n\n\ncharacter\nis.character()\nas.character()\n\n\nnumeric\nis.numeric()\nas.numeric()\n\n\ninteger\nis.integer()\nas.integer()\n\n\ndouble\nis.double()\nas.double()\n\n\nfactor\nis.factor()\nas.factor()\n\n\nlogical\nis.logical()\nas.logical()\n\n\nNA\nis.na()\nas.na()"
  },
  {
    "objectID": "primero/clases/04-tipos.html#variables-de-tiempo",
    "href": "primero/clases/04-tipos.html#variables-de-tiempo",
    "title": "Gestión de tipos de datos",
    "section": "Variables de tiempo",
    "text": "Variables de tiempo\n\n\n\n\nArtwork por @allison_horst\n\n\n\nLos eventos epidemiológicos se presentan en algun momento del tiempo, por lo que las variables de tiempo son habituales componentes de las bases de datos con las que trabaja un epidemiólogo. Estas variables pueden presentarse en distintas unidades de medida, tales como horas, días, años, decadas, etc.\nA veces trabajar con datos tipo fecha y hora puede ser frustrante.Las fechas vienen en muchos formatos diferentes, que hace que reconocerlos y analizarlos sea un desafío.\nPrimero necesitamos que los datos sean reconocidos como formato fecha (Date) y luego debemos lidiar con operaciones específicas como extraer componentes de los horarios, como años, meses o segundos, o cambiar zonas horarias o hacer cálculos entres fechas.\nPara simplificar esta tarea tidyverse trae el paquete lubridate que proporciona herramientas para manipular variables fecha-hora.\nEspecíficamente, lubridate ayuda a los usuarios a:\n\nIdentificar y analizar los datos de fecha y hora.\nExtrer y modificar componentes de una fecha y hora, como años, meses, días, horas, minutos y segundos.\nRealizar cálculos precisos con fecha y hora.\nManejar zonas horarias y horario de verano.\n\nlubridate se instala y activa con tidyverse:\n\nLectura de fechas\nPodemos leer fechas en R usando la serie de funciones ymd() proporcionada por este paquete. Estas funciones analizan el contenido de cadenas de caracteres y las transforman a fechas.\nLas letras y, m y d corresponden al año, mes y día de una fecha. Para leer una fecha, seleccionamos el nombre de la función que coincide con el orden de los elementos contenidos en el objeto original. Por ejemplo, en la siguiente fecha el elemento mes viene primero, seguido por el día y luego el año, al estilo estadounidense. Entonces usaríamos la función mdy():\n\nmdy(\"01-24-2024\")\n\n[1] \"2024-01-24\"\n\n\nEl formato de salida siempre año-mes-día, es decir se organiza del elemento más grande que anida a los otros.\nSi en cambio tuviese la forma en que usamos las fechas nosotros, usaríamos dmy().\n\ndmy(\"24-01-2024\")\n\n[1] \"2024-01-24\"\n\n\nComo se observa el formato de los caracteres de entrada pueden utilizar distintos separadores, como guión medio (-), punto (.), barra inclinada (/), guión bajo (_) o incluso espacios.\nLa clase de los objetos convertidos es Date.\n\nx &lt;- dmy(\"24/01/2024\")\n\nclass(x)\n\n[1] \"Date\"\n\n\n\n\n\nOrden de los elementos\nFunción\n\n\n\n\naño, mes y día\nymd()\n\n\naño, día y mes\nydm()\n\n\nmes, día y año\nmdy()\n\n\ndía, mes y año\ndmy()\n\n\nhora y minuto\nhm()\n\n\nhora, minuto y segundo\nhms()\n\n\naño, mes, día, hora, minuto y segundo\nymd_hms()\n\n\n\nLas funciones que tienen componente de hora crean objetos POSIXct.\nCuando una función dmy() se aplica a un vector de fechas, lubridate supone que todas las fechas tienen el mismo orden y los mismos separadores.\n\n\nManipulando fechas\nCada estructura fecha-hora es una combinación de diferentes elementos, cada uno con su propio valor. Por ejemplo, la mayoría de las fechas incluyen un valor de año, un valor de mes, un valor de día, etc. Juntos estos elementos especifican el momento exacto al que se refiere la fecha y la hora.\nPodemos extraer fácilmente cada elemento de una fecha-hora con la función de acceso que tiene su nombre, como se muestra en la siguiente tabla.\n\n\n\nComponente de fecha\nFunción\n\n\n\n\nAño\nyear()\n\n\nMes\nmonth()\n\n\nSemana\nweek()\n\n\nDía del año\nyday()\n\n\nDía del mes\nmday()\n\n\nDía de la semana\nwday()\n\n\nHora\nhour()\n\n\nMinuto\nminute()\n\n\nSegundo\nsecond()\n\n\nZona horaria (huso horario)\ntz()\n\n\n\nPor ejemplo, si almacenamos la fecha y hora actual del sistema en un objeto:\n\nfecha &lt;- now()\n\nfecha\n\n[1] \"2024-09-13 13:32:13 -03\"\n\n\npodemos extraer cada uno de sus elementos.\nTengamos en cuenta que la función now(), perteneciente al mismo paquete lubridate, devolverá una fecha diferente cada vez que se ejecute.\n\nyear(fecha)\n\n[1] 2024\n\n\n\nmday(fecha)\n\n[1] 13\n\n\n\nhour(fecha)\n\n[1] 13\n\nminute(fecha)\n\n[1] 32\n\n\nPara los elementos de mes y día de la semana (wday), también podemos especificar si queremos extraer el valor numérico del elemento, una abreviatura del nombre del mes o día de la semana, o el nombre completo.\nPor ejemplo:\n\nmonth(fecha)\n\n[1] 9\n\n\n\nmonth(fecha, label = TRUE)\n\n[1] sep\n12 Levels: ene &lt; feb &lt; mar &lt; abr &lt; may &lt; jun &lt; jul &lt; ago &lt; sep &lt; ... &lt; dic\n\n\n\nmonth(fecha, label = TRUE, abbr = FALSE)\n\n[1] septiembre\n12 Levels: enero &lt; febrero &lt; marzo &lt; abril &lt; mayo &lt; junio &lt; ... &lt; diciembre\n\n\n\nwday(fecha, label = TRUE, abbr = FALSE)\n\n[1] viernes\n7 Levels: domingo &lt; lunes &lt; martes &lt; miércoles &lt; jueves &lt; ... &lt; sábado\n\n\nOtra buena noticia es que el paquete se adapta al formato regional del sistema operativo donde se encuentra funcionando, por lo que los nombres de los meses o los días de la semana, en este caso, figuran en español (si nuestro sistema operativo está instalado bajo ese idioma).\nPor otra parte, también podemos usar cualquiera de las funciones de acceso para establecer el valor de un elemento. Por ejemplo,\n\nfecha\n\n[1] \"2024-09-13 13:32:13 -03\"\n\nday(fecha) &lt;- 5\n\nfecha\n\n[1] \"2024-09-05 13:32:13 -03\"\n\n\ncambia nuestra fecha al quinto día del mes. También podemos configurar los elementos para más valores complicados, por ejemplo:\n\nfechas &lt;- ymd_hms(\"2017-01-01 01:00:00\", \"2017-01-01 01:30:00\")\n\nminute(fechas) &lt;- mean(minute(fechas))\n\nfechas # promedió los minutos en los dos casos\n\n[1] \"2017-01-01 01:15:00 UTC\" \"2017-01-01 01:15:00 UTC\"\n\n\nSi asignamos a un elemento un valor mayor de lo admitido, la diferencia se extenderá en el siguiente elemento superior (respetando la cantidad de días del mes de mayo adecuadamente en este caso.)\n\nfecha\n\n[1] \"2024-09-05 13:32:13 -03\"\n\nday(fecha) &lt;- 35 \n\nfecha\n\n[1] \"2024-10-05 13:32:13 -03\"\n\n\nFinalmente, también podemos cambiar las fechas agregando o restando unidades de tiempo.\n\nfecha\n\n[1] \"2024-10-05 13:32:13 -03\"\n\nfecha &lt;- fecha + hours(3)\n\nfecha\n\n[1] \"2024-10-05 16:32:13 -03\"\n\n\nObservemos que hours() (plural) no es la misma función que hour() (singular).\nPor último, algo muy útil para nuestro trabajo es poder extraer la semana epidemiologica, con la función epiweek(), en la que cae una fecha en particular o un conjunto de ellas dentro de una variable.\n\nepiweek(fecha)\n\n[1] 40\n\n\nJunto con la semana epidemiológica se puede obtener el año epidemiológico con la función epiyear()\nPor ejemplo, la fecha 01/01/2022 es el primer día de enero de 2022 pero pertenece a la semana epidemiológica 52 de año 2021. Veamos:\n\nfecha &lt;- dmy(\"01-01-2022\")\n\nfecha\n\n[1] \"2022-01-01\"\n\nepiweek(fecha)\n\n[1] 52\n\n\nSi uno obtiene el año al que pertenece, nos dice que 2022 pero si lo queremos asociar con su semana epidemiológica, nos quedaría que estamos en la semana 52 del año 2022, cosa que no es cierta.\n\nyear(fecha)\n\n[1] 2022\n\n\nEn estas situaciones que no coinciden el año de la fecha con el año epidemiológico de la semana es que se aplica epiyear().\n\nepiyear(fecha)\n\n[1] 2021\n\n\n\n\nCálculos con fecha-horas\nLos cálculos con fechas y horas son más complicados que la aritmética con números, pero puede hacerse con precisión y facilidad mediante este paquete.\n¿Qué es lo que complica a la aritmética con datos de tiempo (fechas u horas)?\nEl tiempo que medimos en el reloj se calibra periódicamente para ajustar las condiciones astronómicas, por caso los años bisiestos o los horarios de verano que se utilizan en muchos países.\nEn diferentes momentos, la duración de meses, semanas, días, horas e incluso minutos puede variar. Por lo tanto, podemos considerar que son unidades relativas de tiempo; su longitud es relativa a cuando ocurren; por el contrario, los segundos siempre tienen una longitud constante (son unidades de tiempo exactas)\nlubridate permite cálculos con unidades relativas y exactas introduciendo cuatro nuevos elementos relacionados: instantes, intervalos, duraciones y períodos. Estos conceptos son tomados del proyecto Joda Time (Colebourne y O’Neill 2010). Conceptos similares para instantes, períodos y duraciones también aparecen en la biblioteca C++ Boost - Date Time (Garland 2011).\nlubridate proporciona funciones auxiliares, clases de objetos y métodos para usar los cuatro conceptos en el lenguaje R.\n\nInstantes\nUn instante es un momento específico en el tiempo, como el 1 de enero de 2024. Creamos un instante cada vez que convertimos una fecha a formato Date de R.\n\nstart_2024 &lt;- ymd_hms(\"2024-01-01 12:00:00\")\n\nlubridate no crea una nueva clase de objetos instantes. En cambio, reconoce cualquier objeto de fecha y hora como un instante. Podemos probar si un objeto es un instante usando el identificador is.instant(). Por ejemplo:\n\nis.instant(start_2024)\n\n[1] TRUE\n\n\n\n\nIntervalos\nLos intervalos, duraciones y períodos son todas formas de registrar tiempos. De estos, los intervalos son los más simples. Un intervalo es un lapso de tiempo que ocurre entre dos instantes específicos.\nPodemos crear objetos de intervalo restando dos instantes, mediante %–% o usando la función new_interval().\n\nstart_2023 &lt;- ymd_hms(\"2023-01-01 12:00:00\")\nstart_2024 &lt;- ymd_hms(\"2024-01-01 12:00:00\")\nintervalo &lt;- start_2023 %--% start_2024\nintervalo\n\n[1] 2023-01-01 12:00:00 UTC--2024-01-01 12:00:00 UTC\n\n\nPodemos acceder a las fechas de inicio y finalización de un objeto de intervalo con int_start() e int_end().\nLos intervalos siempre comienzan en la fecha y hora que ocurre primero y finaliza en la fecha y hora que ocurre último. Por lo tanto, los intervalos siempre tienen una longitud positiva.\n\nint_start(intervalo)\n\n[1] \"2023-01-01 12:00:00 UTC\"\n\n\n\nint_end(intervalo)\n\n[1] \"2024-01-01 12:00:00 UTC\"\n\n\nDesafortunadamente, dado que los intervalos están anclados a sus fechas de inicio y finalización, no son muy útiles para cálculos de fecha y hora.\n\n\nDuraciones\nSi eliminamos las fechas de inicio y finalización de un intervalo, tendremos un intervalo de tiempo genérico que podemos agregar a cualquier fecha. Pero, en que unidad es conveniente medir este período de tiempo? Como vimos anteriormente, si lo almacenamos en segundos, tendrá una longitud exacta ya que los segundos siempre tienen la misma longitud.\nLlamamos duraciones de estos lapsos de tiempo. Alternativamente, podemos registrar el lapso de tiempo en unidades más grandes, como minutos o años.\nDado que la longitud de estas unidades varía con el tiempo, la longitud exacta de el lapso de tiempo dependerá de cuándo comience. Estos períodos de tiempo no exactos se llaman períodos y será discutido en la siguiente sección.\nLa duración de una duración es invariable para saltar años, segundos intercalares y horario de verano porque las duraciones se miden en segundos.\nPor lo tanto, las duraciones tienen longitudes consistentes y se puede comparar fácilmente con otras duraciones. Las duraciones son el objeto apropiado para usar cuando se comparan atributos basados en tiempo, como velocidades, tasas y tiempos de vida.\nEl paquete base de R tiene definido a objetos de tipo duración en la clase difftime.\nlubridate incorpora un segundo tipo: objetos clase duration\nEstos objetos se pueden usar con otros objetos de fecha y hora sin preocuparse sobre en qué unidades se muestran. Se puede crear un objeto de duración con la función duration():\n\nduration(60)\n\n[1] \"60s (~1 minutes)\"\n\n\nPara duraciones grandes, resulta inconveniente describir la longitud en segundos. Por ejemplo, no muchas personas reconocerían que 31557600 segundos es la duración de un año estándar. Por esta razón, los objetos de gran duración son seguidos entre paréntesis por una longitud estimada. Un minuto son 60 segundos, una hora 3600 segundos, un día 86400, una semana 604800 y un año 31557600 (365.25 días).\nLos objetos de clase duration se pueden crear fácilmente con las funciones auxiliares dyears(), dweeks(), ddays(), dhours(), dminutes() y dseconds(). La d en el nombre representa duración.\nCada objeto se crea tomando como unidad los segundos usando las relaciones estimadas descriptas arriba. El argumento de cada función es el número de unidades estimadas que deseamos incluir en la duración.\n\ndminutes(1)\n\n[1] \"60s (~1 minutes)\"\n\n\n\ndseconds(60)\n\n[1] \"60s (~1 minutes)\"\n\n\n\ndminutes(2)\n\n[1] \"120s (~2 minutes)\"\n\n\n\n1:3 * dhours(1)\n\n[1] \"3600s (~1 hours)\"  \"7200s (~2 hours)\"  \"10800s (~3 hours)\"\n\n\nLas duraciones se pueden agregar o restar a cualquier objeto instante.\n\nstart_2024\n\n[1] \"2024-01-01 12:00:00 UTC\"\n\nstart_2024 + ddays(10)\n\n[1] \"2024-01-11 12:00:00 UTC\"\n\n\nLas duraciones también se pueden agregar o restar de intervalos y otras duraciones. Por ejemplo:\n\ndweeks(1) + ddays(6) + dhours(2) + dminutes(1.5) + dseconds(3)\n\n[1] \"1130493s (~1.87 weeks)\"\n\n\nTambién podemos crear duraciones a partir de objetos intervalo y períodos usando as.duration().\n\nas.duration(intervalo)\n\n[1] \"31536000s (~52.14 weeks)\"\n\n\n\n\nPeríodos\nLos períodos registran un intervalo de tiempo en unidades mayores que segundos, como años, meses, semanas, días, horas y minutos. Para mayor comodidad, también podemos crear un período que solo use segundos, pero dicho período tendría las mismas propiedades que una duración. lubridate introduce la clase period para modelar períodos. Construimos objetos de período con las funciones auxiliares years(), months(), weeks(), days(), hours(), minutes() y seconds().\n\nmonths(3)\n\n[1] \"3m 0d 0H 0M 0S\"\n\n\n\nmonths(3) + days(2)\n\n[1] \"3m 2d 0H 0M 0S\"\n\n\nEstas funciones no contienen una d en su nombre, porque no crean duraciones; ya no tienen longitudes consistentes (medidas en segundos). Por ejemplo, meses (2) siempre tiene una duración de dos meses, aunque la duración de dos meses cambiará según cuando comienza el período (podrán ser meses de 30, 31 0 28 días).\nPor esta razón, no podemos calcular exactamente cuánto tiempo será un período en segundos hasta que sepamos cuándo ocurre. Sin embargo, aún podemos realizar cálculos de fecha y hora con períodos. Cuando agregamos o restamos un período a un instante, el período queda asociado al instante. El instante nos dice cuándo ocurre el período, lo que nos permite calcular su longitud exacta en segundos.\nPor ejemplo para un año bisiesto, primero sumamos un año con years():\n\nstart_2024 + years(1)\n\n[1] \"2025-01-01 12:00:00 UTC\"\n\n\nvs. sumar un año como duración con dyears()\n\nstart_2024 + dyears(1)\n\n[1] \"2024-12-31 18:00:00 UTC\"\n\n\nTambién podemos convertir otros objetos intervalo en períodos con la función as.period().\n\nas.period(intervalo)\n\n[1] \"1y 0m 0d 0H 0M 0S\"\n\n\nLos períodos se pueden agregar a instantes, intervalos y otros períodos, pero no a duraciones.\n\n\n\nDivisión con intervalos de tiempo\nA veces necesitamos responder preguntas que implican dividir un intervalo de tiempo por otro. Por ejemplo, ¿Cuántos años tiene una persona nacida el 26 de junio de 1976?\nObjetos de clase interval, duration y period pueden dividirse por otros objetos de las mismas clases. Los resultados de estas divisiones varían dependiendo de la naturaleza de los intervalos de tiempo involucrados. La división modular (%/%) también funciona con estas clases.\nPara ilustrar esto, hacemos un intervalo entre la fecha de nacimiento y la fecha actual.\n\nnacimiento &lt;- ymd(\"1976-06-26\")\n\nhoy &lt;- now()\n\nintervalo &lt;- interval(nacimiento, hoy)\n\nintervalo\n\n[1] 1976-06-26 UTC--2024-09-13 16:32:14 UTC\n\n\nComo las duraciones son una medida exacta de un intervalo de tiempo, podemos dividir este intervalo por una duración para obtener una respuesta exacta.\n\nintervalo / dyears(1)\n\n[1] 48.21818\n\n\nPodríamos utilizar un período en lugar de duración\n\nintervalo / years()\n\n[1] 48.21833\n\n\nPero lo más útil es la división modular para redondear y quedarnos solo con los años:\n\nintervalo %/% dyears()\n\n[1] 48\n\n\nEn resumen, la aritmética con tipos fecha-hora puede involucrar cuatro tipos de objetos: instantes, intervalos, duraciones y períodos.\nlubridate crea nuevas clases de objetos: interval, duration y period. Reconoce que las clases de fecha y hora más comunes, como POSIXt y Date, se refieren a instantes. La siguiente tabla describe qué objetos se pueden combinar con otro y qué tipo de objeto resultará.\n\n\n\n\ninstante\ninterval\nduration\nperiod\n\n\n\n\ninstante\nNA\ninstante\ninstante\ninstante\n\n\ninterval\ninstante\ninterval*\ninterval\ninterval\n\n\nduration\ninstante\ninterval\nduration\nperiod\n\n\nperiod\ninstante\ninterval\nperiod\nperiod\n\n\n\n*= clase duration si los intervalos no se alinean.\n\n\nRedondeando fechas\nAl igual que los números, las fechas se ordenan en forma creciente. Esto permite redondear los tipos de datos fecha-hora.\nlubridate proporciona tres métodos que ayudan a realizar este redondeo: round_date(), floor_date(), y ceiling_date().\nEl primer argumento de cada función es la fecha-hora a ser redondeada. El segundo argumento es la unidad tomada para redondear.\nPor ejemplo, podríamos redondear la siguiente fecha-hora a la unidad día:\n\nnov23 &lt;- ymd_hms(\"2023-11-23 09:38:29\")\n\nnov23\n\n[1] \"2023-11-23 09:38:29 UTC\"\n\nround_date(nov23, \"day\")\n\n[1] \"2023-11-23 UTC\"\n\n\nPero también podríamos desear redondear al comienzo de mes más próximo, asi:\n\nround_date(nov23, \"month\")\n\n[1] \"2023-12-01 UTC\"\n\n\nTenga en cuenta que al redondear un dato fecha-hora a una unidad determinada, se establece la fecha al inicio de esa unidad (al definir día, por ejemplo se establece la información de horas, minutos y segundos en 00).\nLas otras dos funciones de redondeo lo hacen al comienzo del mes menor (floor) o mayor (ceiling).\nPor ejemplo, con ceiling_date(), podemos hallar el último día de cada mes, sin importar la fecha que tengamos almacenada. Luego de ubicar el inicio del próximo mes, restamos un día.\n\nceiling_date(nov23, \"month\") - days(1)\n\n[1] \"2023-11-30 UTC\"\n\n\n\noct02 &lt;- ymd_hms(\"2023-10-02 00:00:00\")\n\nceiling_date(oct02, \"month\") - days(1)\n\n[1] \"2023-10-31 UTC\"\n\n\n\n\nZonas horarias\nLas zonas horarias complejizan a los datos fecha-hora, pero algunas veces nos encontramos con bases de datos o situaciones en que debemos lidiar con ellas. Cuando creamos instantes en R, la zona horaria estándar es la universal (UTC).\nlubridate ofrece dos formas de trabajar con zonas horarias.\nPodemos cambiar la zona horaria en la que se muestra un instante utilizando la función with_tz(). Esto cambia la forma en que se muestra el instante, pero continúa siendo el mismo. Por ejemplo, el objeto fecha tiene cargada una fecha-hora creada a partir de la función now() y al ejecutarse en un equipo con configuración regional de Argentina toma el uso horario de Buenos Aires (aparece -03 al final del día y horario)\n\nfecha\n\n[1] \"2022-01-01\"\n\n\nAl llevarlo a la zona horaria universal, le agrega 3 horas más, aunque sigue siendo el mismo instante.\n\nwith_tz(fecha, \"UTC\")\n\n[1] \"2022-01-01 UTC\"\n\n\nforce_tz() hace lo contrario de with_tz(): cambia el instante real de tiempo guardado en el objeto. Por ejemplo, el siguiente código nos mueve a un nuevo instante que ocurre 3 horas más temprano.\n\nforce_tz(fecha, \"UTC\")\n\n[1] \"2022-01-01 UTC\"\n\n\nEn este caso, un instante horario 11:32:01 UTC correponde al instante 08:32:01 -3\nwith_tz() y force_tz() solo funcionan con zonas horarias reconocidas por el sistema operativo de la computadora que aloja R. Esta lista de zonas horarias variará de una computadora a otra. Para más información ver la página de ayuda de R para Sys.timezone().\nEl código de nuestra zona horaria (es conocida como UTC-03:00 - Ciudad de Buenos Aires) para incorporar al argumento es America/Buenos_Aires"
  },
  {
    "objectID": "primero/clases/04-tipos.html#cadena-de-caracteres",
    "href": "primero/clases/04-tipos.html#cadena-de-caracteres",
    "title": "Gestión de tipos de datos",
    "section": "Cadena de caracteres",
    "text": "Cadena de caracteres\n\n\n\n\nArtwork por @allison_horst\n\n\n\nEl paquete encargado de trabajar con cadenas de caracteres dentro de tidyverse es stringr.\nTodas las funciones del paquete comienzan con str_ y trabajan sobre un vector de caracteres como primer argumento.\nHay tres grandes familias útiles de funciones en string:\nFunciones de manipulación de caracteres: estas funciones permiten manipular caracteres dentro de cadenas\nHerramientas para tratamiento de espacios en blanco: para agregar, eliminar y manipular espacios en blanco.\nFunciones de coincidencia de patrones: trabaja con motores de descripción de patrones, para funciones de busqueda, extracción, reemplazo, etc. Trabajan con expresiones regulares.\nstringr también se instala y activa junto a tidyverse.\n\nManipulación de caracteres\nPodemos obtener la longitud de la cadena con str_lenght()\n\nstr_length(\"abc\")\n\n[1] 3\n\n\nEsta función es equivalente a la función de R base nchar().\nPara acceder a un carácter individual se utiliza sub_str().\nSe necesitan tres argumentos: un vector de caracteres, una posición inicial y una posición final. Cualquiera de las posiciones puede ser un entero positivo, que cuenta a partir de la longitud, o un entero negativo que cuenta desde la derecha. Las posiciones son inclusivas, y si es más larga que la cadena, se truncarán silenciosamente.\n\nx &lt;- c(\"abcdef\", \"ghifjk\")\n\nla tercer letra de cada cadena\n\nstr_sub(x, 3, 3)\n\n[1] \"c\" \"i\"\n\n\ndesde la segunda letra hasta la anteúltima\n\nstr_sub(x, 2, -2)\n\n[1] \"bcde\" \"hifj\"\n\n\nTambién puede utilizar str_sub() para modificar cadenas de caracteres\n\nstr_sub(x, 3, 3) &lt;- \"X\"\n\nx\n\n[1] \"abXdef\" \"ghXfjk\"\n\n\nEl paquete stringr trae incorporado algunas funciones para manipulación de mayúsculas y minúsculas, similares a tolower() y toupper()\n\nx &lt;- \"Curso de lenguaje R\"\n\nconvierte a mayúsculas\n\nstr_to_upper(x)\n\n[1] \"CURSO DE LENGUAJE R\"\n\n\nconvierte a minúsculas\n\nstr_to_lower(x)\n\n[1] \"curso de lenguaje r\"\n\n\nconvierte a tipo título (la primer letra de cada palabra en mayúsculas)\n\nstr_to_title(x)\n\n[1] \"Curso De Lenguaje R\"\n\n\nTambién existen funciones para ordenar secuencias de caracteres\n\nx &lt;- c(\"y\", \"i\", \"k\")\n\nstr_order(x)\n\n[1] 2 3 1\n\n\ndevuelve el orden alfabético del índice de los elementos\n\nstr_sort(x)\n\n[1] \"i\" \"k\" \"y\"\n\n\ndevuelve los caracteres en orden alfabético\n\nstr_sort(x, decreasing = T)\n\n[1] \"y\" \"k\" \"i\"\n\n\nigual al anterior pero en orden decreciente\n\n\nEspacios en blanco\nHay tres funciones que añaden, eliminan o modifican espacios en blanco\nstr_pad() agrega espacio en blanco extra a una cadena a una longitud fija puede ser a izquierda, derecha o ambos lados.\n\nx &lt;- c (\"abc\", \"defghi\")\n\n\nstr_pad(x, 10)\n\n[1] \"       abc\" \"    defghi\"\n\n\nrellena con espacios en blanco hasta alcanzar la cantidad de 10 caracteres por cadena sin definir el argumento side= lo hace a la izquierda\n\nstr_pad(x, 10, side = \"both\")\n\n[1] \"   abc    \" \"  defghi  \"\n\n\naquí lo hacemos rellenando los espacios en blanco a ambos lados\nLo opuesto a rellenar de espacios en blanco es eliminarlos y esta tarea la realiza la función str_trim()\n\nx &lt;- c(\"  a   \", \"b   \",  \"   c\")\n\nstr_trim(x)\n\n[1] \"a\" \"b\" \"c\"\n\n\nelimina todos los espacios en blanco a ambos lados de la cadena\n\nstr_trim(x, side=\"left\")\n\n[1] \"a   \" \"b   \" \"c\"   \n\n\ncon el argumento side= le podemos indicar de que lado queremos eliminarlos\n\n\nPatrones\n\n\n\n\nArtwork por @allison_horst\n\n\n\nLa mayoría de las funciones de stringr para trabajo con patrones de caracteres funcionan con expresiones regulares (un lenguaje conciso para describir patrones de texto).\nBásicamente una expresión regular es una cadena de texto especial para describir un patrón de búsqueda que se puede utilizar para:\n\nlocalizar cadenas de caracteres (ubicar - filtrar)\nextraer una porción de los datos (extraer)\nmodificar los datos localizados (reemplazar)\n\nHabitualmente se construyen concatenando la especificación de caracteres secuenciados junto a otros metacaracteres.\nSon muy útiles cuando tenemos variables de alfanuméricas regulares, es decir con una estructura que se repite. Por ejemplo, los códigos internacionales de enfermedad, conocidos como CIE (actualmente en la versión CIE10/CIE11)\nAlgunos de los metacaracteres para construir expresiones regulares son:\n\n\n\n\n\n\n\nSímbolos y metacaracteres\nDescripción\n\n\n\n\n^\nInicio de la cadena\n\n\n$\nFinal de la cadena\n\n\n[ ]\nCualquier carácter del conjunto entre paréntesis\n\n\n[^]\nCualquier carácter no incluido en el conjunto\n\n\n?\nCero o una ocurrencia de lo que precede al símbolo\n\n\n+\nEl caracter que le precede debe aparecer al menos una vez\n\n\n*\nEl caracter que le precede debe aparecer cero, una o más veces\n\n\n{x}\nx ocurrencias del caracter que lo precede\n\n\n{x,z}\nEntre x y z ocurrencias del caracter que lo precede\n\n\n{x,}\nx o más ocurrencias de lo que lo precede\n\n\n\n\n\n\n\n\n\n\nSímbolos y metacaracteres\nDescripción\n\n\n\n\n|\nUne subexpresiones\n\n\n.\nConcuerda con cualquier carácter individual\n\n\n( )\nAgrupa subexpresiones\n\n\n0-9 a-z A-Z\nRangos de números, letras…\n\n\n\\\nMarca el carácter siguiente como un carácter especial\n\n\n.\nRepresenta un punto dentro del patrón\n\n\ns\nRepresenta un espacio en blanco dentro del patrón\n\n\nn\nRepresenta un salto de línea dentro del patrón\n\n\nd\nRepresenta un dígito numérico dentro del patrón\n\n\nw\nRepresenta un carácter alfanumérico dentro del patrón\n\n\n\n\nVeamos un ejemplo con un grupo de códigos CIE10 relacionados a la hepatitis B.\nTenemos una pequeña tabla de datos con 10 códigos en la variable hepb\n\ncodigos\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nSupongamos que se encuentran insertos en una tabla de datos con otros códigos y necesitamos detectarlos para extraerlos o contarlos.\nSi las expresiones regulares no existiesen deberíamos hacer algo así:\n\ncodigos %&gt;% \n  filter(hepb ==\"B16\" | hepb &gt;= \"B160\" & hepb &lt;= \"B162\" | hepb == \"B169\" | \n         hepb == \"B170\" | hepb ==\"B178\" | hepb ==\"B180\" | hepb ==\"B181\" | \n         hepb == \"B189\")\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nEs decir, concatenar una serie de operadores y conectores lógicos OR dentro de un filtro por ejemplo para lograr su extracción.\nCon las expresiones regulares tenemos una alternativa de hacer esta tarea dividiendo el trabajo en partes y aplicar la función str_detect() de stringr.\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B16[0-2|9]?$\"))  #  selecciona el grupo B16x\n\n  hepb\n1  B16\n2 B160\n3 B161\n4 B162\n5 B169\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B17[08]$\")) # selecciona el grupo B17x\n\n  hepb\n1 B170\n2 B178\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B18[019]$\")) # selecciona el grupo B18x\n\n  hepb\n1 B180\n2 B181\n3 B189\n\n\nY finalmente unirlo con conectores OR:\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B16[0-2|9]?$|^B17[08]$|^B18[019]$\"))\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nO mejor construir una expresión regular más sintética aprovechando los metadatos adecuados.\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B1[6-9][0-9]?$\"))\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nAdemás de la función de detección str_detect() el paquete aporta str_extract() para extraer y str_replace() para reemplazar directamente"
  },
  {
    "objectID": "primero/clases/04-tipos.html#factores",
    "href": "primero/clases/04-tipos.html#factores",
    "title": "Gestión de tipos de datos",
    "section": "Factores",
    "text": "Factores\n\n\n\n\nArtwork por @allison_horst\n\n\n\nLos factores son simplemente el formato de datos que R reserva para las variables categóricas y estan compuesto por valores numéricos internos asociados a etiquetas que definen cada una de los niveles (categorías o niveles definidos).\nEl paquete forcats es parte del ecosistema tidyverse pensado para trabajar con este tipo de dato.\nEn función de que las herramientas del paquete son de aplicación práctica vamos a trabajar con un conjunto de datos ficticios creados con la finalidad de mostrar la potencialidad de forcats.\n\nglimpse(datos)\n\nRows: 19\nColumns: 6\n$ Enfermedad     &lt;chr&gt; \"Si\", \"Si\", \"No\", \"Si\", \"No\", \"No\", \"No\", \"Si\", \"Si\", \"…\n$ Sexo           &lt;chr&gt; \"Varon\", \"Mujer\", \"Mujer\", \"Mujer\", \"Masculino\", \"Varon…\n$ Civil          &lt;chr&gt; \"Soltero\", \"Viudo\", \"Casado\", \"Soltero\", \"Soltero\", \"Vi…\n$ Esalud         &lt;chr&gt; \"Mala\", \"Muy mala\", \"Buena\", \"Mala\", \"Buena\", \"Buena\", …\n$ Ciudad         &lt;chr&gt; \"Mar del Plata\", \"Mar del Plata\", \"Mar del Plata\", \"Mar…\n$ Comorbilidades &lt;chr&gt; \"EPOC\", \"Gastritis\", \"aterosclerosis\", \"TBC\", \"Neumonia…\n\n\nObservamos que el objeto llamado datos tiene 6 variables de tipo caracter y 19 observaciones.\nEstas variables de caracter tienen como característica representar variables cualitativas nominales y ordinales que para su mejor tratamiento dentro del R deberían ser convertidas a factores.\nComenzamos con la primer variable (Enfermedad). La función simple y de R base que conocemos para convertirla en factor es factor().\n\ndatos &lt;- datos |&gt; \n  mutate(Enfermedad = factor(Enfermedad))\n\nlevels(datos$Enfermedad)\n\n[1] \"No\" \"Si\"\n\n\nLa función del paquete forcats para realizar la misma tarea se llama as_factor(). No agrega ningun funcionalidad extra por lo que es indistinto utilizar una forma u otra.\nAquí la utilizamos para convertir la variable Sexo\n\ndatos &lt;- datos |&gt; \n  mutate(Sexo = as_factor(Sexo))\n\nSi queremos visualizar los niveles del factor podemos usar levels() (función de R base):\n\nlevels(datos$Sexo)\n\n[1] \"Varon\"     \"Mujer\"     \"Masculino\" \"Femenino\" \n\n\nEncontramos uno de los problemas habituales cuando trabajamos con datos reales cargados por diferentes usuarios o cuando unimos bases de diverso origen. Las categorías se encuentran etiquetadas de manera diferente aunque conceptualmente se refieran a lo mismo (ejemplo: “Femenino” - “Mujer”)\nDebemos corregir este inconveniente y para esta tarea el paquete ofrece una función que recodifica los niveles. Se llama fct_recode() y la aplicamos así:\n\ndatos &lt;- datos |&gt; \n  mutate(Sexo = fct_recode(Sexo, \n                           Varon = \"Masculino\", \n                           Mujer = \"Femenino\"))\n\nlevels(datos$Sexo)\n\n[1] \"Varon\" \"Mujer\"\n\ndatos |&gt; \n  reframe(fct_count(Sexo))\n\n# A tibble: 2 × 2\n  f         n\n  &lt;fct&gt; &lt;int&gt;\n1 Varon    10\n2 Mujer     9\n\n\nVemos en los argumentos que le indicamos que “Masculino” es igual a Varon y “Femenino” igual a Mujer. Esto provoca que en todos los casos donde aparezca “Masculino” sea reemplazado por Varon y cuando aparezcan “Femenino” se cambie por Mujer.\nFinalmente verificamos que los niveles sean los dos que necesitamos y además podemos producir un listado de frecuencias de los niveles del factor con fct_count() dentro de un reframe() que es la opción correcta al summarise() cuando el resultado es mayor a una fila a partir de la versión 1.1.0 de dplyr.\nHasta aquí tenemos las dos primeras variables convertidas y podrían ser utilizadas en un análisis posterior para construir una tabla de contingencia de Sexo vs Enfermedad.\n\nlibrary(janitor)\n\ndatos |&gt; \n  tabyl(Sexo, Enfermedad)\n\n  Sexo No Si\n Varon  5  5\n Mujer  3  6\n\n\nObservemos que en esta tabla el orden de los niveles de Enfermedad quizás no sea el más conveniente para tablas 2x2 y sus cálculos asociados (razones o diferencias de razones), donde se necesita que la tabla tenga una forma y orden específico para que los valores e las ecuaciones sean los correctos.\nEsta situación causa que muchas veces tengamos que reordenar las categorías de las variables cualitativas y los niveles de los factores son ideales para esto. La función encargada de esta tarea en forcats es fct_relevel() que no es muy diferente al relevel() del R base.\n\ndatos &lt;- datos |&gt; \n  mutate(Enfermedad = fct_relevel(Enfermedad, \"Si\"))\n\ndatos |&gt; \n  tabyl(Sexo, Enfermedad)\n\n  Sexo Si No\n Varon  5  5\n Mujer  6  3\n\n\nAplicado sobre Enfermedad observamos, luego en la tabla 2x2, que la categoría Si aparece primera como necesitamos.\nLo mismo podríamos hacer con la variable Sexo si quisieramos que el nivel de referencia fuese Mujer en lugar de Varon.\n\ndatos &lt;- datos |&gt; \n  mutate(Sexo = fct_relevel(Sexo, \"Mujer\"))\n\ndatos |&gt; \n  tabyl(Sexo, Enfermedad)\n\n  Sexo Si No\n Mujer  6  3\n Varon  5  5\n\n\nContinuamos con la siguiente variable y luego de transformarla pedimos sus niveles.\n\ndatos &lt;- datos |&gt; \n  mutate(Civil = factor(Civil))\n\nlevels(datos$Civil)\n\n[1] \"Casado\"     \"Divorciado\" \"Soltero\"    \"Viudo\"     \n\n\nAparecen 4 niveles para la variable. Para ver la frecuencia de aparición hacemos:\n\ndatos |&gt; \n  reframe(fct_count(Civil))\n\n# A tibble: 5 × 2\n  f              n\n  &lt;fct&gt;      &lt;int&gt;\n1 Casado         5\n2 Divorciado     3\n3 Soltero        7\n4 Viudo          3\n5 &lt;NA&gt;           1\n\n\nEn la frecuencia aparecen los 4 niveles más un valor faltante (NA). Estos valores habitualmente se omiten en muchas de las operaciones que realiza el lenguaje.\nPero supongamos que deseamos mostrar dentro de una tabla de frecuencia la cantidad de valores perdidos o desconocidos que tenemos de la variable Estado Civil. Deberíamos etiquetar ese NA para poder visualizarlo.\nLa función del paquete encargada de la tarea es fct_na_value_to_level()\n\ndatos &lt;- datos |&gt; \n  mutate(Civil = fct_na_value_to_level(Civil, \n                                       level = \"Desconocido\"))\n\ndatos |&gt; \n  reframe(fct_count(Civil))\n\n# A tibble: 5 × 2\n  f               n\n  &lt;fct&gt;       &lt;int&gt;\n1 Casado          5\n2 Divorciado      3\n3 Soltero         7\n4 Viudo           3\n5 Desconocido     1\n\nlevels(datos$Civil)\n\n[1] \"Casado\"      \"Divorciado\"  \"Soltero\"     \"Viudo\"       \"Desconocido\"\n\n\nPensando en poder graficar esta variable construimos un gráfico de barras sencillo.\n\ndatos |&gt; \n  ggplot(aes(x = Civil, fill = Civil)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nUna mejor presentación sería si las barras se encuentran ordenadas (de mayor a menor) por la frecuencia de cada categoría.\nPodríamos ordenar mediante arrange() (del paquete dplyr de tidyverse) pero este ordenamiento sirve solo como prosentación, es decir el nuevo orden no se guarda dentro de los niveles del factor.\nPara poder hacer usamos fct_infreq():\n\ndatos &lt;- datos |&gt; \n  mutate(Civil = fct_infreq(Civil))\n\nlevels(datos$Civil)\n\n[1] \"Soltero\"     \"Casado\"      \"Divorciado\"  \"Viudo\"       \"Desconocido\"\n\n\nAhora el gráfico nos saldría como queremos:\n\ndatos |&gt; \n  ggplot(aes(x = Civil, fill = Civil)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nSigamos con otra de las variables. En este caso Esalud que tiene el estado de salud autoreportado por las personas. Como representa una variable categórica ordinal tenemos que estar atentos al orden de las categorías que R siempre forzará a que cumpla con el alfabético.\nPodemos usar directamente fct_relevel() con los niveles completos en el orden correcto.\n\nclass(datos$Esalud)\n\n[1] \"character\"\n\ndatos &lt;- datos |&gt; \n  mutate(Esalud = fct_relevel(Esalud,\n                              \"Muy buena\",\n                              \"Buena\",\n                              \"Regular\",\n                              \"Mala\",\n                              \"Muy mala\"))\n         \nlevels(datos$Esalud)\n\n[1] \"Muy buena\" \"Buena\"     \"Regular\"   \"Mala\"      \"Muy mala\" \n\n\nObservemos que no hizo falta primero convertir en factor y luego aplicar la función de forcats. Todas las funciones comenzadas con fct_ aplicadas a un tipo caracter convertiran a factor previamente a la operación que realicen.\nEn este caso además los niveles tienen un orden lógico que comienza en “Muy buena” salud y termina en “Muy mala”. Quizás el orden necesario sea inverso y fct_rev() hace la tarea.\n\ndatos &lt;- datos |&gt; \n  mutate(Esalud = fct_rev(Esalud))\n\nlevels(datos$Esalud)\n\n[1] \"Muy mala\"  \"Mala\"      \"Regular\"   \"Buena\"     \"Muy buena\"\n\n\nFinalmente conseguimos que el factor sea ordenado y que los niveles sigan el esquema de aumentar hacia la derecha.\nLa siguiente variable es Ciudad. Veamos su contenido:\n\ndatos |&gt; \n  count(Ciudad)\n\n# A tibble: 4 × 2\n  Ciudad            n\n  &lt;chr&gt;         &lt;int&gt;\n1 Batan             1\n2 Mar del Plata    16\n3 Miramar           1\n4 Santa Clara       1\n\n\nPosee 4 etiquetas con nombres de ciudades. Su frecuencia es:\nVemos que mayoritariamente las observaciones pertenecen a Mar del Plata. Muchas veces cuando estamos frente a situaciones como esta, donde hay varias categorías con poca frecuencia, es mejor agruparlas en un “Otras/os”. Eso mismo vamos a realizar con la función fct_other().\n\ndatos &lt;- datos |&gt; \n  mutate(Ciudad = fct_other(Ciudad, \n                            keep = \"Mar del Plata\", \n                            other_level = \"Otras\"))\n\nlevels(datos$Ciudad)\n\n[1] \"Mar del Plata\" \"Otras\"        \n\ndatos |&gt; \n  count(Ciudad)\n\n# A tibble: 2 × 2\n  Ciudad            n\n  &lt;fct&gt;         &lt;int&gt;\n1 Mar del Plata    16\n2 Otras             3\n\n\nLa última de las variables de la tabla de datos es Comorbilidades.\n\ndatos |&gt; \n  count(Comorbilidades)\n\n# A tibble: 7 × 2\n  Comorbilidades     n\n  &lt;chr&gt;          &lt;int&gt;\n1 EPOC               4\n2 Gastritis          2\n3 Hepatitis          2\n4 Hipertensión       2\n5 Neumonia           3\n6 TBC                4\n7 aterosclerosis     2\n\n\nSus etiquetas son 7 y se trata de enfermedades que podemos vincular a distintos grupos, es decir, que nos va a servir de excusa para probar otra función de forcats.\nLa función es fct_collapse() y permite agrupar niveles a grupos que serían las nuevas etiquetas de nivel.\nLo vamos a hacer asignando a una nueva variable (Comor_agrupadas) y generando los niveles Respiratoria, Digestiva y Circulatorio, para enfermedades respiratorias, enfermedades del aparato digestivo y enfermedades del aparato circulatorio.\n\ndatos &lt;- datos |&gt; \n  mutate(Comor_agrupadas = fct_collapse(Comorbilidades,\n                                      Respiratoria = c(\"EPOC\",\n                                                       \"TBC\", \n                                                       \"Neumonia\"),\n                                      Digestiva = c(\"Hepatitis\",\n                                                    \"Gastritis\"),\n                                      Circulatorio  = c(\"aterosclerosis\",\n                                                        \"Hipertensión\")))\n\nlevels(datos$Comor_agrupadas)\n\n[1] \"Circulatorio\" \"Respiratoria\" \"Digestiva\"   \n\ndatos |&gt; \n  count(Comor_agrupadas)\n\n# A tibble: 3 × 2\n  Comor_agrupadas     n\n  &lt;fct&gt;           &lt;int&gt;\n1 Circulatorio        4\n2 Respiratoria       11\n3 Digestiva           4\n\n\nNos quedan para ver tres funciones más del paquete presentado.\nLa primera es fct_drop() que elimina los niveles que no se utilizan. Veamosla en acción.\nTomamos el caso de una selección de la tabla original datos filtrado por las observaciones que pertenecen a Mar del Plata, guardado en otro dataframe al que llamaremos datos_MdP\n\ndatos_MdP &lt;- datos  |&gt;  \n  filter(Ciudad == \"Mar del Plata\")\n\nSi vemos sus niveles confirmaremos que heredó los que tenía la variable en el tibble original. Pero una tabla nos mostraría que no hay datos para el nivel “Otras”.\n\nlevels(datos_MdP$Ciudad)\n\n[1] \"Mar del Plata\" \"Otras\"        \n\ndatos_MdP |&gt; \n  tabyl(Ciudad)\n\n        Ciudad  n percent\n Mar del Plata 16       1\n         Otras  0       0\n\n\nAquí entra en juego la función fct_drop() que aplicada a la variable Ciudad de datos_MdP produce:\n\ndatos_MdP &lt;- datos_MdP |&gt; \n  mutate(Ciudad = fct_drop(Ciudad))\n\nlevels(datos_MdP$Ciudad)\n\n[1] \"Mar del Plata\"\n\ndatos_MdP |&gt; \n  tabyl(Ciudad)\n\n        Ciudad  n percent\n Mar del Plata 16       1\n\n\nA la inversa, la función fct_expand() incorpora niveles a la lista de niveles de un factor.\nVolvemos a trabajar con el dataframe datos y vamos a asignar nuevos niveles al factor de la variable Ciudad.\n\ndatos &lt;- datos |&gt; \n  mutate(Ciudad = fct_expand(Ciudad, \"La Plata\", \n                             \"Tandil\", \n                             \"CABA\"))\n\nlevels(datos$Ciudad)\n\n[1] \"Mar del Plata\" \"Otras\"         \"La Plata\"      \"Tandil\"       \n[5] \"CABA\"         \n\n\nEsto significa que tenemos tres categorías posibles más en el factor que están disponibles para nuevas observaciones, aunque en el conjunto de datos no esten siendo utilizadas por ahora.\nPor último, la función fct_c() concatena factores combinandos niveles. Para ejemplificar su uso vamos a construir dos factores tipo vector que finalmente uniremos.\nImaginemos que tenemos que unir dos variables pertenecientes a conjuntos de datos que queremos unificar. En la variable1 hay definidos dos niveles “Corrientes” y “Posadas” y en la variable2 tres niveles “Corrientes”, “Resistencia” y “Goya”.\n\nvar1 &lt;- factor(c(\"Corrientes\",\"Corrientes\",\"Posadas\",\"Corrientes\",\n                 \"Posadas\"))\n\nvar2 &lt;- factor(c(\"Resistencia\",\"Goya\",\"Goya\",\"Resistencia\",\"Resistencia\",\n                 \"Corrientes\",\"Goya\"))\n\nvar1\n\n[1] Corrientes Corrientes Posadas    Corrientes Posadas   \nLevels: Corrientes Posadas\n\nvar2\n\n[1] Resistencia Goya        Goya        Resistencia Resistencia Corrientes \n[7] Goya       \nLevels: Corrientes Goya Resistencia\n\n\nA continuación concatenamos aplicando fct_c():\n\nvar3 &lt;- fct_c(var1, var2)\n\nvar3\n\n [1] Corrientes  Corrientes  Posadas     Corrientes  Posadas     Resistencia\n [7] Goya        Goya        Resistencia Resistencia Corrientes  Goya       \nLevels: Corrientes Posadas Goya Resistencia\n\n\nObservamos que no solo une los datos de las variables sino que respeta los niveles definidos de cada uno fusionando las categorías."
  },
  {
    "objectID": "primero/clases/02-introRStudio.html",
    "href": "primero/clases/02-introRStudio.html",
    "title": "Introducción a RStudio",
    "section": "",
    "text": "Una vez instalado el software (R + RStudio + Rtools) tenemos todo lo necesario para comenzar a trabajar con el lenguaje R.\nEn este documento vamos a explicar algunos procedimientos que vamos a llevar a cabo muchas veces en las practicas a lo largo del curso.\nEn principio, aunque instalamos tres programas, el único que debemos ejecutar para ponernos a trabajar es RStudio. Éste se encarga de utilizar a R como motor/interprete y a Rtools si llegamos a necesitar instalar algún paquete desarrollado en C/C++ o Fortran. (proceso desantendido al que no deberemos prestar atención)"
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#proyectos-de-rstudio",
    "href": "primero/clases/02-introRStudio.html#proyectos-de-rstudio",
    "title": "Introducción a RStudio",
    "section": "Proyectos de RStudio",
    "text": "Proyectos de RStudio\nLos proyectos de RStudio se utilizan para organizar todo el código, los resultados y salidas, las fuentes de datos y cualquier otro archivo utilizado en un análisis.\nLa organización del trabajo en proyectos es muy útil para asegurarnos que cada vez que necesitemos importar datos, RStudio los buscará dentro de la carpeta asociada al proyecto.\n\nCrear un nuevo proyecto de RStudio\nCreamos un nuevo proyecto de RStudio seleccionando la opción File y luego New Project … de la barra de menú en la parte superior de la pantalla de RStudio como se muestra en la siguiente figura.\n\n\n\n\n\n\n\n\n\nTambién accedemos a generar un proyecto nuevo a partir de pulsar sobre New Project… del menú desplegado en el extremo derecho superior de la interface de RStudio.\n\n\n\n\n\n\n\n\n\nEn cualquiera de los dos casos aparecerá un cuadro de diálogo que presenta algunas opciones para crear el nuevo proyecto de RStudio.\n\n\n\n\n\n\n\n\n\nPor lo general, seleccionaremos la primera opción, New Directory, que crea una nueva carpeta a la que deberemos colocarle un nombre. Esta es la forma de crear un nuevo proyecto cuando aún no tenemos archivos dentro de alguna carpeta con los que deseemos trabajar.\nEn el caso que tengamos algunos archivos de código o archivos de datos con los que necesitemos trabajar, podemos elegir la segunda opción, Existing Directory. El proyecto tomará el nombre de la carpeta que seleccionemos en forma predeterminada.\n\n\nTipos de proyectos\nExisten varios tipos de proyectos pero nosotros en este curso utilizaremos solo la primera opción, que nos abre la siguiente ventana.\n\n\n\n\n\n\n\n\n\nDebemos completar los dos campos.\nEn Directory name hay que escribir el nombre de la nueva carpeta que también será el nombre de nuestro proyecto.\nEn Create Project as subdirectory of: podemos pulsar sobre el botón Browse… y navegar por nuestro Explorador de Archivos hasta ubicar la carpeta donde queremos que se ubique el nuevo proyecto con su nueva carpeta asociada.\nFinalmente hacemos click en el botón Create Project.\nSupongamos que nombremos a nuestro nuevo proyecto como “Practica R” y que lo generamos dentro de la carpeta Mis Documentos.\n\n\n\n\n\n\n\n\n\nEste nuevo proyecto de RStudio se almacenará en la carpeta Practica R que encontraremos en Mis Documentos.\nLos proyectos de RStudio tienen sus propios entornos, por lo que si cerramos o cambiamos de proyecto, nuestra configuración se mantendrá inalterable.\nEsto es cierto para los scripts y cualquier otra cosa que se pueda necesitar para un análisis, mientras esté almacenado dentro de esa carpeta de trabajo.\nEchemos un vistazo a lo que RStudio realizó.\n\n\n\n\n\n\n\n\n\nEn la figura anterior podemos ver dos cambios en la pantalla de inicio.\nEn primer lugar el panel Files (pantalla inferior derecha) apunta a la nueva carpeta Practica R y dentro de ella vemos un nuevo archivo el nombre del proyecto y la extensión Rproj. Este archivo contiene todas las configuraciones del proyecto.\nEl otro cambio se observa en la parte superior derecha, que muestra el nombre del proyecto activo."
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#scripts",
    "href": "primero/clases/02-introRStudio.html#scripts",
    "title": "Introducción a RStudio",
    "section": "Scripts",
    "text": "Scripts\nComo dijimos en Introducción al lenguaje R un script es un archivo de código que contiene un listado secuencial de funciones para ser ejecutadas por el interprete. Estos archivos permiten guardar el código que vamos creando y volver a utilizarlo tantas veces como se quiera, además de poder compartirlo con otras personas.\n\nCómo creamos un script nuevo en RStudio?\nTenemos dos formas de crear un script nuevo. Desde el menú superior pulsando File &gt; New File &gt; R Script (atajo Ctrl+Shift+N) o con el ícono del documento con un símbolo +, como se muestra debajo.\n\n\n\n\n\n\n\n\n\n\n\nCómo editamos un script en RStudio?\nSi queremos comenzar a escribir código o modificar alguna línea ya escrita vamos a utilizar el editor de código.\nEste editor posee algunas herramientas especiales que nos facilitan el trabajo, evitando problemas de sintaxis entre otras ventajas.\nEstas herramientas las vamos a detallar más adelante.\n\n\nCómo ejecutamos un script en RStudio?\nLa forma de ejecutar habitualmente el código escrito, es línea por línea mediante el uso de la combinación de teclas Ctrl+Enter o el botón Run del editor de código de RStudio. Para esto tenemos que tener el cursor activo en la línea que queremos correr (puede ser en cualquier parte de la línea) y luego de ser ejecutada el cursor saltará automáticamente a la siguiente línea que tenga código.\nMientras ejecutamos cada línea debemos ir observando la salida en la consola y también los cambios que se dan en el bloque Environment (Entorno) donde aparecerán los objetos que vayamos creando y modificando.\n\n\nCómo guardamos un script en RStudio?\nCualquier código agregado o modificación que hayamos realizado al script que nos interese mantener nos obligará a guardar el archivo.\nBasta con pulsar sobre el ícono del diskette celeste del editor de código para guardar el script, o bien hacerlo desde el menú principal File &gt; Save o presionando el atajo Ctrl+S.\nSi en cambio quisiera guardarlo como otro archivo para mantener el script original, podemos guardarlo con diferente nombre mediante File &gt; Save As…\n\n\nCómo abrimos un script en RStudio?\nLos scripts que construyamos o bien que nos compartan siempre tendrán extensión .R y generalmente, se encontrarán dentro de algún proyecto.\nPara abrir estos archivos .R podemos pulsar sobre ellos dentro del panel Files (abajo a la derecha) o bien desde el manú con File &gt; Open file… (atajo de teclado Ctrl+O)\nVisualizaremos el script en una nueva pestaña en el editor de código."
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#herramientas-de-rstudio",
    "href": "primero/clases/02-introRStudio.html#herramientas-de-rstudio",
    "title": "Introducción a RStudio",
    "section": "Herramientas de RStudio",
    "text": "Herramientas de RStudio\n\nAsistente de código\nCuando escribimos desde el teclado en el editor de código o en la consola de RStudio, aparece un asistente de forma automática que autocompleta las funciones que vamos tipeando.\nEsta herramienta de autocompletado también se ejecuta pulsando la tecla de tabulación (Tab) y nos muestra las posibilidades de finalizar las palabras que vamos escribiendo junto al esquema de argumentos obligatorios que tiene asociado dicha función. Solo debemos presionar Enter para seleccionar el término correcto.\n\n\n\n\n\n\n\n\n\nAl sistematizar la escritura de código apoyandonos en el uso del autocompletado vamos a reducir la tasa de errores de sintaxis, dado que las funciones, los argumentos y los nombres de las tablas y variables de nuestros datos van a estar correctamente escritos.\n\n\nAyuda en línea\nSi necesitamos acceder a una ayuda adicional en línea bastará que presionemos la tecla F1 con el cursor situado sobre el nombre de la función escrita en el editor de código para que aparezca la información relacionada en el bloque Help de Rstudio (generalmente panel abajo a la derecha).\n\n\n\n\n\n\n\n\n\n\n\nHistorial de funciones\nOtra característica de utilidad dentro de la Consola de RStudio es que si nos situamos en el prompt activo, y pulsamos las teclas flecha hacia arriba o abajo, veremos pasar la lista completa de código ejecutado en la sesion de trabajo.\nEsto nos ayuda a la hora de volver a ejecutar una función o bien cuando debemos hacer alguna corrección de la o las líneas anteriores, puesto que nos ahorra tiempo y trabajo evitando volver a tener que tipear lo que ya escribimos.\nEste historial de funciones también lo encontramos en el bloque superior derecho de RStudio, dentro de la pestaña History.\nHistory almacena todos las funciones ejecutados en consola de forma acumulativa, incluso anidando sesión tras sesión.\nLos comandos que aparecen en ese panel se pueden copiar y pegar en la Consola o, de forma más directa, puedes seleccionar uno de ellos con el mouse, y pulsar en el botón To Console (Enter) para insertarlo en consola o To Source (Shitft+Enter) para insertarlo en el script activo en el que estemos trabajando.\n\n\n\n\n\n\n\n\n\n\n\nAtajos de teclados relevantes (para Windows)\n\n\n\n\n\n\n\nMenú Archivo (File)\n\n\n\n\n\nCtrl+Shift+N\nCrea un nuevo script\n\n\nCtrl+O\nAbre un script guardado\n\n\nCtrl+S\nGuarda el script activo\n\n\nCtrl+W\nCierra el script activo\n\n\nCtrl+Q\nSale del programa RStudio\n\n\nMenú Edición (Edit)\n\n\n\nCtrl+F\nAbre la ventana de búsqueda (para buscar palabras dentro de un script)\n\n\nCtrl+L\nLimpia la consola\n\n\nMenú Código (Code)\n\n\n\nCtrl+Enter\nEjecuta la línea de código donde está situado el cursor\n\n\nCtrl+Alt+R\nEjecuta todo el código del script activo"
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#paquetes-librerías",
    "href": "primero/clases/02-introRStudio.html#paquetes-librerías",
    "title": "Introducción a RStudio",
    "section": "Paquetes (librerías)",
    "text": "Paquetes (librerías)\nR consta de un sistema base y de librerías adicionales, llamados paquetes (packages) que extienden su funcionalidad.\nSiendo open source cualquier persona puede construir paquetes con nuevas funciones, aunque no todos se publican en el repositorio CRAN (Comprehensive R Archive Network).\nUn grupo de paquetes conforman el sistema base que quedan activos cuando instalamos el software R.\nOtros paquetes se encuentran publicados en el repositorio para ser descargados cuando sea necesario. Actualmente existen más de 19000 paquetes para múltiples aplicaciones.\nExisten dos formas de descargar estos paquetes, directamente desde RStudio/R y por medio del sitio web, descargándolos como archivos comprimidos .zip\nSi el equipo se encuentra conectado a Internet es más cómodo realizar las descargas desde RStudio, pero en el caso de no tener acceso permanente a la red, se pueden descargar desde la web en otro equipo y luego guardar en el equipo donde tenemos el programa R.\nEl sitio web para las descargas de los paquetes publicados es https://cran.r-project.org/web/packages/\nAllí se encuentran los enlaces para ver el listado de paquetes ordenados alfabéticamente o por fecha de publicación.\nUna vez que ingresamos al link del paquete que nos interesa veremos en la página algunos datos relacionados como un breve texto de que trata el paquete, el numero de versión, la fecha de publicación, el autor, el archivo de documentación, y por supuesto los archivos a descargar para cada sistema operativo.\nAfortunadamente en la actualidad la mayoría de las computadoras cuentan con acceso a Internet por lo cual explicaremos como se puede descargar, instalar y activar los paquetes desde RStudio.\nRStudio tiene una pestaña específica para gestionar los paquetes ubicada de forma predeterminada en el bloque inferior derecho de la interfaz (Packages)\n\n\n\n\n\n\n\n\n\nPrácticamente todos las acciones que nos facilita la interfaz de RStudio se traduce internamente en ejecuciones de funciones de R que podemos ver en la consola.\nLa secuencia para instalar un paquete que no tengamos previamente instalado inicia a partir de pulsar el botón Install y la ventana emergente que visualizaremos es la siguiente:\n\n\n\n\n\n\n\n\n\n\nDependencias\nLa gran mayoría de las funciones que integran los paquetes que podemos descargar y utilizar están construidas en el mismo lenguaje R y para su elaboración se usan muchas veces funciones pertenecientes a otros paquetes.\nQue pasa cuando queremos ejecutar una función que necesita de otra que no tenemos instalada? Sucede que no es posible ejecutarla dado que no puede encontrar la o las funciones que están siendo llamadas en su propio código y no existen en la actual instalación de R; por lo tanto nos devolverá un mensaje de error alertando por la función desconocida.\nEsta relación de funciones que llaman a otras funciones se denomina dependencia. Es decir, que un paquete puede depender de otro u otros que tienen funciones que son llamadas y por ende, debe asegurarse su previa instalación para evitar el error.\nHay una forma de asegurarnos cuando instalamos un paquete que a su vez se instalen los paquetes del cual depende y es marcando la opción Install dependencies en la ventana anterior (Install Packages)."
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#lectura-de-archivos-de-datos",
    "href": "primero/clases/02-introRStudio.html#lectura-de-archivos-de-datos",
    "title": "Introducción a RStudio",
    "section": "Lectura de archivos de datos",
    "text": "Lectura de archivos de datos\nEl lenguaje nos permite importar variados formatos de tablas de datos utilizando funciones propias de R base como de paquetes que se dedican a esta tarea.\nEl formato nativo de tablas de datos de R es el texto plano (ASCII - Codigo Estadounidense Estandar para el Intercambio de Informacion) con sus columnas separadas por algún caracter. Estos pueden ser caracteres habituales como la coma (,) o el punto y coma (;) que da lugar a la extensión *.csv, o algunos especiales como la barra vertical (|) que suele utilizar el INDEC para sus productos o bien cualquier otro, como espacios o la tabulación.\nOtra característica que tienen estos archivos es que generalmente poseen una cabecera donde se ubican los nombres de cada columna/variable y por supuesto que cada una de ellas debe respetar un mismo tipo de dato para cumplir con la condición que la hace una tabla/base de datos.\nLo más importante para hacer una buena lectura de la tabla de datos con la que deseamos trabajar es conocer previamente el formato que tiene, si tiene cabecera, que caracter usa como separador de columnas, etc. Al ser un texto plano se puede abrir desde un simple Block de Notas de Windows o desde el mismo RStudio para conocer sus particularidades.\nActualmente y dentro del ecosistema con el que vamos a trabajar durante este curso hay un paquete con funciones diseñadas para importar estos tipos de archivos. Se llama readr y su fuerte es detectar el formato que tiene cada columna en el momento de la lectura.\nPosee una familia de funciones analizadoras donde se destacan:\n\nread_csv(): archivos separados por comas (CSV)\nread_delim(): archivos separados con delimitadores generales\nread_tsv(): archivos separados por tabulaciones\nread_fwf(): archivos con columnas de ancho fijo\nread_table(): archivos formato tabla con columnas separadas por espacios\n\nTodas estas funciones tiene argumentos comunes, además de file = donde se declara el nombre del archivo a importar entre comillas. Algunos de estos argumentos importantes son:\ncol_names = con TRUE le indicamos que la primera fila contiene los nombres de las columnas (con FALSE lo negamos)\nskip = salteamos una cantidad determinada de líneas que el archivo puede contener. En el caso que existan textos que no pertenecen al formato de la tabla de datos.\nlocale = es la configuración regional que el arhivo puede tener. Estos incluyen:\n\nLas marcas decimales y de agrupación, utilizadas al leer números.\nLa codificación de caracteres, utilizada al leer cadenas que no son ASCII.\nLos nombres de meses y días, utilizados al analizar fechas.\nLa zona horaria predeterminada, utilizada al analizar fechas y horas.\n\nLa adecuada configuración de este argumento evitará que palabras que tengan acentos o eñes o diferentes formatos de fecha sean bien reconocidos.\nPor lo tanto, nuestra tarea es hacer coincidir el formato de origen del archivo a leer con la función y los argumentos correctos.\nDurante el proceso de importación, decíamos que las funciones analizan columna por columna a que tipo de dato pertenecen. Los posibles tipos de datos son: character, integer, numeric, double, logical y date/time.\nPor ejemplo, si tenemos un archivo con punto y coma de separador, vamos a utilizar read_csv2() y si queremos importar la tabla de datos que ofrece el INDEC para los datos de las Encuestas Nacionales de Factores de Riesgo utilizaremos read_delim() declarando “|” dentro del argumento delim = (única función de la familia que la incorpora)."
  },
  {
    "objectID": "primero/clases/02-introRStudio.html#agunas-buenas-prácticas-de-trabajo",
    "href": "primero/clases/02-introRStudio.html#agunas-buenas-prácticas-de-trabajo",
    "title": "Introducción a RStudio",
    "section": "Agunas buenas prácticas de trabajo",
    "text": "Agunas buenas prácticas de trabajo\n\nAgrupar nuestros datos, scripts y resultados dentro de proyectos de RStudio (Rproj)\nDeclarar en el inicio de los scripts la activación de paquetes necesarios para ejecutar las funciones incluídas en el código. ( función library() )\nDocumentar el código que vayamos creando por medio de comentarios (iniciados con #)\nCumplir con un correcto estilo de codificación (Intentar utilizar espacios e identación adecuada para que el código sea de fácil lectura)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gestión de Datos",
    "section": "",
    "text": "Descripción\nEste curso…..\n\n\nInstructor\n\nChristian Ballejo    \n\n\n\nTemario\n\n\n\n\n\nFecha\n\n\nTema\n\n\nLectura\n\n\nDiapositiva\n\n\nPráctica\n\n\nRecursos\n\n\n\n\n\n\n01/10/2024\n\n\nBienvenida\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n01/10/2024\n\n\nDatos - Parte 1\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n03/10/2024\n\n\nDatos - Parte 2\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n08/10/2024\n\n\nDatos - Parte 3\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n10/10/2024\n\n\nLenguaje R\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n10/10/2024\n\n\nRStudio\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n10/10/2024\n\n\nTidyverse\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n15/10/2024\n\n\nImportación y exportación de archivos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBibliografía\nR for Data Science (2e)\nEpiRhandbook en español\nData Visualization"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "primero/clases/01-introR.html",
    "href": "primero/clases/01-introR.html",
    "title": "Introducción al lenguaje R",
    "section": "",
    "text": "El sitio oficial r-project.org dice que “R es un entorno de software libre para gráficos y computación estadística. Se compila y se ejecuta en una amplia variedad de plataformas UNIX, Windows y MacOS.”.\nProfundizando en su descripción podemos decir, técnicamente, que es un lenguaje de programación interpretado, orientado a objetos, multiplataforma y open source aplicado al manejo de datos estadísticos.\nA continuación detallamos cada parte de la definición:\nR es un lenguaje de programación estadístico\nR es un lenguaje de programación, con sus estructuras y reglas de sintaxis, que posee una gran variedad de funciones desarrolladas con fines estadísticos.\nR es un lenguaje Orientado a Objetos\nImplementa conceptos de la programación orientada a objetos y esto le permite ser simple y flexible en el manejo de datos. En R todo con lo que trabajamos es considerado un “objeto”: las variables, funciones, datos, resultados, etc. que pueden ser modificados por otros objetos.\nR es un lenguaje interpretado\nNo es necesario compilar los scripts de programación para construir ejecutables sino que directamente se ejecutan por medio del intérprete que devuelve resultados de forma inmediata.\nR es multiplataforma (corre en Linux, Windows y Mac)\nFunciona en diferentes sistemas operativos como Linux, Windows y Mac.\nR es Open Source y se distribuye bajo licencia GNU - GPL\nEsto quiere decir que se distribuye gratuitamente bajo licencia GNU (General Public License) – GPL y que los usuarios tienen la libertad de usar, estudiar, compartir (copiar) y modificar el software."
  },
  {
    "objectID": "primero/clases/01-introR.html#qué-es-el-lenguaje-r",
    "href": "primero/clases/01-introR.html#qué-es-el-lenguaje-r",
    "title": "Introducción al lenguaje R",
    "section": "",
    "text": "El sitio oficial r-project.org dice que “R es un entorno de software libre para gráficos y computación estadística. Se compila y se ejecuta en una amplia variedad de plataformas UNIX, Windows y MacOS.”.\nProfundizando en su descripción podemos decir, técnicamente, que es un lenguaje de programación interpretado, orientado a objetos, multiplataforma y open source aplicado al manejo de datos estadísticos.\nA continuación detallamos cada parte de la definición:\nR es un lenguaje de programación estadístico\nR es un lenguaje de programación, con sus estructuras y reglas de sintaxis, que posee una gran variedad de funciones desarrolladas con fines estadísticos.\nR es un lenguaje Orientado a Objetos\nImplementa conceptos de la programación orientada a objetos y esto le permite ser simple y flexible en el manejo de datos. En R todo con lo que trabajamos es considerado un “objeto”: las variables, funciones, datos, resultados, etc. que pueden ser modificados por otros objetos.\nR es un lenguaje interpretado\nNo es necesario compilar los scripts de programación para construir ejecutables sino que directamente se ejecutan por medio del intérprete que devuelve resultados de forma inmediata.\nR es multiplataforma (corre en Linux, Windows y Mac)\nFunciona en diferentes sistemas operativos como Linux, Windows y Mac.\nR es Open Source y se distribuye bajo licencia GNU - GPL\nEsto quiere decir que se distribuye gratuitamente bajo licencia GNU (General Public License) – GPL y que los usuarios tienen la libertad de usar, estudiar, compartir (copiar) y modificar el software."
  },
  {
    "objectID": "primero/clases/01-introR.html#breve-historia",
    "href": "primero/clases/01-introR.html#breve-historia",
    "title": "Introducción al lenguaje R",
    "section": "Breve historia",
    "text": "Breve historia\nR fue desarrollado a partir del lenguaje S que tiene sus orígenes en Bell Labs de la AT&T (actualmente Lucent Technologies) de mediados de la década del ’70. Posteriormente, S fue vendido y dio origen a una versión propietaria denominada S-Plus que es comercializada por Insighful Corporation.\nEn 1995 dos profesores de estadística de la Universidad de Auckland, en Nueva Zelanda Ross Ihaka y Robert Gentleman, iniciaron el “Proyecto R”, con la intención de desarrollar un programa estadístico inspirado en el lenguaje S pero de dominio público.\nAunque se dice que R es un dialecto de S existen diferencias importantes en el diseño de ambos lenguajes.\nEl software está desarrollado en lenguaje C++ con algunas rutinas agregadas en Fortran) y su nombre se debe a la letra con la que inician los nombres de pila de sus autores (Ross y Robert).\nActualmente es mantenido por un grupo internacional de desarrolladores voluntarios denominado Core Development Team."
  },
  {
    "objectID": "primero/clases/01-introR.html#scripts",
    "href": "primero/clases/01-introR.html#scripts",
    "title": "Introducción al lenguaje R",
    "section": "Scripts",
    "text": "Scripts\nUn script es un archivo de texto plano con una lista secuencial de funciones y comandos del lenguaje R para ser ejecutado por el intérprete de R.\nScript se puede traducir como guión, archivo de órdenes, archivo de procesamiento por lotes o archivo de sintaxis.\nGeneralmente se crea en editores especiales y/o en cualquier procesador básico de texto plano. Se almacena en un archivo que puede ser leído, modificado, guardado y se puede ejecutar completo o línea a línea.\nPoseen una cualidad muy provechosa: son re-utilizables, adaptándolos a otras necesidades.\nDocumentación de los scripts de R:\nLa documentación es una tarea de mucha importancia en cualquier lenguaje de programación, ya que nos permite entender que estamos haciendo en el script. Además nos sirve para el futuro mantenimiento o para la reutilización del código elaborado, tanto para otros usuarios como para nosotros mismos.\nLa forma de documentar los scripts de código en R es utilizando comentarios. Toda línea que comienza con el símbolo # es entendido por el interprete como un comentario y los caracteres que sigan a ese símbolo no seran tenidos en cuenta cuando se ejecute ese código.\n\n# esto es una línea de comentario y no es tenida en cuenta por el intérprete\n\nAsí que a la hora de documentar es preferible abusar de estos comentarios que no utilizarlos."
  },
  {
    "objectID": "primero/clases/01-introR.html#funciones",
    "href": "primero/clases/01-introR.html#funciones",
    "title": "Introducción al lenguaje R",
    "section": "Funciones",
    "text": "Funciones\nLos comandos u órdenes elementales de R se denominan funciones. A algunas se las llama “integradas” porque están incluidas en el núcleo (R base) y sus nombres están reservados.\nTambien podemos utilizar otras pertenecientes a librerías (paquetes) que se pueden instalar y activar.\nToda función tiene un nombre y normalmente recibe argumentos o parámetros que deben ser escritos entre paréntesis y separados por comas. Incluso algunas de ellas que no tienen asociado ningún argumento necesitan finalizar con paréntesis () para ser entendidas como funciones.\nSiempre una función devuelve un resultado, un valor o realiza una acción.\n\n\n\n\n\n\n\n\n\nComo el interprete de R no permite errores en la sintaxis de las expresiones, debemos atender a los siguientes puntos a la hora de escribirlas:\n\nLa sintaxis habitual de una función y sus argumentos es la siguiente:\n\n\nfuncion(arg1, arg2, arg3,...)\n\n\nLos títulos de los argumentos pueden escribirse y mediante un igual agregar el valor correspondiente. También se puede omitir el título del argumento y escribir directamente el valor, pero en este caso, hay que respetar el orden definido por la función.\n\n\nfuncion(arg1=32, arg2=5, arg3=65,...)\n\nes igual a hacer:\n\nfuncion(32, 5, 65,...)\n\nsiempre que se respete el mismo orden.\n\nCon los argumentos se deben cumplir las mismas reglas que en todo el lenguaje. Los valores numéricos, lógicos, especiales y objetos van escritos en forma directa y cuando escribimos caracteres (texto) van necesariamente encerrados entre comillas.\n\n\nfuncion(arg1=3, arg2=NA, arg3=TRUE, arg4=\"less\", arg5=x,...)"
  },
  {
    "objectID": "primero/clases/01-introR.html#librerías-paquetes",
    "href": "primero/clases/01-introR.html#librerías-paquetes",
    "title": "Introducción al lenguaje R",
    "section": "Librerías (paquetes)",
    "text": "Librerías (paquetes)\nLas librerías son grupos de funciones empaquetados que se pueden instalar y utilizar en el análisis de datos. Habitualmente se agrupan por tema o similitud de funciones.\nEstos paquetes se pueden descargar directamente del repositorio oficial de CRAN en Internet (similar al uso de los repositorios de Linux) o bien descargar en formato .zip para luego instalar y usar.\nSe pueden activar y desactivar en cualquier momento del análisis.\nAlgunos poseen dependencias de otros paquetes que serán necesarios para que funcione."
  },
  {
    "objectID": "primero/clases/01-introR.html#sintaxis-errores-y-advertencias",
    "href": "primero/clases/01-introR.html#sintaxis-errores-y-advertencias",
    "title": "Introducción al lenguaje R",
    "section": "Sintaxis, errores y advertencias",
    "text": "Sintaxis, errores y advertencias\nEl lenguaje es muy preciso en su sintaxis y equivocarse en la forma de escribir una función o cualquier otro objeto produce respuestas de error del interprete de R que es habitual cuando iniciamos el aprendizaje.\nLa exactitud en la escritura de comandos y funciones incluye la distinción entre mayúsculas y minúsculas. Es decir, que no es lo mismo una ‘a’ que una ‘A’.\nExisten tres grupos de mensajes de error:\n\nerror de sintaxis\nerror de objeto no encontrado\notros errores\n\nSe dice que hay un error de sintaxis, cuando ejecutamos una línea de código que el motor de R no puede interpretar debido a que algo está mal escrito.\nHabitualmente los errores de sintaxis se deben a que falta o sobra algún elemento necesario en la estructura de una función (comas, parentesis, llaves, corchetes, comillas, etc.)\nPor ejemplo la función rep() repite valores una cantidad de veces. Tiene dos argumentos, x donde se coloca el valor a repetir y times donde se define la cantidad de veces.\n\nrep(x = 3, times = 4) #repetimos 4 veces 3 con rep()\n\n[1] 3 3 3 3\n\n\nSi nos olvidamos de cerrar el paréntesis…\n\nrep(x = 3, times = 4\n    \nError: Incomplete expression: rep(x = 3, times = 4\n\nSi nos olvidamos de separar los argumentos con la coma\n\nrep(x = 3 times = 4)\n\nError: unexpected symbol in \"rep(x =3 times\"\n\nSi en lugar de escribir x como primer argumento y escribimos otra letra…\n\nrep(y =3, times = 4)\n\nError in rep(y = 3, times = 4) : \n  attempt to replicate an object of type 'symbol'\n\nSi escribimos mal la función…\n\nREP(x =3, times = 4)\n\nError in REP(x = 3, times = 4) : no se pudo encontrar la función \"rop\"\n\nEsta última posibilidad es similar a un “objeto no encontrado” por error de sintaxis.\nLos mensajes de error en general y sobre todo al principio pueden parecer extraños y difíciles de entender, pero con un poco de práctica podemos inferir donde está el problema.\nLos errores de objetos no encontrados pueden tener una de varias causas:\n\nel nombre no se escribió correctamente (p.ej.: sintaxis, mayúsculas / minúsculas)\nel paquete o archivo que contiene el objeto no ha sido cargado\nolvidamos poner comillas en un lugar que corresponde\notros motivos posibles\n\nVolvamos al ejemplo anterior, ahora repitiendo un valor tipo character\n\nrep(x = \"A\", times = 4) #repetimos 4 veces 3 con rep()\n\n[1] \"A\" \"A\" \"A\" \"A\"\n\n\nSi olvidamos las comillas…\n\nrep(x = A, times = 4) #repetimos 4 veces 3 con rep()\n\nError: objeto 'A' no encontrado\n\nAdvertencias\nUna advertencia no es algo tan serio, como un error, o al menos no lo parece, ya que esta permite que la función se ejecute igual. Pero puede ocurrir que ignorar una advertencia llegue a ser algo muy serio, si esto implica que la salida de la función es equivocada.\nPor lo tanto, es una buena política entender los mensajes de advertencia para ver si indican problemas para preocuparnos o no.\nResumiendo:"
  },
  {
    "objectID": "primero/clases/01-introR.html#creación-de-objetos",
    "href": "primero/clases/01-introR.html#creación-de-objetos",
    "title": "Introducción al lenguaje R",
    "section": "Creación de objetos",
    "text": "Creación de objetos\nTodas las declaraciones donde se crean objetos, tienen este símbolo de asignación &lt;-.\n\nnombre_objeto &lt;- valor\n\nVeámoslo en un ejemplo:\n\na &lt;- 1\n\nEn este caso asignamos el valor 1 al objeto a. El objeto a es un vector de una posición (un solo valor).\nSi llamasemos al objeto a, el interprete nos devuelve el valor asignado previamente.\n\na\n\n[1] 1\n\n\nObservemos que además de devolvernos el valor aparece delante un 1 entre corchetes [1].Este número es la ubicación o índice del comienzo del objeto, que en este caso tiene una sola posición."
  },
  {
    "objectID": "primero/clases/01-introR.html#estructuras-de-datos",
    "href": "primero/clases/01-introR.html#estructuras-de-datos",
    "title": "Introducción al lenguaje R",
    "section": "Estructuras de datos",
    "text": "Estructuras de datos\nLos objetos contenedores de datos más simples pertenecen a cinco clases que se denominan atómicas y que son los siguientes tipos de datos:\n\ninteger (números enteros)\nnumeric / double (números reales)\ncomplex (números complejos)\nchacacter (cadena de caracteres)\nlogical (lógicos o booleanos – toman valores por si o no)\n\n\n\n\n\n\n\n\n\n\nSin embargo, cada una de estas clases de datos no se encuentran de manera aislada, sino encapsulados dentro de la clase de objeto operacional más básica del lenguaje a la que se denomina vector.\nVector\nUn vector es un conjunto de valores (números o símbolos), todos del mismo tipo ordenados de la forma (elemento 1, elemento 2, … , elemento \\(n\\)) y \\(n\\) es la longitud o tamaño del vector.\nSurge de la definición dos términos importantes: el tipo y la longitud.\nTodos los objetos de datos tienen estos dos atributos intrínsecos.\n\nel tipo, que puede ser integer, numeric, chacacter, complex y logical\nla longitud, que es el número de elementos que contiene el objeto.\n\nEl vector más simple es el que contiene un dato, podría ser numérico de un solo dígito. El tipo sería numeric y la longitud 1.\n\nvec1 &lt;- 1\nvec1\n\n[1] 1\n\n\nOtro vector más grande por ejemplo podría ser (1,5,2). En este caso también es del tipo numeric pero tiene una longitud de 3 elementos (3 posiciones que integran el vector).\n\nvec2 &lt;- c(1,5,2)\nvec2\n\n[1] 1 5 2\n\n\nComo vemos, para concatenar estos tres valores numéricos usamos la forma c(). Esta c es una función de R, justamente para concatenar. (todo lo que aparece siempre antes de paréntesis es una función). Dentro de la función los valores van separados por comas.\nAquí podemos señalar otra característica, según la definición de vector, la colección de elementos se encuentra ordenada, por lo que en nuestro ejemplo la primera posición la ocupa el 1, la segunda el 5 y la tercera el 2. Como el orden importa, si tuviese otro vector (5,1,2), a pesar de tener los mismos elementos no sería el mismo vector porque están ordenados de forma diferente.\nPara ver la longitud del vector usamos:\n\nlength(vec2)\n\n[1] 3\n\n\nNos informa que vec2 tiene 3 elementos.\nAsimismo podemos ver que los datos almacenados en este segundo ejemplo cumplen con la definición en lo que respecta al tipo de dato, ya que cada elemento es del mismo tipo (numeric).\nPara conocer la clase del dato ejecutamos:\n\nclass(vec2)\n\n[1] \"numeric\"\n\n\nVeamos un ejemplo de asignación de otro tipo de dato atómico, como es el character:\n\nvec3 &lt;- \"Hola\"\nvec3\n\n[1] \"Hola\"\n\n\nSiempre que escribamos contenido de tipo caracter debemos hacerlo entre comillas. En este caso generamos el vector vec3 con el contenido “Hola”. A pesar de ser una palabra que, por supuesto, esta compuesta de varios caracteres, dentro del vector vec3 esta ocupa una sola posición.\n\nlength(vec3)\n\n[1] 1\n\n\nRespecto a la clase del dato si usamos la función class() tendremos:\n\nclass(vec3)\n\n[1] \"character\"\n\n\nDataframe\nUn dataframe es un objeto cuya finalidad es contener conjuntos de datos. Se asemeja a una tabla que tiene filas y columnas (dos dimensiones), donde cada columna puede almacenar elementos de diferentes tipos.\nAdemás las columnas suelen tener nombres únicos y podemos referenciarlas por estos nombres, como si fueran variables del conjunto de datos.\nEs el tipo de objeto que utilizamos para almacenar información leída de tablas de datos provenientes de archivos externos (formato texto separado por comas, Excel, etc) y con las cuales acostumbramos a trabajar en el análisis.\nDesde el punto de vista de su estructura, todo dataframe esta conformado por una serie de vectores de la misma longitud ubicados verticalmente uno al lado de otro.\nPodemos verlo en la siguiente porción de código:\n\nHC &lt;- c(\"F324\", \"G21\", \"G34\", \"F231\")\nedad &lt;- c(34,32,34,54)\nsexo &lt;- c(\"M\", \"H\", \"H\", \"M\")\n\ndf1 &lt;- data.frame(HC, edad, sexo)\n\ndf1\n\n    HC edad sexo\n1 F324   34    M\n2  G21   32    H\n3  G34   34    H\n4 F231   54    M\n\n\nCreamos tres vectores con datos de supuestos individuos, su historia clinica, la edad y el sexo. Luego mediante la función data.frame() “unimos” esos vectores en forma vertical para formar un dataframe de 3 variables y 4 observaciones.\nExisten otras estructuras de datos que aparecen en la siguiente figura. Las más habituales en nuestro trabajo son los vectores y los dataframes."
  },
  {
    "objectID": "primero/clases/01-introR.html#operadores-en-r",
    "href": "primero/clases/01-introR.html#operadores-en-r",
    "title": "Introducción al lenguaje R",
    "section": "Operadores en R",
    "text": "Operadores en R\nAdemás de funciones, el lenguaje R cuenta con operadores similares a otros lenguajes de programación, que permiten realizar operaciones con datos.\n\nR como calculadora\nEl lenguaje R cuenta con operadores aritméticos de uso relativamente intuitivo, que permiten realizar operaciones matemáticas como si usasemos una calculadora.\n\n\n\n\n\n\n\n\n\n\n# suma\n2 + 5\n\n[1] 7\n\n# resta\n3 - 2\n\n[1] 1\n\n# multiplicación\n9 * 3\n\n[1] 27\n\n# división\n10 / 2\n\n[1] 5\n\n# potenciación\n5 ^ 2\n\n[1] 25\n\n\nNota: observarán que el interprete del lenguaje al devolvernos un valor en consola lo muestra con una notación inicial de un 1 encerrado entre corchetes [1]. Este número es el índice del vector que nos está mostrando R y que siempre comienza con 1. Si la cantidad de elementos de un vector mostrados por la consola superase el ancho de la pantalla, entonces el listado seguiría debajo y al comienzo de la nueva línea veríamos otro número entre corchetes que sería el indice de ese primer valor. Veamos un ejemplo:\n\n\n [1] 0.10 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24\n[16] 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39\n[31] 0.40 0.41 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.50 0.51 0.52 0.53 0.54\n[46] 0.55 0.56 0.57 0.58 0.59 0.60 0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69\n[61] 0.70 0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.80 0.81 0.82 0.83 0.84\n[76] 0.85 0.86 0.87 0.88 0.89 0.90\n\n\nEl 0.25 que es primer valor de la segunda fila esta en la posición 16 de ese vector de números. Y, por ejemplo, el 0.70 en la posición 61.\nPara otras operaciones matemáticas como la raíz cuadrada o el valor absoluto de un múmero, existen funciones específicas incluídas en R base.\n\n# radicación (raíz cuadrada)\nsqrt(9)\n\n[1] 3\n\n# valor absoluto\nabs(-3)\n\n[1] 3\n\n\nTambién se pueden hacer operaciones con los objetos que almacenan a estos valores numéricos asignados:\n\n# a contiene el valor 3\na &lt;- 3\n\n# b contiene el valor 6\nb &lt;- 6\n\n# aplicamos una fórmula determinada\n(a + b) * b\n\n[1] 54\n\n\nY funciona con objetos como los vectores que contienen más de un elemento, aplicando artimética vectorial, donde las operaciones se realizan elemento a elemento.\n\n# creamos el vector a con 3 elementos\na &lt;- c(1, 2, 3)\n\n# ejecutamos una operación matemática a todos los elementos de a\na * 3\n\n[1] 3 6 9\n\n\nO bien, con operaciones entre objetos, donde se las operaciones se realizan entre los elementos de la misma posición:\n\n# creamos el vector a con 3 elementos\na &lt;- c(1, 2, 3)\n\n# ejecutamos una operación matemática a todos los elementos de a * a\na * a\n\n[1] 1 4 9\n\n\nMediante sum() se puede hacer sumatorias de elementos en vectores numéricos.\n\n# creamos el vector a con 3 elementos\na &lt;- c(1, 2, 3)\n\n# realizamos una sumatoria de todos los elementos de a\nsum(a)\n\n[1] 6\n\n\nOtra función muy utilizada es la que permite que redondeemos valores con decimales.\n\n## redondeamos definiendo 2 digitos decimales\n\nround(23.76859, digits = 2)\n\n[1] 23.77"
  },
  {
    "objectID": "primero/clases/01-introR.html#concatenación-y-secuencias-regulares",
    "href": "primero/clases/01-introR.html#concatenación-y-secuencias-regulares",
    "title": "Introducción al lenguaje R",
    "section": "Concatenación y secuencias regulares",
    "text": "Concatenación y secuencias regulares\nYa usamos la función c() para concatenar elementos. Habitualmente cuando deseemos crear vectores con más de un elemento vamos a recurrir a esta función.\n\n# vector numérico de 4 elementos\nc(6, 3, 6, 8)\n\n[1] 6 3 6 8\n\n# vector caracter de 2 elementos\nc(\"Hola\", \"Chau\")\n\n[1] \"Hola\" \"Chau\"\n\n\nExiste otra forma de concatenar elementos a partir de un operador de rango. Produce un intervalo secuencial de enteros que puede ser ascendente o descendente. El operador es : y se usa de la siguiente forma:\n\n# ascendente\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# descendente\n10:1\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nOtra manera es por medio de la función seq() que tiene como argumentos principales from, to y by\n\n# secuencia de 1 a 20 cada 2\nseq(from = 1, to = 20, by = 2)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\nAlgunos otros ejemplos de la misma función pueden ser:\n\n# secuencia de 0.1 a 0.9 cada 0.1\nseq(from = 0.1, to = 0.9, by = 0.1)\n\n[1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n\n# secuencia de -5 a 5 cada 1\nseq(from = -5, to = 5, by = 1)\n\n [1] -5 -4 -3 -2 -1  0  1  2  3  4  5\n\n# secuencis de 300 a 0 cada 50 (se escribe -50 porque es descendente)\nseq(from = 300, to = 0, by = -50)\n\n[1] 300 250 200 150 100  50   0\n\n\nFinalmente la última posibilidad que vamos a mostrar es la función rep() que repite valores. Su forma más sencilla es rep(x, times = Nº) que coloca un Nº de repeticiones de x, una tras otra.\nAlgunos ejemplos de la función:\n\n# repetimos 5 veces el número 2\nrep(x = 2, times = 5)\n\n[1] 2 2 2 2 2\n\n# combinada con el operador de rango\nrep(1:4, 5)  \n\n [1] 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4\n\n# combinada con la función de concatenación\nrep(c(4.5,6.8,7.2), 2) \n\n[1] 4.5 6.8 7.2 4.5 6.8 7.2\n\n\nTambién existen operadores relacionales y conectores lógicos que vamos a ver más adelante, cuando por ejemplo, necesitemos construir condiciones para filtrar subconjuntos de datos."
  },
  {
    "objectID": "primero/clases/01-introR.html#valores-especiales-en-r",
    "href": "primero/clases/01-introR.html#valores-especiales-en-r",
    "title": "Introducción al lenguaje R",
    "section": "Valores especiales en R",
    "text": "Valores especiales en R\nExisten algunos valores especiales para datos con expresiones reservadas en R, entre ellos encontramos los valores NA, NaN, Inf y NULL.\n\n\n\n\n\n\n\n\n\nEl más relevante de estos valores especiales es el NA que sirve para indicar la inexistencia de valor."
  },
  {
    "objectID": "primero/clases/03-introTidy.html#introducción",
    "href": "primero/clases/03-introTidy.html#introducción",
    "title": "Tidyverse",
    "section": "Introducción",
    "text": "Introducción\nTidyverse es el nombre que se ha dado al conjunto de paquetes desarrollados a partir de la inciativa de Hadley Wickham (jefe científico de Posit -antes RStudio-) y su equipo, para ciencia de datos con R.\nEstos paquetes están diseñados para funcionar juntos y comparten una misma filosofía, que se puede consultar en The tidy tools manifesto.\nLos cuatro principios básicos en los que se basa son:\n\nReutilizar las estructuras de datos\nResolver problemas complejos combinando varias piezas sencillas\nUtilizar programación funcional\nDiseñado para humanos\n\nLos paquetes incluidos en el tidyverse tienen como objetivo cubrir todas las fases del análisis de datos dentro de R: importar datos, ponerlos en formato ordenado (tidy data), buscar relaciones entre ellos (mediante su transformación, visualización y creación de modelos) y comunicar los resultados.\nLa palabra “tidy” se puede traducir como “ordenado” y refiere a que los datos deben cumplir con una estructura determinada donde:\n\nCada variable es una columna de la tabla de datos.\nCada observación es una fila de la tabla de datos.\nCada tabla responde a una unidad de observación o análisis.\n\n\n\n\n\n\n\n\n\n\nAdemás de los paquetes principales que realizan estas funciones, al instalar el tidyverse también se proporcionan otros que ayudan a trabajar con fechas, cadenas de caracteres o factores siguiendo los mismos principios.\nUna de las interesantes incorporaciones transversales en el ambiente tidyverse es el uso de tuberías (pipe en inglés).\nUna tubería conecta un trozo de código con otro mediante el conector %&gt;% que surge del paquete magrittr que permite transformar llamadas de funciones anidadas (con muchos paréntesis) en una simple serie de operaciones que son más fáciles de escribir y comprender. Este aporte fue tan importante que el equipo de desarrolladores que mantiene el lenguaje R incorporó la idea a partir de la versión 4.1.0 de 2021, agregando la funcionalidad nativa con el operador |&gt;.\nNota: durante el curso pueden llegar a coexistir ambas tuberías, dado que funcionan igual. De todas maneras, al utilizar versiones actualizadas del lenguaje preferimos utilizar la tubería nativa que es más eficiente que la propia del tidyverse.\nLa idea de tubería responde al principio donde cada función es un paso y la forma de trabajar se puede ver en el siguiente esquema general:\n\n\n\n\n\n\n\n\n\nBase gramatical\nLa intención de los desarrolladores para este conjunto de paquetes es lograr incorporar una gramática a la sintaxis de las funciones y sus argumentos buscando un entendimiento semántico más claro.\nUna prueba de ello, es que la mayoría de las funciones son verbos que se entrelazan con objetos y argumentos que permiten construir “frases”."
  },
  {
    "objectID": "primero/clases/03-introTidy.html#el-paquete-de-paquetes",
    "href": "primero/clases/03-introTidy.html#el-paquete-de-paquetes",
    "title": "Tidyverse",
    "section": "El paquete de paquetes",
    "text": "El paquete de paquetes\nEl paquete tidyverse nucleo actual (versión 2.0.0) se puede descargar del repositorio oficial CRAN mediante menú Packages de RStudio o ejecutando en consola:\n\ninstall.packages(\"tidyverse\")\n\nSe activa, como cualquier otro paquete, mediante:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::extract() masks dlookr::extract()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nObservamos que nos informa sobre la versión del paquete, el listado de paquetes que acabamos de activar sólo llamando a tidyverse y una serie de conflictos de nombres de funciones.\nEsto es muy habitual cuando activamos varios paquetes, dado que las funciones que se encuentran dentro de ellos pueden llamarse iguales.\nPor ejemplo, existe en el paquete base stats y en el paquete dplyr (que es parte de tidyverse) una función llamada filter(), por lo tanto al activar tidyverse nos informa de esta manera: dplyr::filter() masks stats::filter()\nEn este caso, cuando necesitemos asegurarnos que la función que deseamos ejecutar pertenece a determinado paquete, es recomendable escribirla de la siguiente forma:\n\nnombre_paquete::nombre_función\n\nstats::filter() para la función filter() del paquete stats\ndplyr::filter() para la función filter() del paquete dplyr\nLos paquetes incluidos que se instalan en esta versión son 31:\n\ntidyverse_packages()\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\nExisten otros paquetes (la cantidad crece con el tiempo) que son creados bajo la misma filosofía pero no están incluidos. En esos casos hay que instalarlos y activarlos individualmente.\nPara profundizar sobre tidyverse se puede visitar el sitio https://www.tidyverse.org/ y la primera versión del libro traducido al español r4ds. La segunda versión está disponible en inglés en r4ds(2e)"
  },
  {
    "objectID": "primero/clases/03-introTidy.html#lectura-y-escritura-de-datos",
    "href": "primero/clases/03-introTidy.html#lectura-y-escritura-de-datos",
    "title": "Tidyverse",
    "section": "Lectura y escritura de datos",
    "text": "Lectura y escritura de datos\n\nPaquete readr\nreadr contiene funciones similares a las de la familia read.table() de R base pero desarrollados bajo el ecosistema tidyverse.\nLos archivos de texto plano (ASCII y otras codificaciones) son universalmente utilizados por la mayoría de los gestores de bases de datos y/o planillas de cálculo. Generalmente encontrados con extensiones .txt o .csv (por comma-separated values) son el tipo de archivo de datos más habitual dentro del lenguaje R.\nEstos datos planos tienen dos peculiaridades:\n\nLa cabecera (en inglés header)\nEl caracter o símbolo separador que indica la separación de columnas: pueden estar separadas por comas, puntos y comas, por tabulación, etc…\n\nLa cabecera puede existir o no, y de existir puede ser simple o compleja. La inclusión o no de la cabecera se maneja desde los argumentos col_names y skip.\nCon col_names = TRUE incluimos la primer fila como cabecera (nombre de las columnas) y en FALSE la salteamos.\nCon skip = 0 la lectura de produce desde la primer fila (se puede omitir), pero si la cabecera fuese compleja con varias filas entre títulos y subtítulos, debemos indicar cuantas filas iniciales se “saltea”. Por ejemplo con skip = 5 se saltea las primeras 5 filas del archivo.\nEl otro elemento a tener en cuenta es el caracter separador que utiliza el archivo para indicar cuando comienza una nueva columna (variable).\nGeneralmente los separadores más comunes son: la coma (,), el punto y coma (;), el tabulador (TAB), el espacio ( ), el caracter pipe (|), entre otros posibles.\nAlgunas de las funciones del paquete asumen un separador particular. Por caso read_csv() lee separados por coma y read_tsv() separado por tabulaciones, pero la función read_delim() permite que definamos el separador a través del argumento delim =.\nEn forma detallada el paquete readr soporta siete formatos de archivo a partir de siete funciones:\n\nread_csv(): archivos separados por comas (CSV)\nread_tsv(): archivos separados por tabulaciones\nread_delim(): archivos separados con delimitadores generales\nread_fwf(): archivos con columnas de ancho fijo\nread_table(): archivos formato tabla con columnas separadas por espacios\nread_log(): archivos log web\n\nEn comparación con las funciones base de R, las funciones de readr:\n\nUsan un esquema de nombres consistente de parámetros\nSon más rápida.\nAnalizan eficientemente los formatos de datos comunes, incluyendo fecha/hora.\nMuestran una barra de progreso si la carga va a llevar un tiempo. (para archivos grandes)\n\nViene incluida dentro de la instalación de tidyverse y se activa con él, pero también permite activarse solo:\n\nlibrary(readr)\n\nAlgunos ejemplos de sintaxis:\n\nLeemos un archivo sin cabecera separado por comas\n\n\nread_csv(\"datos/ejemplo-datos.csv\", col_names = F)\n\n# A tibble: 6 × 5\n     X1 X2      X3       X4    X5        \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt; &lt;date&gt;    \n1     9 Leone   Fernando M     1958-12-24\n2    26 Salem   Esteban  M     1954-01-21\n3    35 Orduna  Nicolas  M     1993-06-27\n4    48 Manueli Viviana  F     1965-06-21\n5    49 Orozco  Laura    F     1993-08-15\n6    55 Umpier  Leopoldo M     1952-10-11\n\n\n\nLeemos el mismo archivo con cabecera y separado por punto y comas\n\n\nread_csv2(\"datos/ejemplo-datos-header.csv\", col_names = T)\n\n# A tibble: 6 × 5\n   Iden Apellido Nombre   Sexo  FNac      \n  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;date&gt;    \n1     9 Leone    Fernando M     1958-12-24\n2    26 Salem    Esteban  M     1954-01-21\n3    35 Orduna   Nicolas  M     1993-06-27\n4    48 Manueli  Viviana  F     1965-06-21\n5    49 Orozco   Laura    F     1993-08-15\n6    55 Umpier   Leopoldo M     1952-10-11\n\n\n\nLeemos el archivo con cabecera separado por tabulaciones\n\n\nread_tsv(\"datos/ejemplo-datos-header2.csv\", col_names = T)\n\nRows: 6 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (3): Apellido, Nombre, Sexo\ndbl  (1): Iden\ndate (1): FNac\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 6 × 5\n   Iden Apellido Nombre   Sexo  FNac      \n  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;date&gt;    \n1     9 Leone    Fernando M     1958-12-24\n2    26 Salem    Esteban  M     1954-01-21\n3    35 Orduna   Nicolas  M     1993-06-27\n4    48 Manueli  Viviana  F     1965-06-21\n5    49 Orozco   Laura    F     1993-08-15\n6    55 Umpier   Leopoldo M     1952-10-11\n\n\nObservemos que cada vez que hacemos una lectura la función se encarga de analizar (parse) el tipo de dato que hay en cada columna. En esta última ocasión además, devuelve un listado con el resultado del análisis antes de mostrar la tabla importada.\nLos posibles tipos de datos son los atómicos del lenguaje más algún agregado: character, integer, numeric, double, logical y date/time.\nPor ejemplo, en la tabla leída anteriormente las columnas donde hay números enteros fueron reconocidos como double (&lt;dbl&gt;), los que tienen algún caracter como character (&lt;chr&gt;) y las fechas como date (&lt;date&gt;).\nAhora escribimos la sintaxis para leer un archivo con cabecera compleja (la tabla comienza en la fila 9) separado por |.\n\nread_delim(\"datos/ejemplo-datos-header-skip.txt\", \n           col_names = T, \n           skip = 8,      # salteamos las primeras 8 filas\n           delim = \"|\")\n\n# A tibble: 6 × 5\n   Iden Apellido Nombre   Sexo  FNac      \n  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;     \n1     9 Leone    Fernando M     24/12/1958\n2    26 Salem    Esteban  M     21/01/1954\n3    35 Orduna   Nicolas  M     27/06/1993\n4    48 Manueli  Viviana  F     21/06/1965\n5    49 Orozco   Laura    F     15/08/1993\n6    55 Umpier   Leopoldo M     11/10/1952\n\n\n\nEn estos ejemplos visualizamos el contenido de los archivos leídos en consola con el propósito de mostrar como trabajan las funciones, pero en la práctica cada vez que importemos datos de un archivo debemos asignar su salida a un nombre, que será el nombre del dataframe que reciba los datos dentro de nuestra sesión de trabajo. (&lt;-)\n\n\nFunciones de escritura\nDentro del paquete coexisten funciones espejo de escritura para las posibilidades de lectura más relevantes. Así encontramos estos cuatro:\n\nwrite_csv(): escribe archivos separados por comas (csv)\nwrite_csv2(): escribe archivos separados por punto y comas (csv)\nwrite_tsv(): escribe archivos separados por tabulaciones\nwrite_delim(): escribe archivos separados con delimitadores definidos por el usuario\n\nLos argumentos son generales y para el caso del último más extensos, dado que hay que definir cual es el separador que deseamos en el archivo.\n\nargs(write_delim)\n\nfunction (x, file, delim = \" \", na = \"NA\", append = FALSE, col_names = !append, \n    quote = c(\"needed\", \"all\", \"none\"), escape = c(\"double\", \n        \"backslash\", \"none\"), eol = \"\\n\", num_threads = readr_threads(), \n    progress = show_progress(), path = deprecated(), quote_escape = deprecated()) \nNULL\n\n\nPor ejemplo para exportar un conjunto de datos en texto plano al que denominaremos ejemplo.csv con separador punto y coma y cabecera incluida podemos hacer:\n\nwrite_delim(x = datos, file = \"ejemplo.csv\", delim = \";\")\n\no más sencillo:\n\nwrite_csv2(datos, \"ejemplo.csv\")\n\n\n\n\nPaquete readxl\nUno de los formatos de documentos más comunes en los que se almacenan datos son las hojas de cálculo, en particular, las creadas con el programa Excel de Microsoft Office.\nEl paquete readxl es parte del ecosistema tidyverse y permite leer este tipo de archivos.\nPosee compatibilidad con hojas de cálculo de Excel 97-03, de extensión .xls, y con hojas de cálculo de las versiones más recientes de Excel, de extensión, .xlsx\nLa primera función interesante es excel_sheets(), útil para conocer y listar los nombre de las hojas contenidas dentro de un archivo (libro) Excel.\nPor ejemplo, supongamos que tenemos un archivo denominado datos.xlsx y queremos saber por cuantas hojas está compuesto y que nombre tienen.\n\nlibrary(readxl) # hay que activarlo independientemente de tidyverse\n\nexcel_sheets(\"datos/datos.xlsx\")\n\n[1] \"diabetes\"   \"vigilancia\" \"mortalidad\"\n\n\nObtenemos de esta manera información sobre el archivo. Hay tres hojas llamadas diabetes, vigilancia y mortalidad.\nPara poder leer cada una de estas hojas de datos debemos usar la función read_excel(), que tiene los siguientes argumentos:\n\nargs(read_excel)\n\nfunction (path, sheet = NULL, range = NULL, col_names = TRUE, \n    col_types = NULL, na = \"\", trim_ws = TRUE, skip = 0, n_max = Inf, \n    guess_max = min(1000, n_max), progress = readxl_progress(), \n    .name_repair = \"unique\") \nNULL\n\n\nDonde los más relevantes son:\npath: nombre del archivo y la ubicación (si fuese necesaria) entre comillas\nsheet: nombre de la hoja o número de ubicación\ncol_names: si se activa toma la primer fila como nombres de columnas (variables)\nskip: permite saltear una cantidad determinada de filas antes de comenzar la lectura\nEn primer lugar, cuando ejecutamos esta función, llama a otra denominada excel_format() que determina frente a que formato de archivo estamos. Si es un Excel tipo .xsl o tipo .xlsx. En relación a esta respuesta, luego aplica la función específica para cada caso - read_xls() o readxlsx().\nTodas estas funciones mencionadas en el procedimiento que sigue read_excel() se pueden utilizar en forma específica.\nContinuemos con el archivo datos.xlsx y procedamos a leer los datos de su primer hoja, llamada diabetes.\n\ndiabetes &lt;- read_excel(path = \"datos/datos.xlsx\", \n                       sheet = \"diabetes\",\n                       col_names = T)\n\nhead(diabetes) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 8\n    A1C  hba1 GLUCB   SOG Tol_Glucosa    DM    SM  HOMA\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  6.17   7.9   101   122 IFG             0     1  4.04\n2  5.58   7.2   103   100 IFG             0     0  5.03\n3  5.38   7.1   103    90 IFG             0     1  2.92\n4  5.38   6.6   109    96 IFG             0     1  4.79\n5  5.19   6.3   107    69 IFG             0     1  3.06\n6  4.89   6      NA   117 IFG             0     0  5.77\n\n\nObservemos que en los argumentos escribimos el nombre del archivo que se encuentra en nuestro proyecto y por lo tanto en nuestra carpeta activa, el nombre de la hoja y nos aseguramos que la primer fila representa a la cabecera de la tabla (sus nombres de variables).\nComo el paquete readxl se inscribe dentro del universo tidyverse el formato de salida es un dataframe/tibble. En este caso de 23 observaciones por 8 variables.\nAhora leamos la segunda hoja de nombre vigilancia.\n\nvigilancia &lt;- read_excel(path = \"datos/datos.xlsx\", \n                         sheet = 2, \n                         col_names = F)\n\nhead(vigilancia) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 9\n   ...1 ...2        ...3      ...4  ...5  ...6  ...7 ...8  ...9                 \n  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                \n1   875 09/28/2015  2015 544080000     1    31     1 F     VIGILANCIA EN SALUD …\n2   875 42317       2015 544080000     1    35     1 F     VIGILANCIA EN SALUD …\n3   875 42317       2015 544080000     1    47     1 F     VIGILANCIA EN SALUD …\n4   307 09/26/2015  2015 544005273     1    23     1 M     VIGILANCIA INTEGRADA…\n5   307 09/24/2015  2015 544005273     1    19     1 M     VIGILANCIA INTEGRADA…\n6   875 09/28/2015  2015 544080000     1    63     1 F     VIGILANCIA EN SALUD …\n\n\nCentremos nuestra mirada en los argumentos anteriores: en lugar del nombre de la hoja usamos un 2 que es su ubicación (la segunda hoja del archivo Excel) y configuramos a col_names con F (false) porque el conjunto de datos no tiene cabecera.\nCuando ocurre esta situación donde la tabla no tiene nombre de columnas readxl le asigna nombres del tipo ...1, ...2, ...x\nFinalmente leemos la última hoja disponible del archivo.\n\nmortalidad &lt;- read_excel(path = \"datos/datos.xlsx\", \n                         sheet = \"mortalidad\",\n                         col_names = T, \n                         skip = 1)\n\nhead(mortalidad) # mostramos las 6 primeras observaciones\n\n# A tibble: 5 × 10\n  grupo_edad grupo.I.1.1 grupo.II.1.1 grupo.III.1.1 grupo.I.2.1 grupo.II.2.1\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1 30-44               41          202           222         539         1438\n2 45-59               99         1071           181         759         6210\n3 60-69              114         1782           119         985         9238\n4 70-79              221         2336           119        1571        12369\n5 80+                362         2492            81        2523        14642\n# ℹ 4 more variables: grupo.III.2.1 &lt;dbl&gt;, grupo.I.3.1 &lt;dbl&gt;,\n#   grupo.II.3.1 &lt;dbl&gt;, grupo.III.3.1 &lt;dbl&gt;\n\n\nLo novedoso de esta lectura es el argumento skip = 1 que debimos incorporar dado que, en este caso, la hoja de Excel comienza con una línea de título que no pertenece al conjunto de datos. También que el argumento sheet permite el nombre de la hoja elegida entre comillas.\nRetomando los argumentos generales de la función podemos mencionar estos otros:\nn_max: número máximo de filas leídas\nrange: rango de celdas a leer (definidas como se suele usar en Excel, por ej: B3:D87)\ncol_types: especificación del tipo de dato para cada columna leída. Se pueden utilizar los tipos habituales “numeric”, “logical”, “text”, “date”, etc. Existen dos tipos específicos más: “skip” que saltea la lectura de la columna y “guess” que permite que la función decida cual es el formato adecuado de importación. Este último es el modo predeterminado cuando no especificamos el argumento.\nna: caracter o vector que deseamos se interprete como valor perdido (missing). Por defecto las celdas vacías se interpretan de esta forma y se le asigna NA"
  },
  {
    "objectID": "primero/clases/03-introTidy.html#gestión-de-datos-con-el-paquete-dplyr",
    "href": "primero/clases/03-introTidy.html#gestión-de-datos-con-el-paquete-dplyr",
    "title": "Tidyverse",
    "section": "Gestión de datos con el Paquete dplyr",
    "text": "Gestión de datos con el Paquete dplyr\nEl paquete dplyr es parte del universo tidyverse que fue desarrollado por Hadley Wickham a partir de optimizar una versión del paquete plyr.\nLa contribución significativa del paquete es proporcionar una “gramática” (funciones-verbos) para la manipulación y operaciones de datos que lo hace más fácil de entender.\nLas funciones clave del paquete, responden a las siguientes acciones (verbos):\n\nselect(): devuelve un conjunto de columnas (variables)\nrename(): renombra variables en una conjunto de datos\nfilter(): devuelve un conjunto de filas (observaciones) según una o varias condiciones lógicas\narrange(): reordena filas de un conjunto de datos\nmutate(): añade nuevas variables/columnas o transforma variables existentes\nsummarise()/summarize(): genera resúmenes estadísticos de diferentes variables en el conjunto de datos.\ngroup_by(): agrupa un conjunto de filas seleccionado, en un conjunto de filas de resumen de acuerdo con los valores de una o más columnas o expresiones.\ncount(): contabiliza valores que se repiten, es decir genera tabla de frecuencias.\n\n\nArgumentos comúnes en las funciones dplyr\nTodas las funciones, básicamente, tienen en común una serie de argumentos.\n\nEl primer argumento es el nombre del conjunto de datos (objeto donde esta nuestra tabla de datos)\nLos otros argumentos describen que hacer con el conjunto de datos especificado en el primer argumento, podemos referirnos a las columnas en el objeto directamente sin utilizar el operador $, es decir sólo con el nombre de la columna/variable.\nEl valor de retorno es un nuevo conjunto de datos.\nLos conjunto de datos deben estar bien organizados/estructurados, es decir debe existir una observación por columna y, cada columna representar una variable, medida o característica de esa observación. Es decir, debe cumplir con tidy data.\n\n\n\nActivación del paquete\ndplyr está incluído en el paquete tidyverse, por lo que se encuentra disponible si tenemos activado a este último.\nTambién se puede activar en forma independiente, aunque no es necesario si ya activamos tidyverse:\n\nlibrary(dplyr)\n\n\n\nConjunto de datos para ejemplo\nVisualizar y entender el funcionamiento de estos “verbos” de manipulación es posible si ejemplificamos su aplicación. Por este motivo vamos a leer un conjunto de datos que servirá para ejercitar las funciones del paquete.\n\ndatos &lt;- read_csv(\"datos/noti-vih.csv\") # asignamos la lectura a datos\n\nRows: 48 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): jurisdiccion\ndbl (3): año, casos, pob\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(datos) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 CABA          2015   901  3054237\n4 CABA          2016   427  3050000\n5 Catamarca     2015    69   396552\n6 Catamarca     2016    51   401575\n\n\nLa tabla de datos “noti-vih.csv” contiene datos de notificación de vih por jurisdicción de Argentina para los años 2015 y 2016.\n\n\nFunción select()\nEsta función selecciona las variables que especificamos devolviendo un conjunto de datos “recortado por columna”.\nselect() utiliza un minilenguaje conciso que facilita hacer referencia a las variables según su nombre, ubicación, condición o tipo.\nAlguno de sus operadores son:\n\n: para seleccionar un rango de variables consecutivas.\n- para evitar seleccionar la variable que sigue al signo\n! para tomar el complemento de un conjunto de variables.\n\nVeamos algunas aplicaciones de estas “ayudas” para hacer selecciones.\nTodas las variables menos pob\n\ndatos |&gt;  \n  select(-pob)\n\n# A tibble: 48 × 3\n   jurisdiccion   año casos\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513\n 2 Buenos Aires  2016   957\n 3 CABA          2015   901\n 4 CABA          2016   427\n 5 Catamarca     2015    69\n 6 Catamarca     2016    51\n 7 Chaco         2015    15\n 8 Chaco         2016     9\n 9 Chubut        2015   110\n10 Chubut        2016    89\n# ℹ 38 more rows\n\n\nOtra forma para el mismo resultado anterior (mediante el operador rango :)\n\ndatos |&gt;  \n  select(jurisdiccion:casos)\n\n# A tibble: 48 × 3\n   jurisdiccion   año casos\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513\n 2 Buenos Aires  2016   957\n 3 CABA          2015   901\n 4 CABA          2016   427\n 5 Catamarca     2015    69\n 6 Catamarca     2016    51\n 7 Chaco         2015    15\n 8 Chaco         2016     9\n 9 Chubut        2015   110\n10 Chubut        2016    89\n# ℹ 38 more rows\n\n\nLas variables jurisdiccion y casos\n\ndatos |&gt;  \n  select(jurisdiccion, casos)\n\n# A tibble: 48 × 2\n   jurisdiccion casos\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 Buenos Aires  1513\n 2 Buenos Aires   957\n 3 CABA           901\n 4 CABA           427\n 5 Catamarca       69\n 6 Catamarca       51\n 7 Chaco           15\n 8 Chaco            9\n 9 Chubut         110\n10 Chubut          89\n# ℹ 38 more rows\n\n\nOtra forma para el mismo resultado anterior (mediante números de columna):\n\ndatos |&gt;  \n  select(1, 3)\n\n# A tibble: 48 × 2\n   jurisdiccion casos\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 Buenos Aires  1513\n 2 Buenos Aires   957\n 3 CABA           901\n 4 CABA           427\n 5 Catamarca       69\n 6 Catamarca       51\n 7 Chaco           15\n 8 Chaco            9\n 9 Chubut         110\n10 Chubut          89\n# ℹ 38 more rows\n\n\nTodas las variables pasando año a la primera columna\n\ndatos |&gt;  \n  select(\"año\", everything())\n\n# A tibble: 48 × 4\n     año jurisdiccion casos      pob\n   &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  2015 Buenos Aires  1513 16626374\n 2  2016 Buenos Aires   957 16789474\n 3  2015 CABA           901  3054237\n 4  2016 CABA           427  3050000\n 5  2015 Catamarca       69   396552\n 6  2016 Catamarca       51   401575\n 7  2015 Chaco           15  1153846\n 8  2016 Chaco            9  1125000\n 9  2015 Chubut         110   567010\n10  2016 Chubut          89   577922\n# ℹ 38 more rows\n\n\nEsta última función everything(), pasada como argumento, es una de las posibles funciones llamadas “ayudantes de selección”, entre las cuales se encuentra:\n\nstarts_with(): selecciona todas las columnas que comiencen con el patrón indicado.\nends_with(): selecciona todas las columnas que terminen con el patrón indicado.\ncontains(): selecciona las columnas que posean el patrón indicado.\nmatches(): similar a contains(), pero permite poner una expresión regular.\nall_of(): selecciona las variables pasadas en un vector (todos los nombres deben estar presentes o devuelve un error)\nany_of(): idem anterior excepto que no se genera ningún error para los nombres que no existen.\nnum_range(): selecciona variables con nombre combinados con caracteres y números (ejemplo: num_range(“x”, 1:3) selecciona las variables x1, x2 y x3.\nwhere(): aplica una función a todas las variables y selecciona aquellas para las cuales la función regresa TRUE (por ejemplo: is.numeric() para seleccionar todas las variables numéricas)\ngroup_cols(): selecciona todas las columnas de agrupación.\n\nTodas estas funciones son muy útiles a la hora de seleccionar el conjunto de variables necesarias no solo para un select() básico sino también cuando necesitemos aplicar operaciones simultáneas y/o pivotear tablas de datos que necesiten garantizar formato ordenado (tidy-data).\n\n\nFunción rename()\nEsta función es una extensión de select(), dado que esta última permite cambiar el nombre de variables pero no es muy útil porque descarta todas las variables que no se mencionan explícitamente. En cambio rename() renombra variables mientras que mantiene las demás no mencionadas.\nPor ejemplo, cambiamos el nombre de la variable pob por población.\n\ndatos |&gt; \n  rename(\"población\" = pob)\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos población\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 Buenos Aires  2015  1513  16626374\n 2 Buenos Aires  2016   957  16789474\n 3 CABA          2015   901   3054237\n 4 CABA          2016   427   3050000\n 5 Catamarca     2015    69    396552\n 6 Catamarca     2016    51    401575\n 7 Chaco         2015    15   1153846\n 8 Chaco         2016     9   1125000\n 9 Chubut        2015   110    567010\n10 Chubut        2016    89    577922\n# ℹ 38 more rows\n\n\n\n\nFunción filter()\nAsí como la función select() es utilizada para seleccionar columnas, la función filter() hace lo propio con las filas del conjunto de datos, produciendo un subconjunto de observaciones.\nVeamos un ejemplo sencillo sobre nuestros datos:\n\ndatos |&gt; \n  filter(jurisdiccion == \"Tucuman\")\n\n# A tibble: 2 × 4\n  jurisdiccion   año casos     pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Tucuman       2015   258 1592593\n2 Tucuman       2016   246 1618421\n\n\nUtiliza los mismos operadores de comparación propios del lenguaje R\n\n\n\nComparación\n\n\n\n\n\n&lt;\nmenor a\n\n\n&gt;\nmayor a\n\n\n==\nigual a\n\n\n&lt;=\nmenor o igual a\n\n\n&gt;=\nmayor o igual a\n\n\n!=\nno igual a\n\n\n%in%\nes parte de\n\n\nis.na\nes NA\n\n\n!is.na\nno es NA\n\n\n\nLo mismo con los operadores lógicos que se utilizan como conectores entre las expresiones.\n\n\n\nLógicos\n\n\n\n\n\n&\nAND booleano\n\n\n|\nOR booleano\n\n\nxor\nOR exclusivo\n\n\n!\nNOT\n\n\nany\ncualquier TRUE\n\n\nall\ntodos TRUE\n\n\n\nCuando usamos múltiples argumentos separados por coma dentro de filter() se combinan con un conector AND, es decir cada expresión debe ser verdadera para que una fila sea incluida en la salida.\nPor ejemplo:\nFiltramos a las observaciones que cumplan con la condición que casos sea mayor a 100 y población sea menor a 1000000\n\ndatos |&gt; \n  filter(casos &gt; 100, pob &lt; 1000000)\n\n# A tibble: 7 × 4\n  jurisdiccion   año casos    pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Chubut        2015   110 567010\n2 Jujuy         2015   160 727273\n3 Jujuy         2016   133 734807\n4 Neuquen       2015   109 619318\n5 Neuquen       2016   101 627329\n6 Rio Negro     2015   112 700000\n7 Rio Negro     2016   105 709459\n\n\nPara combinaciones dentro de una misma variable debemos utilizar el conector OR (|) o más útil el operador %in%.\nFiltramos a las jurisdicciones “Buenos Aires” y “La Pampa”\n\ndatos |&gt; \n  filter(jurisdiccion == \"Buenos Aires\" | jurisdiccion == \"La Pampa\")\n\n# A tibble: 4 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 La Pampa      2015    57   343373\n4 La Pampa      2016    67   345361\n\n\n\ndatos |&gt; \n  filter(jurisdiccion %in% c(\"Buenos Aires\", \"La Pampa\"))\n\n# A tibble: 4 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 La Pampa      2015    57   343373\n4 La Pampa      2016    67   345361\n\n\nFiltramos las observaciones de 2016 con casos mayores a 200 utilizando el conector AND (&). Es el mismo resultado que si utilizamos una coma.\n\ndatos |&gt; \n  filter(año == \"2016\" & casos &gt; 200)\n\n# A tibble: 6 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2016   957 16789474\n2 CABA          2016   427  3050000\n3 Cordoba       2016   368  3607843\n4 Mendoza       2016   254  1909774\n5 Salta         2016   230  1352941\n6 Tucuman       2016   246  1618421\n\n\nFiltramos las observaciones inversas a la anterior mediante xor(), que selecciona los valores de año y casos exclusivos (es decir que no se den ambos en TRUE).\n\ndatos |&gt; \n  filter(xor(año == \"2016\", casos &gt; 200))\n\n# A tibble: 25 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374\n 2 CABA          2015   901  3054237\n 3 Catamarca     2016    51   401575\n 4 Chaco         2016     9  1125000\n 5 Chubut        2016    89   577922\n 6 Cordoba       2015   468  3572519\n 7 Corrientes    2016    99  1076087\n 8 Entre Rios    2016   109  1329268\n 9 Formosa       2016    60   582524\n10 Jujuy         2016   133   734807\n# ℹ 15 more rows\n\n\n\n\nFunción arrange()\nLa función arrange() se utiliza para ordenar las filas de un conjunto de datos de acuerdo a una o varias columnas/variables. Por defecto, el ordenamiento es ascendente alfanumérico.\nOrdenamos la tabla datos por la variable pob (forma ascendente predeterminada):\n\ndatos |&gt; \n  arrange(pob)\n\n# A tibble: 48 × 4\n   jurisdiccion       año casos    pob\n   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Tierra del Fuego  2015    36 152542\n 2 Tierra del Fuego  2016    34 156682\n 3 Santa Cruz        2015    65 320197\n 4 Santa Cruz        2016    59 329609\n 5 La Pampa          2015    57 343373\n 6 La Pampa          2016    67 345361\n 7 La Rioja          2015    41 369369\n 8 La Rioja          2016     6 375000\n 9 Catamarca         2015    69 396552\n10 Catamarca         2016    51 401575\n# ℹ 38 more rows\n\n\nPara ordenar en forma descendente podemos utilizar desc() dentro de los argumentos de arrange():\n\ndatos |&gt; \n  arrange(desc(pob))\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2016   957 16789474\n 2 Buenos Aires  2015  1513 16626374\n 3 Cordoba       2016   368  3607843\n 4 Cordoba       2015   468  3572519\n 5 Santa Fe      2016   170  3400000\n 6 Santa Fe      2015   301  3382022\n 7 CABA          2015   901  3054237\n 8 CABA          2016   427  3050000\n 9 Mendoza       2016   254  1909774\n10 Mendoza       2015   316  1880952\n# ℹ 38 more rows\n\n\nPodemos combinar ordenamientos. Por ejemplo, en forma alfabética ascendente para jusrisdiccion y luego numérica descendente para casos.\n\ndatos |&gt; \n  arrange(jurisdiccion, desc(casos))\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374\n 2 Buenos Aires  2016   957 16789474\n 3 CABA          2015   901  3054237\n 4 CABA          2016   427  3050000\n 5 Catamarca     2015    69   396552\n 6 Catamarca     2016    51   401575\n 7 Chaco         2015    15  1153846\n 8 Chaco         2016     9  1125000\n 9 Chubut        2015   110   567010\n10 Chubut        2016    89   577922\n# ℹ 38 more rows\n\n\n\n\nFunción mutate()\nEsta función nos proporciona computar tranformaciones de variables en un conjunto de datos. A menudo, tendremos la necesidad de modificar variables existentes o crear nuevas variables que se calculan a partir de las que tenemos, mutate() nos ofrece una interface clara para realizar este tipo de operaciones.\nPor ejemplo, nos puede interesar calcular tasas crudas para cada jurisdicción y año, en función de los casos y el total de población.\n\ndatos |&gt; \n  mutate(tasa = casos/pob*100000)\n\n# A tibble: 48 × 5\n   jurisdiccion   año casos      pob  tasa\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374  9.10\n 2 Buenos Aires  2016   957 16789474  5.70\n 3 CABA          2015   901  3054237 29.5 \n 4 CABA          2016   427  3050000 14   \n 5 Catamarca     2015    69   396552 17.4 \n 6 Catamarca     2016    51   401575 12.7 \n 7 Chaco         2015    15  1153846  1.30\n 8 Chaco         2016     9  1125000  0.8 \n 9 Chubut        2015   110   567010 19.4 \n10 Chubut        2016    89   577922 15.4 \n# ℹ 38 more rows\n\n\nObservemos que la función realiza el cálculo (en este caso tasas crudas por 100000 habitantes) e incorpora una nueva variable por cada observación con el resultado.\nTambién se pueden construir múltiples variables en la misma expresión, solamente separadas por comas.\n\ndatos |&gt; \n  mutate(tasaxcien_mil = casos/pob*100000, \n         tasaxdiez_mil = casos/pob*10000)\n\n# A tibble: 48 × 6\n   jurisdiccion   año casos      pob tasaxcien_mil tasaxdiez_mil\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374          9.10         0.910\n 2 Buenos Aires  2016   957 16789474          5.70         0.570\n 3 CABA          2015   901  3054237         29.5          2.95 \n 4 CABA          2016   427  3050000         14            1.4  \n 5 Catamarca     2015    69   396552         17.4          1.74 \n 6 Catamarca     2016    51   401575         12.7          1.27 \n 7 Chaco         2015    15  1153846          1.30         0.130\n 8 Chaco         2016     9  1125000          0.8          0.08 \n 9 Chubut        2015   110   567010         19.4          1.94 \n10 Chubut        2016    89   577922         15.4          1.54 \n# ℹ 38 more rows\n\n\nSi necesitemos que estas dos nuevas variables queden dentro de la tabla de datos y no solo mostrarla en consola como hasta ahora, debemos utilizar el operador de asignación:\n\ndatos &lt;- datos |&gt; \n  mutate(tasaxcien_mil = casos/pob*100000, \n         tasaxdiez_mil = casos/pob*10000)\n\nLa propiedad imprescindible es que la función debe poder vectorizar: debe tomar un vector de valores como entrada, y devolver un vector con el mismo número de valores que la salida.\nNo hay forma de enumerar todas las funciones posibles que se podría usar, pero mencionaremos algunas que pueden ser útiles:\n\nOperadores aritméticos: +, -, *, /, ^.\nAritmética modular: %/% (división entera) y %% (resto), donde \\(x == y * (x \\ \\%/\\% \\ y) + (x\\ \\%\\% \\ y)\\). La aritmética modular es una herramienta útil porque te permite dividir números enteros en porciones.\nFunciones matemáticas: log(), log2(), log10(), exp(), sqrt(), abs(), etc\nValores acumulados: R proporciona funciones para ejecutar sumas, productos, mínimos y máximos acumulados: cumsum(), cumprod(), cummin(), cummax(); y dplyr proporciona cummean() para promedios acumulados.\nClasificaciones (ranking): hay una serie de funciones de clasificación, por ejemplo min_rank(). Genera el tipo de clasificación habitual (1º, 2º, etc). El valor predeterminado relaciona los valores más pequeños a rangos pequeños; podemos usar desc(x) para invertir la relación (valores más grandes a rangos más pequeños)\n\nSi utilizamos el mismo nombre de una variable incluída dentro de la tabla de datos, estaremos sobrescribiendola (se usa cuando transformamos una variable, por ejemplo: le cambiamos su tipo de character a factor). Para que la variable sea nueva debe nombrarse con un nombre que no exista previamente dentro de la tabla de datos.\n\n\nFunciones condicionales\nDentro un mutate(), algunas veces vamos a necesitar agrupar, agregar o discretizar variables continuas donde generemos variables dicotómicas o politómicas.\nEstas funciones que llamaremos “condicionales”, dado que utilizan condiciones para decidir que valor tomar, no se limitan a la tarea de construir agrupamientos de variables cuantitativas sino que sirven para cualquier situación donde a partir de una o más condiciones se produzcan una o más valores como respuesta.\n\nCondicional simple - función if_else()\nPara salidas dicotómicas tenemos la función condicional if_else() derivada de la simplificación del IF condicional que existe en todos los lenguajes de programación.\nSupongamos que creamos una nueva variable dentro del dataframe datos que se llama variable_nueva de tipo cualitativa y queremos que la misma tome valores a partir del cumplimiento de una condición de una variable cuantitativa existente denominada var1.\nSi los valores de var1 son mayores a 10, entonces variable_nueva, tomará el valor “mayor a 10”, en caso contrario, tomará el valor “menor o igual a 10”\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"mayor a 10\", \n                                  false = \"menor o igual a 10\"))\n\nif_else() tiene tres argumentos obligatorios, el primero siempre es una condición, el segundo y el tercero son los valores que tomará la nueva variable si esa condición se cumple o no se cumple.\nHabitualmente decimos que en este proceso dicotomizamos una variable, dado que el resultado posible consta siempre de 2 valores.\nLos valores de salida de esta función pueden ser de variado tipo (caracter, numerico o logico) aunque si estamos discretizando una variable cuantitativa generalmente construimos una variable resultado cualitativa ordinal. Es común que esta variable salida sea tipo character (observar que las nuevas categorías van encerradas entre comillas).\nAhora bien, al ser ordinal estas categorías de la variable_nueva deben “ordenarse” en la forma de los valores de la variable, pero el lenguaje R no sabe con que estamos trabajando y respeta siempre el ordenamiento alfanumérico. Por lo tanto, en este ejemplo las categorías se van a estar ordenando al reves del orden numérico natural (de menor a mayor).\n“mayor a 10” se ordena alfabéticamente antes de “menor o igual a 10”, porque luego del empate de las letras m, le siguen la a en el primer caso y la e en el segundo.\nPara ordenar estas categorías debemos transformar la variable de caracter a factor. Esto se puede hacer en un solo paso dentro del mutate:\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"mayor a 10\", \n                                   false = \"menor o igual a 10\"),\n         variable_nueva = factor(variable_nueva, \n                                 levels = c(\"menor o igual a 10\",\n                                            \"mayor a 10\")))\n\nOtra forma más artesanal, igualmente válido, es “forzar” el ordenamiento con las categorías así:\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"2.mayor a 10\", \n                                  false = \"1.menor o igual a 10\"))\n\nAquí agregamos números iniciales a las etiquetas de las categorías para darle el orden que deseamos, sin necesidad de convertir a factor.\n\n\nCondicional multiple\nEn salidas politómicas a partir de variables cuantitativas tenemos varias opciones dependiendo de si los intervalos de clase a construir son regulares o irregulares.\n\n\nFunción cut_interval()\ntidyverse ofrece la función cut_interval() para la creación de intervalos regulares.\nEs una adptación de la función cut() de R base para tidy data y sus argumentos son similares.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = cut_interval(x = var1, \n                                  length = 10,\n                                  right = T,\n                                  labels = T,\n                                  ordered_result = F))\n\nLos argumentos obligatorios y opcionales de la función cut() son:\n\nx: [obligatorio] El conjunto de datos numéricos de entrada (variable cuantitativa continua)\nlength: [obligatorio] la longitud de cada intervalo regular\nright: [opcional] Indica si los intervalos son cerrados a la derecha o viceversa. Por defecto vale TRUE (cerrados a derecha)\nlabels: [opcional] Etiquetas de los intervalos automáticas o numéricas. Valor predeterminado TRUE (intervalos matemáticos)\nordered_result: [opcional] - determina si el resultado es un factor ordenado. Por defecto vale FALSE (la salida es tipo caracter)\n\nLos argumentos opcionales no son necesarios definirlos siempre y cuando los valores por defecto son los que sirven para la tarea.\n\n\nFunción case_when()\nCuando las condiciones no son simples, es decir, el resultado no es dicotómico y además los intervalos son irregulares, utilizamos la función case_when() que es una vectorización de la función if_else().\nSupongamos que no queremos agrupar la variable en dos valores, sino en 3 grupos irregulares.\nEsquema básico de funcionamiento:\n\n# var1 es una variable cuantitativa de números enteros \n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n    var1 &gt;= 0 & var1 &lt; 25  ~  \"Grupo1\", \n    var1 &gt; 24 & var1 &lt; 65  ~    \"Grupo 2\", \n    var1 &gt;= 65             ~    \"Grupo 3\"))\n\nExiste una condición por cada grupo creado, como si fuese un if_else() donde el valor declarado siempre es el verdadero. Se utilizan operadores de comparación como mayor ( &gt; ), menor ( &lt; ) y/o igual ( = ) y conectores lógicos como & ( AND ). En cada línea va una virgulilla similar a la usada en la sintaxis formula ( ~ ) y luego la etiqueta que tomarán las observaciones que cumplan con esa condición en la nueva variable (grupo_var).\nEsta evaluación es secuencial y su funcionamiento provoca que el usuario del lenguaje tenga el control de lo que esta sucediendo, por lo que cualquier mala definición de las condiciones puede provocar resultados incorrectos.\nSi incorporamos el argumento .default podemos indicar que valor toma si no se cumple ninguna de las condiciones anteriores.\nPor ejemplo, podríamos tener algun valor perdido (NA) en var1 y queremos que la variable grupo_var etiquete esos valores perdidos como “Sin dato”:\n\n# var1 es una variable cuantitativa de números enteros con algun valor NA\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n        var1 &gt;= 0 & var1 &lt; 25  ~  \"Grupo1\", \n        var1 &gt; 24 & var1 &lt; 65  ~    \"Grupo 2\", \n        var1 &gt;= 65             ~    \"Grupo 3\",\n        .default = \"Sin dato\"))\n\nLas salidas son de tipo carácter (chr) y debemos manejar el ordenamiento de las etiquetas como vimos anteriormente, por medio de factores o comenzando con caracteres ordenados alfabeticamente.\nPara simplificar el trabajo de estos intervalos de clase irregulares y no provocar errores en la confección de las condiciones, tidyverse tiene a la función between().\n\n\nIntervalos - función between()\nBáicamente opera como un atajo para condiciones de intervalos. Define dentro de los argumentos los límites inferior y superior de un intervalo y se utiliza dentro de una función de condición tipo if_else() o case_when().\nAplicado sobre el ejemplo anterior se vería así:\n\n# var1 es una variable cuantitativa de números enteros con algun valor NA\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n    between(var1, 0, 24)   ~  \"Grupo1\", \n        between(var1, 25, 64)  ~    \"Grupo 2\", \n        between(var1, 65, Inf) ~    \"Grupo 3\",\n        .default = \"Sin dato\"))\n\nLos valores declarados como límites quedan incluídos siempre dentro del intervalo (son cerrados ambos). También podemos utilizar valores reservados como Inf o -Inf cuando desconocemos con que valor máximo o mínimo nos vamos a encontrar en la variable cuantitativa original.\n\n\nEjemplos con variable edad\nTomemos un caso clásico como la variable edad medida en años, variable que generalmente tenemos en toda tabla de datos vinculada a personas. En este ejemplo la variable tiene 106 observaciones.\nUna posibilidad es dicotomizarla usando el valor de la mediana que divide 2 dos partes toda la distribución.\n\ndatos |&gt; \n  summarise(mediana = median(edad))\n\n# A tibble: 1 × 1\n  mediana\n    &lt;dbl&gt;\n1      56\n\n\nAplicando el valor 56 dentro de un if_else podriamos hacer:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"mayor a la mediana\", \n                                  false = \"menor o igual a la mediana\"))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                    n\n  &lt;chr&gt;                      &lt;int&gt;\n1 mayor a la mediana            52\n2 menor o igual a la mediana    54\n\n\nObservamos en el conteo que grupo_edad1 se construyó adecuadamente pero el orden de los niveles no es correcto si queremos que siga el ordenamiento natural de edad (de menor a mayor).\nUna de las formas que vimos es convertir a factor:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"mayor a la mediana\", \n                                  false = \"menor o igual a la mediana\"),\n         grupo_edad1 = factor(grupo_edad1, \n                                 levels = c(\"menor o igual a la mediana\",\n                                            \"mayor a la mediana\")))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                    n\n  &lt;fct&gt;                      &lt;int&gt;\n1 menor o igual a la mediana    54\n2 mayor a la mediana            52\n\n\nVemos que en el conteo el formato de la variable ya no es chr sino fct y el orden de las etiquetas siguen la forma “menor a mayor”.\nOtra forma es:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"2.mayor a la mediana\", \n                                  false = \"1.menor o igual a la mediana\"))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                      n\n  &lt;chr&gt;                        &lt;int&gt;\n1 1.menor o igual a la mediana    54\n2 2.mayor a la mediana            52\n\n\nSi en cambio necesitamos que los grupos sean mas de dos y que estos intervalos de clase sean regulares, podemos usar cut_interval\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;fct&gt;       &lt;int&gt;\n1 [0,10]          3\n2 (10,20]         3\n3 (20,30]         2\n4 (30,40]         3\n5 (40,50]        13\n6 (50,60]        52\n7 (60,70]        27\n8 (70,80]         3\n\n\nLa salida muestra 8 grupos etarios con etiquetas ordenadas con notación matemática, donde un corchete indica que el límite del intervalo es cerrado, es decir contiene el valor y un paréntesis es abierto y no lo hace.Así es que el primer grupo va de 0 a 10 años y el segundo de 11 a 20.\nEstos sucede así porque en forma predeterminada el argumento right está en TRUE. Veamos que pasa si lo cambiamos a FALSE:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    right = F))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;fct&gt;       &lt;int&gt;\n1 [0,10)          3\n2 [10,20)         3\n3 [20,30)         2\n4 [30,40)         3\n5 [40,50)        10\n6 [50,60)        48\n7 [60,70)        32\n8 [70,80]         5\n\n\nEn esta salida el primer grupo va de 0 a 9 y el segundo de 10 a 19.\nHasta ahora la variable grupo_edad2 es de tipo caracter, pero si deseamos que la salida sea factor podemos incorporar el argumento ordered_result en TRUE.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    ordered_result = T))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;ord&gt;       &lt;int&gt;\n1 [0,10]          3\n2 (10,20]         3\n3 (20,30]         2\n4 (30,40]         3\n5 (40,50]        13\n6 (50,60]        52\n7 (60,70]        27\n8 (70,80]         3\n\n\nConstruimos así una variable factor ordenada .\nPor último, con el argumento labels en FALSE hacemos que las etiquetas de los 8 grupos sean numéricas.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    labels = F))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n        &lt;int&gt; &lt;int&gt;\n1           1     3\n2           2     3\n3           3     2\n4           4     3\n5           5    13\n6           6    52\n7           7    27\n8           8     3\n\n\nOtro ejemplo, podría ser aplicando case_when() donde discretizamos la edad en 4 grupos irregulares, forzando sus etiquetas para lograr el orden adecuado.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo3 = case_when(\n    edad &lt; 13              ~ \"1.Niño\",\n    edad &gt; 12 & edad &lt; 26  ~ \"2.Adolescente\",\n    edad &gt; 25 & edad &lt; 65  ~ \"3.Adulto_joven\",\n    edad &gt; 64              ~ \"4.Adulto_mayor\"\n  ))\n\ndatos |&gt; \n  count(grupo3)   \n\n# A tibble: 4 × 2\n  grupo3             n\n  &lt;chr&gt;          &lt;int&gt;\n1 1.Niño             3\n2 2.Adolescente      5\n3 3.Adulto_joven    86\n4 4.Adulto_mayor    12\n\n\nSi no hubiesemos etiquetado con los numeros por delante el orden alfabético hacía que Niño fuese a parar al final del conteo.\nDe la misma forma pero más sencillo y controlado es:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo3 = case_when(\n    between(edad, 0, 12)   ~ \"1.Niño\",\n    between(edad, 13, 25)  ~ \"2.Adolescente\",\n    between(edad, 26, 64)  ~ \"3.Adulto_joven\",\n    between(edad, 65, Inf) ~ \"4.Adulto_mayor\"\n  ))\n\ndatos |&gt; \n  count(grupo3)  \n\n# A tibble: 4 × 2\n  grupo3             n\n  &lt;chr&gt;          &lt;int&gt;\n1 1.Niño             3\n2 2.Adolescente      5\n3 3.Adulto_joven    86\n4 4.Adulto_mayor    12\n\n\n\n\n\nFunción summarise()\nLa función summarise() (se puede escribir también summarize()) resume variables de un conjunto de datos.\n\ndatos |&gt; \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos))\n\n# A tibble: 1 × 2\n  promedio_casos casos_totales\n           &lt;dbl&gt;         &lt;dbl&gt;\n1           192.          9211\n\n\nSu uso es muy interesante cuando la combinamos con group_by() (función que detallaremos luego). Esta situación permite estratificar los resultados por grupos específicos.\nPor ejemplo, podemos agrupar el por año y simultáneamente aplicar el mismo summarise() anterior.\n\ndatos |&gt;  \n  group_by(año) |&gt;  \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos))\n\n# A tibble: 2 × 3\n    año promedio_casos casos_totales\n  &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1  2015           224.          5369\n2  2016           160.          3842\n\n\nEl resultado es una tabla con dos filas, una para cada grupo (año 2015 y año 2016) con los valores promedio y casos totales respectivos.\nAlgunas de las funciones del R base que se pueden utilizar dentro de los argumentos de esta función son:\n\nmin() mínimo\nmax() máximo\nmean() media\nmedian() mediana\nvar() varianza\nsd() desvío\nsum() sumatoria\n\nOtras funciones que se pueden incorporar las provee el mismo paquete dplyr, por ejemplo:\n\nfirst() primer valor en el vector\nlast() último valor en el vector\nn() número de valores en el vector\nn_distinct() números de valores distintos en el vector\n\nDesde la versión 1.4.0 de dplyr la función summarise() incorpora un nuevo argumento para agrupamientos temporales. El argumento .by = trabaja igual que un group_by() previo pero lo hace solo para realizar el calculo definido dentro del resumen evitando que el dataframe de salida mantenga el agrupamiento.\nLa estructura básica de la función actualizada es:\n\ndatos |&gt; \n  summarise(\n    var_resumen = funcion(var),\n    .by = var_grupo\n  )\n\nAplicada en el ejemplo previo:\n\ndatos |&gt;  \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos),\n            .by = año)\n\n# A tibble: 2 × 3\n    año promedio_casos casos_totales\n  &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1  2015           224.          5369\n2  2016           160.          3842\n\n\n\n\nFunción group_by()\nDecíamos recién que la función group_by() es útil cuando trabaja conjuntamente con summarise() dado que agrupa un conjunto de filas seleccionado en un conjunto de filas de resumen de acuerdo con los valores de una o más columnas o expresiones.\nPara ejemplificar su trabajo asociado obtendremos una nueva tabla con el cálculo de las tasas crudas para cada jurisdicción por año (similar al ejemplo de la aplicación de mutate():\n\ndatos |&gt; \n  group_by(jurisdiccion, año) |&gt;  \n  summarise(tasa = casos/pob*100000)\n\n# A tibble: 48 × 3\n# Groups:   jurisdiccion [24]\n   jurisdiccion   año  tasa\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  9.10\n 2 Buenos Aires  2016  5.70\n 3 CABA          2015 29.5 \n 4 CABA          2016 14   \n 5 Catamarca     2015 17.4 \n 6 Catamarca     2016 12.7 \n 7 Chaco         2015  1.30\n 8 Chaco         2016  0.8 \n 9 Chubut        2015 19.4 \n10 Chubut        2016 15.4 \n# ℹ 38 more rows\n\n\nEn la mayoría de estos ejemplos la salida es directa, es decir no construimos nuevos objetos contenedores de los datos producidos y vemos los resultados en consola o en el visualizador de RStudio. Pero en muchas situaciones vamos a necesitar generar nuevos conjunto de datos con las transformaciones realizadas. Si en alguna de estas ocasiones llegamos a agrupar datos mediante group_by() y posteriormente necesitamos volver a tener la información desagrupada existe una función vinculada denominada ungroup() que vamos a necesitar aplicar o bien si no se desea tener el agrupamiento de forma fija se puede usar el argumento .by = del summarise() como mostramos anteriormente.\n\n\nCombinaciones\nEn los ejemplos anteriores vimos como se van integrando alguna de las funciones mediante el uso de la tubería %&gt;% o |&gt;. La idea detrás de la búsqueda gramatical del paquete es poder enlazar las acciones para construir oraciones más complejas.\nUn ejemplo que podría integrar gran parte de los visto sería:\nObtener una nueva tabla con las tasas crudas de casos notificados de VIH, por año y jurisdicción, mayores a 20 x 100000 habitantes ordenadas de mayor a menor.\n\ndatos |&gt;                                   # siempre partimos de los datos\n  group_by(año, jurisdiccion) |&gt;           # agrupamos\n  summarise(tasa = casos/pob*100000) |&gt;    # resumimos\n  filter(tasa &gt; 20) |&gt;                     # filtramos\n  arrange(desc(tasa))                       # ordenamos   \n\n# A tibble: 5 × 3\n# Groups:   año [2]\n    año jurisdiccion      tasa\n  &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1  2015 CABA              29.5\n2  2015 Tierra del Fuego  23.6\n3  2015 Jujuy             22.0\n4  2016 Tierra del Fuego  21.7\n5  2015 Santa Cruz        20.3\n\n\nObservemos que una buena manera de construir el código es respetar un salto de línea para cada término de la oración para una lectura más clara.\nDemostramos así la potencialidad que tienen estas funciones combinadas donde en esta situación integramos las funciones group_by(), summarise() , filter() y arrange() en una misma operación.\n\n\nFunción count()\nEsta última función que presentamos permite contar rápidamente los valores únicos de una o más variables.\nProduce fácilmente tablas de frecuencias absolutas que luego posibilitan construir frecuencias relativas.\nLa aplicamos sobre la variable jurisdiccion de datos\n\ndatos |&gt; \n  count(jurisdiccion)\n\n# A tibble: 24 × 2\n   jurisdiccion     n\n   &lt;chr&gt;        &lt;int&gt;\n 1 Buenos Aires     2\n 2 CABA             2\n 3 Catamarca        2\n 4 Chaco            2\n 5 Chubut           2\n 6 Cordoba          2\n 7 Corrientes       2\n 8 Entre Rios       2\n 9 Formosa          2\n10 Jujuy            2\n# ℹ 14 more rows\n\n\nTiene un par de argumentos opcionales:\n\nname: es el nombre de la columna con el conteo. Por defecto se llama n\nsort: ordena la tabla de frecuencia de mayor a menor\nwt: se puede opcionalmente incorporar una variable con la ponderación (factor de expansión) para el calculo de la frecuencia."
  },
  {
    "objectID": "primero/clases/03-introTidy.html#gráficos-estadísticos-con-ggplot2",
    "href": "primero/clases/03-introTidy.html#gráficos-estadísticos-con-ggplot2",
    "title": "Tidyverse",
    "section": "Gráficos estadísticos con ggplot2",
    "text": "Gráficos estadísticos con ggplot2\nggplot2 es un paquete que se autodefine como librería para “crear elegantes visualizaciones de datos usando una gramática de gráficos”\nPropone una forma intuitiva de construir gráficos basada en The Grammar of Graphics, a partir de utilizar capas y un sistema apoyado en tres componentes básicos:\n\ndatos\ncoordenadas\nobjetos geométricos\n\nLa estructura para construir un gráfico es la siguiente:\n\n\n\n\n\n\n\n\n\n\nAnatomía de gráficos con ggplot2\nEl paquete se basa en una gramática de gráficos que puede ser entendida a partir de conocer sus componentes:\n\n\n\n\n\n\n\n\n\n\ndata es aquél conjunto de datos que vamos a graficar, con toda la información pertinente para realizar el gráfico.\naes reducción de aesthetic mapping o mapeo estético en el que se puede declarar todo lo que puede ser visible de un gráfico.\ngeoms son representaciones para dibujar gráficos (puntos, líneas, cajas, entre otros).\nstats son aquellas transformaciones estadísticas que le hacemos a los datos. Nos ayudan a hacer un resumen del conjunto de datos para visualizar mejor (por ejemplo, la media o la mediana como estadísticas de tendencia central).\nscales facilitan colorear (o escalar) los datos según distintas variables. Dibujan los ejes y las leyendas.\ncoordinate Systems es el sistema de coordenadas para el mapeo del gráfico en un plano bidimensional.\nfacets nos permiten partir el conjunto de datos según factores para graficar en viñetas separadas creando matrices gráficas.\nthemes son conjuntos de características gráficas que permiten controlar la apariencia general de todos los elementos que no son datos (por ejemplo, el color del fondo o el tipo de fuente).\n\nAntes de comenzar a explicar cada componente vamos a leer un conjunto de datos que nos permita mostrar los ejemplos gráficos.\n\nlibrary(tidyverse)\n\nfacultad &lt;- read_csv(\"datos/facultad.csv\") # lectura\n\nhead(facultad) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 18\n     HC SEXO   EDAD ANT_DIABETES ANT_TBC ANT_CANCER ANT_OBESIDAD ANT_ECV ANT_HT\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt; \n1 26880 M        17 NO           NO      NO         SI           NO      SI    \n2 26775 M        18 SI           NO      NO         NO           NO      NO    \n3 26877 M        18 SI           NO      SI         NO           NO      SI    \n4 26776 M        18 NO           NO      NO         SI           SI      NO    \n5 26718 M        18 NO           NO      NO         NO           NO      SI    \n6 26738 M        18 NO           NO      NO         NO           NO      SI    \n# ℹ 9 more variables: ANT_COL &lt;chr&gt;, FUMA &lt;chr&gt;, EDADINI &lt;dbl&gt;, CANTIDAD &lt;dbl&gt;,\n#   COL &lt;dbl&gt;, PESO &lt;dbl&gt;, TALLA &lt;dbl&gt;, SIST &lt;dbl&gt;, DIAST &lt;dbl&gt;\n\n\nEl archivo leído se llama facultad.csv y contiene información de salud sobre ingresantes a una facultad tales como sexo, edad, talla y peso, entre otras. (son datos ficticios con fines docentes).\n\n\nMapeo estético (aesthetic mapping) y objetos geométricos (geom)\nDecíamos que aes() hace referencia al contenido estético del gráfico. Es decir, la función le brinda indicios a ggplot2 sobre cómo dibujar los distintas líneas, formas, colores y tamaños.\nEs importante notar que aes() crea una nueva capa en relación a las variables y agrega leyendas a los gráficos. Al incorporar aes() al llamado de ggplot() estamos compartiendo la información estética en todas las capas. Si deseamos que esa información sólo esté en una de las capas, debemos usar aes() en la capa correspondiente.\nVeamos como funciona y sus diferencias.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO)) # solo la capa estética aes()\n\n\n\n\n\n\n\n\n\n\nEste gráfico solo contiene los ejes que especificamos (PESO y TALLA) pero no contiene los datos. Si deseamos incorporarlos agregamos una capa de puntos con geom_point() a través del símbolo +.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO))  + \n  geom_point()                    # agregamos la capa geométrica de puntos\n\n\n\n\n\n\n\n\n\n\nPodemos diferenciar los puntos según se traten de ingresantes mujeres y hombres, asociando el argumento color dentro de aes() con la variable SEXO.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO, color = SEXO)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nEstos gráficos también posibilitan el agregado de otra capa geométrica, por ejemplo rectas de regresión para cada grupo según sexo.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO, color = SEXO)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")            # agregamos una segunda capa geométrica \n\n\n\n\n\n\n\n\n\n\nEsta función geom_smooth() posee distintos métodos y en este ejemplo utilizamos el de regresión lineal entre talla y peso junto a sus intervalos de confianza.\nA continuación vamos a ver que diferencias existen cuando aes() se encuentra dentro del ggplot() y cuando se ubica en otras capas de funciones como en geom_point()\nDecíamos anteriormente que al incorporar aes() al llamado de ggplot() estamos compartiendo la información estética en todas las capas.\nEntonces si quitamos aes() de allí y lo ubicamos en una capa única, esta configuración deja de afectar al conjunto del gráfico.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO)) + \n  geom_point(aes(color = SEXO)) + # color esta definido en el aes() \n                                  # de la capa geométrica\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\nEn este ejemplo, aes() para el color solo se ubica dentro de geom_point() y por lo tanto dibuja los puntos con sus respectivos colores, pero no afecta a la capa de geom_smooth() produciendo solo una línea de regresión para el conjunto de puntos.\nEs decir que geom_smooth() no recibe la orden de agrupar según SEXO, a raíz de no haber definido color dentro del aes() general.\nEste comportamiento nos permite gran versatilidad en los gráficos que realicemos.\nAlgunas otras funciones de geom_ son:\ngeom_line(), para líneas\ngeom_boxplot(), para boxplot\ngeom_histogram() para histogramas\ngeom_density() para curvas de densidad\ngeom_bar() para barras\nEstas funciones geométricas aplicadas sobre los mismos datos definen el tipo de gráfico.\nPara ejemplificar, podemos gráficar dos variables como SEXO y TALLA generando una base a la que sumaremos capas diferentes de geom():\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, color = SEXO)) + \n  geom_point()                # capa geométrica de puntos\n\n\n\n\n\n\n\n\n\n\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, color = SEXO)) + \n  geom_boxplot()            # capa geométrica de boxplot\n\n\n\n\n\n\n\n\n\n\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, color = SEXO)) + \n  geom_jitter()               # capa geométrica jitter (entramado de puntos)\n\n\n\n\n\n\n\n\n\n\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, fill = SEXO)) + \n  geom_violin()            # capa geométrica de violin\n\n\n\n\n\n\n\n\n\n\nObservemos que en este último gráfico cambiamos, dentro de aes(), color por fill. Mientras que color define el color del contorno del polígono, la línea de una recta o curva y los puntos, fill define el relleno de los objetos como es el caso de los violines construidos o cualquier elemento geométrico de polígono.\n\n\nEscalas (scale)\nLas configuraciones que se pueden realizar con scale son numerosas. Entre ellas encontramos cambios de color de contorno y relleno, cambios de posición, de tamaño y tipo de línea.\nEl argumento para modificar valores de escala comienzan siempre con con scale_ (por ejemplo scale_fill_ )\nSigamos trabajando con el conjunto de datos leído para mostrar ejemplos de gráficos donde agregamos capas de escala para color de relleno. ( scale_fill_brewer() )\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, fill = SEXO)) + \n  geom_boxplot() +\n  scale_fill_brewer(palette = \"Oranges\")   # paleta de los naranjas\n\n\n\n\n\n\n\n\n\n\nEn este ejemplo aplicamos una capa scale_fill_brewer() con una paleta de colores (Oranges) que se vincula con el argumento fill de aes() y definen los colores del boxplot.\nLo mismo hacemos para una gama de grises mediante scale_fill_grey()\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, fill = SEXO)) + \n  geom_boxplot() +\n  scale_fill_grey(start = 0.4, end = 0.8)   # paleta de los grises\n\n\n\n\n\n\n\n\n\n\nOtro uso de escalas, esta vez aplicado a los ejes, es la inversión del eje x.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO, color = SEXO)) +\n  geom_point() +\n  scale_x_reverse()     # escala inversa de x\n\n\n\n\n\n\n\n\n\n\nComo se observa en el gráfico la inclusión de scale_x_reverse() provoca que la escala x se invierta, quedando la TALLA ordenada de mayor a menor.\nPor último, otro ejemplo interesante es aplicado a escalas de etiquetado de ejes. Volvamos al ejemplo reciente de boxplot con relleno en escala de grises, su eje y se dibuja predeterminado desde 130 a casi 200 cms con cortes cada 5 cms y etiquetas cada 10 cms.\nCon escalas continuas manuales de la forma scale_*_continuos() podemos personalizar el eje y.\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, fill = SEXO)) + \n  geom_boxplot() +\n  scale_fill_grey(start = 0.4, end = 0.8)   +\n  scale_y_continuous(breaks = seq(130,200,2))\n\n\n\n\n\n\n\n\n\n\nEn este caso particular definimos un eje y con etiquetas de 2 en 2, mediante la línea scale_y_continuous(breaks = seq(130,200,2))\n\n\nTransformaciones estadísticas (stat)\nAlgunos gráficos no requieren de transformaciones estadísticas, en cambio, otros como boxplot, histogramas, etc poseen valores predeterminados de stat que pueden ser modificados.\nEstos valores se encuentra en forma de argumentos dentro de la función geométrica, por ejemplo para los histograma el argumento bins define la cantidad de intervalos de clase.\n\nfacultad |&gt; \n  ggplot(aes(EDAD)) +\n    geom_histogram(bins = nclass.Sturges(facultad$EDAD), fill = \"Blue\")\n\n\n\n\n\n\n\n\n\n\nVemos que el gráfico se construyó utilizando la regla de Sturges para determinar la cantidad de intervalos de clase para la variable EDAD. (función nclass.Sturges())\nOtras transformaciones estadísticas se incorporan como capas independientes, por ejemplo si queremos agregar los valores de media a los boxplot de talla según sexo construidos anteriormente.\n\nfacultad |&gt; \n  ggplot(aes(SEXO, TALLA, fill = SEXO)) + \n  geom_boxplot() +\n  scale_fill_brewer(palette = \"Greens\") +\n  stat_summary(fun = mean, color = \"darkred\", geom = \"point\", \n               shape = 18, size = 3)\n\n\n\n\n\n\n\n\n\n\nAquí la capa completa surge a partir de la función stat_summary(), con argumentos que indican que se aplique la función mean. Incluye también la definición del objeto geométrico (point) que representa el valor de media (color, forma y tamaño)\n\n\nFacetado (facet)\nCon facet es posible separar gráficos en distintas ventanas o viñetas, creando matrices de gráficos separados por grupos de datos, a partir de la estratificación, en función de diferentes categorías de una variable cualitativa.\nEste comportamiento es sumamente útil cuando tenemos más de una variable categórica o cuando deseamos utilizar color para simbolizar otra variable.\nggplot ofrece dos posibilidades de hacer el facetado:\n\nfacet_wrap() – define subgrupos a partir de los niveles de una sola variable categórica\nfacet_grid() – define subgrupos a partir del cruce de dos variables de categóricas.\n\nUna aplicación de facet_wrap() podría ser que el primer gráfico que hicimos de dispersión de puntos con las variables TALLA y PESO se visualice en dos gráficos distintos según cada categoría de SEXO.\n\nfacultad |&gt; \n  ggplot(aes(TALLA, PESO, color = SEXO)) +\n     geom_point() +\n     facet_wrap(~SEXO)\n\n\n\n\n\n\n\n\n\n\nUsamos facet_grid() para crear una matriz producto del cruce de las variables FUMA y SEXO.Dentro de la cuadrícula graficaremos histogramas de la variable PESO coloreados por SEXO.\n\nfacultad |&gt; \n  ggplot(aes(PESO, fill = SEXO)) +\n     geom_histogram(bins = nclass.Sturges(facultad$PESO)) +\n     scale_fill_brewer(palette = \"Set1\") +\n     facet_grid(SEXO ~ FUMA)\n\n\n\n\n\n\n\n\n\n\nSi observamos las 4 líneas que integran todas las capas del código de ggplot notaremos que estamos integrando varias de las funciones que fuimos mostrando.\nSe hace imposible generar todas combinaciones posibles dada la variedad y extensión de argumentos que posee el paquete. De todas formas, el objetivo de este material es entender la base de funcionamiento, es decir la estructura “gramatical” que proponen sus autores.\n\n\nSistema de coordenadas (Coordinate Systems)\nEn algunas ocasiones puede que necesitemos introducir modificaciones en el sistema de coordinadas predeterminado.\nSobre las coordenadas cartesianas iniciales se puede invertir la orientación para que, por ejemplo, las barras se dibujen horizontales.\n\nfacultad |&gt; \n  ggplot(aes(SEXO, fill = SEXO)) +\n     scale_fill_brewer(palette = \"Set2\") +\n     geom_bar() +\n     coord_flip()   # invierte disposición de ejes\n\n\n\n\n\n\n\n\n\n\n\n\nTemas (themes)\nEl paquete ofrece un conjunto reducido de temas gráficos. El tema por defecto o inicial es theme_gray() pero se puede modificar a partir de agregar una capa de tema dentro de la estructura ggplot.\nA modo de ejemplo repetimos el último gráfico con el tema blanco y negro ( theme_bw() ):\n\nfacultad |&gt; \n  ggplot(aes(SEXO, fill = SEXO)) +\n     scale_fill_brewer(palette = \"Set2\") +\n     geom_bar() +\n     coord_flip() +\n     theme_bw()  # tema blanco y negro\n\n\n\n\n\n\n\n\n\n\nOtro tema que podemos utilizar es theme_dark() que tiene un fondo gris oscuro.\n\nfacultad |&gt; \n  ggplot(aes(SEXO, fill = SEXO)) +\n     scale_fill_brewer(palette = \"Set2\") +\n     geom_bar() +\n     coord_flip() +\n     theme_dark()\n\n\n\n\n\n\n\n\n\n\nEl siguiente cuadro muestra el nombre y presentación de los temas que contiene el paquete.\n\n\n\n\n\n\n\n\n\nContinuando con cuestiones estéticas en otra capa se pueden definir etiquetas, como título, subtítulo y nombres de ejes.\nLa forma de la función con argumentos básicos es labs( x = “Etiqueta X\", y = “Etiqueta Y\", title =“Título del gráfico\", subtitle = \"Subtítulo del gráfico\")\nAdemás se utiliza la función theme() para configurar el tipo de fuente y tamaño, entre otras opciones posibles.\n\nfacultad |&gt; \n  ggplot(aes(SEXO, fill = SEXO)) +\n     scale_fill_brewer(palette = \"Set2\") +\n     geom_bar() +\n     coord_flip() +\n     labs(y = \"Cantidad\", title = \"Distribución de Sexo\") +\n     theme(plot.title=element_text(face=\"italic\", size=16)) \n\n\n\n\n\n\n\n\n\n\n\n\nPaquete esquisse\nEsquisse es un paquete que contiene una aplicación asistente para crear gráficos ggplot2 de forma interactiva. Basta con arrastrar y soltar las variables para asignarlas a diferentes estéticas.\nPodemos visualizar rápidamente los datos de acuerdo con su tipo, exportarlos en varios formatos y recuperar el código para reproducir el gráfico.\nEl paquete se instala mediante el menú Packages de RStudio o ejecutando:\n\ninstall.packages(\"esquisse\")\n\nLuego se puede acceder a la aplicación por medio del acceso Addins\n\n\n\n\n\n\n\n\n\no ejecutando en consola esquisser()\nTambién se puede agregar el nombre de la tabla de datos dentro de los paréntesis\n\nesquisser(datos)\n\nPara más información consultar en la viñeta del paquete en CRAN."
  },
  {
    "objectID": "primero/clases/03-introTidy.html#uniones-en-datos-relacionales",
    "href": "primero/clases/03-introTidy.html#uniones-en-datos-relacionales",
    "title": "Tidyverse",
    "section": "Uniones en datos relacionales",
    "text": "Uniones en datos relacionales\nExisten situaciones donde debemos analizar datos que se encuentran en diferentes tablas.\nCon el fin de responder a nuestras preguntas de interés en ocasiones deberemos unirlas previamente.\nDe manera general, se le llama datos relacionales a esas múltiples tablas de datos que provienen muchas veces de sistemas de bases de datos construidas bajo el modelo relacional o bien cuando las tablas de datos tienen fuentes distintas pero comparten alguna variable común que permita “conectarlas”.\nUn ejemplo recurrente sucede cuando necesitamos calcular la tasa de algún evento de salud y tenemos en una tabla el conteo (dato agregado) del evento (numerador) y en otra el conteo de la población en riesgo (denominador).\n\nTipos de operaciones\nPara trabajar con datos relacionales necesitamos de funciones-verbos que vinculen pares de tablas.\nLas tres familias de funciones del paquete dplyr diseñadas para trabajar con datos relacionales son:\n\nUniones de transformación (del inglés mutating joins), agregan nuevas variables a una tabla a partir de observaciones coincidentes de otra tabla.\nUniones de filtro (del inglés filtering joins), filtran observaciones de una tabla en función de la coincidencia o no coincidencia de otra tabla.\nOperaciones en filas y columnas, sirven para unir tablas por columnas o por filas.\n\n\n\nClaves\n\nLas variables usadas para conectar cada par de variables se llaman claves (del inglés key)\nUna clave es una variable (o un conjunto de variables) que identifican de manera única una observación.\n\nExisten dos tipos de claves:\n\nUna clave primaria identifica únicamente una observación en su propia tabla.\nUna clave foránea únicamente identifica una observación en otra tabla.\n\nUna vez que identificadas las claves primarias en las tablas, es una buena práctica verificar que identifican de forma única cada observación. Una forma de hacerlo es usar count() con las claves primarias y buscar las entradas con n mayor a uno:\n\ndatos |&gt; \n  count(clave_primaria) |&gt; \n  filter(n &gt; 1)\n\nLa salida debería mostrar que no hay ninguna observación que cumpla la condición de n &gt; 1, es decir todas las observaciones tienen una sola clave primaria unívoca.\nEn ocasiones podemos tener claves primarias compuestas por más de una variable. Tendremos que utilizar entonces esta combinación de variables a la vez en las uniones que realicemos.\nOtra situación inversa es no tener ninguna variable como clave primaria, aunque sepamos que cada observación pertenece a una misma unidad de análisis pero de elementos (sujetos, etc) diferentes. Aquí se puede usar la función row_number() que numera en orden ascendente las observaciones de la tabla y almacena esta numeración en una variable, creando una clave subrogada.\n\ndatos &lt;- datos |&gt; \n  mutate(clave = row_number()) \n\n\n\nUniones de transformación\nLa forma más simple de unión es la unión interior (del inglés inner join). Una unión interior une pares de observaciones siempre que sus claves sean iguales.\nUnión interior\nUna unión interior mantiene las observaciones que aparecen en ambas tablas. La estructura del código sirve de base para las demás uniones:\n\ndatos_x |&gt; \n  inner_join(datos_y, by = \"variable_clave\") \n\n\n\n\n\n\nLa propiedad más importante de una unión interior es que las filas no coincidentes no se incluyen en el resultado\nUniones exteriores\nUna unión exterior mantiene las observaciones que aparecen en al menos una de las tablas.\n\nUna unión izquierda (left join) mantiene todas las observaciones en x.\n\n\n\n\n\n\n\nUna unión derecha (right join) mantiene todas las observaciones en y.\n\n\n\n\n\n\n\nUna unión completa (full join) mantiene todas las observaciones en x e y.\n\n\n\n\n\n\nEstas uniones funcionan agregando una observación “virtual” adicional a cada tabla. Esta observación tiene una clave que siempre coincide (de no haber otras claves coincidentes) y un valor que se llena con NA.\nOtra forma de ilustrar diferentes tipos de uniones es mediante un diagrama de Venn.\n\n\n\n\n\nSin embargo, tiene una limitante importante: un diagrama de Venn no puede mostrar qué ocurre con las claves que no identifican de manera única una observación.\n\n\nClaves duplicadas\nHasta ahora todas las situaciones han asumido que las claves son únicas. Pero esto no siempre es así.\nExisten dos posibilidades habituales:\n\nUna tabla tiene claves duplicadas producto de una relación uno a varios.\n\n\n\n\n\n\n\nAmbas tablas tienen claves duplicadas (producto de una relación real varios a varios o por algún “error”)\n\n\n\n\n\n\nSiempre que unimos claves duplicadas, obtenemos todas las posibles combinaciones, es decir, el producto cartesiano\n\n\nVariables claves\nLa forma común del argumento by = donde se define/n la/s variable/s clave/s es igualarlo al nombre la variable o variables concatenadas con c() que deberán tener el mismo nombre en las dos tablas a unir.\nOtra maneras de conectar las tablas sería:\n\nSin definir by = o bien by = NULL, que de forma predeterminada utiliza todas las variables que se llamen de la misma forma (respetando mayúsculas y minúsculas). Esta se denomina unión natural.\nUtilizar la función join_by() en el argumento by = que nos da la posibilidad de declarar cuales son las variables de unión cuando estas tengan nombres distintos en cada tabla.\n\n\ndatos_x |&gt; \n  inner_join(datos_y, \n             by = join_by(var_clave_x == var_clave_y)) \n\nObserven que la igualdad de las variables claves de x e y es un operador de comaparación ==\nEn caso que hubiese más de una variable clave de unión se puede hacer:\n\ndatos_x |&gt; \n  inner_join(datos_y, \n             by = join_by(var1_clave_x == var1_clave_y,\n                          var2_clave_x == var2_clave_y,)) \n\n\n\nUniones de filtro\nLa función semi_join() mantiene todas las observaciones de la tabla x donde la clave coincide con la clave de la tabla y\n\n\n\n\n\nPara hacer lo inverso, anti_join() descarta todas las observaciones de la tabla x donde la clave coincide con la clave de la tabla y\n\n\n\n\n\n\n\nUnión por filas y por columnas\nEn algunas ocasiones necesitamos unir tablas que tienen formatos particulares por medio de filas o por medio de columnas.\nLas funciones de dplyr para esta tarea son:\n\nbind_rows() Une una tabla debajo de otra. Aplica cuando tenemos la misma estructura en tabla de datos divida en varios archivos (por ejemplo, producto de carga simultánea de datos en diferentes computadoras con diferentes data-entry)\nbind_cols() Une una tabla al lado de la otra. Es peligroso su uso si la confundimos con las uniones de transformación porque perdemos integridad de datos en las observaciones. Sirve sólo si el “orden” de las observaciones pueden garantizar la misma identidad de las partes a unir."
  },
  {
    "objectID": "index.html#descripción",
    "href": "index.html#descripción",
    "title": "Gestión de Datos",
    "section": "Descripción",
    "text": "Descripción\nEste curso…..\nInstructor:\n\nChristian Ballejo"
  },
  {
    "objectID": "index.html#bibliografía",
    "href": "index.html#bibliografía",
    "title": "Gestión de Datos",
    "section": "Bibliografía",
    "text": "Bibliografía\nR for Data Science (2e)\nEpiRhandbook en español\nData Visualization"
  },
  {
    "objectID": "index.html#temario",
    "href": "index.html#temario",
    "title": "Gestión de Datos",
    "section": "Temario",
    "text": "Temario\n\n\n\n\n\nFecha\n\n\nTema\n\n\nLectura\n\n\nDiapositiva\n\n\nPráctica\n\n\nRecursos\n\n\n\n\n\n\n01/10/2024\n\n\nBienvenida\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n01/10/2024\n\n\nDatos - Parte 1\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n03/10/2024\n\n\nDatos - Parte 2\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n08/10/2024\n\n\nDatos - Parte 3\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n10/10/2024\n\n\nLenguaje R\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n10/10/2024\n\n\nRStudio\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n10/10/2024\n\n\nTidyverse\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n\n\n15/10/2024\n\n\nImportación y exportación de archivos"
  },
  {
    "objectID": "primero/clases/00-datos.html",
    "href": "primero/clases/00-datos.html",
    "title": "Gestión de datos",
    "section": "",
    "text": "La gestión de datos vinculada a procesos de investigación o vigilancia epidemiológica implica la organización, el almacenamiento, la preservación y la difusión de los datos antes de iniciar la etapa de análisis final.\nLos datos de los estudios de investigación incluyen los materiales generados o recopilados a lo largo de un proceso de investigación. Como podemos imaginar, esta amplia definición incluye mucho más que la gestión de conjuntos de datos digitales. También incluye archivos físicos, documentación, cuestionarios, grabaciones y más. En definitiva, es una tarea importante que comienza mucho antes de que se recopilen los datos, durante la fase de planificación, y continúa mucho después de que finaliza un proyecto de investigación durante la fase de archivo y uso compartido."
  },
  {
    "objectID": "primero/clases/00-datos.html#ciencia-abierta",
    "href": "primero/clases/00-datos.html#ciencia-abierta",
    "title": "Gestión de datos",
    "section": "Ciencia abierta",
    "text": "Ciencia abierta\nCon el auge tecnológico de los últimos años surgió un creciente interés en las prácticas de ciencia abierta, donde compartir datos bien gestionados y documentados ayuda a generar confianza en el proceso de investigación. Compartir datos curados de manera reproducible es “un fuerte indicador para los colegas investigadores de rigor, confiabilidad y transparencia en la investigación científica” según (Alston and Rick 2021). También permite que otros repliquen y aprendan de su trabajo, validen sus resultados para fortalecer la evidencia, así como también detecten potencialmente errores en su trabajo, evitando que se tomen decisiones basadas en datos incorrectos. Compartir sus datos con suficiente documentación y metadatos estandarizados también puede conducir a una mayor colaboración y un mayor impacto ya que los colaboradores pueden acceder y comprender sus datos con facilidad.\nLa ciencia abierta tiene como objetivo hacer que la investigación y la difusión científicas sean accesibles para todos, lo que hace absolutamente necesaria la necesidad de buenas prácticas de gestión de datos.\nOrganizaciones, como el Centro para la Ciencia Abierta (Center for Open Science) https://www.cos.io, se han convertido en un conocido defensor de la ciencia abierta, ofreciendo el Marco de Ciencia Abierta (OSF por Open Science Framework) como una herramienta para promover la ciencia abierta a lo largo de todo el ciclo de vida de la investigación."
  },
  {
    "objectID": "primero/clases/00-datos.html#marcos-existentes---fair",
    "href": "primero/clases/00-datos.html#marcos-existentes---fair",
    "title": "Gestión de datos",
    "section": "Marcos existentes - FAIR",
    "text": "Marcos existentes - FAIR\nEn 2016, se publicaron los Principios FAIR en Scientific Data (Wilkinson 2016), que describen cuatro principios rectores para la gestión y administración de datos científicos. Estos principios se crearon para mejorar y respaldar la reutilización de datos académicos, específicamente la capacidad de las máquinas para acceder y leer datos. Son la base de cómo se deben compartir públicamente todos los datos digitales.\nLos principios son:\nF: Findable (Localizable)\nTodos los datos deben poder encontrarse mediante un identificador persistente y contar con metadatos completos que permitan realizar búsquedas. Estas prácticas ayudan al descubrimiento de información a largo plazo y proporcionan citas registradas.\nA: Accessible (Accesible)\nLos usuarios deberían poder acceder a sus datos. Esto puede significar que sus datos estén disponibles en un repositorio o a través de un sistema de solicitudes. Como mínimo, un usuario debería poder acceder a los metadatos, incluso si los datos reales no están disponibles abiertamente.\nI: Interoperable\nSus datos y metadatos deben utilizar vocabularios y formatos estandarizados. Tanto los humanos como las máquinas deben poder leer e interpretar sus datos. Las licencias no deben suponer una barrera para su uso. Los datos deben estar disponibles en formatos abiertos a los que se pueda acceder mediante cualquier software (por ejemplo, csv, txt, etc).\nR: Reusable (Reutilizable)\nPara brindar contexto para la reutilización de sus datos, sus metadatos deben brindar información sobre la procedencia de los datos, brindar una descripción del proyecto, una descripción general del flujo de trabajo de los datos y los autores a los que se debe citar para una atribución adecuada. También debe tener licencias claras para el uso de los datos."
  },
  {
    "objectID": "primero/clases/00-datos.html#conceptos-básicos-de-un-conjunto-de-datos",
    "href": "primero/clases/00-datos.html#conceptos-básicos-de-un-conjunto-de-datos",
    "title": "Gestión de datos",
    "section": "Conceptos básicos de un conjunto de datos",
    "text": "Conceptos básicos de un conjunto de datos\nUn dato contiene la mínima unidad de información y desde la óptica informática es una representación simbólica (numérica, alfabética, etc) de un atributo o característica de una entidad. Para nosotros el dato siempre representa el valor / medida (variables cuantitativas) o modalidad / categoría (variables cualitativas) de una variable.\nDentro de la investigación cuantitativa, generalmente trabajamos con datos digitales en forma de un conjunto de datos, una colección estructurada de datos.\nUn conjunto de datos mínimo está organizado en un formato rectangular que permite que la información sea legible por la computadora. Los conjuntos de datos rectangulares, también llamados tabulares, se componen de columnas y filas y se asocian a una unidad de investigación u observación.\n\n\n\n\n\nid\nsexo\nedad\npeso\ntalla\ntrabaja\n\n\n\n\n1\nM\n76\n71\n167.0\nFALSE\n\n\n2\nM\n68\n71\n164.0\nFALSE\n\n\n3\nM\n50\n79\n164.0\nFALSE\n\n\n4\nM\n49\n71\n164.0\nTRUE\n\n\n5\nM\n51\n87\n167.5\nTRUE\n\n\n6\nM\n68\n75\n170.0\nFALSE\n\n\n\n\n\n\nColumnas\nLas columnas del conjunto de datos representan las variables o atributos constarán de los siguientes tipos de variables:\nVariables recopiladas\nSon variables recogidas de un instrumento (cuestionario estrcuturado, etc) en fuentes primarias o fuente secundarias (externa).\nVariables creadas\nEstos pueden ser variables construidas o pueden ser variables derivadas o indicadores con fines de resumen (llamada también información agregada), como medias, proporciones, tasas, etc.\nVariables de identificación\nTambién debe incluir valores que identifiquen de forma únivoca a los sujetos en sus datos (por ejemplo, el DNI o historia clínica u otro identificador ad hoc si se desea preservar la identidad).\n\nAtributos de columna\nLas columnas o variables de su conjunto de datos también tienen los siguientes atributos:\nNombres de variables\nUn nombre de variable es la representación corta de la información contenida en una columna.\nLos nombres de las variables deben ser únicos. Ningún nombre de variable en un conjunto de datos puede repetirse.\nTipos de variables\nEl tipo de una variable determina los valores permitidos para una variable, las operaciones que se pueden realizar en la variable y cómo se almacenan los valores.\nAlgunos ejemplos de tipos son numéricos, de caracteres (también llamados texto o string), de fecha o lógicos (valores True y False). Los tipos también se pueden definir de forma más específica según sea necesario (por ejemplo, continuos o categóricos).\nValores variables\nLos valores de las variables hacen referencia a la información contenida en cada columna. En cada variable se puede configurar los valores permitidos predeterminados en forma de validación a la carga de datos.\nAlgunos ejemplos de configuración de valores permitidos para diferentes tipos de variables incluyen:\nVariable de caracter categórico: “sí” | “no”\nVariable numérica entera: 1 a 100\nFecha variable: 01/10/2024 a 31/12/2024\nVariable de carácter de texto libre: se permite cualquier valor\nCualquier cosa fuera de los valores o rangos esperados se considera un error.\nEtiquetas variables\nUna etiqueta de variable es la descripción legible por humanos de lo que representa una variable.\nEsta puede ser una etiqueta con la definición de la variable o directamente la pregunta que vincula la variable con el cuestionario de origen.\n\n\n\nFilas\nLas filas del conjunto de datos representan a los sujetos (también llamados registros u observaciones) de sus datos. Los sujetos de su conjunto de datos pueden ser personas, hogares, ubicaciones como países o provincias, etc.\n\n\nCeldas\nA la intersección entre una columna y una fila la llamamos celda. En cada una de ellas puede haber solo un valor del tipo definido en la columna y que representa al sujeto de la fila."
  },
  {
    "objectID": "primero/clases/00-datos.html#fuentes-de-datos-primaria-y-secundaria",
    "href": "primero/clases/00-datos.html#fuentes-de-datos-primaria-y-secundaria",
    "title": "Gestión de datos",
    "section": "Fuentes de datos primaria y secundaria",
    "text": "Fuentes de datos primaria y secundaria\nEl término datos primarios se refiere a datos recolectados por el investigador por primera vez. Esta situación requiere que se diseñen adecuadamente los instrumentos de recolección y la carga de datos que conlleva la necesidad de contar con una gran cantidad de recursos (tiempo, mano de obra y presupuesto).\nPor otra parte, también requiere de un proceso de limpieza y depuración para tratar, previo al análisis, los datos crudos.\nEn cambio, las fuentes secundarias implican información que ya ha sido recopilada y registrada por otra/s persona/s diferente al analista, generalmente para un propósito que no está relacionado con el análisis actual.\nUn ejemplo en el mundo epidemiológico son las encuestas nacionales de factores de riesgo (ENFR) que el Ministerio de Salud de la Nación Argentina en conjunto con el INDEC llevó a cabo en 2005, 2009, 2013 y 2018. Estas tablas de datos de fuente secundaria están disponibles en el sitio del INDEC"
  },
  {
    "objectID": "primero/clases/00-datos.html#fuentes-de-datos-primaria-y-secundaria-1",
    "href": "primero/clases/00-datos.html#fuentes-de-datos-primaria-y-secundaria-1",
    "title": "Gestión de datos",
    "section": "Fuentes de datos primaria y secundaria",
    "text": "Fuentes de datos primaria y secundaria\nInstrumentos de recolección de datos - Cuestionario estructurado - Tipo de preguntas - Validación - estándares Ética - Consentimientos - confidencialidad - sensibilidad - anonimización Recolección electrónica - Bases de datos (relacional / no relacional) - nombre de variables - codificación de valores - diccionario de datos - prueba piloto\nPlanificación de la gestión de datos (documentación, guías de estilo, etc) Proyectos - estructura de directorios y archivos - metadatos - buenas practicas Captura de datos - Formatos de archivos - formato largo / ancho - variables identificadoras - clave primaria / foránea - uniones\nDepuración y validación de datos\nAlmacenamiento, seguridad, colaboración y archivo de datos\n\nAnálisis - Softwares y lenguajes disponibles"
  },
  {
    "objectID": "primero/clases/00-datos.html#bases-de-datos",
    "href": "primero/clases/00-datos.html#bases-de-datos",
    "title": "Gestión de datos",
    "section": "Bases de datos",
    "text": "Bases de datos\nHasta ahora hemos estado hablando de un conjunto de datos independiente. Sin embargo, es más probable que el proyecto de investigación esté compuesto por varios conjuntos de datos, dependiendo del diseño de estudio y de las diferentes dimensiones de abordaje (por ejemplo, cuestionarios clínicos y de laboratorio). En algún momento, lo más probable es que necesitemos vincular esos conjuntos de datos.\nPara pensar en cómo vincular datos, necesitamos discutir dos cosas: el diseño de la base de datos y la estructura de los datos.\n\n\n\n\n\n\nUna base de datos es “una colección organizada de datos almacenados como múltiples conjuntos de datos”\n\n\n\nEn la terminología de bases de datos, cada conjunto de datos que tenemos se considera una “tabla”. Cada tabla incluye una o más variables que definen de forma única las filas de sus datos (es decir, una clave principal). Las tablas también pueden contener variables asociadas con valores únicos en otra tabla (es decir, claves externas). Este juego de claves principal-externa sirve para “conectar” las tablas de forma horizontal sin perder integridad.\n\n\n\n\n\n\nEs importante tener en cuenta que si no tiene identificadores únicos comunes en todas las tablas, como en el caso de los datos anónimos, no podremos unir datos horizontalmente.\n\n\n\nExiste otra forma de unión de tablas que llamaremos uniones verticales y sucede cuando debemos anexar o apilar datos de un conjunto con otro que siempre deberá tener la misma estructura, es decir los mismo nombres de variables y tipo de datos."
  },
  {
    "objectID": "primero/clases/00-datos.html#instrumentos-de-recolección-de-datos",
    "href": "primero/clases/00-datos.html#instrumentos-de-recolección-de-datos",
    "title": "Gestión de datos",
    "section": "Instrumentos de recolección de datos",
    "text": "Instrumentos de recolección de datos\nLas tablas de datos son producto del almacenamiento de la información que proviene muchas veces de los instrumentos de recolección más comunes en la investigación cuantitativa: el cuestionario estructurado.\nLa forma en que recibimos las variables de análisis tendrán su origen en la confección de estos cuestionarios. Por lo que la construcción de estos instrumentos de recolección nacen pensando en los componentes del dato científico.\nUn dato científico esta compuesto por una unidad de observación, dimensiones de análisis que definen variables de estudio, valores o categorías conceptuales que luego se operacionalizan en indicadores que terminaran siendo los datos que encontramos en las tablas.\nLa unidad de observación es la entidad que deseamos estudiar, es decir, aquella que se observa para efectuar mediciones o para clasificarla en categorías. También se denomina unidad de análisis o unidad experimental y se define acompañada de un tiempo y espacio identificable.\nPor ejemplo, en grandes encuestas como la ENFR tenemos varias unidades de observación: vivienda, hogar, jefe de hogar y persona encuestada.\nEstas unidades de observación fueron abordadas en un espacio específico, domicilio-ciudad-departamento-conglomerado-provincia del país y en un tiempo determinado (encuestas de 2005, 2009, 2013 y 2018).\nLas variables o dimensiones de análisis constituyen los aspectos de las unidades de observación que se han seleccionado para examinar o estudiar, de acuerdo a los problemas e hipótesis de investigación. Concretamente son aquellos atributos, propiedades o características observables de las diferentes unidades de observación.\nPor ejemplo, las variables recabadas en la ENFR son: edad, sexo, nivel de instrucción, actividad física, consumo de alcohol, consumo de tabaco, etc.\nAlgunas de estas variables son simples o directas como la edad donde solo hay que aclarar en que unidad se la está midiendo. Edad en años o edad en meses, etc.\nOtras son constructos más complejos donde para aprehender el concepto buscado se necesitan de una serie de preguntas / variables individuales que recaban información sobre distintas dimensiones del problema. Es el caso, por ejemplo de consumo de alcohol donde podemos consultar sobre si toma, cuando lo hace, cuanto bebe, que bebe, etc.\nMuchas de estas preguntas estan validadas por estudios previos y se copian con la misma estructura en diseños de cuestionarios nuevos para aprovechar la garantía de la validación y la comparabilidad que permite hacerlo.\nCuando hablamos de definiciones operacionales o indicadores vinculados a las variables conceptuales nos referimos a los procedimientos para “medir” a estas variables. Existen variables formuladas en términos abstractos o conceptuales con cierta complejidad que deben descomponerse en varias dimensiones y deben operacionalizarse para poder medirlas.\n\n\n\n\n\n\nUn ejemplo de operacionalización para la variable Hacinamiento es definir el indicador como:\n“Cantidad de personas por cuarto, informadas por algún respondente del hogar”\n\nHasta 3 personas por cuarto es “Sin hacinamiento”\nMás de 3 personas por cuarto es “Con hacinamiento”\n\n\n\n\nPor otra parte, hallamos diferentes tipos de preguntas en un cuestionario estructurado producto de este proceso operacional que va a condicionar la forma de nuestras variables digitales incluidas en la tabla de datos.\nHay preguntas cerradas con valores o códigos establecidos, preguntas abiertas que son muy difíciles de analizar en el ámbito cuantitativo o mixtas donde aparece una opción otro/a que se agrega a las respuestas válidas.\nTenemos también preguntas de respuesta simple, donde solo una es posible y otras de respuesta múltiple donde se puede marcar más de una respuesta simultánea. Esta situación hace que en la construcción de nuestra tabla de datos cada respuesta se refleje como una variable por si o no, produciendo posteriormente un análisis de mayor complejidad.\nSiempre las preguntas cerradas deberán cumplir con dos cualidades particulares, ser exahustivas y excluyentes.\nExahustiva, significa que dentro de las opciones válidas predeterminadas tendremos que tener la posibilidad de abarcar todas las posibles respuestas del entrevistado. Esto provoca que muchas veces aparezcan las opciones, “Sin dato”, “No sabe/No contesta” u “Otro/a”.\nExcluyente, es que no pueden coexistir dos respuestas simultáneamente. Si se produce, entonces habrá que construir variables de respuesta múltiple.\nJunto a las preguntas y sus valores se acompaña la clasificación de variables y definición de escalas. Las variables pueden ser clasificadas en:\n\n\n\nEscala\nEjemplo\n\n\n\n\nNominal\nFuma: “si” - “no”\n\n\nOrdinal\nNivel de ingresos: “Alto” - “Medio” - “Bajo”\n\n\nIntervalo\nHora del día: “0:00”…“24:00”\n\n\nRazón\nPeso (Kgrs): 0….a n\n\n\n\nOtras escalas especiales son las de Likert, Guttman, visuales análogas, etc\nEn muchas oportunidades encontramos en las tablas de datos provenientes de cuestionarios variables codificadas. La codificación es la tarea de asignar códigos a las distintas respuestas de las preguntas del cuestionario y obtener así los distintos valores de las variables con los que se construye la matriz de datos.\nEs necesario estar atento a esta situación porque en algunas tablas de datos de fuente secundaria se suele asignar valores extremos en la escala numérica de variables con este tipo de dato, por ejemplo en la ENFR utilizan 9, 99, 999 dependiendo de los dígitos que tenga la variable para referirse a categorías tipo Ns/Nc o sin dato.\nTodo lo desarrollado anteriormente nos lleva a que cada tabla de datos que construyamos nosotros mismos o las tablas provenientes de fuentes secundarias deben estar acompañadas de diccionario de datos o cuadros de operacionalización donde esten definidas las características, valores legales y codificación de cada variable de estudio.\nVer Manual de uso de la base de datos usuario ENFR 2018"
  },
  {
    "objectID": "primero/clases/00-datos.html#consideraciones-éticas",
    "href": "primero/clases/00-datos.html#consideraciones-éticas",
    "title": "Gestión de datos",
    "section": "Consideraciones éticas",
    "text": "Consideraciones éticas\nNuestras tablas de datos suelen contener información de sujetos humanos lo que conlleva a la responsabilidad de proteger a esos datos. Los datos de humanos pueden contener información identificable que aumenta el riesgo de que los participantes puedan ser revelados en un conjunto de datos. Habitualmente también contienen información sobre temas sensibles vinculado a la salud lo que aumenta aún más los riesgos si se identifica a los participantes.\nCuando se trabaja con sujetos humanos, hay dos tipos de identificadores que se pueden recopilar en el estudio: directos e indirectos.\nLos identificadores directos son exclusivos de un individuo y se pueden utilizar para identificar a un participante. Los identificadores indirectos no son necesariamente exclusivos de un individuo en particular, pero si se combinan con otra información se pueden utilizar para identificar a un participante.\nLa Oficina de Ética de Investigación Humana de la Universidad de Carolina del Norte define 4 tipos de archivos de datos en función a la identifcación personal:\n\nIdentificable: los datos incluyen información de identificación personal. Es común que los datos crudos sin procesar de un estudio de investigación sean identificables.\nCodificado: en este tipo de archivo de datos, se ha eliminado o distorsionado la información de identificación personal y se han reemplazado los nombres por un código (es decir, un identificador único del participante). La única forma de vincular los datos con un individuo es a través de ese código. El archivo de código de identificación (clave de vinculación) se almacena por separado de los datos de investigación. Los datos codificados son, por lo general, el tipo de archivo que se crea después de limpiar los datos sin procesar del estudio (clean_data).\nDesidentificado: en este tipo de archivo, se ha eliminado o distorsionado la información de identificación y los datos ya no se pueden volver a asociar con la persona subyacente (la clave de vinculación ya no existe). Esto es lo que se crea normalmente cuando se comparten públicamente los datos de un estudio de investigación.\nAnónimo: en un conjunto de datos anónimo, nunca se recopila información de identificación, por lo que debería haber poco o ningún riesgo de identificar a un participante específico.\n\n\nSensibilidad\nLos datos suelen clasificarse en función del nivel de sensibilidad. Estos niveles de sensibilidad determinan cómo se pueden recopilar, almacenar y compartir los datos, así como cuál debe ser la respuesta ante cualquier violación de datos. Si bien existe variación, aquí se presenta un resumen general de cómo se puede categorizar la información.\n\nSensibilidad baja: se considera que estos datos no presentan riesgo o que presentan un riesgo bajo si se divulgan. Por lo general, esto incluye datos anónimos y no identificados que no contienen información altamente sensible.\nSensibilidad moderada: Se considera que estos datos tienen un riesgo moderado si se divulgan, lo que significa que podrían afectar negativamente a las personas. Estos datos pueden incluir información identificable o información que podría permitir volver a identificar a los participantes dentro de los propios datos o utilizando una fuente externa. Por lo general, se exige que estos datos se mantengan confidenciales por ley u otros acuerdos. Estos datos deben protegerse contra el acceso no autorizado.\nAlta sensibilidad: estos datos deben estar sujetos a las medidas de seguridad más estrictas y podrían causar un gran daño si se divulgan. Estos datos incluyen información personal identificable o información que podría permitir que los participantes sean reidentificados, así como información privada o altamente sensible (por ejemplo, registros médicos) y, por lo general, se exige que se mantengan confidenciales por ley u otros acuerdos. Estos datos deben protegerse contra el acceso no autorizado."
  },
  {
    "objectID": "primero/clases/00-datos.html#plan-de-gestión-de-datos",
    "href": "primero/clases/00-datos.html#plan-de-gestión-de-datos",
    "title": "Gestión de datos",
    "section": "Plan de gestión de datos",
    "text": "Plan de gestión de datos\nUn plan de gestión de datos es un documento complementario sobre cómo se planea recopilar, almacenar, gestionar y compartir los productos de datos de investigación.\nEs oportuno que acompañe o sea parte del protocolo de investigación o del manual de procedimiento de un programa de vigilancia epidemiológica y puede contener los siguientes items:\n\nDescripción de los datos que se compartirán\n\n\n¿Cuál es la fuente de los datos? (por ejemplo, encuestas, datos existentes, sistemas de vigilancia, etc)\n¿Cómo se limpiarán y conservarán los datos antes de compartirlos?\n¿Cuál será el nivel de agregación? (por ejemplo, nivel de elemento, datos resumidos, solo metadatos)\n\nEs posible que sea necesario compartir los conjuntos de datos de un proyecto de diferentes maneras debido a razones legales, éticas o técnicas.\n\n¿Se compartirán datos tanto brutos como limpios?\n\n\nFormato de los datos a compartir\n\n\n¿Los datos estarán en formato electrónico?\n¿Se proporcionará en un formato no propietario? (por ejemplo, csv)\n¿Se proporcionará más de un formato? (por ejemplo, xlsx y csv)\n¿Se necesitan herramientas para manipular o reproducir datos compartidos? (por ejemplo, software, código)\n\nProporcione detalles sobre esas herramientas (por ejemplo, cómo se puede acceder a ellas, número de versión, sistema operativo requerido).\n\n\n\nDocumentación a compartir\n\n\n¿Qué documentación compartirás?\n\nConsidere la documentación a nivel de proyecto, de conjunto de datos y de variable.\n\n¿En qué formato estará su documentación? (por ejemplo, csv, pdf)\n\n\nNormas\n\n\n¿Planea utilizar algún estándar para cuestiones como metadatos, recopilación de datos o formato de datos?\n\n\nConservación de datos\n\n\n¿Dónde se archivarán los datos internamente?\n\nMedidas de seguridad y accesos\n\n¿Se archivarán los datos para compartirlos públicamente? ¿Dónde?\n¿Cuáles son las características deseables del repositorio? (por ejemplo, identificadores únicos y persistentes asignados a los datos, metadatos recopilados, procedencia de los registros, opciones de licencia)\n¿Cuándo depositará sus datos de estudio en el repositorio y durante cuánto tiempo permanecerán accesibles los datos?\n¿Cómo permitirá la reutilización de datos?\n\n\nConsideraciones sobre acceso, distribución o reutilización\n\n\n¿Existen factores legales, técnicos o éticos que afecten la reutilización, el acceso o la distribución de sus datos?\n¿Se restringirán algunos datos?\n¿Se requieren controles de acceso (por ejemplo, un acuerdo de uso de datos)?\n\n\nProtección de la privacidad y la confidencialidad\n\n\n¿Los participantes firman acuerdos de consentimiento informado? ¿El consentimiento comunica cómo se espera que se utilicen y compartan los datos de los participantes? ¿Cómo evitará la divulgación de información de identificación personal cuando comparta datos?\n\n\nSeguridad de los datos\n\n\n¿Cómo se mantendrá la seguridad y la integridad de los datos durante un proyecto? (por ejemplo, considere el almacenamiento, el acceso, la copia de seguridad y la transferencia de datos)\n\n\nFunciones y responsabilidades\n\n\n¿Cuáles son los roles del personal en la gestión y preservación de datos?\n¿Quién garantiza la accesibilidad, fiabilidad y calidad de los datos?\n¿Existe un plan si un miembro principal del equipo abandona el proyecto o la institución?"
  },
  {
    "objectID": "primero/clases/00-datos.html#planificación-de-la-gestión-de-datos",
    "href": "primero/clases/00-datos.html#planificación-de-la-gestión-de-datos",
    "title": "Gestión de datos",
    "section": "Planificación de la gestión de datos",
    "text": "Planificación de la gestión de datos\nPlanificar las etapas del proceso de investigación o del protocolo de trabajo habitual en la vigilancia epidemiológica consiste en decidir y documentar los pasos a seguir por todo el equipo durante el estudio.\nLa reproducibilidad comienza en la fase de planificación y por lo tanto habrá que dedicar tiempo para crear, documentar y capacitar al personal en estándares de gestión de datos antes de que comience su proyecto, dado que ayuda a garantizar que los procesos se implementen con fidelidad y se puedan replicar de manera consistente.\nUn ejemplo relacionado a esta planificación que es recurrente en todos los casos es la limpieza de datos.\n\nPlan de limpieza de datos\nUn plan de limpieza de datos es una propuesta escrita que describe cómo planeamos transformar los datos sin procesar en datos limpios y utilizables. Este documento no contiene código y no depende de habilidades técnicas. Es necesario sobre todo si compartimos el trabajo con otros integrantes o bien la información se recolecta o recibe de forma periódica (por ejemplo en vigilancia epidemiológica). Dado que este documento describe las transformaciones previstas para cada conjunto de datos sin procesar, permite que cualquier miembro del equipo brinde comentarios sobre el proceso de limpieza de datos.\nUn ejemplo de un plan simple de limpieza de datos para un archivo de datos cualquiera:\n\n1. Importar datos crudos\n2. Visualizar datos (filas y columnas)\n3. Remover registros duplicados en caso de existir (usando las reglas del caso, duplicados completos o por claves)\n4. Anonimizar datos \n5. Renombrar variables basado en el diccionario de datos\n6. Diagnosticar variables (tipos, inconsistencias, etc)\n7. Depurar datos diagnosticados\n8. Detección de valores perdidos (missing)\n9. Creación de variables construidas (clasificación, cálculo, agrupamientos, etc)\n10. Exportar datos limpios en el formato elegido \n\nAsí como se desarrolla este plan de limpieza se definen otros planes para la recolección, análisis, comunicación, publicación, etc."
  },
  {
    "objectID": "primero/clases/00-datos.html#guía-de-estilo",
    "href": "primero/clases/00-datos.html#guía-de-estilo",
    "title": "Gestión de datos",
    "section": "Guía de estilo",
    "text": "Guía de estilo\nLas guías de estilo crean estandarización dentro y entre proyectos. Los beneficios de usarlas de manera consistente mejora la interpretación de las estructuras del proyecto y organiza mejor la información, así como también aumentan la reproducibilidad e interoperabilidad.\nSon muy útiles para proyectos colaborativos o integrados por muchas personas. Se pueden crear para proyectos individuales, pero también se pueden crear a nivel de equipo para que se apliquen en todos los proyectos.\n\nBuenas prácticas\nAntes de profundizar en las partes de una guía de estilo, hay algunas cosas que debemos saber sobre cómo las computadoras leen los nombres para comprender el “por qué” detrás de algunas de estas prácticas.\n\nEvite los espacios.\n\n\nLas operaciones de línea de comandos y algunos sistemas operativos no las admiten, por lo que es mejor evitarlas por completo. Las direcciones web URL tampoco.\nEl guión bajo (_) y el guion (-) son generalmente buenos delimitadores para usar en lugar de espacios.\n\n\nCon excepción de (_) y (-), evite los caracteres especiales en directorios y nombres de archivos.\n\n\nLos ejemplos incluyen, entre otros ?, ., *, , /, +, ’, &, “.\nLas computadoras asignan un significado específico a muchos de estos caracteres especiales.\nEvite caracteres acentuados y eñes\n\n\nExisten varias convenciones de nomenclatura que puedes elegir para añadir a tu guía de estilo. El uso de estas convenciones te ayuda a ser coherente con los delimitadores y las mayúsculas, lo que no solo hace que tus nombres sean más legibles para los humanos, sino que también permite que tu computadora lea y busque nombres más fácilmente.\nOrdenado de manera útil, donde se tenga en cuenta la clasificación alfanumérica y el completado de ceros a la izquierda cuando hay más de un dígito. Utilización del estándar ISO 8601 para fechas (AAAA-MM-DD).\nLa longitud de los caracteres es importante. Las computadoras no pueden leer nombres que superen una determinada longitud de caracteres. Esto se aplica a las rutas de archivos, los nombres de archivos y los nombres de variables.\n\n\n\nEstructura de directorio\nAl decidir cómo estructuramos los directorios del proyecto (la organización de carpetas y archivos dentro de un sistema operativo), hay varias cosas que debemos considerar.\nCarpetas\nEn primer lugar, pensemos en organizar el directorio en una estructura de carpetas jerárquica para delinear claramente los segmentos del proyecto y mejorar la capacidad de búsqueda.\nAl crear la estructura de carpetas, buscamos un equilibrio entre una estructura profunda y una superficial.\n\nSi es demasiado superficial, habrá demasiados archivos en una carpeta, lo cual resulta difícil de clasificar.\nSi la ruta es demasiado profunda, se necesitarán demasiados clics para llegar a un archivo, y las rutas de archivo pueden tener demasiados caracteres. Una ruta de archivo incluye la longitud completa de las carpetas y el nombre del archivo. (por ejemplo, el límite de ruta de Windows es de 260 caracteres).\n\nConsidere establecer un límite de caracteres en los nombres de las carpetas (nuevamente para reducir los problemas al alcanzar los límites de caracteres de la ruta).\n\nHaga que los nombres de sus carpetas sean significativos y fáciles de interpretar.\nNo utilice espacios en los nombres de sus carpetas.\nUtilice (_) o (-) para separar palabras.\nCon excepción de (-) y (_), no utilice caracteres especiales en los nombres de sus carpetas.\nSea coherente con los delimitadores y el uso de mayúsculas y minúsculas. Siga una convención de nomenclatura existente.\nSi prefiere que sus carpetas aparezcan en un orden específico, agregue el número de orden al comienzo del nombre de la carpeta, con ceros a la izquierda para garantizar una clasificación adecuada (01_, 02_).\n\nUn ejemplo de estructura de directorios completa de un proyecto podría ser el siguiente:\n\n\nnombre_proyecto/\n├── 01_planificacion\n|   ├── proyecto\n|   |   ├── fuentes\n|   |   |   └── ...\n|   ├── reuniones\n|   |   ├── minutas\n|   |   |   └── ...\n|   └── ...\n├── 02_documentacion\n|   ├── formularios\n|   |   └── ...\n|   ├── diccionarios_datos\n|   |   └── ...\n|   ├── protocolo\n|   └── ...\n├── 03_recoleccion_datos\n|   ├── materiales\n|       └── ...\n├── 04_seguimiento\n│   ├── cronograma\n|       └── ...\n├── 05_datos\n│   ├── cohorte1\n│   |   ├── pacientes\n|   |   |   ├── encuesta\n|   |   |   |   ├── datos_limpios\n|   |   |   |   |   ├── archivos\n|   |   |   |   |   |   └── log.txt\n|   |   |   |   ├── datos_crudos\n|   |   |   |   |   ├── archivos\n|   |   |   |   |   |   └── log.txt\n|   |   |   |   └── ...  \n|   |   |   └── ... \n|   |   └── ...\n|   └── ...   \n└── ...\n\nArchivos\nA menudo tenemos apuro por guardar nuestros archivos y tal vez no consideramos lo poco claros que serán los nombres para los futuros usuarios (incluidos nosotros mismos).\nNuestros nombres de archivos por sí solos deberían poder responder preguntas como:\n\n¿Qué son estos documentos?\n¿Cuando se crearon estos documentos?\n¿Cuál documento es la versión más reciente?\n\nUna guía de estilo de nombres de archivos nos ayuda a nombrar los archivos de una manera que nos permita responder a estas preguntas. Podemos tener una guía de nombres de archivos general o guías de nombres de archivos para diferentes propósitos que requieren diferentes estrategias de organización (por ejemplo, una guía de nombres para notas de reuniones de proyectos, otra guía de nombres para archivos de datos de proyectos). Repasemos varias convenciones que se deben tener en cuenta al nombrar los archivos.\n\nQue los nombres sean descriptivos (un usuario debe poder comprender el contenido del archivo sin abrirlo).\nNo se debe utilizar ninguna información de identificación personal en un nombre de archivo (por ejemplo, nombre del participante).\nNunca utilice espacios entre palabras.\nUtilice (-) o (_) para separar palabras.\nCon excepción de (_) y (-), nunca utilice caracteres especiales.\nSea coherente con los delimitadores y el uso de mayúsculas y minúsculas. Siga una convención de nomenclatura existente.\nConsidere limitar la cantidad de caracteres permitidos para evitar alcanzar el límite de su ruta.\nFormatee las fechas de forma uniforme y no utilice barras diagonales (/) para separar partes de una fecha. Es conveniente formatear las fechas utilizando la norma ISO 8601 de una de estas dos maneras: AAAA-MM-DD o AAAAMMDD\nAl versionar manualmente los nombres de archivos, elija un indicador consistente para usar. Un método consiste es añadir un número al nombre del archivo. Con este método, considere rellenar a la izquierda los números individuales con un 0 para mantener el nombre del archivo con la misma longitud a medida que crece (v01, v02). Otro método es agregar una fecha al nombre del archivo, utilizando el estándar ISO 8601.\nSi sus archivos necesitan ejecutarse en un orden secuencial, agregue el número de orden al comienzo del nombre del archivo, con ceros a la izquierda para garantizar una clasificación adecuada (01_, 02_).\nMantenga metadatos redundantes (información) en el nombre del archivo. Esto reduce la confusión si alguna vez mueves un archivo a una carpeta diferente o envías un archivo a un colaborador. También permite realizar búsquedas en tus archivos. Por ejemplo, coloque siempre la palabra “raw” (crudo) o “clean” (limpio) en un nombre de archivo de datos, incluso si el archivo está alojado en una carpeta “raw” o “clean”.\nElija un orden para los metadatos del nombre del archivo (por ejemplo, proyecto -&gt; tiempo -&gt; participante -&gt; instrumento).\n\nAlgunos ejemplos de nombres de archivos:\n\n01_proy1_depuracion-datos_v06.R\n02_proy1_modelos-ajustados_2024-09-11.R\nfig01_barras-grupo_etario.png\ntabla_poblacion_indec.xlsx\n\n\n\nVariables\nEl mismo cuidado o aplicación de las buenas prácticas vistas hasta el momento aplican en la elección de los nombres de variables de las tablas de datos.\nHay dos tipos de reglas: las que son requisitos no negociables que realmente deberían incluirse en la guía de estilo (si no se sigue estas reglas, enfrentaremos serios problemas de interpretación tanto para los humanos como para las máquinas) y las sugerencias de mejores prácticas que se recomiendan pero no son obligatorias.\nObligatorio\n\nNo nombre una variable con ninguna palabra clave o función reservada y utilizada en ningún lenguaje de programación (como if, for, repeat).\nEstablecer un límite de caracteres (La mayoría de los programas estadísticos tienen un límite de caracteres en los nombres de las variables.) Considere el equilibrio entre el límite de caracteres y la interpretación.\nNo utilice espacios ni caracteres especiales, excepto (_). No están permitidos en la mayoría de los programas. Incluso el (-) no está permitido en programas como R y SPSS ya que puede confundirse con un signo menos. Si bien (.) está permitido en R y SPSS, no está permitido en Stata, por lo que es mejor evitar su uso.\nNo comience el nombre de una variable con un número. Esto no está permitido en muchos programas estadísticos.\n\nSugerido\n\nEvite agregar acentos y eñes a las palabras que use como nombre de variable.\nTrate que todas las tablas tengan un identificador único de observación o registro. Si no está vinculado específicamente a cada unidad de análisis, genere uno arbitrario pero que identifique cada observación (suelen usarse ID numéricos secuenciales).\nPreste atención al uso de minúsculas y mayúsculas. La mayoría de los lenguajes de análisis son sensibles a estas diferencias.\nSi hay variables producto de preguntas con respuestas múltiples, comience los nombres de variables asociadas con el mismo prefijo (sintomas_fiebre, sintomas_vomitos, sintomas_mialgias).\nSepare con prefijos y sufijos los nombres de las variables que pertenecen a distintos bloques de una encuesta o a diferentes tipos de participantes. Por ejemplo en las ENFR los prefijos denotan el bloque de la encuesta, BI_ = Bloque Individual, BH_ = Bloque Hogar y el sufijo _J identifica variables del jefe de hogar.\n\nAlgunos ejemplos de nombres de variables:\n\nbi_hi_01 = bloque hogar -&gt; ingresos del hogar -&gt; pregunta 01 \nrango_edad_j = rango de edad -&gt; jefes de hogar\nnivel_instruccion_agrupado -&gt; variable agrupada - nivel de instruccion\ncondicion_actividad_c -&gt; variable construida - condicion de actividad\n\n\n\nCodificación de valores\nSe pueden definir codificaciones que sigan el esquema propuesto dentro del diccionario de datos de la tabla. En algunas ocasiones, variables de interes dicotómica que luego darán lugar a análisis de regresión suelen declararse con 1 para el Si y 0 para el No, orientandose el valor al proceso de funciones de regresión logistica de lenguajes como R.\nAlgunas pautas a considerar en esta tarea son:\n\nLos códigos deben ser únicos. Asignamos “sí” = 1 | “no” = 0 y evitamos “sí” = 1 | “no” = 1\nLos códigos deben ser consistentes dentro de una variable. Para sexo asignamos “masculino” = ‘m’ y evitamos que “masculino” = ‘m’ o ‘M’ o ‘Masculino’ o ‘masculino’ dado que para la maquina terminarán siendo valores distintos por el uso de minúscula y mayúscula.\nLos códigos deben ser consistentes en todo el proyecto. Si asignamos “sí” = 1 | “no” = 0 como valor para todos los elementos de sí/no, evitamos asignar “sí” = 1 | “no” = 0 para algunas variables y “sí” = 1 | “no” = 2 para otras.\nAlineamos los códigos con las opciones de respuesta lo mejor posible. Asignar “ninguno” = 0 | “1” = 1 | “2” = 2 | “3 o más” = 3 y evitamos “ninguno” = 1 | “1” = 2 | “2” = 3 | “3 o más” = 4\nLos códigos de escala tipo Likert deben ordenarse lógicamente. Asignamos “totalmente en desacuerdo” = 1 | “en desacuerdo” = 2 | “de acuerdo” = 3 | “totalmente de acuerdo” = 4 y evitamos “totalmente en desacuerdo” = 1 | “en desacuerdo” = 3 | “de acuerdo” = 4 | “totalmente de acuerdo” = 2\n\nRespecto a los valores faltantes hay una variedad de estilos, pero se pueden resumir en dos opciones generales:\n\nPodemos elegir dejar todos los valores faltantes en blanco.\n\n\nLa ventaja de esta opción es que no hay posibilidad de que los códigos de valores faltantes asignados (por ejemplo, -999) se confundan con valores reales. La preocupación con este método es que no hay manera de discernir si el valor realmente falta, o fue borrado por accidente u omitido durante el ingreso de datos.\n\n\nLa otra opción es definir códigos faltantes y agregarlos a los datos.\n\n\nEste código puede ser numérico (por ejemplo, “faltante” = 99 o -999) o de caracteres (por ejemplo, “faltante” = ‘Sin dato’) y puede ser un código uniforme aplicado a todos los datos faltantes, o puede ser varios códigos asignados para diferentes tipos de datos faltantes.\nUna ventaja de este método es que elimina la incertidumbre que teníamos con las celdas en blanco. Si se completa un valor, ahora tenemos la certeza de que no se eliminó ni se omitió durante la entrada de datos.\nOtro beneficio es que esto le permite especificar razones distintas para los datos faltantes (por ejemplo, “Sin dato” = 99, “Ilegible” = 98) si eso es importante para su estudio.\nEl mayor problema que puede ocurrir con este método es que sus códigos podrían confundirse con valores reales (si alguien no conoce la documentación sobre valores faltantes) o si usa un valor que no coincide con su tipo de variable, entonces introduce nuevos problemas de tipo de variable (por ejemplo, si se usa ‘NULL’ en una variable numérica, esa variable ya no será numérica) o se calculo la media de edad con valores 999 que no son reales y van a sesgar el resultado."
  },
  {
    "objectID": "primero/clases/00-datos.html#formatos-de-archivos",
    "href": "primero/clases/00-datos.html#formatos-de-archivos",
    "title": "Gestión de datos",
    "section": "Formatos de archivos",
    "text": "Formatos de archivos\nSi el proyecto de datos esta vinculado a la recolección propia, es decir a una fuente primaria de información, es recomendable que el/los archivo/s sea alguno de los formatos abiertos de texto plano con separadores. Estos archivos son universales, conocidos como valores separados por coma (csv), que utilizan separadores clásicos como (,) coma, (;) punto y coma, (tab) tabulaciones u otro simbolo a elección (por ejemplo, los archivos de la ENFR tienen la (|) barra verticual como separador de columnas).\nLas extensiones de estos archivos generalmente son .csv o .txt, o alguna otra pero el contenido siempre es texto plano que puede leerse desde cualquier block de notas.\nEn el caso que los datos provengan de una fuente secundaria es posible que el formato de los archivos sea de de un tipo específico que tendrá relación con el software donde se hizo la carga de datos o bien en el formato que los responsables de la recolección eligieron para compartir la información.\nHabitualmente los archivos .xls / .xlsx (Microsoft Excel), .dbf (database), .accdb (Microsoft Access) son usados en archivos creados dentro de proyectos sencillos donde las planillas de calculo o programa de bases de datos se pueden correr en computadoras personales.\nSi los datos fuern procesados previamente por algun software estadístico puede que los archivos compartidos tengan formato .sas7bdat (SAS), .sav (SPSS), dta (Stata) o .RData (R).\nTambién podemnos llegar a encontrar archivos .json (acrónimo de JavaScript Object Notation, ‘notación de objeto de JavaScript’) que es un formato abierto de texto sencillo o .xml(del inglés eXtensible Markup Language, traducido como ‘Lenguaje de Marcas Extensible’)."
  },
  {
    "objectID": "primero/clases/00-datos.html#almacenamiento-y-seguridad",
    "href": "primero/clases/00-datos.html#almacenamiento-y-seguridad",
    "title": "Gestión de datos",
    "section": "Almacenamiento y seguridad",
    "text": "Almacenamiento y seguridad\nA medida que comenzamos a recopilar datos, es importante tener una estructura bien planificada para almacenarlos de forma segura y trabajar con ellos durante el estudio activo. Hay varios objetivos que debemos tener en cuenta al configurar el sistema de almacenamiento y seguridad de archivos:\n\nSeguridad: garantizar que sus archivos no se pierdan, corrompan o editen inesperadamente.\n\nPara cumplir con este punto se establecen formas y protocolos que se ejecuten periódicamente de copias de seguridad que pueden realizarse en discos rígidos, espacios en un servidor central o servicios online tipo Google Drive, Dropbox, etc que deberan contar con los accesos restringidos a los usuarios autorizados del proyecto.\n\nConfidencialidad: asegurarse de que personas no autorizadas no vean ni accedan a información confidencial.\n\nNo solo estamos hablando de los archivos electrónicos producto de la recolección de datos sino también de los formularios, cuestionarios, planillas o cualquier otro dispositivo en papel que tenga información de identificación y/o sensible de participantes.\nArmarios con cerraduras y espacios físicos con medidas de seguridad son recomendados en estas situaciones. Lo mismo respecto del lugar donde se encuentra la o las computadoras del equipo de trabajo, sus pendrive y discos rígidos externos.\n\nAccesibilidad y usabilidad de los archivos: asegurarse de que el equipo de trabajo pueda encontrar los archivos fácilmente y que pueda comprender qué contienen.\n\nExisten varias formas de lograr este objetivo y deberá evaluarse durante la planificación. Se pueden usar espacios de colaboración tipo Google Drive o proyectos privados de sistema de control de versiones como GitHub o GitLab. Dependerá de las capacidades de los integrantes del equipo y del nivel de comodidad buscado."
  },
  {
    "objectID": "primero/clases/00-datos.html#depuración-de-datos",
    "href": "primero/clases/00-datos.html#depuración-de-datos",
    "title": "Gestión de datos",
    "section": "Depuración de datos",
    "text": "Depuración de datos\nIncluso con los esfuerzos de recopilación y captura de datos mejor diseñados, los datos aún requieren al menos un poco de procesamiento adicional antes de que estén en un formato que le permita compartir con confianza. Lo que se haga en la fase de procesamiento de datos, o limpieza de datos, dependerá en gran medida de las transformaciones planificadas para sus datos, así como del nivel de garantía de calidad y procesos de control implementados durante la recopilación y captura.\nEn situaciones donde los datos provienen de fuentes secundarias, las hay con garatía de calidad y también sin controles como la información que sale de muchos sistemas de vigilancia epidemiológica (por ejemplo, el SNVS del SISA).\nLa limpieza de datos es el proceso de organizar y transformar datos sin procesar en un conjunto de datos al que se puede acceder y analizar fácilmente. Esta etapa puede dar como resultado esencialmente dos tipos diferentes de conjuntos de datos: un conjunto de datos curado para fines de intercambio de datos generales y un conjunto de datos limpio para un análisis específico.\nUn conjunto de datos limpio para el intercambio significa que incluye toda la muestra del estudio (no se elimina a nadie), todos los datos faltantes siguen etiquetados como faltantes (no se realiza ninguna imputación) y no se han calculado variables específicas del análisis. Cualquier limpieza adicional se realiza en otra fase de limpieza durante los análisis.\nSe puede pensar en los datos en tres fases distintas:\n\nDatos brutos\n\n\nEste es el archivo sin procesar que proviene directamente de su fuente de recopilación o captura de datos. Si sus datos se recopilan electrónicamente, este es el archivo que extrae de su herramienta. Si sus datos se recopilan en papel, estos son los datos que se han ingresado en un formato legible por máquina. Si tiene una fuente de datos secundaria, este es el archivo que descarga o recibe del proveedor externo.\nEstos datos normalmente no se comparten fuera del equipo de investigación, ya que suelen contener información identificable y a menudo es necesario procesarlos más para que un usuario final pueda descifrarlos.\n\n\nDatos depurados del estudio\n\n\nÉste es el conjunto de datos que se puede compartir públicamente.\n\n\nDatos analíticos\n\n\nEste conjunto de datos se crea a partir del conjunto depurado de datos (ya sea por su equipo o por otros investigadores), pero se modifica aún más para un análisis específico. Este conjunto de datos normalmente también se puede compartir públicamente en un repositorio (por ejemplo Zenodo) en el momento de la publicación para permitir la replicación del análisis asociado. Aquí aparecen las variables creadas en el análisis, posibles eliminaciones de observaciones y/o variables e imputaciones de valores perdidos.\n\n\n\n\n\n\nflowchart TB\n  A[Datos crudos] --&gt; B[Datos limpios]\n  B --&gt; C[Datos analíticos]\n\n\n\n\n\n\n\nCriterios de calidad\nAntes de limpiar nuestros datos, debemos tener un entendimiento compartido sobre cómo esperamos que se vean una vez que se depuren, que aseguren una determinada calidad.\nLos siguientes son criterios posibles de limpieza:\n\nCompleto\n\n\nLa cantidad de filas en su conjunto de datos debe coincidir con la cantidad de formularios completados registrados en su base de datos de seguimiento de participantes. Esto significa que todos los formularios que recopiló se capturaron (ya sea que se ingresaron o se recuperaron). También significa que eliminó todos los datos extraños que no pertenecen (por ejemplo, duplicados, participantes que no están en la muestra final, etc).\nLa cantidad de columnas de sus datos coincide con la cantidad de variables que tiene en su diccionario de datos (es decir, no se eliminaron variables accidentalmente). De manera similar, no debería haber datos faltantes inesperados para las variables (es decir, si se recopilaron los datos, deberían existir en su conjunto de datos).\nPuede haber observaciones y/o variables eliminadas, pero a partir de una decisión consciente y debidamente documentada.\n\n\nVálido\n\n\nLas variables se ajustan a las restricciones que ha establecido en su diccionario de datos (por ejemplo, tipos de variables, valores y rangos de variables permitidos, la falta de elementos a nivel de elemento se alinea con las reglas del universo de variables y los patrones de omisión definidos)\n\n\nPreciso\n\n\nMuchas veces no hay forma de saber si un valor es verdadero o no. Sin embargo, es posible utilizar su conocimiento implícito de un participante o una fuente de datos para descubrir valores erróneos.\n\n\nCoherente\n\n\nLos valores de las variables se miden, formatean o categorizan de manera consistente dentro de una columna (por ejemplo, todos los valores de la fecha de la encuesta tienen el formato AAAA-MM-DD).\nEn colecciones repetidas del mismo formulario, todas las variables se nombran, miden, formatean o codifican de manera consistente (por ejemplo, las categorías y/o códigos cargados en las variables son las del diccionario de datos).\n\n\nAnonimizado\n\n\nSi se promete confidencialidad a los participantes, es necesario anonimizar los datos. En las primeras fases de limpieza, esto simplemente significa que se eliminan todos los identificadores directos de los datos y se reemplazan con códigos de estudio (es decir, identificador único del participante). Antes de compartir públicamente los datos, puede ser necesario un trabajo adicional para eliminar también los identificadores indirectos.\n\n\nInterpretable\n\n\nLas variables se nombran para que coincidan con el diccionario de datos y esos nombres son legibles tanto para humanos como para máquinas. Según sea necesario, se agregan etiquetas de variables y valores como metadatos integrados para facilitar la interpretación.\n\n\nAnalizable\n\n\nEl conjunto de datos tiene un formato rectangular (filas y columnas), legible por máquina y cumple con las reglas básicas de organización de datos."
  },
  {
    "objectID": "primero/clases/00-datos.html#softwares-y-lenguajes-de-análisis",
    "href": "primero/clases/00-datos.html#softwares-y-lenguajes-de-análisis",
    "title": "Gestión de datos",
    "section": "Softwares y lenguajes de análisis",
    "text": "Softwares y lenguajes de análisis\n(documentación, guías de estilo, etc) Proyectos - estructura de directorios y archivos - metadatos - buenas practicas Captura de datos - Formatos de archivos\nDepuración y validación de datos\nAlmacenamiento, seguridad, colaboración y archivo de datos\n\nAnálisis - Softwares y lenguajes disponibles"
  },
  {
    "objectID": "primero/clases/00-datos.html#softwares-y-lenguajes-de-análisis-estadístico",
    "href": "primero/clases/00-datos.html#softwares-y-lenguajes-de-análisis-estadístico",
    "title": "Gestión de datos",
    "section": "Softwares y lenguajes de análisis estadístico",
    "text": "Softwares y lenguajes de análisis estadístico\nEn el ámbito cuantitativista del mundo epidemiológico se utilizan diversos paquetes estadísticos. Un paquete estadístico es un programa informático que está especialmente diseñado para resolver problemas en el área de la estadística, que estos casos aplicamos a estudios epidemiológicos.\nLos paquetes más sencillos tienen interfaz gráfica por ventanas, lo que implica facilidad de uso y aprendizaje pero un mayor encorsetamiento a la hora de hacer cálculos que el programa no tenga predefinidos. Los programas más complejos exigen conocer su lenguaje de programación, pero suelen ser mucho más flexibles al poderse incluir en ellos librerías con funciones, tests o contrastes que no traen instalados por defecto.\nExisten multitud de paquetes informáticos, tanto de software privado como de software libre y/o open source, dentro de los cuales encontramos:\n\n\n\nInterfaz gráfica (GUI)\nInterfaz de línea de comando (CLI)\n\n\n\n\nExcel\nLenguaje R\n\n\nSPSS\nStata\n\n\nEpiDat\nLenguaje Python\n\n\nEpiInfo\nSAS\n\n\nStata\nLenguaje Julia\n\n\nSAS\nPSPP\n\n\nStatgraphics\n\n\n\nMinitab\n\n\n\nPSPP\n\n\n\n\nAlgunos poseen tanto interfaz gráfica como de línea de comando, aunque no llegan a ser un lenguaje de programación. Cada una con sus ventajas y desventajas, suele ser más veloz el aprendizaje de los paquetes gráficos pero también limitados a la hora de hacer cosas más complejas. La curva de aprendizaje de los lenguajes de programación como R, Python o Julia es lenta pero a su vez no tiene límites respecto del tipo de análisis que necesitemos."
  },
  {
    "objectID": "primero/clases/00-datos.html#bibliografía",
    "href": "primero/clases/00-datos.html#bibliografía",
    "title": "Gestión de datos",
    "section": "Bibliografía",
    "text": "Bibliografía"
  },
  {
    "objectID": "primero/clases/05-datosPerdidos.html",
    "href": "primero/clases/05-datosPerdidos.html",
    "title": "Datos perdidos (missing)",
    "section": "",
    "text": "Cuando trabajamos con datos los valores perdidos o faltantes (conocidos en inglés como missing) pueden constituir un serio problema en nuestras variables por lo que deben explorarse y manejarse cuidadosamente en las etapas iniciales del análisis.\nEstos datos pueden faltar por muchas razones, pero generalmente se suelen agrupar en dos categorías: valores faltantes informativos y valores faltantes aleatorios. Los informativos implican una causa estructural, ya sea por deficiencias en la forma en que se recopilaron los datos o por anomalías en el entorno de observación. Los aleatorios son aquellos que tienen lugar independientemente del proceso de recopilación de datos.\nDependiendo de si los valores faltantes son de uno u otro tipo, se procederá de una u otra manera. A los informativos, en general, se les puede asignar un valor concreto (por ejemplo, “Ninguno” o “Sin dato”), ya que este valor puede convenir tenerlo como una categoría más de la variable. Los aleatorios, en cambio, pueden manejarse mediante la eliminación o la imputación.\nResumiendo, las tareas habituales respecto a estos valores consisten en:\nRespecto a la imputación existen numerosa bibliografía sobre diversos algoritmos que no vamos a incluir en este curso."
  },
  {
    "objectID": "primero/clases/05-datosPerdidos.html#detectar-observaciones-incompletas-valores-missing",
    "href": "primero/clases/05-datosPerdidos.html#detectar-observaciones-incompletas-valores-missing",
    "title": "Datos perdidos (missing)",
    "section": "Detectar observaciones incompletas (valores missing)",
    "text": "Detectar observaciones incompletas (valores missing)\nEl lenguaje R gestiona a los datos perdidos mediante el valor especial reservado NA de Not Available (No disponible),\nEn principio, sólo vamos a enfocarnos en como podemos utilizar algunas funciones del lenguaje para detectarlos y contabilizarlos. A partir de su identificación decidiremos que hacer con ellos, dependiendo de su cantidad y extensión, es decir, si los valores faltantes son la mayoría de una variable o la mayoría de una observación o bien si representan la falta de respuesta de una pregunta, con lo cual convenga etiquetarlos.\nUna manera de abordar esta tarea con R base para una variables es hacer la sumatoria de valores NA, usando la función de identificación is.na().\nPara ejemplificar, tomamos una tabla de datos de vigilancia con 200 observaciones y 56 variables.\n\ndatos |&gt; \n  summarise(Cantidad_NA = sum(is.na(FECHA_FIN_TRAT)))\n\n# A tibble: 1 × 1\n  Cantidad_NA\n        &lt;int&gt;\n1         142\n\n\nLa consulta dice que hay 142 observaciones vacías en la variable FECHA_FIN_TRAT. Lo malo es que debemos hacer esta tarea variable por variable, lo que resulta muy trabajoso.\nTambién la función summary() aplicada sobre el dataframe completo informa la cantidad de NA de variables cuantitativas, lógicas y fecha, pero no lo hace con las de tipo caracter.\n\nsummary(datos)\n\n     SEXO           FECHA_NACIMIENTO              EDAD_DIAGNOSTICO\n Length:200         Min.   :1934-12-13 00:00:00   Min.   : 0.00   \n Class :character   1st Qu.:1973-11-06 12:00:00   1st Qu.:23.00   \n Mode  :character   Median :1989-07-27 00:00:00   Median :33.00   \n                    Mean   :1985-12-04 18:14:24   Mean   :37.02   \n                    3rd Qu.:1999-11-17 12:00:00   3rd Qu.:49.00   \n                    Max.   :2023-05-05 00:00:00   Max.   :88.00   \n                                                                  \n   GRUPEDAD         PROVINCIA_RESIDENCIA ID_PROV_INDEC_RESIDENCIA\n Length:200         Length:200           Length:200              \n Class :character   Class :character     Class :character        \n Mode  :character   Mode  :character     Mode  :character        \n                                                                 \n                                                                 \n                                                                 \n                                                                 \n DEPARTAMENTO_RESIDENCIA ID_DEPTO_INDEC_RESIDENCIA LOCALIDAD_RESIDENCIA\n Length:200              Length:200                Length:200          \n Class :character        Class :character          Class :character    \n Mode  :character        Mode  :character          Mode  :character    \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n ESTABLECIMIENTO_SALUD ESTABLECIMIENTO_CARGA PROVINCIA_CARGA   \n Length:200            Length:200            Length:200        \n Class :character      Class :character      Class :character  \n Mode  :character      Mode  :character      Mode  :character  \n                                                               \n                                                               \n                                                               \n                                                               \n DEPTO_CARGA        ESTAB_CLINICA      DEPTO_CLINICA          PPL           \n Length:200         Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n SERVICIO_PENITENCIARIO FECHA_APERTURA               \n Length:200             Min.   :2021-09-20 00:00:00  \n Class :character       1st Qu.:2023-04-12 18:00:00  \n Mode  :character       Median :2023-07-16 00:00:00  \n                        Mean   :2023-07-14 09:07:12  \n                        3rd Qu.:2023-10-18 12:00:00  \n                        Max.   :2024-04-18 00:00:00  \n                                                     \n FECHA_NOTIFICACION            MOTIVO_CONSULTA    CLASIFICACION_MANUAL\n Min.   :2023-01-03 00:00:00   Length:200         Length:200          \n 1st Qu.:2023-04-03 12:00:00   Class :character   Class :character    \n Median :2023-07-03 00:00:00   Mode  :character   Mode  :character    \n Mean   :2023-07-01 12:36:00                                          \n 3rd Qu.:2023-10-03 00:00:00                                          \n Max.   :2023-12-27 00:00:00                                          \n                                                                      \n CLASIF_INICIO_TRAT ID_PULMONAR             FIS                        \n Length:200         Length:200         Min.   :2020-12-20 00:00:00.00  \n Class :character   Class :character   1st Qu.:2023-02-20 00:00:00.00  \n Mode  :character   Mode  :character   Median :2023-05-12 12:00:00.00  \n                                       Mean   :2023-05-10 05:22:06.31  \n                                       3rd Qu.:2023-08-09 18:00:00.00  \n                                       Max.   :2023-12-21 00:00:00.00  \n                                       NA's   :48                      \n ID_EXTRAPULMONAR   FECHA_INICIO_SINTOMA             RESULTADO_RX      \n Length:200         Min.   :2022-08-15 00:00:00.00   Length:200        \n Class :character   1st Qu.:2023-03-01 00:00:00.00   Class :character  \n Mode  :character   Median :2023-05-17 12:00:00.00   Mode  :character  \n                    Mean   :2023-05-28 01:50:46.15                     \n                    3rd Qu.:2023-08-09 00:00:00.00                     \n                    Max.   :2023-12-26 00:00:00.00                     \n                    NA's   :44                                         \n Bacteriologia      Baciloscopia         Cultivo          PRUEBA_RESISTENCIA\n Length:200         Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n RESISTENCIA           Droga           Tipo_Resistencia  \n Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n ESTABLECIMIENTO_MUESTRA DEPARTAMENTO_MUESTRA ESTABLECIMIENTO_DIAG\n Length:200              Length:200           Length:200          \n Class :character        Class :character     Class :character    \n Mode  :character        Mode  :character     Mode  :character    \n                                                                  \n                                                                  \n                                                                  \n                                                                  \n DEPARTAMENTO_DIAG   Prueba_VIH            VIH           \n Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n TRATAMIENTO_ANTIRRETROVIRAL Diag_rapido        Resultado_diag_rapido\n Length:200                  Length:200         Length:200           \n Class :character            Class :character   Class :character     \n Mode  :character            Mode  :character   Mode  :character     \n                                                                     \n                                                                     \n                                                                     \n                                                                     \n   EMBARAZO           DIABETES         CONSUMO_PROB_DROGAS ENF_RESP_CRONICA  \n Length:200         Length:200         Length:200          Length:200        \n Class :character   Class :character   Class :character    Class :character  \n Mode  :character   Mode  :character   Mode  :character    Mode  :character  \n                                                                             \n                                                                             \n                                                                             \n                                                                             \n    COVID           SE_DECLARA_PUEBLO_INDIGENA  ETNIA        \n Length:200         Length:200                 Mode:logical  \n Class :character   Class :character           NA's:200      \n Mode  :character   Mode  :character                         \n                                                             \n                                                             \n                                                             \n                                                             \n  TABAQUISMO        ALCOHOLISMO         ESTAB_TTO        \n Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n FECHA_INICIO_TRAT                FECHA_FIN_TRAT                  \n Min.   :2023-01-03 00:00:00.00   Min.   :2023-03-09 00:00:00.00  \n 1st Qu.:2023-03-20 00:00:00.00   1st Qu.:2023-08-21 00:00:00.00  \n Median :2023-07-02 00:00:00.00   Median :2023-10-23 12:00:00.00  \n Mean   :2023-06-28 21:42:25.22   Mean   :2023-10-23 02:04:08.27  \n 3rd Qu.:2023-10-05 00:00:00.00   3rd Qu.:2024-01-11 12:00:00.00  \n Max.   :2024-01-08 00:00:00.00   Max.   :2024-04-05 00:00:00.00  \n NA's   :43                       NA's   :142                     \n RESULTADO_TRATAMIENTO\n Length:200           \n Class :character     \n Mode  :character     \n                      \n                      \n                      \n                      \n\n\nMás completo y en una sola línea la función find_na() del paquete dlookr muestra el porcentaje de valores perdidos en todas las variables de una tabla de datos y se complementa con el gráfico de barras de pareto plot_na_pareto().\n\nlibrary(dlookr)\n\nfind_na(datos, rate = T) # argumento rate = T muestra % de valores NA\n\n                       SEXO            FECHA_NACIMIENTO \n                        0.0                         0.0 \n           EDAD_DIAGNOSTICO                    GRUPEDAD \n                        0.0                         0.0 \n       PROVINCIA_RESIDENCIA    ID_PROV_INDEC_RESIDENCIA \n                        0.0                         0.0 \n    DEPARTAMENTO_RESIDENCIA   ID_DEPTO_INDEC_RESIDENCIA \n                        4.5                         0.0 \n       LOCALIDAD_RESIDENCIA       ESTABLECIMIENTO_SALUD \n                        0.0                         0.0 \n      ESTABLECIMIENTO_CARGA             PROVINCIA_CARGA \n                        0.0                         0.0 \n                DEPTO_CARGA               ESTAB_CLINICA \n                        0.0                        10.0 \n              DEPTO_CLINICA                         PPL \n                       10.0                         0.0 \n     SERVICIO_PENITENCIARIO              FECHA_APERTURA \n                        0.0                         0.0 \n         FECHA_NOTIFICACION             MOTIVO_CONSULTA \n                        0.0                        90.5 \n       CLASIFICACION_MANUAL          CLASIF_INICIO_TRAT \n                        0.0                         0.0 \n                ID_PULMONAR                         FIS \n                        0.0                        24.0 \n           ID_EXTRAPULMONAR        FECHA_INICIO_SINTOMA \n                        0.0                        22.0 \n               RESULTADO_RX               Bacteriologia \n                        0.0                         0.0 \n               Baciloscopia                     Cultivo \n                        0.0                         0.0 \n         PRUEBA_RESISTENCIA                 RESISTENCIA \n                        0.0                         0.0 \n                      Droga            Tipo_Resistencia \n                        0.0                         0.0 \n    ESTABLECIMIENTO_MUESTRA        DEPARTAMENTO_MUESTRA \n                       36.0                        36.0 \n       ESTABLECIMIENTO_DIAG           DEPARTAMENTO_DIAG \n                       38.0                        38.0 \n                 Prueba_VIH                         VIH \n                        0.0                         0.0 \nTRATAMIENTO_ANTIRRETROVIRAL                 Diag_rapido \n                       99.5                         0.0 \n      Resultado_diag_rapido                    EMBARAZO \n                        0.0                         0.0 \n                   DIABETES         CONSUMO_PROB_DROGAS \n                        0.0                         0.0 \n           ENF_RESP_CRONICA                       COVID \n                        0.0                        99.5 \n SE_DECLARA_PUEBLO_INDIGENA                       ETNIA \n                        0.0                       100.0 \n                 TABAQUISMO                 ALCOHOLISMO \n                        0.0                         0.0 \n                  ESTAB_TTO           FECHA_INICIO_TRAT \n                       17.5                        21.5 \n             FECHA_FIN_TRAT       RESULTADO_TRATAMIENTO \n                       71.0                         0.0 \n\n\n\nplot_na_pareto(datos, \n               only_na = T) # argumento only_na = T muestra variables solo con algún valor NA"
  },
  {
    "objectID": "primero/clases/05-datosPerdidos.html#gestión-de-nas-con-naniar",
    "href": "primero/clases/05-datosPerdidos.html#gestión-de-nas-con-naniar",
    "title": "Datos perdidos (missing)",
    "section": "Gestión de NA’s con naniar",
    "text": "Gestión de NA’s con naniar\n\n\n\n\n\nEl paquete naniar es un paquete que reúne funciones diseñadas para el manejo de valores faltantes pensado para una gestión completa.\n\nlibrary(naniar)\n\nSus caracteristicas generales son:\n\nProporciona funciones analíticas y visuales de detección y gestión\nEs compatible con el mundo “tidy” de tidyverse\nAborda las relaciones o estructura de la falta de datos.\nPosibilita el trabajo de imputación (no tratado en este curso)\n\nDe las muchas funciones que tiene el paquete seleccionamos algunas para mostrar que son muy útiles para una tarea básica.\nLa función miss_var_summary() proporciona un resumen sobre los valores NA en cada variable del dataframe similar a find_na() que vimos anterioremente pero con una salida en forma de tabla y un recento absoluto, además de porcentual.\n\nmiss_var_summary(datos)\n\n# A tibble: 56 × 3\n   variable                    n_miss pct_miss\n   &lt;chr&gt;                        &lt;int&gt;    &lt;num&gt;\n 1 ETNIA                          200    100  \n 2 TRATAMIENTO_ANTIRRETROVIRAL    199     99.5\n 3 COVID                          199     99.5\n 4 MOTIVO_CONSULTA                181     90.5\n 5 FECHA_FIN_TRAT                 142     71  \n 6 ESTABLECIMIENTO_DIAG            76     38  \n 7 DEPARTAMENTO_DIAG               76     38  \n 8 ESTABLECIMIENTO_MUESTRA         72     36  \n 9 DEPARTAMENTO_MUESTRA            72     36  \n10 FIS                             48     24  \n# ℹ 46 more rows\n\n\nPor el lado gráfico, ofrece la función gg_miss_var() que representa la información de la tabla anterior pero a través de un gráfico lollipop horizontal de tipo ggplot2.\n\ngg_miss_var(datos, \n            show_pct = T) # muestra valores en porcentajes\n\n\n\n\n\n\n\n\nHay otra viaulización muy interesante porque muestra las relaciones de los valores ausentes de las variables cuya función se llama gg_miss_upset() y genera un gráfico Upset en función de la existencia de valores NA.\n\ngg_miss_upset(datos) \n\n Por defecto, construye el gráfico tomando las primeras 10 variables de la tabla de datos con valores NA de forma decreciente. Esto se puede modificar cambiando el argumentos nset =.\nTiene dos entradas para su lectura. En la parte inferior izquierda nos muestra los nombres de las variables con valores NA ordenadas de menor a mayor medida en una escala absoluta. El gráfico de barras principal, ordenado de forma predeterminada de mayor a menor, informa sobre las cantidades absolutas de valores NA de las combinaciones que aperecen debajo del eje x del gráfico.\nPor ejemplo, la variable ETNIA tiene todos sus observaciones como NA y la variable COVID casi lo mismo, mientras que la variable FIS cerca de 50.\nPodemos eliminar del gráfico a esas dos variables con casi todos los valores NA, usando formas de tidyverse previas dado que las funciones de naniar son compatibles.\n\ndatos |&gt; \n  select(-ETNIA, -COVID) |&gt; \n  gg_miss_upset() \n\n\nAl quitar esas dos variables, aparecen dos nuevas con cantidades menores de NA que FIS (FECHA_INICIO_TRAT y FECHA_INICIO_SINTOMA), es decir siguen siendo 10 por defecto.\nSi miramos los datos faltantes con estructura notamos que la combinación más frecuente de NA combinados es FECHA_FIN_TRAT, MOTIVO_CONSULTA y TRATAMIENTO_ANTIRETROVIRAL con 39 observaciones a las que le faltan valores en las tres variables simultáneamente."
  },
  {
    "objectID": "primero/clases/05-datosPerdidos.html#reemplazo-de-valores",
    "href": "primero/clases/05-datosPerdidos.html#reemplazo-de-valores",
    "title": "Datos perdidos (missing)",
    "section": "Reemplazo de valores",
    "text": "Reemplazo de valores\nEl paquete tiene además dos funciones de reemplazo que funcionan como herramientas antagónicas.\nreplace_with_na() reemplaza valores o etiquetas específicas con valores NA y replace_na_with() hace lo contrario, reemplaza valores NA con valores específicos, como “Sin dato” por ejemplo.\nLa primera función trabaja sobre el dataframe completo adignando valores NA en la categoría o valor que le indiquemos.\nPor ejemplo, la variable ID_PROV_INDEC_RESIDENCIA no tiene valores perdidos pero si hay una categoría/código desconocido (“00”), entonces podemos decirle que ese código sea NA.\n\ndatos |&gt; \n  summarise(Cantidad_NA = sum(is.na(ID_PROV_INDEC_RESIDENCIA)))\n\n# A tibble: 1 × 1\n  Cantidad_NA\n        &lt;int&gt;\n1           0\n\ndatos |&gt; \n   replace_with_na(replace = list(ID_PROV_INDEC_RESIDENCIA = \"00\")) |&gt;     \n  summarise(Cantidad_NA = sum(is.na(ID_PROV_INDEC_RESIDENCIA)))\n\n# A tibble: 1 × 1\n  Cantidad_NA\n        &lt;int&gt;\n1           2\n\n\nreplace_na_with() etiqueta valores faltantes con categorías definidas que serán tenidas en cuenta a la hora de hacer tablas u otras operaciones. Esta función se utiliza dentro de mutate() del tidyverse.\nLa variable MOTIVO_CONSULTA tiene 181 valores NA que serán etiquetados como “Sin dato” de esta forma:\n\ndatos |&gt; \n  count(MOTIVO_CONSULTA)\n\n# A tibble: 4 × 2\n  MOTIVO_CONSULTA              n\n  &lt;chr&gt;                    &lt;int&gt;\n1 Contacto                     2\n2 Examen de Salud              1\n3 Sintomático Respiratorio    16\n4 &lt;NA&gt;                       181\n\ndatos |&gt; \n  mutate(MOTIVO_CONSULTA = replace_na_with(MOTIVO_CONSULTA, \n                                           \"Sin dato\")) |&gt; \n  count(MOTIVO_CONSULTA)\n\n# A tibble: 4 × 2\n  MOTIVO_CONSULTA              n\n  &lt;chr&gt;                    &lt;int&gt;\n1 Contacto                     2\n2 Examen de Salud              1\n3 Sin dato                   181\n4 Sintomático Respiratorio    16"
  },
  {
    "objectID": "primero/clases/05-datosPerdidos.html#eliminación-de-valores-na",
    "href": "primero/clases/05-datosPerdidos.html#eliminación-de-valores-na",
    "title": "Datos perdidos (missing)",
    "section": "Eliminación de valores NA",
    "text": "Eliminación de valores NA\nCuando decidimos eliminar valores NA de alguna variable, salvo que se quite la variable entera, tenemos que tener en cuenta que perdemos la observación completa, incluso valores válidos que se encuentran en otras variables.\nR base tiene una función llamada na.omit() que omite toda observación donde al menos haya un solo NA en alguna variable.\n\nna.omit(datos)\n\n# A tibble: 0 × 56\n# ℹ 56 variables: SEXO &lt;chr&gt;, FECHA_NACIMIENTO &lt;dttm&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;dttm&gt;, …\n\n\nAplicar esta función sobre el dataframe datos produce que no quede ninguna observación, dado que vimos que la variable ETNIA tenía sus doscientos valores vacíos.\nUna función superadora es drop_na() de tidyr que pertenece a tidyverse, porque omite observaciones que tengan variables que definamos, por ejemplo:\n\ndatos |&gt; \n  drop_na(ETNIA)\n\n# A tibble: 0 × 56\n# ℹ 56 variables: SEXO &lt;chr&gt;, FECHA_NACIMIENTO &lt;dttm&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;dttm&gt;, …\n\ndatos |&gt; \n  drop_na(FIS)\n\n# A tibble: 152 × 56\n   SEXO  FECHA_NACIMIENTO    EDAD_DIAGNOSTICO GRUPEDAD PROVINCIA_RESIDENCIA\n   &lt;chr&gt; &lt;dttm&gt;                         &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;               \n 1 M     1948-06-22 00:00:00               74 70-74    Tierra del Fuego    \n 2 F     1981-06-20 00:00:00               41 40-44    Buenos Aires        \n 3 F     1989-03-30 00:00:00               33 30-34    Buenos Aires        \n 4 M     2006-11-17 00:00:00               16 15-19    Chaco               \n 5 M     1993-06-02 00:00:00               29 25-29    Jujuy               \n 6 M     1989-04-08 00:00:00               33 30-34    Buenos Aires        \n 7 F     1977-07-30 00:00:00               45 45-49    Buenos Aires        \n 8 F     2008-01-10 00:00:00               15 15-19    Chaco               \n 9 M     1987-11-27 00:00:00               35 35-39    Buenos Aires        \n10 F     2002-12-21 00:00:00               20 20-24    Buenos Aires        \n# ℹ 142 more rows\n# ℹ 51 more variables: ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;dttm&gt;, …\n\n\nEn el ejemplo anterior aplicamos la función sobre la variable ETNIA y FIS, en el primer caso omite todas las observaciones y en el segundo caso 48 observaciones, mostrando las 152 restantes sin NA en la variable.\nPor último, debemos saber que eliminar observaciones por valores faltantes reduce la potencia de cualquier test de hipotesis o modelo que hagamos porque se reduce el tamaño de la muestra."
  },
  {
    "objectID": "primero/clases/06-depuracion.html",
    "href": "primero/clases/06-depuracion.html",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "",
    "text": "En el ámbito de los proyectos de análisis de datos, el preprocesamiento, también conocido como preparación de datos, es una etapa crucial que precede al análisis propiamente dicho. Esta fase esencial tiene como objetivo acondicionar los datos para su posterior análisis, garantizando su confiabilidad e integridad.\nLas tareas de preprocesamiento son específicas para cada conjunto de datos y dependen de los objetivos del proyecto y las técnicas de análisis que se emplearán. Sin embargo, existen tareas comunes que son aplicables a la mayoría de los casos, entre las que se encuentran el diagnóstico y la limpieza de datos."
  },
  {
    "objectID": "primero/clases/06-depuracion.html#exploración-y-diagnóstico-de-datos",
    "href": "primero/clases/06-depuracion.html#exploración-y-diagnóstico-de-datos",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "Exploración y diagnóstico de datos",
    "text": "Exploración y diagnóstico de datos\nLa etapa de diagnóstico de datos es fundamental para comprender la estructura y características del conjunto de datos que se va a analizar. Esta fase involucra una serie de tareas esenciales, como:\nAnálisis de la estructura de la tabla de datos: Esta tarea implica comprender la organización de los datos, identificando las variables, sus tipos de datos y la distribución de los registros. Es relevante vincular este proceso con el “diccionario de datos” de la tabla o base, ya sea de fuente secundaria o creada por nosotros mismos.\nVerificación del tipo de dato de cada variable de interés: Es crucial determinar el tipo de dato de cada variable (numérica, categórica, fecha-hora, etc.) para aplicar las técnicas de análisis adecuadas.\nDetección de valores faltantes: La presencia de valores faltantes puede afectar significativamente los resultados del análisis. Es importante identificar estos valores y determinar la mejor manera de manejarlos (eliminación, imputación, etc.).\nIdentificación de las categorías de las variables cualitativas: En el caso de variables categóricas, es necesario identificar las categorías existentes y evaluar su distribución.\nAnálisis de los mínimos y máximos de valores de cada variable cuantitativa: Para variables numéricas, es importante determinar los valores mínimos y máximos para detectar posibles valores atípicos o errores de entrada.\nExisten diversas herramientas y funciones que facilitan la etapa de diagnóstico de datos. En este curso, se presentarán algunas de las funciones más útiles de paquetes de R."
  },
  {
    "objectID": "primero/clases/06-depuracion.html#skimr",
    "href": "primero/clases/06-depuracion.html#skimr",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "Skimr",
    "text": "Skimr\n\n\n\n\n\nEste paquete tiene funciones diseñadas para obtener un resumen rápido de la estructura de tablas de datos y son compatibles con el ecosistema tidyverse.\nLa función principal del paquete es skim y puede ser aplicada a todo el dataframe o bien a una variable o a un grupo de ellas.\n\nProporciona un conjunto más amplio de estadísticas que summary(), incluyendo valores faltantes, completos, número total (n) y desvío estándar (sd).\nInforma de cada tipo de dato por separado.\nManeja fechas, valores lógicos y otros tipos.\n\nTrabajemos con skimr sobre un conjunto de datos provenientes de la vigilancia del SNVS.\n\nlibrary(skimr)\n\nskim(datos)\n\n\nData summary\n\n\nName\ndatos\n\n\nNumber of rows\n200\n\n\nNumber of columns\n56\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n47\n\n\nDate\n7\n\n\nlogical\n1\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSEXO\n0\n1.00\n1\n1\n0\n3\n0\n\n\nGRUPEDAD\n0\n1.00\n3\n5\n0\n18\n0\n\n\nPROVINCIA_RESIDENCIA\n0\n1.00\n4\n16\n0\n18\n0\n\n\nID_PROV_INDEC_RESIDENCIA\n0\n1.00\n2\n2\n0\n18\n0\n\n\nDEPARTAMENTO_RESIDENCIA\n9\n0.96\n4\n26\n0\n81\n0\n\n\nID_DEPTO_INDEC_RESIDENCIA\n0\n1.00\n2\n5\n0\n89\n0\n\n\nLOCALIDAD_RESIDENCIA\n0\n1.00\n4\n57\n0\n106\n0\n\n\nESTABLECIMIENTO_SALUD\n0\n1.00\n11\n82\n0\n125\n0\n\n\nESTABLECIMIENTO_CARGA\n0\n1.00\n5\n82\n0\n117\n0\n\n\nPROVINCIA_CARGA\n0\n1.00\n4\n16\n0\n17\n0\n\n\nDEPTO_CARGA\n0\n1.00\n4\n22\n0\n70\n0\n\n\nESTAB_CLINICA\n20\n0.90\n11\n76\n0\n112\n0\n\n\nDEPTO_CLINICA\n20\n0.90\n4\n23\n0\n73\n0\n\n\nPPL\n0\n1.00\n2\n2\n0\n2\n0\n\n\nSERVICIO_PENITENCIARIO\n0\n1.00\n2\n19\n0\n7\n0\n\n\nMOTIVO_CONSULTA\n181\n0.09\n8\n24\n0\n3\n0\n\n\nCLASIFICACION_MANUAL\n0\n1.00\n10\n67\n0\n9\n0\n\n\nCLASIF_INICIO_TRAT\n0\n1.00\n5\n34\n0\n6\n0\n\n\nID_PULMONAR\n0\n1.00\n2\n15\n0\n3\n0\n\n\nID_EXTRAPULMONAR\n0\n1.00\n5\n31\n0\n13\n0\n\n\nRESULTADO_RX\n0\n1.00\n9\n28\n0\n8\n0\n\n\nBacteriologia\n0\n1.00\n8\n15\n0\n3\n0\n\n\nBaciloscopia\n0\n1.00\n8\n15\n0\n6\n0\n\n\nCultivo\n0\n1.00\n8\n26\n0\n7\n0\n\n\nPRUEBA_RESISTENCIA\n0\n1.00\n2\n15\n0\n2\n0\n\n\nRESISTENCIA\n0\n1.00\n15\n25\n0\n4\n0\n\n\nDroga\n0\n1.00\n2\n26\n0\n6\n0\n\n\nTipo_Resistencia\n0\n1.00\n2\n10\n0\n4\n0\n\n\nESTABLECIMIENTO_MUESTRA\n72\n0.64\n5\n102\n0\n73\n0\n\n\nDEPARTAMENTO_MUESTRA\n72\n0.64\n5\n32\n0\n46\n0\n\n\nESTABLECIMIENTO_DIAG\n76\n0.62\n5\n160\n0\n62\n0\n\n\nDEPARTAMENTO_DIAG\n76\n0.62\n5\n37\n0\n39\n0\n\n\nPrueba_VIH\n0\n1.00\n2\n15\n0\n2\n0\n\n\nVIH\n0\n1.00\n8\n15\n0\n3\n0\n\n\nTRATAMIENTO_ANTIRRETROVIRAL\n199\n0.01\n2\n2\n0\n1\n0\n\n\nDiag_rapido\n0\n1.00\n2\n2\n0\n2\n0\n\n\nResultado_diag_rapido\n0\n1.00\n15\n62\n0\n9\n0\n\n\nEMBARAZO\n0\n1.00\n2\n15\n0\n3\n0\n\n\nDIABETES\n0\n1.00\n2\n2\n0\n2\n0\n\n\nCONSUMO_PROB_DROGAS\n0\n1.00\n2\n15\n0\n2\n0\n\n\nENF_RESP_CRONICA\n0\n1.00\n2\n15\n0\n2\n0\n\n\nCOVID\n199\n0.01\n2\n2\n0\n1\n0\n\n\nSE_DECLARA_PUEBLO_INDIGENA\n0\n1.00\n2\n15\n0\n2\n0\n\n\nTABAQUISMO\n0\n1.00\n2\n15\n0\n2\n0\n\n\nALCOHOLISMO\n0\n1.00\n2\n15\n0\n2\n0\n\n\nESTAB_TTO\n35\n0.82\n11\n76\n0\n102\n0\n\n\nRESULTADO_TRATAMIENTO\n0\n1.00\n6\n22\n0\n7\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nFECHA_NACIMIENTO\n0\n1.00\n1934-12-13\n2023-05-05\n1989-07-27\n198\n\n\nFECHA_APERTURA\n0\n1.00\n2021-09-20\n2024-04-18\n2023-07-16\n151\n\n\nFECHA_NOTIFICACION\n0\n1.00\n2023-01-03\n2023-12-27\n2023-07-03\n147\n\n\nFIS\n48\n0.76\n2020-12-20\n2023-12-21\n2023-05-12\n116\n\n\nFECHA_INICIO_SINTOMA\n44\n0.78\n2022-08-15\n2023-12-26\n2023-05-17\n116\n\n\nFECHA_INICIO_TRAT\n43\n0.78\n2023-01-03\n2024-01-08\n2023-07-02\n119\n\n\nFECHA_FIN_TRAT\n142\n0.29\n2023-03-09\n2024-04-05\n2023-10-23\n52\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\nETNIA\n200\n0\nNaN\n:\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nEDAD_DIAGNOSTICO\n0\n1\n37.02\n18.63\n0\n23\n33\n49\n88\n▂▇▅▃▁\n\n\n\n\n\nLa salida completa de skim() separa los resultados por partes. Un resumen de datos inicial, donde vemos la cantidad de filas y columnas con la frecuencia de tipo de variable. Luego le siguen tablas con información descriptiva univariada, donde podemos ver que dependiendo del tipo de variable nos muestra diferentes estadísticos y hasta un mini histograma en el caso de las numéricas."
  },
  {
    "objectID": "primero/clases/06-depuracion.html#dlookr",
    "href": "primero/clases/06-depuracion.html#dlookr",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "dlookr",
    "text": "dlookr\n\n\n\n\n\nEl paquete se define como una “colección de herramientas que permiten el diagnóstico, la exploración y la transformación de datos”.\nEl diagnóstico de datos proporciona información y visualización de valores faltantes, valores atípicos y valores únicos y negativos para ayudarle a comprender la distribución y la calidad de sus datos.\nContiene funciones, compatibles con tidyverse, que nos facilitan ver la calidad de nuestros datos, además de otras que tienen por objetivo la exploración y su transformación.\nEntre estas funciones encontramos:\n\ndiagnose()\nPermite diagnosticar variables del dataframe y devuelve como resultado: el tipo de dato de la variable, la cantidad de valores faltantes, su porcentaje, la cantidad de valores únicos y su tasa (valores únicos/observaciones). Lo observamos en forma de tabla interactiva:\n\nlibrary(dlookr)\n\ndiagnose(datos)\n\n\n\n\n\n\n\nAl ser compatible con tidyverse se puede editar antes o después de la función, por ejemplo si quisiéramos filtrar variables con valores faltantes (de mayor a menor):\n\ndiagnose(datos) |&gt; \n  select(!starts_with(\"unique\")) |&gt; \n  filter(missing_count &gt; 0) |&gt; \n  arrange(desc(missing_count))\n\n# A tibble: 16 × 4\n   variables                   types     missing_count missing_percent\n   &lt;chr&gt;                       &lt;chr&gt;             &lt;int&gt;           &lt;dbl&gt;\n 1 ETNIA                       logical             200           100  \n 2 TRATAMIENTO_ANTIRRETROVIRAL character           199            99.5\n 3 COVID                       character           199            99.5\n 4 MOTIVO_CONSULTA             character           181            90.5\n 5 FECHA_FIN_TRAT              Date                142            71  \n 6 ESTABLECIMIENTO_DIAG        character            76            38  \n 7 DEPARTAMENTO_DIAG           character            76            38  \n 8 ESTABLECIMIENTO_MUESTRA     character            72            36  \n 9 DEPARTAMENTO_MUESTRA        character            72            36  \n10 FIS                         Date                 48            24  \n11 FECHA_INICIO_SINTOMA        Date                 44            22  \n12 FECHA_INICIO_TRAT           Date                 43            21.5\n13 ESTAB_TTO                   character            35            17.5\n14 ESTAB_CLINICA               character            20            10  \n15 DEPTO_CLINICA               character            20            10  \n16 DEPARTAMENTO_RESIDENCIA     character             9             4.5\n\n\n\n\ndiagnose_category()\nAsí como existe diagnose() como una función general, también hay funciones que sirven para el diagnóstico específico por tipo de dato.\ndiagnose_category() lo hace con las variables categóricas, es decir de caracter, de factor y de factor ordenado, mostrando información de cada categoría de cada variable (N, frecuencia, proporción y ranking).\n\ndatos|&gt; \n diagnose_category()\n\n\n\n\n\n\n\n\n\ndiagnose_numeric()\nPara variables numéricas tenemos a diagnose_numeric() que nos brinda estadísticos resumen descriptivos univariados.\n\ndatos|&gt; \n diagnose_numeric()\n\n\n\n\n\n\n\nObservamos que sobre la única variable numérica de datos nos calcula el mínimo, primer cuartil, media, mediana, tercer cuartil, máximo, la cantidad de ceros, la cantidad de números negativos y la cantidad de datos atípicos."
  },
  {
    "objectID": "primero/clases/06-depuracion.html#diagnose_outlier",
    "href": "primero/clases/06-depuracion.html#diagnose_outlier",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "diagnose_outlier()",
    "text": "diagnose_outlier()\nSobre los datos atípicos diagnose_outlier() nos amplía la información:\n\ndatos|&gt; \n diagnose_outlier()\n\n\n\n\n\n\n\nAquí la variable EDAD_DIAGNOSTICO no tiene datos atípicos por lo que el conteo y proporción es de cero, la media de los outlier no existe y la media contando y no contando estos outlier da lo mismo (37,02)"
  },
  {
    "objectID": "primero/clases/06-depuracion.html#plot_outlier",
    "href": "primero/clases/06-depuracion.html#plot_outlier",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "plot_outlier()",
    "text": "plot_outlier()\nAgreguemos algún dato atípico a EDAD_DIAGNOSTICO para poder mostrar este gráfico.\n\ndatos[10, \"EDAD_DIAGNOSTICO\"] &lt;- 105  # cambiamos la edad de la observación 10 \n\n\ndatos |&gt; \n  plot_outlier(EDAD_DIAGNOSTICO) \n\n\n\n\n\n\n\n\nEl gráfico siempre se va a producir si al menos tenemos un dato atípico en la variable. Grafica un boxplot e histograma contando los valores outlier que la variable tenga y otro quitándolos.\n\nOtras funciones del paquete\ndlookr tiene muchas otras funciones, como find_na() y plot_pareto_na() vistas en el documento sobre datos faltantes, o de análisis descriptivo más completo que mostraremos más adelante.\nTambién hay algunas que tienen como objetivo la conversión de datos y/o la imputación de datos ausentes, que no trabajaremos en el curso pero pueden encontrarse en el sitio del desarrollador https://choonghyunryu.github.io/dlookr/index.html"
  },
  {
    "objectID": "primero/clases/06-depuracion.html#depuración-de-datos",
    "href": "primero/clases/06-depuracion.html#depuración-de-datos",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "Depuración de datos",
    "text": "Depuración de datos\n\n\n\n\n\nUna vez finalizado el diagnóstico de datos, se procede a la etapa de depuración, donde se corrigen los errores identificados y se prepara el conjunto de datos para su análisis. La depuración involucra técnicas como la eliminación de valores faltantes, la corrección de errores de entrada, la transformación de variables y el manejo de valores atípicos.\nUn flujo de trabajo modelo partiendo de datos crudos y terminando en datos limpios es el siguiente:\n\n\n\n\n\nDurante este proceso puede haber múltiples situaciones dependiendo de la calidad original de los datos crudos, desde carecer de encabezados o contener tipos de datos incorrectos, pasando por tener que corregir etiquetas de categorías incorrectas, etc.\nLas herramientas de dplyr en tidyverse nos van a facilitar esta tarea que suele ocupar entre un 70 y 80% del tiempo de trabajo cuando analizamos datos."
  },
  {
    "objectID": "primero/clases/06-depuracion.html#gestión-de-duplicados",
    "href": "primero/clases/06-depuracion.html#gestión-de-duplicados",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "Gestión de duplicados",
    "text": "Gestión de duplicados\nUn caso habitual con el que debemos lidiar es el tener observaciones duplicadas, total o parcialmente. Por este motivo, debemos conocer las características de la o las tablas con las que estamos trabajando, es decir, si las observaciones tiene claves unívocas, si estas observaciones se pueden repetir, si la relación es uno a uno o uno a varios cuando hay más de una tabla relacionada, etc.\nEntonces, el primer paso será asegurarnos que los datos cumplen con el criterio que conocemos haciendo una detección de observaciones y/o partes de observaciones (variables clave) que se encuentran duplicadas.\nLuego, hay diferentes tareas que se pueden realizar para gestionar estos datos duplicados, cuando su existencia no es la esperada:\n\nEliminación de duplicados a partir de observaciones únicas.\nRecortar tabla de datos para eliminar duplicados\nMarcar duplicados (conservando duplicados en la tabla)\n\nLa función get_dupes() del paquete janitor es muy útil porque identifica estas repeticiones.\n\nlibrary(janitor)\n\ndatos |&gt; \n  get_dupes(everything())\n\n# A tibble: 0 × 57\n# ℹ 57 variables: SEXO &lt;chr&gt;, FECHA_NACIMIENTO &lt;date&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;, …\n\n\nAplicada sobre el dataframe entero detecta aquellas observaciones que sean iguales en todas sus observaciones. Esto es difícil que pase pero puede suceder cuando por alguna falla técnica el sistema desde donde se obtienen los datos duplica registros completos.\nOtra posibilidad es utilizar la variable que es clave en la tabla de datos o las variables que constituyen una clave combinada.\nPor ejemplo, en este caso, usemos una serie de variables como SEXO, FECHA_NACIMIENTO, ID_PROV_INDEC_RESIDENCIA e ID_DEPTO_INDEC_RESIDENCIA para ver si hay observaciones donde estos datos se repitan.\n\ndatos |&gt; \n  get_dupes(SEXO, FECHA_NACIMIENTO, \n            ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA)\n\n# A tibble: 2 × 57\n  SEXO  FECHA_NACIMIENTO ID_PROV_INDEC_RESIDENCIA ID_DEPTO_INDEC_RESIDENCIA\n  &lt;chr&gt; &lt;date&gt;           &lt;chr&gt;                    &lt;chr&gt;                    \n1 M     1947-06-29       90                       90063                    \n2 M     1947-06-29       90                       90063                    \n# ℹ 53 more variables: dupe_count &lt;int&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, DEPARTAMENTO_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;,\n#   FECHA_NOTIFICACION &lt;date&gt;, MOTIVO_CONSULTA &lt;chr&gt;, …\n\n\nEncontramos dos observaciones que tienen los mismo valores en esta combinación de variables. Un hombre nacido el 29/06/1947 en la provincia de Tucumán, en el departamento Lules.\nSupongamos que no puede existir dos veces la misma persona en la tabla y que, además para confirmar esto tenemos alguna variable más segura como el DNI, por ejemplo.\n\nEliminación de duplicados por observaciones únicas\nPara eliminar filas duplicadas en una tabla de datos podemos utilizar la función distinct() de dplyr.\nLa función tiene un argumento denominado .keep_all que permite valores TRUE o FALSE. Si se iguala a TRUE se mantienen en el resultado todas las variables que son parte de la tabla, aunque estas no estén declaradas dentro del distinct().\nPor defecto, este argumento se encuentra igualado a FALSE.\n\nnrow(datos)\n\n[1] 200\n\ndatos |&gt; \n  distinct(SEXO, FECHA_NACIMIENTO, ID_PROV_INDEC_RESIDENCIA, \n           ID_DEPTO_INDEC_RESIDENCIA, \n           .keep_all = T)\n\n# A tibble: 199 × 56\n   SEXO  FECHA_NACIMIENTO EDAD_DIAGNOSTICO GRUPEDAD PROVINCIA_RESIDENCIA\n   &lt;chr&gt; &lt;date&gt;                      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;               \n 1 M     1948-06-22                     74 70-74    Tierra del Fuego    \n 2 F     1981-06-20                     41 40-44    Buenos Aires        \n 3 F     1989-03-30                     33 30-34    Buenos Aires        \n 4 M     2006-11-17                     16 15-19    Chaco               \n 5 M     1993-06-02                     29 25-29    Jujuy               \n 6 M     1989-04-08                     33 30-34    Buenos Aires        \n 7 F     1977-07-30                     45 45-49    Buenos Aires        \n 8 M     1968-04-09                     54 50-54    Misiones            \n 9 F     2008-01-10                     15 15-19    Chaco               \n10 M     1987-11-27                    105 35-39    Buenos Aires        \n# ℹ 189 more rows\n# ℹ 51 more variables: ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;, …\n\n\nObservamos que las 200 observaciones distinct() nos devuelve 199. Eliminó una de las dos que tenían duplicadas esa serie de variables definidas, pero no podemos controlar cuál de ellas elimina.\n\n\nEliminación de duplicados por recorte de observaciones\nRecortar es similar a filtrar, la diferencia está en que se filtra por condiciones y recortamos por posiciones.\nLa familia de funciones de dplyr que se puede utilizar para recortar es slice_*().\nEstas funciones pueden ser muy útiles si se aplican a un dataframe agrupado porque la operación de recorte se realiza en cada grupo por separado.\nPor ejemplo, podemos usar la FECHA_NOTIFICACION para seleccionar la mas vieja. Esto se hace combinado group_by() y slice_min() (observación con el valor mínimo)\n\ndatos |&gt; \n  get_dupes(SEXO, FECHA_NACIMIENTO, \n             ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA) |&gt; \n  select(SEXO, FECHA_NACIMIENTO, FECHA_NOTIFICACION)\n\n# A tibble: 2 × 3\n  SEXO  FECHA_NACIMIENTO FECHA_NOTIFICACION\n  &lt;chr&gt; &lt;date&gt;           &lt;date&gt;            \n1 M     1947-06-29       2023-03-10        \n2 M     1947-06-29       2023-02-24        \n\ndatos |&gt; \n  group_by(SEXO, FECHA_NACIMIENTO, \n           ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA) |&gt; \n  slice_min(FECHA_NOTIFICACION) |&gt; \n  filter(SEXO == \"M\", FECHA_NACIMIENTO == dmy(\"29/06/1947\")) |&gt; \n  select(SEXO, FECHA_NACIMIENTO, FECHA_NOTIFICACION) |&gt; \n  ungroup()\n\nAdding missing grouping variables: `ID_PROV_INDEC_RESIDENCIA`,\n`ID_DEPTO_INDEC_RESIDENCIA`\n\n\n# A tibble: 1 × 5\n  ID_PROV_INDEC_RESIDENCIA ID_DEPTO_INDEC_RESIDENCIA SEXO  FECHA_NACIMIENTO\n  &lt;chr&gt;                    &lt;chr&gt;                     &lt;chr&gt; &lt;date&gt;          \n1 90                       90063                     M     1947-06-29      \n# ℹ 1 more variable: FECHA_NOTIFICACION &lt;date&gt;\n\n\n\n\nMarcar duplicados\nSi, en cambio, lo que buscamos es mantener a todas las observaciones de la tabla pero marcar aquellos que consideramos duplicados podemos hacer:\n\nRecortar el dataframe original a sólo las filas para el análisis. Guardar los ID de este dataframe reducido en un vector.\nEn el dataframe original, creamos una variable de marca usando una función condicional, basándonos si el ID está presente en el dataframe reducido (vector de ID anterior).\n\nPrimer paso, en esta tabla no existe un ID único por lo que vamos a crear una clave subrogada.\n\ndatos &lt;- datos |&gt; \n  mutate(ID = row_number())\n\nAhora usaremos este ID para crear un vector con los números de las dos observaciones anteriores que están duplicadas.\n\nID_duplicados &lt;- datos |&gt; \n  get_dupes(SEXO, FECHA_NACIMIENTO, \n             ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA) |&gt; \n  pull(ID)\n\nID_duplicados\n\n[1]  44 166\n\n\nFinalmente aplicamos este vector con una función como if_else() para marcar con una X en la variable duplicado.\n\ndatos &lt;- datos |&gt; \n  mutate(duplicado = if_else(ID %in% ID_duplicados, \"X\", NA))\n\nLuego podriamos filtrar los duplicados directamente\n\ndatos |&gt; \n  filter(duplicado == \"X\")\n\n# A tibble: 2 × 58\n  SEXO  FECHA_NACIMIENTO EDAD_DIAGNOSTICO GRUPEDAD PROVINCIA_RESIDENCIA\n  &lt;chr&gt; &lt;date&gt;                      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;               \n1 M     1947-06-29                     75 75-79    Tucumán             \n2 M     1947-06-29                     75 75-79    Tucumán             \n# ℹ 53 more variables: ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;,\n#   FECHA_NOTIFICACION &lt;date&gt;, MOTIVO_CONSULTA &lt;chr&gt;, …"
  },
  {
    "objectID": "primero/clases/06-depuracion.html#datos-ordenados",
    "href": "primero/clases/06-depuracion.html#datos-ordenados",
    "title": "Exploración, depuración y gestión de tablas de datos",
    "section": "Datos ordenados",
    "text": "Datos ordenados\nLas tablas de datos con la que trabajamos dentro de tidyverse deben cumplir con ciertas características de los “datos ordenados” (tidy data).\nLlamamos tidy data cuando:\n\nCada variable está en una columna\nCada observación está en una fila\nCada celda del cruce entre una columna y una fila es un valor\nCada tabla pertenece a una unidad de observación\n\n\n\n\n\n\nA veces las tablas se parecen a esto:\n\n\n\n\n\ncountry\n2010\n2011\n2012\n2013\n\n\n\n\nArgentina\n40374224\n40728738\n41086927\n41446246\n\n\nBrazil\n195210154\n196935134\n198656019\n200361925\n\n\nUruguay\n3371982\n3383486\n3395253\n3407062\n\n\n\n\n\n\n\nCumple con las reglas de “datos ordenados”?\nNo. \nNo lo hace porque lo que vemos como cabecera de columnas en 2010, 2011, etc. son categorías de la variable año (year) y no nombres de variables.\nEn cambio esta tabla, aunque tenga la misma información, si cumple con el formato ordenado.\n\n\n\n\n\ncountry\nyear\npopulation\n\n\n\n\nArgentina\n2010\n40374224\n\n\nArgentina\n2011\n40728738\n\n\nArgentina\n2012\n41086927\n\n\nArgentina\n2013\n41446246\n\n\nBrazil\n2010\n195210154\n\n\nBrazil\n2011\n196935134\n\n\nBrazil\n2012\n198656019\n\n\nBrazil\n2013\n200361925\n\n\nUruguay\n2010\n3371982\n\n\nUruguay\n2011\n3383486\n\n\nUruguay\n2012\n3395253\n\n\nUruguay\n2013\n3407062\n\n\n\n\n\n\n\nGeneralmente los problemas comunes en tabla “desordenadas” de datos son:\n\nUna variable se extiende por varias columnas.\nUna observación está dispersa entre múltiples filas\n\nEl paquete tidyr de tidyverse resuelve estos problemas y mediante sus funciones pivot_ nos permite pivotear las tablas a lo “ancho” o “largo”.\n\nFunción pivot_longer() - Convierte nombres de columnas en valores de una nueva variable.\nFunción pivot_wider() - Convierte valores de una variable en columnas nuevas.\n\nPara pasar de formato ancho a largo, es decir cuando los valores de una variable se extiende por varias columnas, se utilizan como mínimo estos argumentos:\n\ntabla_ancho |&gt; \n  pivot_longer(cols = -paises,        # todas las columnas -paises\n               names_to = \"anio\",     # nombre de la columna de los nombres\n               values_to = \"casos\")   # nombre la columna de los valores\n\n\n\n\n\n\nEl formato inverso, cuando una observación está dispersa entre múltiples filas, sería:\n\ntabla_largo |&gt; \n  pivot_wider(names_from = tipo,    # nombres de los valores de tipo\n              values_from = casos)  # valores de los valores de casos"
  }
]